[{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mapper-system-introduction","dir":"Articles","previous_headings":"","what":"Mapper system introduction","title":"Devel: Customised model components with the bru_mapper system","text":"inlabru latent model component generates effect, given latent state vector. purpose mapper system define link state vectors effect vectors. ordinary model component, named \\(c\\), link can represented matrix-vector product \\[ \\eta_c(u_c) = A_c(\\text{input}) u_c, \\] \\(u_c\\) latent state vector, \\(\\eta_c(u_c)\\) resulting component effect vector, \\(A_c(\\text{input})\\) component model matrix. matrix depends component inputs (covariates, index information, etc) main, group, replicate, weights component definition. wider scope component definitions discussed component vignette. , focus mapper system , basic building blocks used construct built-mappers, finally construct new mappers. -package documentation mapper methods contained four parts: Regular users normally need methods ?bru_mapper sometimes ?bru_mapper_generics. methods ?bru_mapper_methods provides details allows user query mappers use outside context inlabru model definitions. bru_mapper_define() bru_get_mapper() methods needed implementing mapper class.","code":"?bru_mapper # Mapper constructors ?bru_mapper_generics # Generic and default methods ?bru_mapper_methods # Specialised mapper methods ?bru_get_mapper # Mapper extraction methods"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mappers","dir":"Articles","previous_headings":"","what":"Mappers","title":"Devel: Customised model components with the bru_mapper system","text":"main purpose mapper class allow evaluating component effect, given input latent state, calling mapper associated component definition.","code":"ibm_eval(mapper, input, state)"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"basic-mappers","dir":"Articles","previous_headings":"Mappers","what":"Basic mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Basic mappers take covariate vectors matrices input numeric vectors state. Constructors: bru_mapper_const() bru_mapper_linear() bru_mapper_index(n) bru_mapper_factor(values, factor_mapping) bru_mapper_matrix() bru_mapper_harmonics(order, scaling, intercept, interval)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"const","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"const","title":"Devel: Customised model components with the bru_mapper system","text":"const mapper defines mapping empty state vector. used define offset components, \\(\\eta(u)_j = z_j\\), \\(z\\) fixed input vector, indexed \\(j\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"linear","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"linear","title":"Devel: Customised model components with the bru_mapper system","text":"linear mapper defines mapper length 1 state vector. used define ordinary “fixed” covariate effects, linear covariate state variable; \\(\\eta(u)_j = z_j u\\), \\(u\\) state, \\(z\\) input covariate vector.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"index","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"index","title":"Devel: Customised model components with the bru_mapper system","text":"index(n) mapper defines direct mapping length n state variable. used structured unstructured “random effect” component effects; \\(\\eta(u)_j = u_{z_j}\\), \\(u\\) state vector, \\(z\\) input index vector.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"factor","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"factor","title":"Devel: Customised model components with the bru_mapper system","text":"factor(values, factor_mapping) mapper defines direct mapping state vector length equal number factor levels values (factor_mapping = \"full\"), one less (factor_mapping = \"contrast\"). factor level represented dummy 0/1 variable, equivalently, input used label index state vector; \\(\\eta(u)_j = u_{z_j}\\). \"contrast\" case, first factor level removed model, corresponding effect defined zero.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"matrix","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"matrix","title":"Devel: Customised model components with the bru_mapper system","text":"matrix mapper defines direct matrix multiplication pre-computed model matrix \\(A_\\text{input}\\) state vector; \\(\\eta(u) = A_\\text{input} u\\). used e.g. linear model formula input, converted component model matrix handing mapper system.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"harmonics","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"harmonics","title":"Devel: Customised model components with the bru_mapper system","text":"harmonics(order, scaling, intercept, interval) mapper defines sum weighted harmonics real interval \\((L, U)\\), frequency additionally scaled factors determined scale; \\(\\eta(u_j) = \\sum_{k=1}^{1+2p} A_{j,k} u_k\\), \\(A_{j,k}=s_k\\) \\(k=1\\), \\(A_{j,2k}=s_{k+1}\\cos[2\\pi k (z_j - L)/(U-L)]\\) \\(k=1,2,\\dots,p\\), \\(A_{j,2k+1}=s_{k+1}\\sin[2\\pi k (z_j - L)/(U-L)]\\) \\(k=1,2,\\dots,p\\), \\(p=\\)order. intercept TRUE, state vector length \\(1+2p\\). intercept FALSE, first, constant, column removed, state vector length \\(2p\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"transformation-mappers","dir":"Articles","previous_headings":"Mappers","what":"Transformation mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Transformation mappers mappers normally combined mappers, steps sequence transformations, individual transformation mappers. bru_mapper_scale() bru_mapper_aggregate(rescale)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"scale","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"scale","title":"Devel: Customised model components with the bru_mapper system","text":"scale mapper multiplies input vector state vector. used INLA models implement weights component scaling, final stage pipe mapper, see .","code":"mapper <- bru_mapper_scale() ibm_eval(mapper,   input = ...,   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"aggregate","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"aggregate","title":"Devel: Customised model components with the bru_mapper system","text":"aggregate mapper aggregates state vector elements blockwise summation scaling elements weights. can used summation, integration, averaging (rescale=TRUE).","code":"mapper <- bru_mapper_aggregate(rescale = ...) ibm_eval(mapper,   input = list(block = ..., weights = ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"compound-mappers","dir":"Articles","previous_headings":"Mappers","what":"Compound mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Compound mappers define collections chains mappings, can take various forms input. state vector normally numeric vector, can cases list vectors. bru_mapper_collect(mappers, hidden) bru_mapper_multi(mappers) bru_mapper_pipe(mappers)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"collect","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"collect","title":"Devel: Customised model components with the bru_mapper system","text":"collect mapper defines compound mapper Jacobian block-diagonal, block defined separate sub-mapper. hidden = TRUE, can used INLA models user-visible part latent state part internal state, \"bym\" models.","code":"mapper <- bru_mapper_offset(list(name1 = ..., name2 = ..., ...),   hidden = FALSE ) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... ) # If hidden = TRUE, the inla_f=TRUE argument \"hides\" all but the first mapper: ibm_eval(mapper,   input = name1_input,   state = ...,   inla_f = TRUE )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"multi","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"multi","title":"Devel: Customised model components with the bru_mapper system","text":"multi mapper defines compound mapper Jacobian row-wise Kronecker product sub-mapper Jacobians. can used INLA models construct internal mapper main, group, replicate, also user-defined models single rgeneric cgeneric model defined e.g. space-time product domain.","code":"mapper <- bru_mapper_multi(list(name1 = ..., name2 = ..., ...)) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"pipe","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"pipe","title":"Devel: Customised model components with the bru_mapper system","text":"Pipe mappers chain multiple mappers sequence, evaluation result mapper given state vector next mapper.","code":"mapper <- bru_mapper_pipe(list(name1 = ..., name2 = ..., ...)) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"the-core-model-component-mapper","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"The core model component mapper","title":"Devel: Customised model components with the bru_mapper system","text":"model component mappers currently defined pipe mapper containing multi mapper followed scale mapper:","code":"mapper <-   bru_mapper_pipe(     list(       mapper = bru_mapper_multi(list(main = ..., group = ..., replicate = ...)),       scale = bru_mapper_scale()     )   ) ibm_eval(mapper,   input = list(     mapper = list(main = ..., group = ..., replicate = ...),     scale = ...   ),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"object-mappers","dir":"Articles","previous_headings":"Mappers","what":"Object mappers","title":"Devel: Customised model components with the bru_mapper system","text":"object predefined mapper conversion methods, use bru_mapper(object) obtain suitable mapper object. Current predefined object mappers defined objects classes: inla.mesh; Use bru_mapper(object) inla.mesh.1d; Use bru_mapper(object, indexed) details given .","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"model-object-mappers","dir":"Articles","previous_headings":"Mappers","what":"Model object mappers","title":"Devel: Customised model components with the bru_mapper system","text":"inla model objects predefined mappers, use bru_get_mapper(object) Current predefined model object mappers defined models classes: inla.spde; includes inla.spde2.matern() inla.spde2.pcmatern() models. conversion method calls bru_mapper() appropriate way mesh type used model inla.rgeneric; relies rgeneric definition including \"mapper\" callback argument. less invasive method, works rgeneric cgeneric models, define bru_get_mapper() method class, needs include unique class identifier, e.g. add class(object) <- c(\"my_unique_model_class\", class(object)) define register namespace.","code":"bru_get_mapper.my_unique_model_class <- function(model, ...) {   ... }"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"special-mappers","dir":"Articles","previous_headings":"Mappers","what":"Special mappers","title":"Devel: Customised model components with the bru_mapper system","text":"bru_mapper_taylor()","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mapper-methods","dir":"Articles","previous_headings":"","what":"Mapper methods","title":"Devel: Customised model components with the bru_mapper system","text":"example inla_f argument matters bru_mapper_collect class, hidden=TRUE argument used indicate first mapper used INLA::f() inputs, e.g. \"bym2\" models. inla_f=FALSE (default), ibm_n ibm_values methods return total number latent variables, inla_f=TRUE get values needed INLA::f() instead: bru_mapper_multi class, multi argument provides access inner layers multi-mapper: default ibm_inla_subset method determines inla subset comparing full values information ibm_values(mapper, inla_f = FALSE) inla specific values information ibm_values(mapper, inla_f = TRUE), determine logical vector identifying inla values subset. Custom mappers normally need specialise method.","code":"ibm_n(mapper, inla_f, ...) ibm_n_output(mapper, input, ...) ibm_values(mapper, inla_f, ...) ibm_jacobian(mapper, input, state, ...) ibm_eval(mapper, input, state, ...) ibm_names(mapper, ...) ibm_inla_subset(mapper, ...) mapper <- bru_mapper_collect(   list(     a = bru_mapper_index(3),     b = bru_mapper_index(2)   ),   hidden = TRUE ) ibm_n(mapper) #> [1] 5 ibm_values(mapper) #> [1] 1 2 3 4 5 ibm_n(mapper, inla_f = TRUE) #> [1] 3 ibm_values(mapper, inla_f = TRUE) #> [1] 1 2 3 ibm_n(mapper, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, multi = TRUE) #> $a #> [1] 1 2 3 #>  #> $b #> [1] 1 2 ibm_n(mapper, inla_f = TRUE, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, inla_f = TRUE, multi = TRUE) #> $a #> [1] 1 2 3 #>  #> $b #> [1] 1 2 mapper <- bru_mapper_multi(list(   a = bru_mapper_index(3),   b = bru_mapper_index(2) )) ibm_n(mapper) #> [1] 6 ibm_n(mapper, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper) #> [1] 1 2 3 4 5 6 ibm_values(mapper, multi = TRUE) #>   a b #> 1 1 1 #> 2 2 1 #> 3 3 1 #> 4 1 2 #> 5 2 2 #> 6 3 2 ibm_n(mapper, inla_f = TRUE) #> [1] 6 ibm_n(mapper, multi = TRUE, inla_f = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, inla_f = TRUE) #> [1] 1 2 3 4 5 6 ibm_values(mapper, multi = TRUE, inla_f = TRUE) #>   a b #> 1 1 1 #> 2 2 1 #> 3 3 1 #> 4 1 2 #> 5 2 2 #> 6 3 2"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mappers-for-inla-mesh-objects","dir":"Articles","previous_headings":"","what":"Mappers for inla.mesh objects","title":"Devel: Customised model components with the bru_mapper system","text":"component models referenced character label (e.g. \"iid\", \"bym2\", \"rw2\" etc), inlabru construct default mappers, cases replicate default INLA::f() behaviour. inla.mesh inla.mesh.1d classes, default mappers can constructed pre-defined bru_mapper S3 methods. 2d meshes (inla.mesh), 1d meshes (inla.mesh.1d),","code":"bru_mapper(mesh) # If ibm_values() should return mesh$loc (e.g. for \"rw2\" models # with degree=1 meshes) bru_mapper(mesh, indexed = FALSE) # If ibm_values() should return seq_along(mesh$loc) (e.g. for # inla.spde2.pcmatern() models) bru_mapper(mesh, indexed = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"customised-mappers","dir":"Articles","previous_headings":"","what":"Customised mappers","title":"Devel: Customised model components with the bru_mapper system","text":"mapper object store enough information order ibm_* methods work. simplest case customised mapper just attached new class label front S3 class() information existing mapper, obtain class override standard ibm_* method implementations. commonly, one instead start basic list(), might contain existing mapper object, add methods know use information. cases, bru_mapper_define() method used properly set class information: Implementations can avoid define ibm_n ibm_values methods, instead computing storing n, n_inla, values, values_inla mapper object construction: default ibm_n ibm_values methods checks values available, return appropriate values depending inla_f argument. *_inla values requested available, methods fall back non-inla versions. needed information found, default methods give error message. Note: version 2.6.0, ibm_amatrix used instead ibm_jacobian. Version 2.6.0 still supports , default ibm_jacobian method call ibm_amatrix, give deprecation message later, may removed future version.","code":"bru_mapper_define(mapper, new_class) bru_mapper_define(   mapper = list(n = 10, values = 1:10),   new_class = \"my_bru_mapper_class_name\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Devel: Customised model components with the bru_mapper system","text":"Let’s build mapper class bru_mapper_p_quadratic model component takes input covariates values \\(a_{ij}\\), \\(=1,\\dots,m\\) \\(j=1,\\dots,p\\), matrix data.frame evaluates full quadratic expression \\[ \\eta_i = x_0 + \\sum_{j=1}^p a_{ij} x_j +   \\frac{1}{2}\\sum_{j=1}^p\\sum_{k=1}^j \\gamma_{j,k} a_{ij}a_{ik} x_{j,k}, \\] latent component vector \\(\\boldsymbol{x}=[x_0,x_1,\\dots,x_p,x_{1,1},\\dots,x_{p,1},x_{2,2}\\dots,x_{p,p}]\\), \\[ \\gamma_{j,k} = \\begin{cases} 1, & j = k,\\\\ 2, & j > k. \\end{cases} \\] start constructor method. Like bru_mapper_matrix, require user supply vector covariate labels, store character vector. also include min_degree parameter control intercept (min_degree <= 0) linear terms (min_degree <= 1) included model. ibm_n method can compute value \\(n\\) \\(n=1+p+\\frac{p(p+1)}{2}\\): ibm_values, default method sufficient, returning vector \\([1,\\dots,n]\\) \\(n\\) obtained ibm_n(mapper). However, clearer result naming, can use character vector, least INLA f() models allow (option argument bru_mapper_p_quadratic constructor control ): approach ibm_n ibm_values works, wasteful recompute n values information call. Instead can use default method check n values stored mapper object, return . change . method definitions _, can end constructor method like , making subsequent method calls faster: Note order matters, since ibm_values_bru_mapper_p_quadratic function calls ibm_n(mapper). can now define main part mapper interface computes model matrix linking latent variables component effect. ’s required NULL input return \\(0\\)--\\(n\\) matrix. output mapper different size NROW(input), mapper define ibm_n_output(mapper, input, ...) method return output size given input.","code":"bru_mapper_p_quadratic <- function(labels, min_degree = 0, ...) {   if (is.factor(labels)) {     mapper <- list(       labels = levels(labels),       min_degree = min_degree     )   } else {     mapper <- list(       labels = as.character(labels),       min_degree = min_degree     )   }   bru_mapper_define(mapper, new_class = \"bru_mapper_p_quadratic\") } ibm_n.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   (mapper$min_degree <= 0) + (mapper$min_degree <= 1) * p + p * (p + 1) / 2 } ibm_values.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   n <- ibm_n(mapper)   jk <- expand.grid(seq_len(p), seq_len(p))   jk <- jk[jk[, 2] <= jk[, 1], , drop = FALSE]   c(     if (mapper$min_degree <= 0) \"Intercept\" else NULL,     if (mapper$min_degree <= 1) mapper$labels else NULL,     paste0(mapper$labels[jk[, 1]], \":\", mapper$labels[jk[, 2]])   ) } bru_mapper_p_quadratic <- function(labels, min_degree = 0, ...) {   ...   mapper <- bru_mapper_define(mapper, new_class = \"bru_mapper_p_quadratic\")   mapper$n <- ibm_n_bru_mapper_p_quadratic(mapper)   mapper$values <- ibm_values_bru_mapper_p_quadratic(mapper)   mapper } ibm_jacobian.bru_mapper_p_quadratic <- function(mapper, input, ...) {   if (is.null(input)) {     return(Matrix::Matrix(0, 0, ibm_n(mapper)))   }   p <- length(mapper$labels)   n <- ibm_n(mapper)   N <- NROW(input)   A <- list()   in_ <- as(input, \"Matrix\")   idx <- 0   if (mapper$min_degree <= 0) {     idx <- idx + 1     A[[idx]] <- Matrix::Matrix(1, N)   }   if (mapper$min_degree <= 1) {     idx <- idx + 1     A[[idx]] <- in_   }   for (k in seq_len(p)) {     idx <- idx + 1     A[[idx]] <- in_[, seq(k, p, by = 1), drop = FALSE] * in_[, k]     A[[idx]][, k] <- A[[idx]][, k] / 2   }   A <- do.call(cbind, A)   colnames(A) <- as.character(ibm_values(mapper))   A }"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"basic-component-features","dir":"Articles","previous_headings":"","what":"Basic component features","title":"Defining model components","text":"Model components defined using formula syntax similar R-INLA differences. basic syntax my_component_name user-chosen label model component. label used model summaries, label relevant parts fitted model object, access model components sampling model using generate() predict(). main argument defines input data component. example, intercept-like component vector ones input. linear effect covariate vector covariate values input. 2-dimensional SPDE effect takes 2-column matrix coordinate locations input. argument can general R expression, details . main argument doesn’t need named. arguments normally named, avoid confusion. type model component specified using model component, (see ?component, ?INLA::inla.list.models()$latent). component type associated bru_mapper method takes main input constructs component design matrix. Users can also specify mapper methods (see ?bru_mapper). syntax replaces INLA::f() function disadvantage clear separation name covariate label effect, user often substantial amount pre-processing data construct relevant inputs. documentation defining model components can viewed ?component. rest vignette goes detail defining model components highlights advantages syntax.","code":"~ my_component_name(   main = ...,   model = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"what-is-a-component-design-matrix","dir":"Articles","previous_headings":"","what":"What is a component design matrix?","title":"Defining model components","text":"linear additive predictor latent Gaussian model can written \\[ \\begin{equation} \\eta(u)_i = u_0 + \\sum_{k=1}^K a_{ik} u_{ik} , \\end{equation} \\] \\(u\\) multivariate Gaussian vector, \\(a_k\\) input information covariates weights random effects \\(= 1, \\ldots, n\\). can also written \\(\\eta(u) = Au\\), \\(\\) model design matrix \\(\\)-th row \\(\\left[1, a_{i1}, \\ldots, a_{iK}\\right]\\). can also conceptally think predictor sum \\(D\\) model components, partition \\(= \\left[^{(1)} \\cdots ^{(D)}\\right]\\), component associated component design matrix \\(^{(d)}\\). example, component intercept parameter, \\(^{(d)} = \\left[1, \\ldots, 1\\right]^\\intercal\\). component linear effect covariate \\(z\\) \\(^{(d)} = \\left[z_1, \\ldots, z_n\\right]^\\intercal\\). complicated effects, SPDE models, component design matrix maps latent Gaussian parameters predictor (also known “projector” matrix context). construction \\(^{(d)}\\) handled automatically bru_mapper methods, define general (linear) component effects \\(\\eta^{(d)}(u^{(d)}) = ^{(d)} u^{(d)}\\). linear predictor defined \\[ \\eta(u^{(1)},\\dots,u^{(D)}) = \\sum_{d=1}^D \\eta^{(d)}(u^{(d)}) = \\sum_{d=1}^D ^{(d)} u^{(d)} . \\] Non-linear predictors defined R expressions component label denotes corresponding component effect.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"mapper-methods","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Mapper methods","title":"Defining model components","text":"component type associated method converting information given component definition component design matrix. full model design matrix used internally call INLA::inla() fit model. advantage specifying mapper methods supports automatic ‘stack building’. key feature inlabru full model stack constructed automatically component definitions. building blocks stack built using bru_mapper methods.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"mapper-example-2d-spde","dir":"Articles","previous_headings":"What is a component design matrix? > Mapper methods","what":"Mapper example: 2D SPDE","title":"Defining model components","text":"mapper 2D SPDE effect takes input 2-column matrix coordinates represent locations evaluate effect. parameters SPDE component defined mesh nodes may locations effect evaluated. appropriate weights required evaluate effect observation locations can constructed using INLA::inla.spde.make.(). mapper model component takes information component definition, case minimum information required SPDE model object, 2-column matrix main evaluated . mapper calls INLA::inla.spde.make.() appropriate arguments extracted information. (NOTE: Deliberately going huge detail ; bru_mapper vignette details.)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"defining-main-group-and-replicate-","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Defining main, group, and replicate.","title":"Defining model components","text":"arguments main, group, replicate can take general R expression input. expression evaluated environment consists named variables data (note: sp objects includes column names @coords slot well columns @data). names found data global environment searched objects name. example, suppose data columns named x y, 2D SPDE model component specified expression cbind(x,y) internally evaluated environment contains columns data, includes variables x y. full data object can accessed using .data. key-word. equivalent way define component keyword allows code written works arbitrarily named input data, rather hardcoding specific name dataset may change future. objects required evaluate R expression found data, global environment searched. allows users access objects global environment, data-structures may different dimension response data. avoids need pre-process everything single data.frame. functionality allowing general R expressions can used extend types data can passed bru(), like() lgcp() functions. basis support spatial data structures sp objects, also experimental support allow users pass data list. inlabru thus readily extendible, given appropriate functions extract relevant information component, associated mappers convert information component design matrix. addition three main inputs, optional weights argument also takes R expression, result used scale component. can used spatially varying coefficient models, weights argument provides covariate values.","code":"~ my_spde_effect(   cbind(x, y),   model = spde_model ) get_xy <- function(df) {   cbind(df$x, df$y) } ~ my_spde_effect(   get_xy(.data.),   model = spde_model )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"inlabru-specific-component-types","dir":"Articles","previous_headings":"What is a component design matrix?","what":"inlabru-specific component types","title":"Defining model components","text":"addition majority latent models can defined using INLA::f() function (see INLA::inla.list.models()$latent)), inlabru also following models: 'linear', 'fixed', 'offset', 'factor_full' 'factor_contrast').","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"shortcuts","dir":"Articles","previous_headings":"","what":"Shortcuts","title":"Defining model components","text":"shortcuts defining model components. Parameters predictor evaluations (intercept-like parameters). Using covariate stored sp Spatial* terra SpatRaster object. Defining linear effects using lm-style syntax. Behaviour main, group replicate function given arguments.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"intercept-like-components","dir":"Articles","previous_headings":"Shortcuts","what":"Intercept-like components","title":"Defining model components","text":"syntax can used shortcut n length predictor vector. Note shortcut makes assumption approriate length predictor. many models can easily deduced inspecting input data, always case, example response covariate data different dimensions joint likelihood models shared components.","code":"~ my_intercept(1) ~ my_intercept(   main = rep(1, n),   model = \"linear\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"sp-covariates","dir":"Articles","previous_headings":"Shortcuts","what":"sp covariates","title":"Defining model components","text":"main, group, replicate, name Spatial* SpatRaster object stored global R environment, inlabru attempts something intelligent extracting covariate information locations data passed bru() like(). requires data SpatialPoints* sf object. Spatial* inputs, inlabru applying sp::coordinates() data extracting covariate information using sp::(). shorcut internally calls eval_spatial() almost equivalent Note requires a_spatial_object stored global R environment (environment associated model definition code) findable expression internally evaluated inlabru. Also note get_sp_covariate function extracts first column sp object evaluation. general situations, one can either specify optional main_layer argument extract another named indexed column, directly use main = eval_spatial(a_spatial_object, .data., layer = some_layer). Note assumes coordinates() applied input data sensible thing , might case models! example, input data SpatialPolygonsDataFrame coordinates() returns centroid polygon. specific input type support developed, support sp gradually deprecated favour sf terra, special cases may given precise meaning.","code":"~ my_sp_effect(   main = a_spatial_object,   model = \"linear\" ) get_sp_covariate <- function(df) {   locs <- coordinates(df)   over(locs, an_sp_object)[, 1] }  ~ my_sp_effect(   main = get_sp_covariate(.data.),   model = \"linear\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"lm-style-syntax","dir":"Articles","previous_headings":"Shortcuts","what":"lm-style syntax","title":"Defining model components","text":"Since inlabru version 2.5.0, feature added allow users specify linear fixed effects using formula input. uses model = 'fixed' component type. syntax data columns named x1, x2, x3, x4. case, inlabru creates design matrix component running allows users define interactions concise way, utilising functionality already supported MatrixModels package. formula interpreted conventional way, x1:x2 interaction covariates x1 x2, including individual fixed effects, x3:x4 interaction x3 x4 inclusive individual fixed effects x3 x4. Note implementation technical reasons, estimated parameters appear 'summary.random' instead normal 'summary.fixed' part inla/bru output object. alternative using shortcut user define name individual components term formula.","code":"~ my_fixed_effects(   main = ~ x1:x2 + x3 * x4,   model = \"fixed\" ) MatrixModels::model.Matrix(~ x1:x2 + x3 * x4, .data.)"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"a-function-given-with-no-arguments","dir":"Articles","previous_headings":"Shortcuts","what":"A function given with no arguments","title":"Defining model components","text":"main, group, replicate given function covariates, function applied data. example, equivalent ","code":"~ a_component(   main = a_function,   model = ... ) ~ a_component(   main = a_function(.data.),   model = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"non-linear-predictors","dir":"Articles","previous_headings":"Shortcuts","what":"Non-linear predictors","title":"Defining model components","text":"inlabru supports non-linear predictors, \\(\\tilde{\\eta}(u,v)\\) non-linear function \\(\\eta_u\\) \\(\\eta_v\\). important note mapping component effect vector \\(\\eta_u=^{(u)} u\\) happens non-linear function applied. , example, \\(\\tilde{\\eta}(u,v) = \\exp(\\eta_u + \\eta_v)\\) evaluated \\(\\exp(^{(u)} u + ^{(v)} v)\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"a-small-toy-problem","dir":"Articles","previous_headings":"","what":"A small toy problem","title":"Nonlinear model approximation","text":"Hierarchical model: \\[ \\begin{aligned} \\lambda &\\sim \\mathsf{Exp}(\\gamma) \\\\ (y_i|\\lambda) &\\sim \\mathsf{Po}(\\lambda), \\text{ independent across $=1,\\dots,n$} \\end{aligned} \\] \\(\\overline{y}=\\frac{1}{n}\\sum_{=1}^n y_i\\), posterior density \\[ \\begin{aligned} p(\\lambda | \\{y_i\\}) &\\propto p(\\lambda, y_1,\\dots,y_n) \\\\ &\\propto \\exp(-\\gamma\\lambda) \\exp(-n\\lambda) \\lambda^{n\\overline{y}} \\\\ &= \\exp\\{-(\\gamma+n)\\lambda\\} \\lambda^{n\\overline{y}}, \\end{aligned} \\] density \\(\\mathsf{Ga}(\\alpha = 1+n\\overline{y}, \\beta = \\gamma+n)\\) distribution.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"latent-gaussian-predictor-version","dir":"Articles","previous_headings":"","what":"Latent Gaussian predictor version","title":"Nonlinear model approximation","text":"Introducing latent Gaussian variable \\(u\\sim\\mathsf{N}(0,1)\\), model can reformulated \\[ \\begin{aligned} \\lambda(u) &=-\\ln\\{1-\\Phi(u)\\}/\\gamma \\\\ (y_i|u) &\\sim \\mathsf{Po}(\\lambda(u)) \\end{aligned} \\] need derivatives \\(\\lambda\\) respect \\(u\\): \\[ \\begin{aligned} \\frac{\\partial\\lambda(u)}{\\partial u} &= \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)}   = \\lambda'(u) \\\\ \\frac{\\partial^2\\lambda(u)}{\\partial u^2} &= - \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)} \\left( u + \\frac{\\phi(u)}{1-\\Phi(u)} \\right) = -\\lambda'(u)\\left\\{u-\\gamma\\lambda'(u)\\right\\} \\\\ \\frac{\\partial\\ln\\lambda(u)}{\\partial u} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial\\lambda(u)}{\\partial u}   =\\frac{1}{-\\ln\\{1-\\Phi(u)\\}} \\frac{\\phi(u)}{1-\\Phi(u)}   = \\frac{\\lambda'(u)}{\\lambda(u)} \\\\ \\frac{\\partial^2\\ln\\lambda(u)}{\\partial u^2} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial^2\\lambda(u)}{\\partial u^2}   -\\frac{1}{\\lambda(u)^2} \\left(\\frac{\\partial\\lambda(u)}{\\partial u}\\right)^2   = \\frac{-\\lambda'(u)\\{u - \\gamma\\lambda'(u)\\}}{\\lambda(u)}   - \\frac{\\lambda'(u)^2}{\\lambda(u)^2}\\\\   &= -\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{   u - \\gamma\\lambda'(u) +\\frac{\\lambda'(u)}{\\lambda(u)}   \\right\\} \\end{aligned} \\]","code":"lambda <- function(u, gamma) {   -pnorm(u, lower.tail = FALSE, log.p = TRUE) / gamma } lambda_inv <- function(lambda, gamma) {   qnorm(-lambda * gamma, lower.tail = FALSE, log.p = TRUE) } D1lambda <- function(u, gamma) {   exp(dnorm(u, log = TRUE) - pnorm(u, lower.tail = FALSE, log.p = TRUE)) / gamma } D2lambda <- function(u, gamma) {   D1L <- D1lambda(u, gamma)   -D1L * (u - gamma * D1L) } D1log_lambda <- function(u, gamma) {   D1lambda(u, gamma) / lambda(u, gamma) } D2log_lambda <- function(u, gamma) {   D1logL <- D1log_lambda(u, gamma)   -D1logL * (u - gamma * D1lambda(u, gamma = gamma) + D1logL) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"latent-gaussian-posterior-approximations","dir":"Articles","previous_headings":"","what":"Latent Gaussian posterior approximations","title":"Nonlinear model approximation","text":"basic approximation posterior distribution \\(\\lambda\\) given \\(y\\) can defined deterministic transformation Gaussian distribution obtained 2nd order Taylor approximation \\(\\ln p(u|\\{y_i\\})\\) posterior mode \\(u_0\\) \\(p(u|\\{y_i\\})\\). needed derivatives \\[ \\begin{aligned} \\frac{\\partial\\ln p(u|\\{y_i\\})}{\\partial u} &= \\frac{\\partial\\ln\\phi(u)}{\\partial u} - n\\lambda'(u) + n\\overline{y}\\frac{\\lambda'(u)}{\\lambda(u)} = -u + n\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ \\overline{y} - \\lambda(u) \\right\\} \\\\ \\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2} &= -1 - n \\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ u - \\gamma\\lambda'(u) + \\frac{\\lambda'(u)}{\\lambda(u)} \\right\\} \\left\\{ \\overline{y} - \\lambda(u) \\right\\} - n \\frac{\\lambda'(u)^2}{\\lambda(u)} \\end{aligned} \\] mode \\(u_0\\), first order derivative zero, \\[ \\begin{aligned} \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - \\left\\{ u_0 - \\gamma\\lambda'(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\right\\} u_0 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned} \\] quadratic approximation log-posterior density mode \\(u_0\\) \\[ \\ln \\breve{p}(u|\\{y_i\\}) = \\text{const} - \\frac{(u-u_0)^2}{2} \\left[ - \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} \\right] \\] inlabru, approximation first linearises \\(\\ln \\lambda(u)\\) \\(u_0\\) applying Taylor approximation \\(\\ln p(u|\\{y_i\\})\\). linearised log-predictor \\[ \\ln \\overline{\\lambda}(u) = \\ln \\lambda(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)}(u - u_0) \\] \\[ \\overline{\\lambda}'(u) = \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\overline{\\lambda}(u) \\] second order derivative linearised log-posterior density \\[ \\begin{aligned} \\left.\\frac{\\partial^2\\ln \\overline{p}(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned} \\]","code":"log_p <- function(u, y, gamma) {   L <- lambda(u, gamma)   n <- length(y)   dnorm(u, log = TRUE) - n * L + n * mean(y) * log(L) - sum(lgamma(y + 1)) } D1log_p <- function(u, y, gamma) {   n <- length(y)   -u + n * D1log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) } D2log_p <- function(u, y, gamma) {   n <- length(y)   -1 +     n * D2log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) -     n * D1log_lambda(u, gamma) * D1lambda(u, gamma) } g <- 1 y <- c(0, 1, 2) y <- c(0, 0, 0, 0, 0) y <- rpois(5, 5) mu_quad <- uniroot(   D1log_p,   lambda_inv((1 + sum(y)) / (g + length(y)) * c(1 / 10, 10), gamma = g),   y = y, gamma = g )$root sd_quad <- (-D2log_p(mu_quad, y = y, gamma = g))^-0.5 sd_lin <- (1 + length(y) * D1log_lambda(mu_quad, gamma = g)^2 * lambda(mu_quad, gamma = g))^-0.5 lambda0 <- lambda(mu_quad, gamma = g)"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"posterior-densities","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior densities","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(lambda_inv(x, gamma = g), y = y, gamma = g)) /         D1lambda(lambda_inv(x, gamma = g), gamma = g) / (           exp(log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) /             D1lambda(lambda_inv(lambda0, gamma = g), gamma = g)         ) *         dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)     },     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = (1 + sum(y)) / (g + length(y)),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(x, y = y, gamma = g) -         log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) *         (dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y)) *           D1lambda(lambda_inv(lambda0, gamma = g), gamma = g))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y)) *         D1lambda(x, gamma = g)     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),     gamma = g   ), lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(lambda0, gamma = g), lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(mean(y), gamma = g), lty = \"Plain mean\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"posterior-cdfs","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior CDFs","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"CDF\") +   geom_function(     fun = pgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin)     },     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = (1 + sum(y)) / (g + length(y)),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"CDF\") +   geom_function(     fun = function(x) {       pgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),       gamma = g     ),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(     xintercept = lambda_inv(lambda0, gamma = g),     lty = \"Bayes mode\"   )) +   geom_vline(mapping = aes(     xintercept = lambda_inv(mean(y), gamma = g),     lty = \"Plain mean\"   ))"},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"the-inla-method-for-linear-predictors","dir":"Articles","previous_headings":"","what":"The INLA method for linear predictors","title":"Iterative linearised INLA method","text":"INLA method used compute fast approximative posterior distribution Bayesian generalised additive models. hierarchical structure model latent Gaussian components \\(\\boldsymbol{u}\\), covariance parameters \\(\\boldsymbol{\\theta}\\), measured response variables \\(\\boldsymbol{y}\\), can written \\[ \\begin{aligned} \\boldsymbol{\\theta} &\\sim p(\\boldsymbol{\\theta}) \\\\ \\boldsymbol{u}|\\boldsymbol{\\theta} &\\sim \\mathcal{N}\\!\\left(\\boldsymbol{\\mu}_u, \\boldsymbol{Q}(\\boldsymbol{\\theta})^{-1}\\right) \\\\ \\boldsymbol{\\eta}(\\boldsymbol{u}) &= \\boldsymbol{}\\boldsymbol{u} \\\\ \\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta} & \\sim p(\\boldsymbol{y}|\\boldsymbol{\\eta}(\\boldsymbol{u}),\\boldsymbol{\\theta}) \\end{aligned} \\] typically linear predictor element, \\(\\eta_i(\\boldsymbol{u})\\), linked location parameter distribution observation \\(y_i\\), \\(\\), via (non-linear) link function \\(g^{-1}(\\cdot)\\). R-INLA implementation, observations assumed conditionally independent, given \\(\\boldsymbol{\\eta}\\) \\(\\boldsymbol{\\theta}\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"approximate-inla-for-non-linear-predictors","dir":"Articles","previous_headings":"","what":"Approximate INLA for non-linear predictors","title":"Iterative linearised INLA method","text":"premise inlabru method non-linear predictors build existing implementation, add linearisation step. properties resulting approximation depend nature non-linearity. Let \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\) non-linear predictor, .e. deterministic function \\(\\boldsymbol{u}\\), \\[ \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}) = \\textsf{fcn} (\\boldsymbol{u}), \\] let \\(\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\) 1st order Taylor approximation \\(\\boldsymbol{u}_0\\), \\[ \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}) = \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) + \\boldsymbol{B}(\\boldsymbol{u} - \\boldsymbol{u}_0) = \\left[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) - \\boldsymbol{B}\\boldsymbol{u}_0\\right] + \\boldsymbol{B}\\boldsymbol{u} , \\] \\(\\boldsymbol{B}\\) derivative matrix non-linear predictor, evaluated \\(\\boldsymbol{u}_0\\). Hence, define \\[ \\begin{aligned} \\boldsymbol{y} | \\boldsymbol{u}, {\\boldsymbol{\\theta}} &\\overset{d}{=} \\boldsymbol{y} | \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}), {\\boldsymbol{\\theta}} \\\\ &\\sim p (\\boldsymbol{y} | g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})], {\\boldsymbol{\\theta}})\\\\ \\end{aligned} \\] non-linear observation model \\(p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta})\\) approximated replacing non-linear predictor linearisation, linearised model defined \\[ \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|g^{-1}[\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) \\approx p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) \\] non-linear model posterior factorised \\[ \\widetilde{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\widetilde{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}), \\] linear model approximation factorised \\[ \\overline{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}). \\]","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"fixed-point-iteration","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors","what":"Fixed point iteration","title":"Iterative linearised INLA method","text":"remaining step approximation choose linearisation point \\(\\boldsymbol{u}_*\\). given linearisation point \\(\\boldsymbol{v}\\), INLA compute posterior mode \\(\\boldsymbol{\\theta}\\), \\[ \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} \\overline{p}_\\boldsymbol{v} ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ), \\] joint conditional posterior mode \\(\\boldsymbol{u}\\), \\[ \\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} \\overline{p}_\\boldsymbol{v} ( \\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} ) . \\] Define Bayesian estimation functional1 \\[ f(\\overline{p}_{\\boldsymbol{v}}) = (\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}}) \\] let \\(f(p)=(\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}})\\) denote corresponding posterior modes true posterior distribution, \\[ \\begin{aligned}     \\widehat{{\\boldsymbol{\\theta}}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} p ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ), \\\\     \\widehat{\\boldsymbol{u}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{{\\boldsymbol{\\theta}}}). \\end{aligned} \\] fixed point \\((\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*})\\) ideally close \\((\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}})\\), .e. close true marginal/conditional posterior mode. can achieve conditional latent mode, \\(\\boldsymbol{u}_*=\\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*})\\). therefore seek latent vector \\(\\boldsymbol{u}_*\\) generates fixed point functional, \\((\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*})\\). One key fixed point iteration observation model linked \\(\\boldsymbol{u}\\) non-linear predictor \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})\\), since leads simplified line search method . Let \\(\\boldsymbol{u}_0\\) initial linearisation point latent variables obtained initial INLA call. Iterate following steps \\(k=0,1,2,...\\) Compute predictor linearisation \\(\\boldsymbol{u}_0\\). Compute linearised INLA posterior \\(\\overline{p}_{\\boldsymbol{u}_0}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\). Let \\((\\boldsymbol{\\theta}_1,\\boldsymbol{u}_1)=(\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_0},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{u}_0})=f(\\overline{p}_{\\boldsymbol{u}_0})\\) initial candidate new linearisation point. Let \\(\\boldsymbol{v}_\\alpha=(1-\\alpha)\\boldsymbol{u}_1+\\alpha\\boldsymbol{u}_0\\), find value \\(\\alpha\\) minimises \\(\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\|\\). Set new linearisation point \\(\\boldsymbol{u}_0\\) equal \\(\\boldsymbol{v}_\\alpha\\) repeat step 1, unless iteration converged given tolerance. potential improvement step 4 might also take account prior distribution \\(\\boldsymbol{u}\\) minimisation penalty, avoid moving indicated full likelihood optimisation.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"line-search","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors > Fixed point iteration","what":"Line search","title":"Iterative linearised INLA method","text":"step 4, ideally want \\(\\alpha\\) \\[ \\mathop{\\mathrm{arg\\,max}}_{\\alpha} \\left[\\ln p(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)\\right]_{\\boldsymbol{u}=\\boldsymbol{v}_\\alpha}. \\] However, since requires access internal likelihood prior density evaluation code, instead use simpler alternative. consider norms form \\(\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\|\\) depend nonlinear linearised predictor expressions, known quantities, given \\(\\boldsymbol{u}_0\\), current INLA estimate component wise predictor variances. Let \\(\\sigma_i^2 = \\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}))\\) current estimate posterior variance predictor element \\(\\). define inner product space predictor vectors \\[ \\langle \\boldsymbol{},\\boldsymbol{b} \\rangle_V = \\sum_i \\frac{a_i b_i}{\\sigma_i^2} . \\] squared norm difference predictor vectors \\(\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)\\) \\(\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\),respect inner product, defined \\[ \\| \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\|^2_V = \\sum_i \\frac{|\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{v}_\\alpha)-\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}_1)|^2}{\\sigma_i^2} . \\] Using norm target loss function line search avoids many potentially expensive evaluations true posterior conditional log-density. evaluate \\(\\widetilde{\\boldsymbol{\\eta}}_1=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\) make use linearised predictor information. Let \\(\\widetilde{\\boldsymbol{\\eta}}_\\alpha=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)\\) \\(\\overline{\\boldsymbol{\\eta}}_\\alpha=\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)=(1-\\alpha)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0)+\\alpha\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\). words, \\(\\alpha=0\\) corresponds previous linear predictor, \\(\\alpha=1\\) current estimate INLA. exact line search minimise \\(\\|\\widetilde{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|\\). Instead, define quadratic approximation non-linear predictor function \\(\\alpha\\), \\[ \\breve{\\boldsymbol{\\eta}}_\\alpha = \\overline{\\boldsymbol{\\eta}}_\\alpha + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1) \\] minimise quartic polynomial \\(\\alpha\\), \\[ \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1) \\|^2 . \\end{aligned} \\] initial expansion contraction steps carried , leading initial guess \\(\\alpha=\\gamma^k\\), \\(\\gamma>1\\) scaling factor (see ?bru_options, bru_method$factor) \\(k\\) (signed) number expansions contractions, quadratic expression replaced \\[ \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\frac{\\alpha^2}{\\gamma^{2k}} (\\widetilde{\\boldsymbol{\\eta}}_{\\gamma^k} - \\overline{\\boldsymbol{\\eta}}_{\\gamma^k}) \\|^2 , \\end{aligned} \\] minimised interval \\(\\alpha\\[\\gamma^{k-1},\\gamma^{k+1}]\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"posterior-non-linearity-checks","dir":"Articles","previous_headings":"","what":"Posterior non-linearity checks","title":"Iterative linearised INLA method","text":"Whereas inlabru optimisation method leads estimate \\(\\| \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}_*) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*)\\|=0\\) specific \\(\\boldsymbol{u}_*\\), overall posterior approximation accuracy depends degree nonlinearity vicinity \\(\\boldsymbol{u}_*\\). two main options evaluating nonlinearity, using sampling approximate posterior distribution. first option \\[ \\begin{aligned} \\sum_i \\frac{E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}\\left[ |\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})-\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})|^2\\right]}{\\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}))} , \\end{aligned} \\] posterior expectation component-wise variance-normalised squared deviation non-linear linearised predictor. Note normalising variance includes variability induced posterior uncertainty \\(\\boldsymbol{\\theta}\\), whereas \\(\\|\\cdot\\|_V\\) norm used line search used posterior mode. Another option \\[ E_{(\\boldsymbol{u},\\boldsymbol{\\theta})\\sim \\overline{p}(\\boldsymbol{u},\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] = E_{\\boldsymbol{\\theta}\\sim \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left\\{ E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] \\right\\} \\] Kullback–Leibler divergence conditional posterior densities, \\(\\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right)\\), integrated approximate posterior distribution \\(\\boldsymbol{\\theta}\\). Implementing require access likelihood prior distribution details. next section explores detail.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"accuracy","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Accuracy","title":"Iterative linearised INLA method","text":"wish assess accurate approximation . Thus, compare \\(\\widetilde{p}(\\boldsymbol{u} | \\boldsymbol{y}, \\boldsymbol{\\theta} )\\) \\(\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},\\boldsymbol{\\theta})\\). Bayes’ theorem, \\[ \\begin{aligned}     p(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}}) &= \\frac{p(\\boldsymbol{u},\\boldsymbol{y}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})} \\\\     &= \\frac{p(\\boldsymbol{y}|\\boldsymbol{u},{\\boldsymbol{\\theta}}) p(\\boldsymbol{u}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})}, \\end{aligned} \\] \\(p(\\boldsymbol{u}|\\boldsymbol{\\theta})\\) Gaussian density \\(p(\\boldsymbol{y}|\\boldsymbol{\\theta})\\) scaling factor doesn’t depend \\(\\boldsymbol{u}\\). can therefore focus behaviour \\(\\ln p(\\boldsymbol{y}|\\boldsymbol{\\theta},\\boldsymbol{u})\\) exact linearised observation models. Recall observation likelihood depends \\(\\boldsymbol{u}\\) \\(\\boldsymbol{\\eta}\\). Using Taylor expansion respect \\(\\boldsymbol{\\eta}\\) \\(\\boldsymbol{\\eta}^*=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*)\\), \\[ \\begin{aligned}     \\ln p(\\boldsymbol{y}|\\boldsymbol{\\eta},\\boldsymbol{\\theta}) &=     \\ln p (\\boldsymbol{y}|{\\boldsymbol{\\theta}},\\boldsymbol{\\eta}^*))  \\\\     &\\qquad + \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) \\\\     &\\qquad + \\frac{1}{2}\\sum_{,j} \\left.\\frac{\\partial^2}{\\partial\\eta_i\\partial\\eta_j} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) (\\eta_j - \\eta^*_j) + \\mathcal{O}(\\|\\boldsymbol{\\eta}-\\boldsymbol{\\eta}^*\\|^3), \\end{aligned} \\] Similarly, component \\(\\widetilde{\\boldsymbol{\\eta}}\\), \\[ \\begin{aligned} \\widetilde{\\eta}_i(\\boldsymbol{u}) &= \\eta^*_i +\\left[\\left.\\nabla_{u}\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right]^\\top (\\boldsymbol{u} - \\boldsymbol{u}_*) \\\\&\\quad +\\frac{1}{2}(\\boldsymbol{u} - \\boldsymbol{u}_*)^\\top\\left[\\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right] (\\boldsymbol{u} - \\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}^*\\|^3) \\\\&= \\eta_i^* + b_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\\\&= \\overline{\\eta}_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned} \\] \\(\\nabla_u\\nabla_u^\\top\\) Hessian respect \\(\\boldsymbol{u}\\), \\(b_i\\) linear \\(\\boldsymbol{u}\\), \\(h_i\\) quadratic \\(\\boldsymbol{u}\\). Combining two expansions taking difference full linearised log-likelihoods, get \\[ \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned} \\] Note log-likelihood Hessian difference contribution involves third order \\(\\boldsymbol{u}\\) terms higher, expression includes terms second order. Let \\[ g_i^*=\\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*} \\] \\[ \\boldsymbol{H}^*_i = \\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*} . \\] form sum products, \\(\\boldsymbol{G}=\\sum_i g_i^*\\boldsymbol{H}_i^*\\). \\[ \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\frac{1}{2}     \\sum_i g_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{H}_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3)     \\\\&=     \\frac{1}{2}     (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{G} (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3). \\end{aligned} \\] \\(\\boldsymbol{m}=\\mathsf{E}_\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})\\) \\(\\boldsymbol{Q}^{-1}=\\mathsf{Cov}_\\overline{p}(\\boldsymbol{u},\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})\\), obtain \\[ \\begin{aligned} \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right] &\\approx     \\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}\\nabla_{\\boldsymbol{u}}^\\top  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right] &\\approx     \\boldsymbol{G} ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[    \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right] &\\approx     \\frac{1}{2}     \\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1}) + \\frac{1}{2} (\\boldsymbol{m}-\\boldsymbol{u}_*)\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top . \\end{aligned} \\] \\(\\boldsymbol{\\theta}\\) configuration INLA output, can extract \\(\\boldsymbol{m}\\) sparse precision matrix \\(\\boldsymbol{Q}\\) Gaussian approximation. non-sparsity structure \\(\\boldsymbol{G}\\) contained non-sparsity \\(\\boldsymbol{Q}\\), allows use Takahashi recursion (inla.qinv(Q)) compute corresponding \\(\\boldsymbol{Q}^{-1}\\) values needed evaluate trace \\(\\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1})\\). Thus, implement numerical approximation error analysis needs special access log-likelihood derivatives \\(g_i^*\\), \\(H_i^*\\) can principle evaluated numerically. given \\(\\boldsymbol{\\theta}\\), \\[ \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &= E_{\\overline{p}}\\left[\\ln\\frac{\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}\\right] \\\\&= E_{\\overline{p}}\\left[ \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})} \\right] - \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})} . \\end{aligned} \\] first term approximated . second term can also approximated using derived quantities (continued…). Summary: form observation likelihood discrepancy shows , given linearised posterior \\(\\mathsf{N}(\\boldsymbol{m},\\boldsymbol{Q}^{-1})\\), Gaussian approximation nonlinear model posterior, \\(\\mathsf{N}(\\widetilde{\\boldsymbol{m}},\\widetilde{\\boldsymbol{Q}}^{-1})\\), can obtained \\(\\widetilde{\\boldsymbol{Q}}=\\boldsymbol{Q}-\\boldsymbol{G}\\) \\(\\widetilde{\\boldsymbol{Q}}\\widetilde{\\boldsymbol{m}}=\\boldsymbol{Q}\\boldsymbol{m}-\\boldsymbol{G}\\boldsymbol{u}_*\\). K-L divergence becomes \\[ \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &\\approx \\frac{1}{2} \\left[ \\ln\\det(\\boldsymbol{Q})- \\ln\\det(\\boldsymbol{Q}-\\boldsymbol{G}) -\\mathop{\\mathrm{tr}}\\left(\\boldsymbol{G}\\boldsymbol{Q}^{-1}\\right) + (\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top\\boldsymbol{G}(\\boldsymbol{Q}-\\boldsymbol{G})^{-1}\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) \\right] . \\end{aligned} \\] INLA posterior mean \\(\\boldsymbol{m}=\\boldsymbol{u}_*\\), e.g. models additive Gaussian observation noise, \\(\\boldsymbol{\\theta}=\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*}\\), last term vanishes. Note: implementing K-L divergence accuracy metric, -product improved posterior estimates based \\(\\widetilde{\\boldsymbol{m}}\\) \\(\\widetilde{\\boldsymbol{Q}}\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"well-posedness-and-initialisation","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Well-posedness and initialisation","title":"Iterative linearised INLA method","text":"side note, one might concerned initialisation , convergence , saddle point. Although implemented inlabru, want talk technicality define initial linearisation point \\(u_0\\). Generally speaking, values \\(\\boldsymbol{u}_0\\) work except case gradient evaluated \\(\\boldsymbol{u}_0\\) \\(\\boldsymbol{0}\\) linearisation point never move away prior mean also \\(\\boldsymbol{0}\\). general, tends saddle point problem. cases problem can handled changing predictor parameterisation just changing initialisation point using bru_initial option. However, true saddle point problems, indicates predictor parameterisation may lead multimodal posterior distribution ill-posed way. fundamental problem fixed changing initialisation point. examples, \\(\\beta\\) \\(\\boldsymbol{u}\\) latent Gaussian components, predictors 1, 3, 4 typically safe, predictor 2 fundamentally non-identifiable. \\[ \\begin{aligned} \\boldsymbol{\\eta}_1 &= \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_2 &= \\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_3 &= e^\\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_4 &= F_\\beta^{-1} ( \\Phi(z_\\beta)) \\boldsymbol{u}, \\quad z_{\\beta} \\sim \\mathsf{N}(0,1) . \\end{aligned} \\] Note \\(\\boldsymbol{\\eta}_3\\) \\(\\boldsymbol{\\eta}_4\\), partial derivatives respect \\(\\beta\\) zero \\(\\boldsymbol{u}=\\boldsymbol{0}\\). However, first inlabru iteration give non-zero estimate \\(\\boldsymbol{u}\\), subsequent iteration involve \\(\\beta\\) \\(\\boldsymbol{u}\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"proper-posterior-prediction-scores","dir":"Articles","previous_headings":"","what":"Proper posterior prediction scores","title":"Prediction scores","text":"prediction score \\(S(F,y)\\) evaluates measure closeness prediction distribution identified \\(F\\), observed value \\(y\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"a-basic-score-and-motivating-remarks","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"A basic score, and motivating remarks","title":"Prediction scores","text":"common score Squared Error, \\[ S_\\text{SE}(F,y) = [y - \\mathbb{E}_F(Y)]^2, \\] like predictions low values \\(S_\\text{SE}(F,y)\\), indicating “good” prediction, specific sense puts penalty squared deviation prediction mean true observed value. can imagine constructing scoring functions penalise aspects prediction. score “lower better” called negatively oriented, score “higher better” called positively oriented. One can always turn one type score changing sign, simplify presentation, ’ll make scores negatively oriented, like squared error. often care prediction uncertainty just mean (least care!). Just adding prediction variance penalty squared error wouldn’t useful, construct new, “better”, prediction reducing stated prediction variance zero. understate real prediction uncertainty, wouldn’t fair scoring approach comparing different prediction models. next section, make fairness idea precise.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"proper-and-strictly-proper-scores","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Proper and strictly proper scores","title":"Prediction scores","text":"expected value distribution identified \\(G\\) denoted \\(S(F,G):=\\mathbb{E}_{Y\\sim F}[S(F,Y)]\\). negatively oriented score, seek scoring functions fair, sense one , average, make better prediction generated data. requires \\(S(F,G)\\geq S(G,G)\\) predictive distributions \\(F\\) distribution \\(G\\). scores call proper. addition, equality score expectations hold \\(F=G\\), score strictly proper. Non-strict proper scores ignore aspect prediction, typically sensitive summary information, mean, median, /variance. ’s notable proper scores retain properness affine transformations, just potential changes whether positively negatively oriented. \\(S(F,y)\\) proper score, \\[ S'(F,y) = + b S(F,y),\\quad ,b\\\\mathbb{R}, \\] also proper score, orientation \\(b>0\\) opposite orientation \\(b<0\\). degenerate case \\(b=0\\) gives score \\(\\) predictions, technically proper score (better ideal prediction), useless one (ideal prediction better prediction).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"examples","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Examples","title":"Prediction scores","text":"log-score: \\(S_\\text{log}(F,y) = -\\log\\{p_F(y)\\}\\), \\(p_F(y)\\) predictive pdf pmf \\(y\\), strictly proper score. Squared Error: \\(S_\\text{SE}(F,y) = [y - \\mathbb{E}_F(Y)]^2\\) proper score Brier score: Binary events: \\[S_\\text{Brier}(F,z) = [z - \\mathbb{P}_F(Z = 1)]^2,\\] \\(Z\\\\{0,1\\}\\) binary event indicator, strictly proper score event prediction, non-strict respect underlying outcome \\(y\\) generating event indicator, e.g. via \\(z=(y=0)\\). Class indicator events: \\(y\\\\{1,\\dots,K\\}\\) class category outcome, Brier score can generalised \\[S_\\text{MultiBrier}(F,y) = \\sum_{k=1}^K [(y = k) - \\mathbb{P}_F(Y=k)]^2\\] can seen Squared Error Multinomial prediction model \\(z_k=(y=k)\\), \\(\\{z_1,\\dots,z_K\\}\\sim\\text{Multinomial}(1,\\{p_1,\\dots,p_K\\})\\), \\(p_k=\\mathbb{P}_F(Y=k)\\). Sometimes, sum normalised \\(1/K\\). generalised Brier score proper score. Dawid-Sebastiani: \\[S_\\text{DS}(F,y)=[y - \\mathbb{E}_F(Y)]^2 / \\mathbb{V}_F(Y) + \\log[\\mathbb{V}_F(Y)]\\] proper score. ’s derived strictly proper log-score Gaussian prediction, ’s also non-strict proper score distributions. advantage involves predictive mean variance, making computable also cases log-densities hard obtain. Since ’s based symmetric Gaussian distribution, tends affected skewness, applied care cases. Absolute (Median) Error: \\(S_\\text{AE}(F,y)=|y - \\text{median}_F|\\) proper score, expectation minimised medians \\(F\\) \\(G\\) match. Note \\(|y-\\mathbb{E}_F(Y)|\\), absolute error respect expectation, proper score! Another way expressing \\(|y-m_F|\\) proper score respect median, .e. proper \\(m_F\\) taken median \\(F\\), point prediction. applied literature, distinction often overlooked, predictive mean inserted SE AE scores, making resulting AE score comparisons less clear . CRPS (Continuous Ranked Probability Score): \\[ S_\\text{CRPS}(F,y)=   \\int_{-\\infty}^\\infty [\\mathbb{P}_F(Y \\leq x) - (y \\leq x)]^2 \\,\\mathrm{d}x \\] strictly proper score, related absolute error point predictions. scores include Interval score minimised short prediction intervals intended coverage probability, Quantile score, generalises Absolute Median Error quantiles median.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"improper-scores","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Improper scores","title":"Prediction scores","text":"’ve seen scores strictly proper, others proper scores, sensitive specific aspects predictive distribution, mean, median, /variance. contrast, improper scores fulfil fairness idea. scores include aforementioned penalised squared error, \\([y-\\mathbb{E}(Y)]^2+\\mathbb{V}_F(Y)\\), also probability/density function, \\(p_F(y)\\). latter might come surprise, log-score proper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"mean-errorscore","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Mean error/score","title":"Prediction scores","text":"point, considered individual scores. summarising predictions \\(\\{F_i\\}\\) collection observations \\(\\{y_i\\}\\), usually compute mean score, \\[ S(\\{F_i\\},\\{y_i\\}) = \\frac{1}{N}\\sum_{=1}^N S(F_i,y_i) . \\] comparing two different prediction models \\(F\\) \\(F'\\), scores dependent respect observations \\(y_i\\). means order easily handle score variability comparison, treat paired sample problem. pairwise score differences given \\[ S(F_i,F'_i,y_i) = S(F_i,y_i) - S(F'_i,y_i) . \\] ’s also much reasonable make conditional independence assumptions differences, plain score values \\(S(F_i,y_i)\\); \\[ \\mathbb{V}_{\\{y_i\\}\\sim G}\\left[\\frac{1}{N}\\sum_{=1}^N S(F_i,y_i)\\right] = \\frac{1}{N^2}\\sum_{=1}^N\\sum_{j=1}^N\\mathbb{C}_{\\{y_i\\}\\sim G}\\left[S(F_i,y_i),S(F_j,y_j)\\right] \\] \\[ \\mathbb{V}_{\\{y_i\\}\\sim G}\\left[\\frac{1}{N}\\sum_{=1}^N S(F_i,y_i) - S(F'_i,y_i)\\right] \\approx \\frac{1}{N^2}\\sum_{=1}^N\\mathbb{V}_{y_i\\sim G_i}\\left[ S(F_i,y_i) - S(F'_i,y_i)\\right]. \\] Note taking average prediction scores, averages prediction score differences, quite different assessing summary statistics collection predictions, since scores individual observation; ’re assessing collective value distribution, might misleading. example, consider spatial model estimated procession empirical distribution predictive means matches observed data. Scores based marginal empirical distribution able detect location values maximally different actual locations, whereas averages individual scores sensitive .","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"poisson-model-example","dir":"Articles","previous_headings":"","what":"Poisson model example","title":"Prediction scores","text":"Consider model Poisson outcomes \\(y\\), conditionally log-linear predictor \\(\\lambda=\\exp(\\eta)\\), \\(\\eta\\) linear expression latent variables. posterior predictive distributions Poisson mixture distributions across posterior distribution \\(\\lambda\\), \\(p(\\lambda|\\text{data})\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"moment-scores","dir":"Articles","previous_headings":"Poisson model example","what":"Moment scores","title":"Prediction scores","text":"Squared Error Dawid-Sebastiani scores, ’ll need posterior expectation variance: \\[   \\mathbb{E}(Y|\\text{data}) = \\mathbb{E}[\\mathbb{E}(Y|\\lambda,\\text{data}) | \\text{data}] = \\mathbb{E}(\\lambda | \\text{data}) \\] \\[   \\mathbb{V}(Y|\\text{data}) = \\mathbb{E}[\\mathbb{V}(Y|\\lambda,\\text{data}) | \\text{data}] +     \\mathbb{V}[\\mathbb{E}(Y | \\text{data}) | \\text{data}]      = \\mathbb{E}[\\lambda | \\text{data}] + \\mathbb{V}[\\lambda | \\text{data}] \\] .e. sum posterior mean variance lambda. SE DS scores therefore relatively easy compute estimating model inlabru. just need estimate posterior mean variance predict() test data point. eta expression linear predictor, newdata holds covariate information prediction points, run","code":"pred <- predict(fit, newdata, formula = ~ exp(eta), n.samples = 2000) post_E <- pred$mean post_Var <- pred$mean + pred$sd^2 SE_score <- (newdata$y - post_E)^2 DS_score <- (newdata$y - post_E)^2 / post_Var + log(post_Var)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"log-probability-and-log-density-scores","dir":"Articles","previous_headings":"Poisson model example","what":"Log-Probability and log-density scores","title":"Prediction scores","text":"full log-score can actually also estimated/computed similar way. seek, fixed observation y, \\(\\log[\\mathbb{P}(Y = y | \\text{data})]\\) probability \\[   \\mathbb{P}(Y = y | \\text{data}) = \\mathbb{E}[\\mathbb{P}(Y = y | \\lambda, \\text{data}) | \\text{data}], \\] can estimate using predict(): estimate log_score (increase n.samples needed sufficiently small Monte Carlo error).","code":"pred <- predict(fit,   newdata,   formula = ~ dpois(y, rate = exp(eta)),   n.samples = 2000 ) log_score <- log(pred$mean)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"crps","dir":"Articles","previous_headings":"Poisson model example","what":"CRPS","title":"Prediction scores","text":"Yet another option use CRPS, prediction value \\(y_i\\) \\[ S_\\text{CRPS}(F_i,y_i) = \\sum_{k=0}^\\infty [\\mathbb{P}(Y_i \\leq k |\\text{data}) - (y_i \\leq k)]^2 \\] , one first need get \\(\\mathbb{P}(Y \\leq k | \\text{data})\\) predict call ppois(k, rate = exp(eta)), vector \\(k=0,1\\dots,K\\), \\(y_i\\), sufficiently large \\(K>\\max_i{y_i}\\) remainder negligible. However, avoid repeated predict() calls \\(y_i\\), storage requirements order \\((K+1) \\times N\\times N_\\text{samples}\\). avoid , one option reformulate estimator recursive estimator, batches simulations used iteratively compute estimator. basic estimator can proceed follows: Define \\(K\\geq K_0=\\max_i(y_i)\\) sufficiently large posterior predictive probability \\(K\\) negligible. Perhaps value like \\(K=K_0+4\\sqrt{K_0}\\) might sufficient. can check afterwards, change needed. Simulate samples \\(\\lambda^{(j)}\\sim p(\\lambda|\\text{data})\\) using generate() (size \\(N\\times N_\\text{samples}\\)). \\(=1,\\dots,N\\), use samples estimate residuals \\(r_{ik}=\\mathbb{P}(Y\\leq k|\\text{data})-(y_i\\leq k)\\), \\(k\\0,1,2,\\dots,K\\), \\[   \\widehat{p}_{ik} = \\frac{1}{N_\\text{samples}} \\sum_{j=1}^{N_\\text{samples}}   \\{   \\mathbb{P}(Y\\leq k|\\lambda^{(j)}_i)   -   (y_i\\leq k)   \\} .   \\] 3. Compute \\[ S_\\text{CRPS}(F_i,y_i) \\approx \\sum_{k=0}^{K} r_{ik}^2   \\]","code":"# some large value, so that 1-F(K) is small max_K <- ceiling(max(y)) + 4 * sqrt(max(y)) pred <- generate(fit, newdata,   formula = ~ {     lambda <- exp(eta)     k <- seq(0, max_K)     do.call(       cbind,       lapply(         seq_along(y),         function(i) {           F <- ppois(k, rate = lambda[i])           data.frame(             k = c(k, k),             i = c(i, i),             type = rep(c(\"F\", \"residual\"), each = length(F)),             value = c(F, F - (y[i] <= k))           )         }       )     )   },   n.samples = 2000 ) F_estimate <-   (pred %>%     filter(type == \"F\") %>%     group_by(i) %>%     summarise(F = sum(mean), groups = \"drop\") %>%     pull(F)) crps_score <-   (pred %>%     filter(type == \"residual\") %>%     group_by(i) %>%     summarise(crps = sum(mean^2), groups = \"drop\") %>%     pull(crps)) # Check that the cutoff point K has nearly probability mass 1 below it, # for all i: min(F_estimate)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"posterior-expectation-of-conditional-scores","dir":"Articles","previous_headings":"","what":"Posterior expectation of conditional scores","title":"Prediction scores","text":"cases, one might tempted consider posterior distribution properties conditional predictive scores, e.g. posterior expectation \\(\\mathbb{E}_{\\lambda|\\text{data}}[S(F_\\lambda, y)]\\) \\(S(F_\\lambda, y)\\) posterior distribution \\(\\lambda\\) Poisson model. Squared Error, \\[ \\begin{aligned} \\mathbb{E}_{\\lambda|\\text{data}}[(y - \\lambda)^2] &= \\mathbb{E}_{\\lambda|\\text{data}}[\\{y - \\mathbb{E}(\\lambda|\\text{data}) + \\mathbb{E}(\\lambda|\\text{data}) - \\lambda\\}^2] \\\\ &= [y - \\mathbb{E}(\\lambda|\\text{data})]^2 + \\mathbb{E}_{\\lambda|\\text{data}}(\\mathbb{E}(\\lambda|\\text{data}) - \\lambda\\}^2] \\\\ &= [y - \\mathbb{E}(\\lambda|\\text{data})]^2 + \\mathbb{V}(\\lambda|\\text{data}) . \\end{aligned} \\] ’s noteworthy similar improper score \\([y - \\mathbb{E}(y|\\text{data})]^2 + \\mathbb{V}(y|\\text{data})\\), also new case, one can model artificially small posterior variance smaller expected score, making type construction problematic interpret. However, cases provide alternative approaches compute proper scores full posterior predictive distributions. \\(\\lambda_{ij}\\), \\(j=1,\\dots,J\\) samples posterior distribution, one score estimator \\[ \\widehat{S}(F_i,y_i) = (y_i - \\frac{1}{J}\\sum_{j=1}^J \\lambda_{ij})^2 , \\] averaging samples inside quadratic expression, can use instead take advantage new expression , \\[ [y - \\mathbb{E}(\\lambda|\\text{data})]^2 = \\mathbb{E}_{\\lambda|\\text{data}}[(y - \\lambda)^2] - \\mathbb{V}(\\lambda|\\text{data}) \\] score can estimated particular case, approach unlikely improvement accurate basic estimator.However, scores may potentially practical benefits.","code":"pred <- predict(fit, newdata, formula = ~ exp(eta)) scores <- (y - pred$mean)^2 pred <- predict(fit, newdata, formula = ~ list(   cond_scores = (y - exp(eta))^2,   lambda = exp(eta) )) scores <- pred$cond_scores$mean - pred$lambda$sd^2"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"an-alternative-estimator-for-crsp","dir":"Articles","previous_headings":"Posterior expectation of conditional scores","what":"An alternative estimator for CRSP","title":"Prediction scores","text":"CRPS score, closed form expressions available distributions, conditionally paramters, full predictive mixture distribution. take similar approach SE, let \\(F\\) \\(F_\\lambda\\) denote unconditional conditional cumulative distribution functions posterior predictive distribution. \\(F(x)=\\mathbb{E}_{\\lambda|\\text{data}}[F_\\lambda(x)]\\) \\(x\\), \\[ \\begin{aligned} S_\\text{CRPS}(F,y) &= \\int_{-\\infty}^\\infty [F(x) - (y\\leq x)]^2 \\,\\mathrm{d}x \\\\ &= \\mathbb{E}_{\\lambda|\\text{data}}\\left[ \\int_{-\\infty}^\\infty [F_\\lambda(x) - (y\\leq x)]^2 \\,\\mathrm{d}x \\right] - \\int_{-\\infty}^\\infty \\left\\{\\mathbb{E}_{\\lambda|\\text{data}}\\left[F_\\lambda(x)^2\\right] - \\mathbb{E}_{\\lambda|\\text{data}}[F_\\lambda(x)]^2\\right\\} \\,\\mathrm{d}x \\\\ &= \\mathbb{E}_{\\lambda|\\text{data}}\\left[ S_\\text{CRPS}(F_\\lambda,y) \\right] - \\int_{-\\infty}^\\infty \\mathbb{V}_{\\lambda|\\text{data}}[F_\\lambda(x)] \\,\\mathrm{d}x . \\end{aligned} \\] Note didn’t need use particular model properties , holds predictive model mixture structure, \\(\\lambda\\) collection model parameters. also note resemblance alternative expression Squared Error; CRPS can seen integral Brier scores predicting event indicators form \\(z=(y\\leq x)\\), probability \\(F(x)\\). Poisson case, can now estimate CRPS scores like , makes code bit easier previous version needed generate(). However, can shown two approaches nearly identical Monte Carlo variance, previous version likely preferable doesn’t require knowing closed form CRPS expression. Formulas functions Poisson CRPS, well distributions, can found http://cran.nexr.com/web/packages/scoringRules/vignettes/crpsformulas.html#poisson-distribution-pois","code":"poisson_crps <- function(y, rate) {   # compute the CRPS score for a single y, for the given rate paramter. } max_K <- 100 # some large value, so that 1-F(K) is small pred <- predict(fit, newdata,   formula = ~ {     lambda <- exp(eta)     list(       crps = vapply(         seq_along(y),         function(i) poisson_crps(y[i], lambda[i]),         0.0       ),       F = do.call(         cbind,         lapply(           seq_along(y),           function(i) {             data.frame(               i = i,               F = ppois(seq(0, max_K), rate = lambda[i])             )           }         )       )     )   },   n.samples = 2000 ) crps_score <-   pred$crsp$mean -   (pred$F %>%     group_by(i) %>%     summarise(F_var = sum(sd^2), groups = \"drop\") %>%     pull(F_var))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in one dimension","text":"vignette going see fit SPDE one-dimensional point data, .e. data consist points things located, number points area.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in one dimension","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in one dimension","text":"Take look point (frequency) data","code":"data(Poisson2_1D, package = \"inlabru\") ggplot(pts2) +   geom_histogram(aes(x = x),     binwidth = 55 / 20,     boundary = 0, fill = NA, color = \"black\"   ) +   geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +   coord_fixed(ratio = 1)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in one dimension","text":"Build 1D mesh: Make latent components 1D SPDE model, using integrate--zero constraint better identifiability: want fit actual points, inlabru functions used bru() like(..., family = \"cp\"). special case also shortcut function lgcp() (‘Log Gaussian Cox Process’), doesn’t support features. standard way specifying function space integration via domain argument. , formula = x ~ . means observed points x, . denotes linear predictor sum latent components.","code":"x <- seq(0, 55, length.out = 50) mesh1D <- inla.mesh.1d(x, boundary = \"free\") matern <- inla.spde2.pcmatern(mesh1D,   prior.range = c(150, 0.75),   prior.sigma = c(0.1, 0.75),   constr = TRUE ) comp <- ~ spde1D(x, model = matern) + Intercept(1) fit.spde <- bru(   comp,   like(x ~ ., family = \"cp\", data = pts2, domain = list(x = mesh1D)) ) ## Equivalent call for this particular example: # fit.spde <- lgcp(comp, formula = x ~ ., data = pts2, domain = list(x = mesh1D))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"spde-parameters","dir":"Articles > Web","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in one dimension","text":"can look posterior distributions parameters SPDE using function spde.posterior. returns x y values plot posterior PDF data frame, can printed using plot function. see PDF range parameter, example:  Look help file spde.posterior plot posterior log SPDE range parameter, SPDE variance /log variance, Matern covariance function. Make sure understand difference plotted range variance parameters, covariance function (involves parameters). can get feel sensitivity priors specifying different priors looking posterior plots.","code":"post.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"range\") plot(post.range) post.log.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.range\") plot(post.log.range) # SOLUTION post.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"variance\") plot(post.variance) # SOLUTION post.log.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.variance\") plot(post.log.variance) # SOLUTION post.matcorr <- spde.posterior(fit.spde, name = \"spde1D\", what = \"matern.correlation\") plot(post.matcorr) # SOLUTION"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"predicting-intensity","dir":"Articles > Web","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in one dimension","text":"can also now predict scale want. example, predict ‘response’ scale (.e. intensity function \\(\\lambda(s)\\)), call predict thus: predict linear predictor scale (.e. log intensity, \\(\\log(\\lambda(s))\\)), call predict thus: ’s plot prediction 95% credible interval:  compare underlying intensity function generated data? function lambda2_1D( ) dataset Poission2_1D calculates true intensity used simulating data. order plot , make data frame x- y-coordinates giving true intensity function, \\(\\lambda(s)\\). use lots x-values get nice smooth plot (150 values). Plot fitted true intensity functions:","code":"predf <- data.frame(x = seq(0, 55, by = 1)) # Set up a data frame of explanatory values at which to predict pred_spde <- predict(fit.spde, predf, ~ exp(spde1D + Intercept), n.samples = 1000) pred_spde_lp <- predict(fit.spde, predf, ~ spde1D + Intercept, n.samples = 1000) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   xlab(\"x\") + ylab(\"Intensity\") xs <- seq(0, 55, length = 150) true.lambda <- data.frame(x = xs, y = lambda2_1D(xs)) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = true.lambda, aes(x, y)) +   xlab(\"x\") + ylab(\"Intensity\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"goodness-of-fit","dir":"Articles > Web","previous_headings":"","what":"Goodness-of-Fit","title":"LGCPs - An example in one dimension","text":"can look goodness--fit mode using inlabru function bincount( ), plots 95% credible intervals specified set bins along x-axis together observed count bin: credible intervals shown red rectangles, mean fitted value short horizontal blue line, observed data black points:","code":"bc <- bincount(   result = fit.spde,   observations = pts2,   breaks = seq(0, max(pts2), length = 12),   predictor = x ~ exp(spde1D + Intercept) )  attributes(bc)$ggp"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"estimating-abundance","dir":"Articles > Web","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in one dimension","text":"Abundance integral intensity space. estimate integrating predicted intensity x. Integration done adding intensity locations x weighted particular weight. locations x weights constructed using fm_int function can look abundance estimate typing mean posterior mean abundance. sd estimated standard error posterior abundance. cv estimated coefficient variation (stander error divided mean). q0.025 q0.975 95% credible interval bounds. q0.5 posterior median abundance quite simple! posterior abundance takes account variance due us knowing parameters intensity function. neglects variance number point locations, given intensity function. include need modify predict( ) follows: calculates statistics calculated Lambda, evey value N 50 250, rather posterior mean N alone: compute 95% prediction interval median follows Compare Lambda Nest plotting: First calculate posterior conditional mean Lambda plot unconditional posterior  differences make sense ?","code":"ips <- fm_int(mesh1D, name = \"x\") head(ips) #>          x    weight .block #> 1 0.000000 0.1870748      1 #> 2 1.122449 0.3741497      1 #> 3 2.244898 0.3741497      1 #> 4 3.367347 0.3741497      1 #> 5 4.489796 0.3741497      1 #> 6 5.612245 0.3741497      1 Lambda <- predict(fit.spde, ips, ~ sum(weight * exp(spde1D + Intercept))) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err sd.mc_std_err #> 1 130.4533 11.62741 110.2648 130.1588 154.3992 130.1588        1.162741     0.8869087 Nest <- predict(   fit.spde, ips,   ~ data.frame(     N = 50:250,     dpois = dpois(50:250,       lambda = sum(weight * exp(spde1D + Intercept))     )   ) ) Nest[Nest$N %in% 100:105, ] #>      N        mean          sd       q0.025         q0.5     q0.975       median mean.mc_std_err #> 51 100 0.003778783 0.007115300 3.679394e-07 0.0005431958 0.02744416 0.0005431958    0.0007115300 #> 52 101 0.004301858 0.007740466 5.651663e-07 0.0007111854 0.02958766 0.0007111854    0.0007740466 #> 53 102 0.004866573 0.008354217 8.597263e-07 0.0009220016 0.03158591 0.0009220016    0.0008354217 #> 54 103 0.005472090 0.008948446 1.295304e-06 0.0011837083 0.03339181 0.0011837083    0.0008948446 #> 55 104 0.006117063 0.009515621 1.933094e-06 0.0015050913 0.03496158 0.0015050913    0.0009515621 #> 56 105 0.006799638 0.010049007 2.857895e-06 0.0018955109 0.03625661 0.0018955109    0.0010049007 #>    sd.mc_std_err #> 51   0.000995352 #> 52   0.001035392 #> 53   0.001063168 #> 54   0.001077285 #> 55   0.001076862 #> 56   0.001061652 inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 100.6664 131.7453 167.8635 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_point(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err     ),     fill = \"grey\",     alpha = 0.5   ) +   geom_point(aes(x = N, y = plugin_estimate, colour = \"Plugin\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\")) +   ylab(\"pmf\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/1d_lgcp.html","id":"comparison-to-gam-fit","dir":"Articles > Web","previous_headings":"","what":"Comparison to GAM fit","title":"LGCPs - An example in one dimension","text":"Now refit GAM count data Poisson2_1D plot estimated intensity function GAM fit, together LGCP fitted true intensity. get plot like (thick line true intensity, thin solid line inlabru fit, dashed line GAM fit:","code":"cd2 <- countdata2 fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd2) dat4pred <- data.frame(x = seq(0, 55, length = 100), exposure = rep(cd2$exposure[1], 100)) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # SOLUTION plot(pred_spde) +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure, colour = \"gam()\"), lty = 2) +   geom_line(data = true.lambda, aes(x, y, colour = \"True\"), lwd = 1.5) +   geom_point(data = cd2, aes(x, y = count / exposure)) +   ylab(\"Intensity\") + xlab(\"x\") # SOLUTION"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in two dimensions","text":"vignette going working dataset obtained R package spatstat. set two-dimensional LGCP estimate Gorilla abundance.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in two dimensions","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in two dimensions","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : dataset list containing number R objects, including locations nests, boundary survey area INLA mesh - see help(gorillas) details. Extract objects need list, objects, don’t keep typing ‘gorillas$’: Plot points (nests(. (ggplot2 function coord_fixed() sets aspect ratio, defaults 1.)","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary ggplot() +   gg(mesh) +   gg(nests) +   gg(boundary) +   coord_fixed() +   ggtitle(\"Points\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in two dimensions","text":"Fit LGCP model locations gorilla nests, predict survey region, produce plot estimated density - look like plot shown . Recall steps specifying, fitting predicting : Specify model, comprising (2D models) coordinates left ~ SPDE + Intercept(1) right. Please use SPDE prior specification stated . Call lgcp( ), passing (2D models) model components, SpatialPointsDataFrame containing observed points SpatialPolygonsDataFrame defining survey boundary using samplers argument. Call predict( ), passing fitted model 2., locations predict appropriate predictor specification. locations predict can SpatialPixelsDataFrame covering mesh, obtained calling fm_pixels(mesh, format = \"sp\").","code":"matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) )  cmp <- coordinates ~ mySmooth(coordinates,   model = matern ) +   Intercept(1)  fit <- lgcp(cmp, nests, samplers = boundary, domain = list(coordinates = mesh))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"predicting-intensity","dir":"Articles > Web","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in two dimensions","text":"get plot like (command assumes prediction object called lambda):  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object lambda).","code":"pred <- predict(   fit,   fm_pixels(mesh, mask = gorillas$boundary, format = \"sp\"),   ~ data.frame(     lambda = exp(mySmooth + Intercept),     loglambda = mySmooth + Intercept   ) )  pl1 <- ggplot() +   gg(pred$lambda) +   gg(boundary) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Response Scale)\") +   coord_fixed()  pl2 <- ggplot() +   gg(pred$loglambda) +   gg(boundary) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Linear Predictor Scale)\") +   coord_fixed()  multiplot(pl1, pl2, cols = 2) ggplot() +   gg(cbind(pred$lambda, data.frame(property = \"q0.500\")), aes(fill = median)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.025\")), aes(fill = q0.025)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.975\")), aes(fill = q0.975)) +   coord_equal() +   facet_wrap(~property)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"spde-parameters","dir":"Articles > Web","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in two dimensions","text":"Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :","code":"int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp.html","id":"estimating-abundance","dir":"Articles > Web","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in two dimensions","text":"Finally, estimate abundance using predict function. first step need estimate integrated lambda. integration weight values contained fm_int() output. Given generous interval boundaries (500, 800) lambda can estimate posterior abundance distribution via Get quantiles via … mean via plot posteriors:  true number nests 647; mean median posterior distribution abundance close done anything wrong!","code":"Lambda <- predict(   fit,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda #>      mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 670.141 29.01076 620.6783 665.3128 723.1996 665.3128        2.901076 #>   sd.mc_std_err #> 1      1.962823 Nest <- predict(   fit, fm_int(mesh, boundary),   ~ data.frame(     N = 500:800,     dpois(500:800,       lambda = sum(weight * exp(mySmooth + Intercept))     )   ) ) inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 596.7946 666.0384 737.1878 inla.emarginal(identity, marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 666.3551 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Spatial covariates","text":"going fit spatial models gorilla data, using factor continuous explanatory variables practical. fit one using factor variable vegetation, using continuous covariate elevation (Jump bottom practical want start gently 1D example!)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Spatial covariates","text":"dataset list (see help(gorillas) details. Extract objects need list, convenience:","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"factor-covariates","dir":"Articles > Web","previous_headings":"","what":"Factor covariates","title":"LGCPs - Spatial covariates","text":"Look vegetation type, nests boundary:  , mesh:","code":"ggplot() +   gg(gcov$vegetation) +   gg(boundary) +   gg(nests, color = \"white\", cex = 0.5) +   coord_equal() ggplot() +   gg(gcov$vegetation) +   gg(mesh) +   gg(boundary) +   gg(nests, color = \"white\", cex = 0.5) +   coord_equal()"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-only","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with vegetation type only","title":"LGCPs - Spatial covariates","text":"seems vegetation type might good predictor nearly nests fall vegetation type Primary. construct model vegetation type fixed effect. , need tell ‘lgcp’ find vegetation type point space, creating model components fixed effect call vegetation (call anything), follows: Notes: * need tell ‘lgcp’ factor fixed effect, model=\"factor_full\", giving one coefficient factor level. * need careful overparameterisation using factors. Unlike regression models like ‘lm()’, ‘glm()’ ‘gam()’, ‘lgcp()’, inlabru automatically remove first level absorb intercept. Instead, can either use model=\"factor_full\" without intercept, model=\"factor_contrast\", remove first level. Fit model usual: Predict intensity, plot median intensity surface. (older versions, predicting takes time vegetation values outside mesh ‘inlabru’ needed predict first. Since v2.0.0, vegetation pre-extended.) predidct function inlabru takes data argument SpatialPointsDataFrame, SpatialPixelsDataFrame data.frame. can use inlabru function pixels generate SpatialPixelsDataFrame within boundary, using mask argument, shown .  surprisingly, given nests Primary vegetation, high density vegetation. substantial patches predicted high density nests, areas predicted low density nests. estimated abundance (really 647 nests ):","code":"comp1 <- coordinates ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1 comp1alt <- coordinates ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + Intercept(1) fit1 <- lgcp(comp1, nests, samplers = boundary, domain = list(coordinates = mesh)) pred.df <- fm_pixels(mesh, mask = boundary, format = \"sp\") int1 <- predict(fit1, pred.df, ~ exp(vegetation))  ggplot() +   gg(int1) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") +   coord_equal() ips <- fm_int(mesh, boundary) Lambda1 <- predict(fit1, ips, ~ sum(weight * exp(vegetation))) Lambda1 #>       mean       sd   q0.025     q0.5  q0.975   median mean.mc_std_err #> 1 647.3736 24.33849 600.5223 646.6732 689.562 646.6732        2.433849 #>   sd.mc_std_err #> 1      1.443532"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-and-a-spde-type-smoother","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with vegetation type and a SPDE type smoother","title":"LGCPs - Spatial covariates","text":"Lets try explain pattern nest distribution captured vegetation covariate, using SPDE: plot median intensity surface  … expected integrated intensity (mean abundance) Look contributions linear predictor SPDE vegetation: function scale_fill_gradientn sets scale plot legend. set span range three linear predictor components plotted (medians plotted default).","code":"pcmatern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(1, 0.01) )  comp2 <- coordinates ~   -1 +   vegetation(gcov$vegetation, model = \"factor_full\") +   mySmooth(coordinates, model = pcmatern) fit2 <- lgcp(comp2, nests, samplers = boundary, domain = list(coordinates = mesh)) int2 <- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)  ggplot() +   gg(int2, aes(fill = q0.025)) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests) +   coord_equal() Lambda2 <- predict(   fit2,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + vegetation)) ) Lambda2 #>       mean     sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 678.2476 28.906 622.6718 677.4625 729.9437 677.4625          2.8906 #>   sd.mc_std_err #> 1        1.8058 lp2 <- predict(fit2, pred.df, ~ list(   smooth_veg = mySmooth + vegetation,   smooth = mySmooth,   veg = vegetation )) lprange <- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.lp2 <- ggplot() +   gg(lp2$smooth_veg) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth + vegetation\") +   coord_equal()  plot.lp2.spde <- ggplot() +   gg(lp2$smooth) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth\") +   coord_equal()  plot.lp2.veg <- ggplot() +   gg(lp2$veg) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"vegetation\") +   coord_equal()  multiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, cols = 3)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"a-model-with-spde-only","dir":"Articles > Web","previous_headings":"Factor covariates","what":"A model with SPDE only","title":"LGCPs - Spatial covariates","text":"need vegetation ? Fit model SPDE + Intercept, choose models basis DIC, using ‘deltaIC()’.  NOTE: behaviour DIC currently bit unclear, investigated. WAIC related leave-one-cross-validation, appropriate use current current LGCP likelihood implementation. Classic mode: Experimental mode:","code":"comp3 <- coordinates ~ mySmooth(coordinates, model = pcmatern) + Intercept(1) fit3 <- lgcp(comp3,   data = nests,   samplers = boundary,   domain = list(coordinates = mesh) ) int3 <- predict(fit3, pred.df, ~ exp(mySmooth + Intercept))  ggplot() +   gg(int3) +   gg(boundary, alpha = 0) +   gg(nests) +   coord_equal() Lambda3 <- predict(   fit3,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda3 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 673.9943 24.44844 624.9049 671.5871 725.4862 671.5871        2.444844 #>   sd.mc_std_err #> 1      1.778658 knitr::kable(deltaIC(fit1, fit2, fit3, criterion = c(\"DIC\")))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"cv-and-spde-parameters-for-model-2","dir":"Articles > Web","previous_headings":"Factor covariates","what":"CV and SPDE parameters for Model 2","title":"LGCPs - Spatial covariates","text":"going Model fit2. Lets look spatial distribution coefficient variation  Plot vegetation “fixed effect” posteriors. First get names - $marginals.random$vegetation fitted object, contains fixed effect marginal distribution data  Use spde.posterior( ) obtain plot SPDE parameter posteriors Matern correlation covariance functions model.","code":"ggplot() +   gg(int2, aes(fill = sd / mean)) +   gg(boundary, alpha = 0) +   gg(nests) +   coord_fixed() flist <- vector(\"list\", NROW(fit2$summary.random$vegetation)) for (i in seq_along(flist)) flist[[i]] <- plot(fit2, \"vegetation\", index = i) multiplot(plotlist = flist, cols = 3) spde.range <- spde.posterior(fit2, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit2, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"continuous-covariates","dir":"Articles > Web","previous_headings":"","what":"Continuous covariates","title":"LGCPs - Spatial covariates","text":"Now lets try model elevation (continuous) explanatory variable. (First centre elevations stable fitting.)  elevation variable class ‘SpatialGridDataFrame’, can handled way vegetation covariate. However, since cases data may stored differently, methods needed access stored values. cases, can define function knows evaluate covariate arbitrary points survey region, call function component definition. case, can use powerful method ‘sp’ package . use create needed function. NOTE: new method eval_spatial() handles automatically, supports terra SpatRaster sf geometry points objects, mismatching coordinate systems well. brevity going consider models elevation , elevation SPDE, SPDE . just fit one elevation SPDE. create model pass lgcp thus: Note elevation effect defined. used Spatial grid object directly specified like whereas function method specify covariate like : also now include intercept term. model fitted usual way: Summary model selection Predict plot density   Now look elevation SPDE effects space. Leave Intercept swamps spatial effects elevation SPDE plots interested comparing effects elevation SPDE. First need predict linear predictor scale. code , similar used vegetation factor variable, produces plots want.  might also want look posteriors fixed effects SPDE. Adapt code used vegetation factor .  Plot SPDE parameter posteriors Matern correlation covariance functions model.   Also estimate abundance. data.frame second call leads inclusion N prediction object, easier plotting. Plot way previous practicals","code":"elev <- gcov$elevation elev$elevation <- elev$elevation - mean(elev$elevation, na.rm = TRUE)  ggplot() +   gg(elev) +   gg(boundary, alpha = 0) +   coord_fixed() f.elev <- function(xy) {   # turn coordinates into SpatialPoints object:   # with the appropriate coordinate reference system (CRS)   spp <- SpatialPoints(data.frame(x = xy[, 1], y = xy[, 2]),     proj4string = fm_CRS(elev)   )   # Extract elevation values at spp coords, from our elev SpatialGridDataFrame   v <- over(spp, elev)   if (any(is.na(v$elevation))) {     v$elevation <- bru_fill_missing(elev, spp, v$elevation)   }   return(v$elevation) } matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(1, 0.01) )  ecomp <- coordinates ~ elev(f.elev(coordinates(.data.)), model = \"linear\") +   mySmooth(coordinates, model = matern) + Intercept(1) vegetation(gcov$vegetation, model = \"factor_full\") elev(f.elev(coordinates(.data.)), model = \"linear\") efit <- lgcp(ecomp, nests, samplers = boundary, domain = list(coordinates = mesh)) summary(efit) #> inlabru version: 2.7.0.9021 #> INLA version: 23.06.15 #> Components: #> elev: main = linear(f.elev(coordinates(.data.))), group = exchangeable(1L), replicate = iid(1L) #> mySmooth: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L) #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L) #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ . #> Time used: #>     Pre = 1.03, Running = 11.8, Post = 0.705, Total = 13.5  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> elev      0.004 0.001      0.002    0.004      0.006 0.004   0 #> Intercept 1.116 0.494      0.110    1.127      2.060 1.127   0 #>  #> Random effects: #>   Name     Model #>     mySmooth SPDE2 model #>  #> Model hyperparameters: #>                    mean    sd 0.025quant 0.5quant 0.975quant mode #> Range for mySmooth 1.82 0.222      1.428     1.81       2.30 1.77 #> Stdev for mySmooth 1.02 0.085      0.861     1.01       1.20 1.00 #>  #> Deviance Information Criterion (DIC) ...............: 513.76 #> Deviance Information Criterion (DIC, saturated) ....: NA #> Effective number of parameters .....................: -831.13 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 3091.89 #> Effective number of parameters .................: 896.62 #>  #> Marginal log-Likelihood:  -1255.04  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') deltaIC(fit1, fit2, fit3, efit) #>   Model       DIC Delta.DIC #> 1  fit1 -562.5418     0.000 #> 2  efit  513.7652  1076.307 #> 3  fit3  518.7773  1081.319 #> 4  fit2  612.1971  1174.739 e.int <- predict(efit, pred.df, ~ exp(mySmooth + elev + Intercept)) e.int.log <- predict(efit, pred.df, ~ (mySmooth + elev + Intercept))  ggplot() +   gg(e.int, aes(fill = log(sd))) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") +   coord_equal() ggplot() +   gg(e.int.log, aes(fill = exp(mean + sd^2 / 2))) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") +   coord_equal() e.lp <- predict(   efit,   pred.df,   ~ list(     smooth_elev = mySmooth + elev,     elev = elev,     smooth = mySmooth   ) ) lprange <- range(e.lp$smooth_elev$mean, e.lp$elev$mean, e.lp$smooth$mean)  library(RColorBrewer) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.e.lp <- ggplot() +   gg(e.lp$smooth_elev, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE + elevation\") +   coord_equal()  plot.e.lp.spde <- ggplot() +   gg(e.lp$smooth, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE\") +   coord_equal()  plot.e.lp.elev <- ggplot() +   gg(e.lp$elev, mask = boundary) +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"elevation\") +   coord_equal()  multiplot(plot.e.lp,   plot.e.lp.spde,   plot.e.lp.elev,   cols = 3 ) LambdaE <- predict(   efit,   ipoints(boundary, mesh),   ~ sum(weight * exp(Intercept + elev + mySmooth)) ) LambdaE #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 675.0772 28.13319 627.3081 674.3766 733.5248 674.3766        2.813319 #>   sd.mc_std_err #> 1      1.937987 flist <- vector(\"list\", NROW(efit$summary.fixed)) for (i in seq_along(flist)) {   flist[[i]] <- plot(efit, rownames(efit$summary.fixed)[i]) } multiplot(plotlist = flist, cols = 2) spde.range <- spde.posterior(efit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(efit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot) Lambda <- predict(   efit, fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + elev + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 667.6977 28.52219 621.7413 665.7608 727.8757 665.7608        2.852219 #>   sd.mc_std_err #> 1      2.136471  Nest.e <- predict(   efit,   fm_int(mesh, boundary),   ~ data.frame(     N = 200:1000,     density = dpois(200:1000,       lambda = sum(weight * exp(mySmooth + elev + Intercept))     )   ),   n.samples = 2000 ) Nest.e$plugin_estimate <- dpois(Nest.e$N, lambda = Lambda$median) ggplot(data = Nest.e) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"non-spatial-evaluation-of-the-covariate-effect","dir":"Articles > Web","previous_headings":"Continuous covariates","what":"Non-spatial evaluation of the covariate effect","title":"LGCPs - Spatial covariates","text":"previous examples posterior prediction focused spatial prediction. inlabru version 2.2.8, feature available overriding component input value specification component definition. model component can evaluated directly, arbitrary values functions named adding suffix _eval end component name predictor expression, disabling normal component evaluation components include = character(0) (since ’re bypassing normal input elev component, supplying data components). version 2.8.0, inlabru attempts automatically detect model components used expression, include argument can usually left entirely. Since elevation effect model linear, resulting plot isn’t interesting, method can applied non-linear effects well, combined general R expressions.","code":"elev.pred <- predict(   efit,   data.frame(elevation = seq(0, 100, length.out = 1000)),   formula = ~ elev_eval(elevation),   include = character(0) # Not needed from version 2.8.0 )  ggplot(elev.pred) +   geom_line(aes(elevation, mean)) +   geom_ribbon(     aes(elevation,       ymin = q0.025,       ymax = q0.975     ),     alpha = 0.2   ) +   geom_ribbon(     aes(elevation,       ymin = mean - 1 * sd,       ymax = mean + 1 * sd     ),     alpha = 0.2   )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html","id":"a-1d-example","dir":"Articles > Web","previous_headings":"","what":"A 1D Example","title":"LGCPs - Spatial covariates","text":"Try fitting 1-dimensional model point data inlabru dataset Poisson2_1D. comes covariate function called cov2_1D. Try reproduce plot (used lectures) showing effects Intercept + z SPDE. (may find helpful build model fitted previous practical, adding covariate model specification.)","code":"data(Poisson2_1D) ss <- seq(0, 55, length = 200) z <- cov2_1D(ss) x <- seq(1, 55, length = 100) mesh <- inla.mesh.1d(x, degree = 1)  comp <- x ~   beta_z(cov2_1D(x), model = \"linear\") +   spde1D(x, model = inla.spde2.matern(mesh)) +   Intercept(1)  fitcov1D <- lgcp(comp, pts2, domain = list(x = mesh)) pr.df <- data.frame(x = x) prcov1D <- predict(   fitcov1D,   pr.df,   ~ list(     total = exp(beta_z + spde1D + Intercept),     fx = exp(beta_z + Intercept),     spde = exp(spde1D)   ) )  ggplot() +   gg(prcov1D$total, color = \"red\") +   geom_line(aes(x = prcov1D$spde$x, y = prcov1D$spde$median), col = \"blue\", lwd = 1.25) +   geom_line(aes(x = prcov1D$fx$x, y = prcov1D$fx$median), col = \"green\", lwd = 1.25) +   geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +   xlab(expression(bold(s))) +   ylab(expression(hat(lambda)(bold(s)) ~ ~\"and its components\")) +   annotate(geom = \"text\", x = 40, y = 6, label = \"Intensity\", color = \"red\") +   annotate(geom = \"text\", x = 40, y = 5.5, label = \"z-effect\", color = \"green\") +   annotate(geom = \"text\", x = 40, y = 5, label = \"SPDE\", color = \"blue\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Distance sampling","text":"’re going estimate distribution abundance line transect survey dolphins Gulf Mexico. data also available R package dsm (go name mexdolphins). inlabru data called mexdolphin.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Distance sampling","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Distance sampling","text":"’ll start loading data extracting mesh (convenience). Plot data (initial code just get rid tick marks)","code":"data(mexdolphin, package = \"inlabru\") mesh <- mexdolphin$mesh noyticks <- theme(   axis.text.y = element_blank(),   axis.ticks = element_blank() )  noxticks <- theme(   axis.text.x = element_blank(),   axis.ticks = element_blank() )  ggplot() +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal()"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"spatial-model-with-a-half-normal-detection-function","dir":"Articles > Web","previous_headings":"","what":"Spatial model with a half-normal detection function","title":"LGCPs - Distance sampling","text":"samplers dataset lines, polygons, need tell inlabru strip half-width, W, case data 8. start plotting distances histogram frequencies distance intervals:  need define half-normal detection probability function. must take distance first argument linear predictor sigma parameter (call lsig) second: Specify fit SPDE model data using half-normal detection function form. need define (Matern) covariance function SPDE need now separately define components model (SPDE, Intercept detection function parameter lsig) … formula, describes components combined form linear predictor (remembering need offset due unknown direction detections!): fit model, passing components formula (previously formula constructed invisibly inlabru), specify integration domains spatial distance dimensions: Look SPDE parameter posteriors   Predict spatial intensity, plot :  Predict detection function plot , generate plot like one . , make sure doesn’t try evaluate effects components can’t evaluated using given input data. , ’re providing distances spatial coordinates, evaluate spatial random field predict() call. can specify providing vector component names include prediction calculations, “lsig”, include = \"lsig\". See ?predict.bru information. version 2.8.0, inlabru attmepts automatically detect components used predictor expression, include argument can usually left . average detection probability within maximum detection distance estimated 0.702004. can look posterior expected number dolphins usual: including randomness expected number. case, turns need lots posterior samples, e.g. 2,000 smooth Monte Carlo error posterior, takes little compute:","code":"W <- 8 ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance),     breaks = seq(0, W, length = 9),     boundary = 0, fill = NA, color = \"black\"   ) +   geom_point(aes(x = distance), y = 0, pch = \"|\", cex = 4) hn <- function(distance, lsig) {   exp(-0.5 * (distance / exp(lsig))^2) } matern <- inla.spde2.pcmatern(mexdolphin$mesh,   prior.sigma = c(2, 0.01),   prior.range = c(50, 0.01) ) cmp <- ~ mySPDE(main = coordinates, model = matern) +   lsig(1) + Intercept(1) form <- coordinates + distance ~ mySPDE +   log(hn(distance, lsig)) +   Intercept + log(2) fit <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     coordinates = mesh,     distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))   ),   formula = form ) spde.range <- spde.posterior(fit, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pxl <- fm_pixels(mesh, nx = 100, ny = 50, mask = mexdolphin$ppoly, format = \"sp\") pr.int <- predict(fit, pxl, ~ exp(mySPDE + Intercept))  ggplot() +   gg(pr.int) +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal() distdf <- data.frame(distance = seq(0, 8, length = 100)) dfun <- predict(fit, distdf, ~ hn(distance, lsig)) plot(dfun) predpts <- fm_int(mexdolphin$mesh, mexdolphin$ppoly) Lambda <- predict(fit, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 244.4344 51.11059 169.5301 237.7928 360.1069 237.7928        5.111059 #>   sd.mc_std_err #> 1      3.642107 Ns <- seq(50, 450, by = 1) Nest <- predict(fit, predpts,   ~ data.frame(     N = Ns,     density = dpois(Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err,       colour = NULL, fill = \"Posterior\"     ),     alpha = 0.2   ) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\", fill = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"hazard-rate-detection-function","dir":"Articles > Web","previous_headings":"","what":"Hazard-rate Detection Function","title":"LGCPs - Distance sampling","text":"Try , use hazard-rate detection function model: Solution: Plots:","code":"hr <- function(distance, lsig) {   1 - exp(-(distance / exp(lsig))^-1) } formula1 <- coordinates + distance ~ mySPDE +   log(hr(distance, lsig)) +   Intercept + log(2)  fit1 <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     coordinates = mesh,     distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))   ),   formula = formula1 ) spde.range <- spde.posterior(fit1, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit1, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pr.int1 <- predict(fit1, pxl, ~ exp(mySPDE + Intercept))  ggplot() +   gg(pr.int1) +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   noyticks +   noxticks +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   guides(fill = FALSE) +   coord_equal() distdf <- data.frame(distance = seq(0, 8, length = 100)) dfun1 <- predict(fit1, distdf, ~ hr(distance, lsig)) plot(dfun1) predpts <- fm_int(mexdolphin$mesh, mexdolphin$ppoly) Lambda1 <- predict(fit1, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda1 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 291.6575 86.14881 155.3975 273.5984 472.4208 273.5984        8.614881 #>   sd.mc_std_err #> 1      5.814332  Ns <- seq(50, 650, by = 1) Nest1 <- predict(   fit1,   predpts,   ~ data.frame(     N = Ns,     density = dpois(Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest1$plugin_estimate <- dpois(Nest1$N, lambda = Lambda1$mean) ggplot(data = Nest1) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err,       colour = NULL, fill = \"Posterior\"     ),     alpha = 0.2   ) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\", fill = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"comparing-the-models","dir":"Articles > Web","previous_headings":"","what":"Comparing the models","title":"LGCPs - Distance sampling","text":"Look goodness--fit two models distance dimension","code":"bc <- bincount(   result = fit,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length = 9),   predictor = distance ~ hn(distance, lsig) ) attributes(bc)$ggp bc1 <- bincount(   result = fit1,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length = 9),   predictor = distance ~ hn(distance, lsig) ) attributes(bc1)$ggp"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html","id":"fit-models-only-to-the-distance-sampling-data","dir":"Articles > Web","previous_headings":"","what":"Fit Models only to the distance sampling data","title":"LGCPs - Distance sampling","text":"Half-normal first Half-normal next Plot lines histogram observations First scale lines area histogram Half-normal: Hazard-rate: Combine lines single object plotting Plot without 95% credible intervals  Plot 95% credible intervals (without taking count rescaling account)","code":"formula <- distance ~ log(hn(distance, lsig)) + Intercept cmp <- ~ lsig(1) + Intercept(1) dfit <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))),   formula = formula,   options = list(bru_initial = list(lsig = 1, Intercept = 3)) ) detfun <- predict(dfit, distdf, ~ hn(distance, lsig)) formula1 <- distance ~ log(hr(distance, lsig)) + Intercept cmp <- ~ lsig(1) + Intercept(1) dfit1 <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = INLA::inla.mesh.1d(seq(0, 8, length.out = 30))),   formula = formula1 ) detfun1 <- predict(dfit1, distdf, ~ hr(distance, lsig)) hnline <- data.frame(distance = detfun$distance, p = detfun$mean, lower = detfun$q0.025, upper = detfun$q0.975) wts <- diff(hnline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hnarea <- sum(wts * hnline$p) n <- length(mexdolphin$points$distance) scale <- n / hnarea hnline$En <- hnline$p * scale hnline$En.lower <- hnline$lower * scale hnline$En.upper <- hnline$upper * scale hrline <- data.frame(distance = detfun1$distance, p = detfun1$mean, lower = detfun1$q0.025, upper = detfun1$q0.975) wts <- diff(hrline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hrarea <- sum(wts * hrline$p) n <- length(mexdolphin$points$distance) scale <- n / hrarea hrline$En <- hrline$p * scale hrline$En.lower <- hrline$lower * scale hrline$En.upper <- hrline$upper * scale dlines <- rbind(   cbind(hnline, model = \"Half-normal\"),   cbind(hrline, model = \"Hazard-rate\") ) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) +   geom_ribbon(     data = dlines, aes(x = distance, ymin = En.lower, ymax = En.upper, group = model, col = model, fill = model),     alpha = 0.2, lty = 2   )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Multiple Likelihoods","text":"vignette going working inlabru’s ´gorillas´ dataset originally obtained R package spatstat. data set contains two types gorillas nests marked either major minor. set multi-likelihood model nests creates two spatial LGCPs share common intercept employ different spatial smoothers.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Multiple Likelihoods","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Multiple Likelihoods","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : Plot nests visualize group membership (major/minor) color:","code":"data(gorillas, package = \"inlabru\") ggplot() +   gg(gorillas$mesh) +   gg(gorillas$nests, aes(color = group)) +   gg(gorillas$boundary) +   coord_fixed() +   ggtitle(\"Gorillas nests and group membership\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"fiting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fiting the model","title":"LGCPs - Multiple Likelihoods","text":"First, define components enter joint model. , intercept common LGCPs two different spatial smoothers, one nest group. Given components define linear predictor likelihoods. (Using “.” indicates pure additive model, one can use include/exclude options like() indicate components actively involved model.) Setting Cox process likelihoods easy example. nest types observed within window: … provide ´bru´ function.","code":"matern <- inla.spde2.pcmatern(gorillas$mesh,   prior.range = c(0.1, 0.01),   prior.sigma = c(1, 0.01) )  cmp <- ~   Common(coordinates, model = matern) +     Difference(coordinates, model = matern) +     Intercept(1) fml.major <- coordinates ~ Intercept + Common + Difference / 2 fml.minor <- coordinates ~ Intercept + Common - Difference / 2 lik_minor <- like(\"cp\",   formula = fml.major,   data = gorillas$nests[gorillas$nests$group == \"major\", ],   samplers = gorillas$boundary,   domain = list(coordinates = gorillas$mesh) ) lik_major <- like(\"cp\",   formula = fml.minor,   data = gorillas$nests[gorillas$nests$group == \"minor\", ],   samplers = gorillas$boundary,   domain = list(coordinates = gorillas$mesh) ) jfit <- bru(cmp, lik_major, lik_minor,   options = list(     control.inla = list(int.strategy = \"eb\"),     bru_max_iter = 1   ) ) library(patchwork) pl.major <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"rerunning","dir":"Articles > Web","previous_headings":"","what":"Rerunning","title":"LGCPs - Multiple Likelihoods","text":"Rerunning previous estimate starting point sometimes improves accuracy posterior distribution estimation.","code":"jfit0 <- jfit jfit <- bru_rerun(jfit) library(patchwork) pl.major <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\") summary(jfit0) #> inlabru version: 2.7.0.9021 #> INLA version: 23.06.15 #> Components: #> Common: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L) #> Difference: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L) #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L) #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common - Difference/2 #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common + Difference/2 #> Time used: #>     Pre = 1.75, Running = 138, Post = 0.171, Total = 140  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> Intercept -0.354 1.366     -3.031   -0.354      2.323 -0.354   0 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     2.926 0.613      1.927    2.856      4.324 2.713 #> Stdev for Common     2.032 0.321      1.482    2.003      2.740 1.944 #> Range for Difference 2.000 2.372      0.231    1.292      8.122 0.584 #> Stdev for Difference 0.168 0.095      0.045    0.148      0.407 0.110 #>  #> Deviance Information Criterion (DIC) ...............: 590.66 #> Deviance Information Criterion (DIC, saturated) ....: NA #> Effective number of parameters .....................: -773.59 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 2693.39 #> Effective number of parameters .................: 637.12 #>  #> Marginal log-Likelihood:  -1204.94  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') summary(jfit) #> inlabru version: 2.7.0.9021 #> INLA version: 23.06.15 #> Components: #> Common: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L) #> Difference: main = spde(coordinates), group = exchangeable(1L), replicate = iid(1L) #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L) #> Likelihoods: #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common - Difference/2 #>   Family: 'cp' #>     Data class: 'SpatialPointsDataFrame' #>     Predictor: coordinates ~ Intercept + Common + Difference/2 #> Time used: #>     Pre = 1.44, Running = 70.1, Post = 0.15, Total = 71.7  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> Intercept -0.354 1.366     -3.032   -0.354      2.324 -0.354   0 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     2.939 0.616      1.941     2.87      4.352 2.718 #> Stdev for Common     2.048 0.349      1.462     2.01      2.830 1.939 #> Range for Difference 1.362 0.760      0.397     1.20      3.282 0.904 #> Stdev for Difference 0.173 0.105      0.041     0.15      0.437 0.105 #>  #> Deviance Information Criterion (DIC) ...............: 590.99 #> Deviance Information Criterion (DIC, saturated) ....: NA #> Effective number of parameters .....................: -773.32 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 2713.73 #> Effective number of parameters .................: 647.31 #>  #> Marginal log-Likelihood:  -1205.53  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_multilikelihood.html","id":"single-likelihood-version","dir":"Articles > Web","previous_headings":"","what":"Single-likelihood version","title":"LGCPs - Multiple Likelihoods","text":"particular model, can also rewrite problem single point process product domain space group. versions <= 2.7.0, integration domain numeric, convert group variable 0/1 variable, group_major <- group == \"major\". Plotting ratios exp(Common) exp(Difference) new fit old confirms results small numerical differences.","code":"fml.joint <- coordinates + group_major ~ Intercept + Common + (group_major - 0.5) * Difference gorillas$nests$group_major <- gorillas$nests$group == \"major\" lik_joint <- like(\"cp\",   formula = fml.joint,   data = gorillas$nests,   samplers = gorillas$boundary,   domain = list(     coordinates = gorillas$mesh,     group_major = c(0, 1)   ) ) jfit_joint <- bru(cmp, lik_joint,   options = list(     control.inla = list(int.strategy = \"eb\"),     bru_max_iter = 2   ) ) library(patchwork) pl.major <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit_joint$summary.random$Common$mean -       jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas$mesh,     mask = gorillas$boundary,     col = exp(jfit_joint$summary.random$Difference$mean -       jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_plotsampling.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - Plot sampling","text":"practical demonstrates use samplers argument lgcp, need use observed points sample plots survey region.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_plotsampling.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - Plot sampling","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_plotsampling.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - Plot sampling","text":"dataset list (see help(gorillas) details. Extract objects need list, convenience: gorillas data also contains plot sample subset covers 60% survey region.  plot survey, points within rectangles detected, also informative plot points (real plot survey , seen ).","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov sample <- gorillas$plotsample plotdets <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   geom_text(aes(label = sample$counts$count, x = sample$counts$x, y = sample$counts$y)) +   coord_fixed() +   labs(x = \"Easting\", y = \"Northing\") plot(plotdets) plotwithall <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(nests, pch = \"+\", cex = 4, color = \"blue\") +   geom_text(aes(label = sample$counts$count, x = sample$counts$x, y = sample$counts$y)) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   coord_fixed() +   labs(x = \"Easting\", y = \"Northing\") plot(plotwithall)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_plotsampling.html","id":"inference","dir":"Articles > Web","previous_headings":"","what":"Inference","title":"LGCPs - Plot sampling","text":"observed nest locations SpatialPointsDataFrame sample$nests, plots SpatialPolygonsDataFrame sample$plots. , using following SPDE setup: Fit LGCP model SPDE data using samplers= argument function lgcp( ): Plot density surface fitted model  Estimate integrated intensity lambda. compute overall integrated intensity, representative imagined new realisation point process, conditional expectation takes actually observed nests account, recognising complete information surveyed plots. Fit model full dataset (points gorillas$nests), get previous fit, kept . Plot intensity surface estimate integrated intensity plot look like :  values Lambda.empirical, Lambda, Lambda.close plot samples gave sufficient information overall prediction: Now, let’s compare results  understand reason differences posteriors abundance estimates?","code":"matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) ) cmp <- coordinates ~ my.spde(coordinates, model = matern)  fit <- lgcp(cmp, sample$nests, samplers = sample$plots, domain = list(coordinates = mesh)) pxl <- fm_pixels(mesh, mask = boundary, format = \"sp\") lambda.sample <- predict(fit, pxl, ~ exp(my.spde + Intercept)) lambda.sample.plot <- ggplot() +   gg(lambda.sample) +   gg(sample$plots) +   gg(boundary, col = \"yellow\") +   coord_fixed()  lambda.sample.plot Lambda <- predict(fit, fm_int(mesh, boundary), ~ sum(weight * exp(my.spde + Intercept))) Lambda.empirical <- predict(   fit,   rbind(     cbind(fm_int(mesh, boundary), data.frame(all = TRUE)),     cbind(fm_int(mesh, sample$plots), data.frame(all = FALSE))   ),   ~ (sum(weight * exp(my.spde + Intercept) * all) -     sum(weight * exp(my.spde + Intercept) * !all) +     nrow(sample$nests)) ) rbind(   Lambda,   Lambda.empirical ) fit.all <- lgcp(cmp, gorillas$nests,   samplers = gorillas$boundary,   domain = list(coordinates = mesh) ) lambda.all <- predict(fit.all, pxl, ~ exp(my.spde + Intercept)) Lambda.all <- predict(fit.all, fm_int(mesh, boundary), ~ sum(weight * exp(my.spde + Intercept))) rbind(   Lambda,   Lambda.empirical,   Lambda.all,   Lambda.all.empirical =     c(nrow(gorillas$nests), 0, rep(nrow(gorillas$nests), 3), rep(NA, 4)) ) #> Warning in rbind(deparse.level, ...): number of columns of result, 8, is not a #> multiple of vector length 9 of arg 4 #>       mean       sd   q0.025     q0.5   q0.975   median mean.mc_std_err #> 1 657.7217 51.38671 559.7668 652.2019 774.2544 652.2019        5.138671 #> 2 647.5517 35.24422 587.2376 648.6938 709.8401 648.6938        3.524422 #> 3 671.7567 25.17391 629.5282 669.1353 717.6747 669.1353        2.517391 #> 4 647.0000  0.00000 647.0000 647.0000 647.0000       NA              NA #>   sd.mc_std_err #> 1      3.978608 #> 2      2.100448 #> 3      1.504915 #> 4            NA library(patchwork) lambda.sample.plot + lambda.all.plot +   plot_layout(guides = \"collect\") &   theme(legend.position = \"left\") &   scale_fill_continuous(limits = range(c(0, 340)))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Point processes useful spatial data analysis wide applications ecology, epidemiology, seismology, computational neuroscience, etc. Residual analysis effective assessment method spatial point processes, commonly takes frequentist approach. vignette, calculate residuals models https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html using Bayesian approach residual methods “Residual Analysis spatial point processes” (Baddeley et al).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"theory-of-residuals-for-spatial-point-process-models","dir":"Articles > Web","previous_headings":"","what":"Theory of Residuals for Spatial point process models","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider spatial point pattern \\(\\mathbf{x} = \\{x_1, \\dots, x_n \\}\\) \\(n\\) points bounded region \\(W\\) \\(\\mathbb{R}^2\\). model spatial point process \\(\\mathbf{X}\\) probability density \\(f_{\\theta}\\) parameter \\(\\theta\\), innovation process model defined \\[\\begin{equation}\\label{eq:innovations}     I_{\\theta}(B) = n(\\mathbf{X} \\cap B) - \\int_B \\lambda_{\\theta} (u) \\, du \\end{equation}\\] , \\(\\int_B \\lambda_{\\theta}(u) \\, du\\) expected number points fitted model bounded subset \\(B\\). Innovations satisfy \\(\\mathbb{E}_{\\theta} \\left[ I_{\\theta}(B)\\right] = 0\\) . Given data \\(\\mathbf{x}\\) model parameter estimate \\(\\hat{\\theta}\\), raw residuals given \\[\\begin{equation}\\label{eq:raw residuals}     R_{\\hat{\\theta}}(B) = n(\\mathbf{x} \\cap B) - \\int_B \\hat{\\lambda}(u) \\,du \\end{equation}\\] Increments innovation process \\(\\) raw residuals Poisson processes \\(R\\) analogous errors raw residuals linear models respectively.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"types-of-residuals","dir":"Articles > Web","previous_headings":"Theory of Residuals for Spatial point process models","what":"Types of Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"can scale raw residual scaling increments \\(R_{\\hat{\\theta}}\\). \\ \\(h\\)-weighted innovations given \\[\\begin{equation}\\label{eq:h innovations}     (B, h, \\lambda) = \\sum_{x_i \\\\mathbf{X} \\cap B} h(x_i) -     \\int_B h(u) \\lambda(u) \\,du \\end{equation}\\] leads \\(h\\)-weighted residuals \\[\\begin{equation} \\label{eq:h residuals}     R(B, \\hat{h}, \\hat{\\theta}) = (B, \\hat{h}, \\hat{\\lambda}) =     \\sum_{x_i \\\\mathbf{x} \\cap B} h(x_i) - \\int_B \\hat{h}(u) \\hat{\\lambda}(u)\\,du \\end{equation}\\] Since innovation mean 0, true model yield \\[ \\mathbb{E}\\left[R(B, \\hat{h}, \\hat{\\theta})\\right] \\approx 0. \\] Changing choice weight function \\(h\\), yields different types residuals.","code":""},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"pearson-residuals","dir":"Articles > Web","previous_headings":"Theory of Residuals for Spatial point process models > Types of Residuals","what":"Pearson Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":", zero values \\(\\hat{\\lambda}(u)\\) cause issues calculating residuals set \\(\\hat{h}(u) \\hat{\\lambda}(u) = \\sqrt{\\hat{\\lambda}(u)}\\) \\(u\\). three types residuals : \\[\\begin{eqnarray} \\text{Scaled:} \\qquad & R(B, \\hat{h}, \\hat{\\theta}) & = n(\\mathbf{x} \\cap B) - \\int_B \\hat{\\lambda}(u) \\,du \\\\ \\text{Inverse:} \\qquad & R\\left(B, \\frac{1}{\\hat{\\lambda}}, \\hat{\\theta}\\right) & = \\sum_{x_i \\\\mathbf{x} \\cap B} \\frac{1}{\\hat{\\lambda}(x_i)} - \\int_B \\mathbf{1} \\{ x_i \\\\mathbf{x} \\} \\,du \\\\ \\text{Pearson:} \\qquad &  R\\left( B, \\frac{1}{\\sqrt{\\hat{\\lambda}}},\\hat{\\theta} \\right) & = \\sum_{x_i \\\\mathbf{x} \\cap B} \\frac{1}{\\sqrt{\\hat{\\lambda}(x_i)}} - \\int_B \\sqrt{\\hat{\\lambda}(u)} \\,du \\end{eqnarray}\\] Note \\(\\hat{\\lambda}(u)\\) \\(\\hat{h}(u)\\) estimates \\(\\lambda (u)\\) \\(h(u)\\) respectively","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"motivation-for-choice-of-residuals","dir":"Articles > Web","previous_headings":"Theory of Residuals for Spatial point process models","what":"Motivation for choice of residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"scaling residuals nothing raw residuals hence depict residual data . However, Pearson residuals use weighted function \\(h(u) = \\frac{1}{\\lambda(u)}\\) helps obtain normalised residuals since denominator accounts variance residuals hence makes reliable sample size. use inverse residual project less clear. However, know easier compute residual since GNZ formula estimate value $h(u) = value \\(\\lambda(u)\\). notation’s sake discussion, let \\(h_{s}(u), h_{}(u), h_p(u)\\) indicate weight function scaling, inverse Pearson residuals respectively. , \\(h_s(u) = \\mathbf{1}\\{u \\B\\}, h_i(u) = \\frac{1}{\\lambda(u)}, h_p(u) = \\frac{1}{\\sqrt{\\lambda(u)}}\\). can also see \\(h_s(u) = \\left(h_i(u)\\right)^0\\) \\(h_p(u) = \\left(h_i(u)\\right)^{1/2}\\), values Pearson residuals lie somewhere two residuals. , case, inverse residuals useful, find easier compute hand terms estimates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"computation-of-residuals","dir":"Articles > Web","previous_headings":"","what":"Computation of Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"vignette, residuals models https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html computed using Bayesian approach residuals described . done using inlabru package. models used : Model 1 (Vegetation Model): model defined gorilla nests vegetation type fixed covariate. Model 2 (Elevation Model): model defined gorilla nests elevation continuous variable. Model 3 (Intercept Model): model defined gorilla nests constant effect. Model 4 (SPDE Smooth type model): model defined gorilla nests depend SPDE type smooth function. functions used calculate residuals models given Code appendix end vignette.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"loading-gorillas-data","dir":"Articles > Web","previous_headings":"Computation of Residuals","what":"Loading gorillas data","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"vignette uses gorillas dataset “inlabru” package R modelling spatial Poisson processes. , ``inlabru” package uses Latent Gaussian Cox Processes model data using different model definitions. Initially, set \\(B\\) defines \\(B=W\\), \\(W\\) object boundary. function prepare_residual_calculations() defined compute data frame observations \\(x_i\\) sample points \\(u \\W\\) compute residual, matrix A_sum helps calculate summation term residual matrix A_integrate helps calculate integral term residual. function residual_df defined compute three types residuals given model choice \\(B\\) given set observations.","code":"# Load data data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov # Define the subset B B <- boundary  # Store the required matrices and data frames for residual computation As <- prepare_residual_calculations(   samplers = B, domain = mesh,   observations = nests )"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"vegetation-model","dir":"Articles > Web","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Vegetation Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model taken https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html . model defined gorilla nests vegetation type fixed covariate. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed \\(B = W\\).  Note: data frame produced residual_df() originally contains columns Type, mean.mc_std_err, sd.mc_std_err median removed tables vignette highlight essential non-recurring data. editing data frames done function edit_df.","code":"# Define the vegetation model comp1 <- coordinates ~   vegetation(gcov$vegetation, model = \"factor_contrast\") + Intercept(1)  fit1 <- lgcp(comp1, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int1 <- predict(fit1,   newdata = fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(vegetation + Intercept) ) ggplot() +   gg(int1) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") +   coord_equal() ## Regions defined for each Polygons # Calculate the residuals for the vegetation model veg_res <- residual_df(   fit1, As$df, expression(exp(vegetation + Intercept)),   As$A_sum, As$A_integrate ) knitr::kable(edit_df(veg_res, c(\"Type\", \"mean.mc_std_err\", \"sd.mc_std_err\", \"median\")))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"elevation-model","dir":"Articles > Web","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Elevation model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html . model defined gorilla nests elevation continuous variable. code chunk shows model defined lgcp() also displays model form plot.  residuals model \\(B = W\\) given :","code":"# Define the Elevation model comp2 <- coordinates ~ elev(elev, model = \"linear\") +   mySmooth(coordinates, model = matern) + Intercept(1)  fit2 <- lgcp(comp2, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int2 <- predict(   fit2,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(elev + mySmooth + Intercept) ) ggplot() +   gg(int2) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") +   coord_equal() ## Regions defined for each Polygons"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"intercept-model","dir":"Articles > Web","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Intercept Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html . model defined gorilla nests constant effect. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed \\(B = W\\).  residuals model \\(B = W\\) given :","code":"# Define the Intercept model comp3 <- coordinates ~ Intercept(rep(1, nrow(.data.))) fit3 <- lgcp(comp3, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int3 <- predict(   fit3,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(Intercept) ) ggplot() +   gg(int3) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") +   coord_equal() ## Regions defined for each Polygons"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"smooth-model","dir":"Articles > Web","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Smooth Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_covars.html . model defined gorilla nests depend SPDE type smooth function. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed \\(B = W\\).  residuals model \\(B = W\\) given :","code":"# Define the Smooth model comp4 <- coordinates ~ mySmooth(coordinates, model = matern) +   Intercept(1) fit4 <- lgcp(comp4, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int4 <- predict(   fit4,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(mySmooth + Intercept) ) ggplot() +   gg(int4) +   gg(boundary) +   gg(nests, shape = \"+\") +   coord_equal() ## Regions defined for each Polygons"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"comparing-models","dir":"Articles > Web","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Comparing models","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Firstly, plots four models, see visual similarities Elevation smooth models appear . , expect two models show similar trends residuals.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"redefining-the-set-b","dir":"Articles > Web","previous_headings":"Computation of Residuals","what":"Redefining the set B","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider defining new type set \\(B\\) consists two subpolygons within boundary. done partition() function divides polygon grids based number rows columns desired resolution. code chunk demonstrates use function dividing polygon calculating residuals choice \\(B\\).  , can seen two lines residual data type residual. signifies residual_df function calculated residuals partition. compare residuals effectively, function residual_plot() defined plots residuals corresponding polygon B. discussed later vignette. Another type partitioning considered three sections region residuals displayed :","code":"# Create a grid for B partitioned into two B1 <- partition(samplers = boundary, nrows = 1, ncols = 2) plot(B1, main = \"Two partitions of B\") As1 <- prepare_residual_calculations(   samplers = B1, domain = mesh,   observations = nests ) # Residuals for the vegetation model veg_res2 <- residual_df(   fit1, As1$df, expression(exp(vegetation + Intercept)),   As1$A_sum, As1$A_integrate ) knitr::kable(edit_df(veg_res2, c(   \"Type\", \"mean.mc_std_err\",   \"sd.mc_std_err\", \"median\" )))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"residuals-of-models-at-different-resolutions","dir":"Articles > Web","previous_headings":"Computation of Residuals","what":"Residuals of models at different resolutions","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider two resolutions \\(B\\), given plots . use resolution argument instead nrow ncol. Due way terra::rast() interprets arguments, using resolution doesn’t guarantee complete coverage samplers polygon. Using two new choices \\(B\\), residuals calculated four models resolutions using residual_df(). functions set_csc() residual_plot() defined plot three types residuals model partition \\(B\\). code chunk demonstrates plotting done vegetation model resolution \\(B = B_3\\). , useful type residual colour scale resolutions.","code":"## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons # Residuals of Vegetation model Residual_fit1_B3 <- residual_df(   model = fit1, df = As3$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As3$A_sum,   A_integrate = As3$A_integrate )  Residual_fit1_B4 <- residual_df(   model = fit1, df = As4$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  # Colour scales for each model to cover both resolutions fit1_csc <- set_csc(rbind(Residual_fit1_B3, Residual_fit1_B4), rep(\"RdBu\", 3))  # Store plots plotB3_fit1 <- residual_plot(B3, Residual_fit1_B3, fit1_csc, \"Vegetation Model\") plotB4_fit1 <- residual_plot(B4, Residual_fit1_B4, fit1_csc, \"Vegetation Model\")  # comparing the vegetation model ((plotB3_fit1$Scaling | plotB3_fit1$Inverse | plotB3_fit1$Pearson) /   (plotB4_fit1$Scaling | plotB4_fit1$Inverse | plotB4_fit1$Pearson)) +   plot_annotation(title = \"Vegetation Model\") +   plot_layout(guides = \"collect\") &   theme(legend.position = \"bottom\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"comparing-different-types-of-residuals-for-each-model","dir":"Articles > Web","previous_headings":"Computation of Residuals > Residuals of models at different resolutions","what":"Comparing different types of residuals for each model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Now, plots help compare residuals model two resolutions \\(B\\) type residual.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"discussion","dir":"Articles > Web","previous_headings":"Computation of Residuals > Residuals of models at different resolutions > Comparing different types of residuals for each model","what":"Discussion","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"section, discuss findings output code. relevant point used repeatedly discussion since colour scales residuals chosen negative positive values hues red blue respectively, negative positive residuals imply overestimation underestimation gorilla nests model respectively. Thus, red regions plot imply overestimation gorilla nests model region blue regions plot imply underestimation gorilla nests model region. common observation models scaling residuals seem highest range among residuals since direct interpretations residuals models. Also, Pearson residuals seem take values scaling inverse residuals resolutions four models. However, almost types residuals model, positive negative residual values extreme \\(B_3\\) resolution corresponding residual values extreme \\(B_4\\) resolution type residual. bias ``experimental” mode explored points project. vegetation intercept model, regions negative positive residuals remain residuals different levels type residual. Also, seems north north-west region models underestimated model remaining regions overestimated model different levels. elevation model, type residual slight variations negative positive residuals corresponding regions fixed resolution. means different residuals suggest particular polygon overestimated underestimated model. However, happens points containing extremes residuals regions. Pearson residuals supposedly reliable case normalised residuals. three types residuals contain larger proportions negative residuals suggest model overestimates gorilla population region (different amounts different regions).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"comparing-different-models-for-each-type-of-residual","dir":"Articles > Web","previous_headings":"Computation of Residuals > Residuals of models at different resolutions","what":"Comparing different models for each type of residual","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Another way compare residuals, consider type residual separately plot residuals four models resolution. helps compare models given type residual choice \\(B\\). , useful colour scale 4 models. code chunk demonstrates code plotting “Pearson” residuals \\(B = B_4\\). Now, plots help compare 4 models particular choice \\(B\\) chosen residual type.","code":"## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons ## Regions defined for each Polygons # Calculate the residuals for all models at B4 Residual_fit1_B4 <- residual_df(   model = fit1, df = As4$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  Residual_fit2_B4 <- residual_df(   model = fit2, df = As4$df,   expr = expression(exp(elev + mySmooth + Intercept)),   A_sum = As4$A_sum, A_integrate = As4$A_integrate )  Residual_fit3_B4 <- residual_df(   model = fit3, df = As4$df,   expr = expression(exp(Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  Residual_fit4_B4 <- residual_df(   model = fit4, df = As4$df,   expr = expression(exp(mySmooth + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  # Set the colour scale B4res <- rbind(   Residual_fit1_B4, Residual_fit2_B4,   Residual_fit3_B4, Residual_fit4_B4 ) B4csc <- set_csc(B4res, rep(\"RdBu\", 3))  # Plots for residuals of all 4 models with resolution B4 plotB4_veg <- residual_plot(B4, Residual_fit1_B4, B4csc, \"Vegetation Model\") plotB4_elev <- residual_plot(B4, Residual_fit2_B4, B4csc, \"Elevation Model\") plotB4_int <- residual_plot(B4, Residual_fit3_B4, B4csc, \"Intercept Model\") plotB4_smooth <- residual_plot(B4, Residual_fit4_B4, B4csc, \"Smooth Model\")  # Comparing all models for B4 Pearson residuals ((plotB4_veg$Pearson | plotB4_elev$Pearson) /   (plotB4_int$Pearson | plotB4_smooth$Pearson)) +   plot_annotation(\"B4 Pearson Residuals\") +   plot_layout(guides = \"collect\") &   theme(legend.position = \"bottom\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"discussion-1","dir":"Articles > Web","previous_headings":"Computation of Residuals > Residuals of models at different resolutions > Comparing different models for each type of residual","what":"Discussion","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Firstly, common feature three figures residual plots vegetation intercept models relatively similar elevation smooth models relatively similar well resolutions type residual. Also, fixed type residual chosen model, \\(B_3\\) residuals less extreme compared \\(B_4\\) residuals, plausibly owing bias ``experimental” mode . Another feature three types residuals elevation intercept model less extreme residual values compared vegetation intercept models given type residual. suggest former two better models gorilla nesting given region. residual values wider range \\(B=B_4\\) \\(B = B_3\\). scaling residuals Pearson residuals, elevation smooth models less extreme values residuals relative vegetation intercept models. suggests elevation smooth models suited estimating gorilla nesting locations \\(W\\). Also, significant underestimation north-west areas vegetation intercept models areas underestimated two models. However, explored , residuals calculated ``experimental” mode produces overestimates two models, must kept mind reaching conclusions suitable model nesting locations. inverse residuals, observations hold, except residuals elevation smooth models residuals significantly less extreme relative vegetation intercept models seen case Pearson scaling residuals resolutions \\(B_3\\) \\(B_4\\).","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_residuals.html","id":"function-definitions","dir":"Articles > Web","previous_headings":"Code appendix","what":"Function definitions","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"","code":"# Niharika Reddy Peddinenikalva # Vacation Scholarship project  suppressPackageStartupMessages(library(\"INLA\")) suppressPackageStartupMessages(library(\"inlabru\")) suppressPackageStartupMessages(library(\"RColorBrewer\")) suppressPackageStartupMessages(library(\"ggplot2\")) suppressPackageStartupMessages(library(\"dplyr\")) suppressPackageStartupMessages(library(\"lwgeom\")) suppressPackageStartupMessages(library(\"patchwork\")) suppressPackageStartupMessages(library(\"terra\")) suppressPackageStartupMessages(library(\"data.table\")) theme_set(theme_bw())    #' ---------------------------------- #' prepare_residual_calculations #' ---------------------------------- #' #' Computes the A_sum, A_integrate matrices and the data frame used for #' calculating the residuals for the given set of polygons B  #' Input: #' @param samplers A SpatialPolygonDataFrame containing partitions for which #' residuals are to be calculated #' @param domain A mesh object #' @param observations A SpatialPointsDataFrame containing observed data #' #' Output: #' @return A_sum - matrix used to compute the summation term of the residuals #' @return A_integrate - matrix used to compute the integral term #' @return df - SpatialPointsDataFrame containing all the locations 'u' for #' calculating residuals #' prepare_residual_calculations <- function(samplers, domain, observations) {   # Calculate the integration weights for A_integrate   ips <- fm_int(domain = domain, samplers = samplers)    # Set-up the A_integrate matrix   # A_integrate has as many rows as polygons in the samplers,   # as many columns as mesh points   A_integrate <- inla.spde.make.A(mesh = domain, ips, weights = ips$weight,                                   block = ips$.block, block.rescale = \"none\")     # Set-up the A_sum matrix   # A_sum has as many rows as polygons in the samplers,   # as many columns as observed points   # each row has 1s for the points in the corresponding polygon   idx <- sf::st_within(sf::st_as_sf(observations), sf::st_as_sf(samplers), sparse = TRUE)   A_sum <- sparseMatrix(i = unlist(idx),                         j = rep(seq_len(nrow(observations)),                                 vapply(idx, length, 1L)),                         x = rep(1, length(unlist(idx))),                         dims = c(nrow(samplers), nrow(observations)))     # Setting up the data frame for calculating residuals   observations$obs <- TRUE   df <- SpatialPointsDataFrame(     coords = rbind(domain$loc[,1:2], coordinates(observations)),     data = bind_rows(data.frame(obs = rep(FALSE, domain$n)), observations@data),     proj4string = domain$crs)    # Return A-sum, A_integrate and the data frame for predicting the residuals   list(A_sum = A_sum, A_integrate = A_integrate, df = df) }    #' ------------ #' residual_df #' ------------ #' #' Computes the three types if residuals and returns a data frame containing #' information about all 3 residuals for each partition of 'B' #' #' Inputs: #' @param model fitted model for which residuals need to be calculated #' @param df SpatialPointsDataFrame object containing all the locations 'u' #' for calculating residuals #' @param expr an expression object containing the formula of the model #' @param A_sum matrix used to compute the summation term of the residuals #' @param A_integrate matrix that computes the integral term of the residuals #' #' Outputs: #' @return Data frame containing residual information for each of the #' partitions of the subset 'B' #'  residual_df <- function(model, df, expr, A_sum, A_integrate) {   # Compute residuals   res <- predict(object = model,                  newdata = df,                  ~{                    lambda <- eval(expr)                    h1 <- lambda * 0 + 1                    h2 <- 1 / lambda                    h3 <- 1 / sqrt(lambda)                    data.frame(                      Scaling_Residuals =                        as.vector(A_sum %*% h1[obs]) -                        as.vector(A_integrate %*% (h1 * lambda)[!obs]),                      Inverse_Residuals =                        as.vector(A_sum %*% h2[obs]) -                        as.vector(A_integrate %*% (h2 * lambda)[!obs]),                      Pearson_Residuals =                        as.vector(A_sum %*% h3[obs]) -                        as.vector(A_integrate %*% (h3 * lambda)[!obs])                    )                  },                  used = bru_used(expr)   )    # Label the three types of residuals   res$Scaling_Residuals$Type <- \"Scaling Residuals\"   res$Inverse_Residuals$Type <- \"Inverse Residuals\"   res$Pearson_Residuals$Type <- \"Pearson Residuals\"   do.call(rbind, res) }      #' -------------- #' set_csc #' -------------- #' #' Sets the colour scale for the three types of residuals #' #' Inputs: #' @param residuals frame containing residual information for each of the #' partitions of the subset 'B' #' @param col_theme vector of themes for each type of residual #' #' Outputs: #' @return a list of 3 colour scales for each type of residual #'  set_csc <- function(residuals, col_theme) {   # Store data for the colour scale of the plots for each type of residual   cscrange <- data.frame(residuals %>% group_by(Type) %>%                            summarise(maxabs=max(abs(mean))))    # Set the colour scale for all three types of residuals   scaling_csc <-     scale_fill_gradientn(colours = brewer.pal(9, col_theme[1]),                          name = \"Scaling Residual\",                          limits =                            cscrange[cscrange$Type == \"Scaling Residuals\", 2] *                            c(-1,1))    inverse_csc <-     scale_fill_gradientn(colours = brewer.pal(9, col_theme[2]),                          name = \"Inverse Residual\",                          limits =                            cscrange[cscrange$Type == \"Inverse Residuals\", 2] *                            c(-1,1))    pearson_csc <-     scale_fill_gradientn(colours = brewer.pal(9, col_theme[3]),                          name = \"Pearson Residual\",                          limits =                            cscrange[cscrange$Type == \"Pearson Residuals\", 2] *                            c(-1,1))    list(\"Scaling\" = scaling_csc, \"Inverse\" = inverse_csc, \"Pearson\" = pearson_csc) }    #' --------------- #' residual_plot #' --------------- #' #' plots the three types of residuals for each polygon #' #' Input: #' @param samplers A SpatialPolygonsDataFrame containing partitions for which #' residuals are to be calculated #' @param residuals frame containing residual information for each of the #' partitions of the subset 'B' #' @param csc list of three colour scales for the three types of residuals #' @param model_name string containing the name of the model being assessed #' #' Output: #' @return a list of three subplots scaling, inverse and Pearson residuals #' for the different partitions of samplers   residual_plot <- function(samplers, residuals, csc, model_name) {   # Initialise the scaling residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Scaling Residuals\") %>%     pull(mean)   scaling <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Scaling\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Scaling\"))    # Initialise the inverse residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Inverse Residuals\") %>%     pull(mean)   inverse <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Inverse\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Inverse\"))    # Initialise the Pearson residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Pearson Residuals\") %>%     pull(mean)   pearson <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Pearson\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Pearson\"))    # Return the three plots in a list   list(Scaling = scaling, Inverse = inverse,        Pearson = pearson) }     #' ------------------ #' partition #' ------------------ #' #' Partitions the region based on the given criteria for calculating residuals #' in each partition. Parts of this function are taken from concepts in #' https://rpubs.com/huanfaChen/grid_from_polygon #' #' Input: #' @param samplers A SpatialPolygonsDataFrame containing region for which #' partitions need to be created #' @param resolution resolution of the grids that are required #' @param nrows number of rows of grids that are required #' @param ncols number of columns of grids that are required #' #' Output: #' @return a partitioned SpatialPolygonsDataFrame as required #' #' partition <- function(samplers, resolution = NULL, nrows = NULL, ncols = NULL) {   # Create a grid for the given boundary   if (is.null(resolution)) {     grid <- rast(terra::ext(samplers), crs = proj4string(samplers),                    nrows = nrows, ncols = ncols)   }    if (is.null(c(nrows, ncols))) {     grid <- rast(terra::ext(samplers), crs = proj4string(samplers),                  resolution = resolution)    }    gridPolygon <- terra::as.polygons(grid)    # Extract the boundary with subpolygons only   sf::as_Spatial(sf::st_as_sf(terra::intersect(gridPolygon, terra::vect(samplers)))) }   #' ------------------ #' edit_df #' ------------------ #' #' Edits the residual data frames to remove columns that need not be displayed #' #' Input: #' @param df the data frame which needs to be edited #' @param columns a vector of columns that need to be deleted from df #' #' Output: #' @return the edited data frame with only the desired columns #' #' edit_df <- function(df, columns) {   # Remove the columns that are not required   df[, !(colnames(df) %in% columns)]  }"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_spatiotemporal.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"LGCPs - An example in space and time","text":"vignette going working dataset obtained R package MRSea. set LGCP spatio-temporal SPDE model estimate species distribution.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_spatiotemporal.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in space and time","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2) sp::set_evolution_status(2L)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_spatiotemporal.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"LGCPs - An example in space and time","text":"Load dataset, coordinates UTM kilometres: points (representing animals) sampling regions dataset associated season. Let’s look observed points sampling regions seasons:","code":"data(mrsea, package = \"inlabru\") ggplot() +   gg(mrsea$mesh) +   gg(mrsea$boundary) +   gg(mrsea$samplers) +   gg(mrsea$points, size = 0.5) +   coord_fixed() +   facet_wrap(~season) +   ggtitle(\"MRSea observation seasons\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_spatiotemporal.html","id":"integration-points","dir":"Articles > Web","previous_headings":"","what":"Integration points","title":"LGCPs - An example in space and time","text":"inlabru point process model knows construct numerical integration scheme LGCP likelihood. can also call internal functions directly see integration scheme look like. model take time (season) account construct integration points LGCP accordingly. Using fm_int() can specify product domain space. Note omitting step simply aggregate sampling regions time. Plot integration points:","code":"ips <- fm_int(   domain = list(coordinates = mrsea$mesh, season = 1:4),   samplers = mrsea$samplers ) ggplot() +   gg(mrsea$mesh) +   gg(ips, aes(size = weight)) +   scale_size_area(max_size = 1) +   facet_wrap(~season) +   coord_fixed()"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_spatiotemporal.html","id":"fitting-the-model","dir":"Articles > Web","previous_headings":"","what":"Fitting the model","title":"LGCPs - An example in space and time","text":"Fit LGCP model locations animals. example employ spatio-temporal SPDE. Note group ngroup parameters employed let SPDE model know name time dimension (season) total number distinct points time. Predict plot intensity seasons:","code":"matern <- inla.spde2.pcmatern(mrsea$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(10, 0.01) )  cmp <- coordinates + season ~ Intercept(1) +   mySmooth(     coordinates,     model = matern,     group = season,     ngroup = 4   )  fit <- lgcp(cmp,   data = mrsea$points,   samplers = mrsea$samplers,   domain = list(     coordinates = mrsea$mesh,     season = seq_len(4)   ) ) ppxl <- fm_pixels(mrsea$mesh, mask = mrsea$boundary, format = \"sp\") ppxl_all <- fm_cprod(ppxl, data.frame(season = seq_len(4)))  lambda1 <- predict(   fit,   ppxl_all,   ~ data.frame(season = season, lambda = exp(mySmooth + Intercept)) ) pl1 <- ggplot() +   gg(as(lambda1, \"SpatialPixelsDataFrame\"), aes(fill = q0.5)) +   gg(mrsea$points, size = 0.3) +   facet_wrap(~season) +   coord_equal() pl1"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/Apptainer.html","id":"installation-procedures","dir":"Articles > Web","previous_headings":"","what":"Installation Procedures","title":"Installation of INLA and inlabru with Apptainer on HPC","text":"Check Apptainer available HPC. , ask administrator install . Type HPC terminal check version installed. Type code pull rocker/geospatial Singularity Image Format (SIF) file latest R version. illustration, ’ll assume file stored ./your_container.sif. Put following job script execute R file non-interactively. Note: Use inla.setOption(num.threads = ncpu) limit number threads (ncpu) since INLA set automatically. ncpu also directly links RAM requirements.","code":"$ apptainer version # To pull the docker image  $ apptainer pull your_container.sif docker://rocker/geospatial:latest # once the sif is downloaded, get into an interactive shell  $ apptainer shell your_container.sif # Inside the interactive shell, one can install INLA on a personal library path $ R --verbose  # Now, in a R environment > options(repos = c(     INLA = 'https://inla.r-inla-download.org/R/testing',     CRAN = 'https://cloud.r-project.org')) > install.packages(\"INLA\")  # One may be asked to create a personal library path. > install.packages(\"inlabru\")  # quit R > q() # To execute an R file with apptainer $ apptainer exec ./your_container.sif Rscript --no-restore --no-save --verbose file_to_run.R"},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/web/devel_flow.html","id":"component-input-evaluation","dir":"Articles > Web","previous_headings":"","what":"Component input evaluation","title":"Devel: Model evaluation flowchart","text":"<label> main, group, replicate, weights, given expression expr evaluated data context, producing input component mapper. spatial covariate inputs, corresponding <label>_layer expression also evaluated. Red nodes indicate deprecated behaviour retained backwards compatibility.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/devel_flow.html","id":"intergration-point-construction","dir":"Articles > Web","previous_headings":"","what":"Intergration point construction","title":"Devel: Model evaluation flowchart","text":"Classic integration structure Flow diagram new integration scheme construction, implemented fm_int(domain, samplers) methods.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"traditional INLA code involving inla.mesh objects inla.spde models, inla.spde.make.() function used construct component design matrix maps spatial/spatio-temporal locations latent variables associated mesh basis functions. 2-manifold meshes, flat spherical meshes, implementation one latent variable per mesh node, linked piecewise linear basis functions mesh triangles. 1-manifolds intervals cyclic domains, piecewise linear piecewise quadratic basis functions supported. inla.spde.make.() interface supports variety features, can broken simple building blocks. inlabru bru_mapper system, building blocks easily customised specific uses, aren’t necessarily connected spde models, block feature used aggregate rows design matrix, e.g. construct numerical integration schemes. haven’t already, go read bru_mapper vignette information various bru_mapper classes methods. come back continue.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"converting-the-basic-inla-spde-make-a-calls-into-mappers","dir":"Articles > Web","previous_headings":"","what":"Converting the basic inla.spde.make.A calls into mappers","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"basic inla.spde.make.call map purely spatial points mesh:  basic conversion becomes limited just basic case evaluating mesh. bru_mapper, becomes generally useful","code":"mesh <- inla.mesh.2d(cbind(0, 0), offset = 2, max.edge = 10) loc <- matrix(runif(10) * 2 - 1, 5, 2) ggplot() +   gg(mesh) +   geom_point(aes(loc[, 1], loc[, 2])) +   coord_equal() A.loc <- inla.spde.make.A(mesh, loc = loc) A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631 A.loc <- fm_evaluator(mesh, loc = loc)$proj$A A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631 mapper <- bru_mapper(mesh) A.loc <- ibm_jacobian(mapper, input = loc) A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"mapping-with-a-precomputed-location-mapping","dir":"Articles > Web","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Mapping with a precomputed location mapping","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"","code":"index <- c(1, 3, 5, 2, 1, 2) inla.spde.make.A(A.loc = A.loc, index = index) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120  mapper <- bru_mapper_taylor(jacobian = A.loc[index, , drop = FALSE]) ibm_jacobian(mapper) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120  # For run-time indexing: mapper <-   bru_mapper_pipe(     list(       matrix = bru_mapper_taylor(jacobian = A.loc),       index = bru_mapper_index(nrow(A.loc))     )   ) ibm_jacobian(mapper, input = list(index = index)) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"group-mapping-with-a-group-mesh","dir":"Articles > Web","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Group mapping with a group mesh","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"","code":"inla.spde.make.A(..., group = group.values, group.mesh = group.mesh)  mapper <- bru_mapper_multi(list(   main = bru_mapper(mesh),   group = bru_mapper(group.mesh) )) ibm_jacobian(mapper, input = list(main = loc, group = group.values))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"blockwise-aggregation","dir":"Articles > Web","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Blockwise aggregation","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"Blockwise aggregation can implemented bru_mapper_aggregate mapper. Rescaling options: block_rescale = \"none\" corresponds rescale = FALSE block_rescale = \"count\" corresponds rescale = TRUE providing weights, interpreted weights 1, rescaling sum weights equivalent dividing number elements block. block_rescale = \"weights\" corresponds rescale = TRUE block_rescale = \"sum\" supported aggregation mapper.","code":"block_rescale <- \"none\" # one of \"none\", \"count\", \"weights\", \"sum\" inla.spde.make.A(...,   weights = weights,   block = block,   block.rescale = block_rescale,   n.block = n_block ) mapper <- bru_mapper_pipe(   list(     main = bru_mapper_multi(list(main = bru_mapper(mesh), ...)),     block = bru_mapper_aggregate(       rescale = (block_rescale != \"none\"),       n_block = n_block     )   ) ) ibm_jacobian(mapper,   input = list(     main = list(main = loc),     block = list(block = block, weights = weights)   ) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/mesh_mapping.html","id":"inla-spde-make-index","dir":"Articles > Web","previous_headings":"","what":"inla.spde.make.index","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"benefit mapper approach encapsulates information, mapper needs carried around code needs , doesn’t restrict group replicate mappings integer indices; index mappers can replaced mappers, e.g. allow interpolation group indices, 1d mesh mapper.","code":"ngroup <- 2 nrepl <- 3  summary(   as.data.frame(     inla.spde.make.index(\"field\",       n.spde = mesh$n,       n.group = ngroup,       n.repl = nrepl     )   ) ) #>      field    field.group    field.repl #>  Min.   :1   Min.   :1.0   Min.   :1    #>  1st Qu.:3   1st Qu.:1.0   1st Qu.:1    #>  Median :5   Median :1.5   Median :2    #>  Mean   :5   Mean   :1.5   Mean   :2    #>  3rd Qu.:7   3rd Qu.:2.0   3rd Qu.:3    #>  Max.   :9   Max.   :2.0   Max.   :3  mapper <- bru_mapper_multi(list(   field.main = bru_mapper(mesh),   field.group = bru_mapper_index(ngroup),   field.replicate = bru_mapper_index(nrepl) )) summary(ibm_values(mapper, multi = TRUE, inla_f = TRUE)) #>    field.main  field.group  field.replicate #>  Min.   :1    Min.   :1.0   Min.   :1       #>  1st Qu.:3    1st Qu.:1.0   1st Qu.:1       #>  Median :5    Median :1.5   Median :2       #>  Mean   :5    Mean   :1.5   Mean   :2       #>  3rd Qu.:7    3rd Qu.:2.0   3rd Qu.:3       #>  Max.   :9    Max.   :2.0   Max.   :3"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/publications.html","id":"articles","dir":"Articles > Web","previous_headings":"","what":"Articles","title":"Publications","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168. Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whales, Annals Applied Statistics, 11, 2270–2297, doi:10.1214/17-AOAS1078, [arXiv, PDF].","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/publications.html","id":"presentations","dir":"Articles > Web","previous_headings":"","what":"Presentations","title":"Publications","text":"F. E. Bachl @ TIES/GRASPA 2017 Conference Climate Ecology, Bergamo, Italy, July 24-26inlabru: Bayesian modeling point procesanalysis ecological data beyond [Abstract, Slides] D. L. Borchers @ South African Statistical Association Conference, Cape Town, South Africa, 28th Nov 1st DecWildlife Survey Models: Thinned spatial point processes unknown thinning probabilities [Slides] F. E. Bachl @ Autumn meeting latent Gaussian Models, Trondheim, Norway, September 17-18Live inlabru demo [HTML, R] F. E. Bachl @ Fifth Workshop Bayesian Inference Latent Gaussian Models Applications, Bath, UK, 14-16 September 2016Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ Smoegen Workshop, Smoegen, August 15-18 2016 Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ NOAA San Diego, USA, August 2016Spatial point process models distance sampling surveys animals occur groups [Slides] D. L. Borchers @ International Environmetrics Society Conference 2016, Edinburgh, UK, 18-22 July 2016 Wildlife survey models: thinned spatial point processes unknown thinning probabilities Y. Yuan @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Poster: Point process models spatio-temporal distance sampling data [Abstract] F. E. Bachl @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Spatial point process models distance sampling surveys animals occur groups [Abstract, Slides] Y. Yuan @ National Centre Statistical Ecology Conference, Falmouth, UK, July 2015Spatial point process models distance sampling data Y. Yuan @ Spatial Statistics, Emerging Patterns, Avignon, France, June 2015Spatial point process models distance sampling data","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"Random Fields in One Dimension","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"get-the-data","dir":"Articles > Web","previous_headings":"","what":"Get the data","title":"Random Fields in One Dimension","text":"Put count data cd (just ‘cd’ less type ‘countdata2’.) Take look count data.  Tip: RStudio > Help > Cheatsheets > Data visualisation ggplot2 useful reference ggplot2 syntax.","code":"data(Poisson2_1D) cd <- countdata2 cd #>            x count exposure #> 1   2.319888     9 4.639776 #> 2   6.959664    13 4.639776 #> 3  11.599439    11 4.639776 #> 4  16.239215    22 4.639776 #> 5  20.878991    20 4.639776 #> 6  25.518766    19 4.639776 #> 7  30.158542    16 4.639776 #> 8  34.798318     8 4.639776 #> 9  39.438093     4 4.639776 #> 10 44.077869     4 4.639776 #> 11 48.717645     4 4.639776 ggplot(cd) +   geom_point(aes(x, y = count)) +   ylim(0, max(cd$count))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"fitting-a-generalised-additive-model-gam","dir":"Articles > Web","previous_headings":"","what":"Fitting a Generalised Additive Model (GAM)","title":"Random Fields in One Dimension","text":"’re familiar GAMs syntax gam don’t worry, point just provide something can compare inlabru model fit. term s(x,k=10) just specifies nonparametric smooth function fitted data, 10 degrees freedom (df). (larger df, wiggly fitted curve (recall lecture effect spline methods defined, without discretisation dependent penalty); gam selects ‘best’ df.) Notice use offset=. (Refer slides explanation offset.) variable exposure data frame cd size bin count made. can look fitted model using summary( ) want , need understand output, code makes predictions immediately familiar GAMs. Make prediction data frame, get predictions add data frame First make vectors x-values associated (equal) exposures: put data frame: predict Ploting fit data using ggplot2 commands give plot shown ","code":"fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd) summary(fit2.gam) xs <- seq(0, 55, length = 100) exposures <- rep(cd$exposure[1], 100) dat4pred <- data.frame(x = xs, exposure = exposures) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # add column for prediction in data frame ggplot(dat4pred2) +   geom_line(aes(x = x, y = gam), lty = 2) +   ylim(0, max(dat4pred2$gam, cd$count)) +   geom_point(aes(x = x, y = count), cd)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"fitting-an-spde-model-with-inlabru","dir":"Articles > Web","previous_headings":"","what":"Fitting an SPDE model with inlabru","title":"Random Fields in One Dimension","text":"Make mesh. avoid boundary effects region interest, let mesh extend outside data range. … see mesh points :","code":"x <- seq(-10, 65, by = 1) # this sets mesh points - try others if you like mesh1D <- inla.mesh.1d(x, boundary = \"free\") ggplot() +   gg(mesh1D)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"using-function-bru-to-fit-to-count-data","dir":"Articles > Web","previous_headings":"Fitting an SPDE model with inlabru","what":"Using function bru( ) to fit to count data","title":"Random Fields in One Dimension","text":"need specify model components model formula order fit . can done inside call bru( ) bit messy, ’ll store comp first pass bru( ). response variable data frame cd called count model specification needs left ~. add intercept component + Intercept(1) right hand side (models use intercepts), want fit Gaussian random field (GRF), must GRF specification. inlabru GRF specification function, allows GRF calculated point space inlabru calculations. user gets name GRF function. syntax ‘myname(input, model= …)’, : ‘myname’ whatever want call GRF (called field ); input specifies coordinates GRF SPDE ‘lives’. working one dimension, called dimension x set data set. model= designates type effect, SPDE model object INLA function inla.spde2.pcmatern( ), requires mesh passed , pass 1D mesh created , `mesh1D. models adds model components, don’t need specify full predictor formula. Instead, can provide name output left ~ component specification, “.” right hand side, cause add components (unless subset selected via include/exclude arguments like()). Predict values x points used mesh (data argument must data frame, see ?predict.bru): Let’s plot compare fitted model true model. expected counts true model stored variable E_nc2 comes dataset Poisson2_1D. ease use plotting ggplot2 (needs data frame), create data frame call true.lambda, containing x- y variables shown . Given inlabru predictions always intensity function scale, understand divide count cd$exposure? (due course allow predictions count scale well.) ggplot2 commands generate plot shown . shows true intensities short horizontal blue lines, observed intensities black dots, fitted intensity function red curve, 95% credible intervals shown light red band curve.  Compare inlabru fit gam fit:","code":"the_spde <- inla.spde2.pcmatern(mesh1D,   prior.range = c(1, 0.01),   prior.sigma = c(1, 0.01) )  comp <- ~ field(x, model = the_spde) + Intercept(1, prec.linear = 1 / 2^2)  fit2.bru <- bru(   comp,   like(count ~ .,     data = cd,     family = \"poisson\",     E = exposure   ) )  summary(fit2.bru) #> inlabru version: 2.7.0.9021 #> INLA version: 23.06.15 #> Components: #> field: main = spde(x), group = exchangeable(1L), replicate = iid(1L) #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L) #> Likelihoods: #>   Family: 'poisson' #>     Data class: 'data.frame' #>     Predictor: count ~ . #> Time used: #>     Pre = 1.33, Running = 0.348, Post = 0.223, Total = 1.9  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode   kld #> Intercept 1.014 0.761     -0.004    0.862      3.413 0.825 0.001 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant   mode #> Range for field 34.543 23.136       9.71   28.529     95.914 20.078 #> Stdev for field  0.519  0.164       0.27    0.496      0.907  0.451 #>  #> Deviance Information Criterion (DIC) ...............: 60.05 #> Deviance Information Criterion (DIC, saturated) ....: 14.40 #> Effective number of parameters .....................: 5.47 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 58.20 #> Effective number of parameters .................: 2.83 #>  #> Marginal log-Likelihood:  -36.81  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') x4pred <- data.frame(x = xs) pred2.bru <- predict(fit2.bru, x4pred, x ~ exp(field + Intercept), n.samples = 1000) true.lambda <- data.frame(x = cd$x, y = E_nc2 / cd$exposure) ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_point(data = true.lambda, aes(x, y), pch = \"_\", cex = 9, col = \"blue\") +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\") ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure), lty = 2) +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields.html","id":"looking-at-the-posterior-distributions","dir":"Articles > Web","previous_headings":"Fitting an SPDE model with inlabru","what":"Looking at the posterior distributions","title":"Random Fields in One Dimension","text":"can look Intercept posterior using function plot( ), .  know variable called Intercept order use function. see fixed effect parameters’ posterior distributions available plotted, can type tell SPDE parameters, type just tells SPDE fit2.bru called ‘field’, tell associated parameter names . parameters used estimation cryptic – interested range variance Matern covariance funcion, functions internal parameters. can look posterior distributions range parameter log variance parameters follows. (look posterior log variance variance posterior skewed easier view log variance)  can look posterior distributions Matern correlatioin covariance funcitons follows:","code":"plot(fit2.bru, \"Intercept\") names(fit2.bru$marginals.fixed) names(fit2.bru$marginals.random) #> [1] \"field\" spde.range <- spde.posterior(fit2.bru, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit2.bru, \"field\", what = \"log.variance\")  range.plot <- plot(spde.range) var.plot <- plot(spde.logvar) multiplot(range.plot, var.plot) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.correlation\")) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.covariance\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields_2d.html","id":"setting-things-up","dir":"Articles > Web","previous_headings":"","what":"Setting things up","title":"Random Fields in 2D","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) library(sp) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields_2d.html","id":"modelling-on-2d-domains","dir":"Articles > Web","previous_headings":"","what":"Modelling on 2D domains","title":"Random Fields in 2D","text":"now construct 2D model, generate sample random field, attempt recover field observations locations. Tomorrow, look general mesh constructions adapt irregular domains. First, build high resolution mesh true field, using low level INLA functions  pointwise standard deviation field? Along straight boundaries, variance twice target variance. corners variance 4 times large.  Generate sample model:   Extract observations random locations:","code":"bnd <- spoly(data.frame(easting = c(0, 10, 10, 0), northing = c(0, 0, 10, 10))) mesh_fine <- inla.mesh.2d(boundary = bnd, max.edge = 0.2) ggplot() +   gg(mesh_fine) +   coord_equal() # Note: the priors here will not be used in estimation matern_fine <-   inla.spde2.pcmatern(mesh_fine,     prior.sigma = c(1, 0.01),     prior.range = c(1, 0.01)   ) true_range <- 4 true_sigma <- 1 true_Q <- inla.spde.precision(matern_fine, theta = log(c(true_range, true_sigma))) true_sd <- diag(inla.qinv(true_Q))^0.5 ggplot() +   gg(mesh_fine, col = true_sd) +   coord_equal() true_field <- inla.qsample(1, true_Q)[, 1]  truth <- expand.grid(   easting = seq(0, 10, length = 100),   northing = seq(0, 10, length = 100) ) truth$field <- fm_evaluate(   mesh_fine,   loc = as.matrix(truth),   field = true_field ) coordinates(truth) <- c(\"easting\", \"northing\") truth <- as(truth, \"SpatialPixelsDataFrame\")  pl_truth <- ggplot() +   gg(truth, mapping = aes(easting, northing, fill = field)) +   coord_equal() +   ggtitle(\"True field\") pl_truth ## Or with another colour scale: csc <- colsc(truth$field) multiplot(pl_truth, pl_truth + csc, cols = 2) n <- 200 mydata <- data.frame(easting = runif(n, 0, 10), northing = runif(n, 0, 10)) mydata$observed <-   fm_evaluate(     mesh_fine,     loc = as.matrix(mydata),     field = true_field   ) +   rnorm(n, sd = 0.4) coordinates(mydata) <- c(\"easting\", \"northing\") ggplot() +   gg(mydata, aes(col = observed))"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/random_fields_2d.html","id":"estimating-the-field","dir":"Articles > Web","previous_headings":"","what":"Estimating the field","title":"Random Fields in 2D","text":"Construct mesh covering data:  Construct SPDE model object Matern model: Specify model components: Fit model inspect results: Predict field lattice, generate single realisation posterior distribution: Compare truth estimated field (posterior mean sample posterior distribution):  Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object pred).","code":"mesh <- inla.mesh.2d(boundary = bnd, max.edge = 0.5) ggplot() +   gg(mesh) +   coord_equal() matern <-   inla.spde2.pcmatern(mesh,     prior.sigma = c(10, 0.01),     prior.range = c(1, 0.01)   ) cmp <- observed ~ field(coordinates, model = matern) + Intercept(1) fit <- bru(cmp, mydata, family = \"gaussian\") summary(fit) pix <- fm_pixels(mesh, nx = 200, ny = 200, format = \"sp\") pred <- predict(   fit, pix,   ~ field + Intercept ) samp <- generate(fit, pix,   ~ field + Intercept,   n.samples = 1 ) pred$sample <- samp[, 1] pl_posterior_mean <- ggplot() +   gg(pred) +   gg(bnd) +   ggtitle(\"Posterior mean\") +   coord_fixed() pl_posterior_sample <- ggplot() +   gg(pred, aes(fill = sample)) +   gg(bnd) +   ggtitle(\"Posterior sample\") +   coord_fixed()  # Common colour scale for the truth and estimate: csc <- colsc(truth$field, pred$mean, pred$sample) multiplot(pl_truth + csc,   pl_posterior_mean + csc,   pl_posterior_sample + csc,   cols = 3 ) int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit, \"field\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"field\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"field\", what = \"matern.covariance\")) multiplot(covplot, corplot) csc <- colsc(   pred@data[\"median\"],   pred@data[\"q0.025\"],   pred@data[\"q0.975\"] ) ## Common colour scale from SpatialPixelsDataFrame  gmedian <- ggplot() +   gg(pred[\"median\"]) +   coord_equal() +   csc glower95 <- ggplot() +   gg(pred[\"q0.025\"]) +   coord_equal() +   csc +   theme(legend.position = \"none\") gupper95 <- ggplot() +   gg(pred[\"q0.975\"]) +   coord_equal() +   csc +   theme(legend.position = \"none\")  multiplot(gmedian, glower95, gupper95,   layout = matrix(c(1, 1, 2, 3), byrow = TRUE, ncol = 2) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"introduction","dir":"Articles > Web","previous_headings":"","what":"Introduction","title":"Spatially Varying Coefficient Models with inlabru","text":"Spatially varying coefficient models (SVCs, Gelfand et al. 2003) often used model data relationships dependent independent variables uniform across space, common situation exploring phenomena across large spatial extents (Finley 2011). Meehan et al. (2019) described SVC model evaluate continent-scaled variation bird abundance trends. SVC model used analysis employed discrete aerial units (100 km grid cells), spatial structure described neighborhood matrices spatial relationships described intrinsic conditional autoregressive model (Besag 1974). online supplement paper included code building model using R-INLA package (Rue et al. 2009) R statistical programming language (R Core Team 2021). manuscript code can accessed https://github.com/tmeeha/inlaSVCBC. vignette, describe build SVC model similar described Meehan et al. (2019), within continuous-space framework. model computed using stochastic partial differential equation (SPDE) approach Lindgren et al. (2011, 2022), implemented inlabru interface R-INLA package R. SPDE approach employs computationally efficient approximation Gaussian random field parameters directly comparable Matérn covariance function. benefits continuous-space versus discrete-space SVC include potential finer resolution estimation prediction, better understanding range spatial correlation, reduction boundary effects associated discrete-space analyses. build model using subset data described Meehan et al. (2019). Specifically, use counts American Robin (Turdus migratorius) south central North America collected 1987 2016 Audubon Christmas Bird Count (CBC). overall goal analysis produce spatially explicit estimates annual relative abundance well long-term relative abundance trends robins account spatial temporal variation count effort.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"model","dir":"Articles > Web","previous_headings":"","what":"Model","title":"Spatially Varying Coefficient Models with inlabru","text":"model used analyze data assumes counts come negative binomial distribution expected count dispersion parameter. expected count log-linear predictor: \\[\\log(\\lambda_{st}) = \\kappa_{s} + \\alpha_s + \\epsilon_{s} \\log[\\text{Effort}_{st}] + \\tau_{s} \\text{Year}_{st}\\] natural log expected count, \\(\\log(\\lambda_{st})\\), site \\(s\\) year \\(t\\), modeled zero-centered, normally distributed intercept per site, \\(\\kappa_s\\), spatially varying intercept, \\(\\alpha_s\\), spatially varying effect log count effort hours, \\(\\epsilon_s\\), spatially varying linear effect year, \\(\\tau_s\\). spatially structured effects modeled Gaussian random fields Matérn covariance functions range variance parameters. Model parameters \\(\\kappa_s\\), \\(\\alpha_s\\), \\(\\epsilon_s\\) \\(\\tau_s\\) analogous Meehan et al. (2019). example, \\(\\kappa_s\\) included account site-level differences counts, possibly due habitat availability observer experience. \\(\\alpha_s\\) can interpreted effort-corrected abundance index year zero. \\(\\epsilon_s\\) exponent power-law effort-correction function. \\(\\tau_s\\) long-term temporal trend given site.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"environment","dir":"Articles > Web","previous_headings":"","what":"Environment","title":"Spatially Varying Coefficient Models with inlabru","text":"get started data analysis, set environment, loading packages, setting options. Next define coordinate reference system (CRS) spatial analysis create base map later use. CRS uses USA Contiguous Albers Equal-Area Conic projection, identified EPSG code 6703. modify CRS slightly units kilometers, distances widespread count sites especially large numbers (Krainski et al. 2018).","code":"# libraries library(maps) library(ggplot2) library(sf) library(terra) library(tidyterra) # raster plotting library(tidyr) library(scales) library(inlabru) library(INLA) library(dplyr) # Note: the 'splancs' package also needs to be installed, # but doesn't need to be loaded  # set option select <- dplyr::select options(scipen = 99999) options(max.print = 99999) options(stringsAsFactors = FALSE) # define a crs epsg6703km <- paste(   \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5\",   \"+lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83\",   \"+units=km +no_defs\" )  # make a base map states <- st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE)) %>%   filter(ID %in% c(     \"texas\", \"oklahoma\", \"kansas\", \"missouri\",     \"arkansas\", \"louisiana\"   )) %>%   st_transform(epsg6703km)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"import-data","dir":"Articles > Web","previous_headings":"","what":"Import data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next import bird count data GitHub repository associated Meehan et al. (2019), turn data set spatially referenced points. use subset data (30 years, 6 US states) analysis reduce computing time (~ 1 min). Note site selection zero filling, important components trend analyses, already conducted resulting data set. inlabru package contains pregenerated version data subset, called robins_subset, can accessed data(robins_subset), avoid accessing full data online. following code used generate subset: load data, filter observation sites less 20 years data, add index variables uniquely index site year information, transform coordinates epsg6703km CRS: rough view changes robin relative abundance, account variation count effort, can seen plotting raw counts per site year.","code":"robins_subset <- read.csv(paste0(   \"https://raw.github.com/tmeeha/inlaSVCBC\",   \"/master/code/modeling_data.csv\" )) %>%   select(     circle, bcr, state, year, std_yr, count, log_hrs,     lon, lat, obs   ) %>%   mutate(year = year + 1899) %>%   filter(     state %in% c(       \"TEXAS\", \"OKLAHOMA\", \"KANSAS\", \"MISSOURI\",       \"ARKANSAS\", \"LOUISIANA\"     ),     year >= 1987   ) data(robins_subset) count_dat <- robins_subset %>%   mutate(site_idx = as.numeric(factor(paste(circle, lon, lat)))) %>%   group_by(site_idx) %>%   mutate(n_years = n()) %>%   filter(n_years >= 20) %>%   ungroup() %>%   mutate(     std_yr = year - max(year),     obs = seq_len(nrow(.)),     site_idx = as.numeric(factor(paste(circle, lon, lat))),     year_idx = as.numeric(factor(year)),     site_year_idx = as.numeric(factor(paste(circle, lon, lat, year)))   ) %>%   st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326, remove = FALSE) %>%   st_transform(epsg6703km) %>%   mutate(     easting = st_coordinates(.)[, 1],     northing = st_coordinates(.)[, 2]   ) %>%   arrange(circle, year) # map it ggplot() +   geom_sf(     data = count_dat %>% filter(year_idx %in% seq(1, 30, 3)),     aes(col = log(count + 1))   ) +   geom_sf(data = states, fill = NA) +   coord_sf(datum = NA) +   facet_wrap(~year) +   scale_color_distiller(palette = \"Spectral\") +   theme_bw()"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"make-spatial-data","dir":"Articles > Web","previous_headings":"","what":"Make spatial data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next use count data make map distinct count sites save coordinates sites, unique across years, later spatial modeling plotting.","code":"# make a set of distinct study sites for mapping site_map <- count_dat %>%   select(circle, easting, northing) %>%   distinct() %>%   select(circle, easting, northing)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"spde-components","dir":"Articles > Web","previous_headings":"","what":"SPDE components","title":"Spatially Varying Coefficient Models with inlabru","text":"Computing continuous-space model R-INLA using SPDE approach requires construction four distinct sets data model objects (Blangiardo Cameletti 2015, Krainski et al. 2018). First, create modeling mesh, used provide piecewise linear representation continuous spatial surface, based triangulation modeled region. , mesh get reused spatial terms model. Second, construct SPDE model object specifies properties spatial model. , use SPDE object spatial terms model. plain R-INLA, also need create index vectors projector matrices (matrices often called). However, inlabru, objects created automatically, user need deal directly. works automatic creation bru_mapper object knows map mesh nodes spatial data locations. Thus, two R-INLA functions needed user code SPDE modelling steps inla.mesh.2D() inla.spde2.pcmatern(), inla.spde.make.index() inla.spde.make.() functions called internally inlabru code , rather fm_evaluator() used instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"modeling-mesh","dir":"Articles > Web","previous_headings":"","what":"Modeling mesh","title":"Spatially Varying Coefficient Models with inlabru","text":"various things consider constructing mesh (Lindgren Rue 2015, Blangiardo Cameletti 2015, Krainski et al. 2018, Bakka et al. 2018). constructing one, balance trade-capturing fine-scaled features Gaussian random field computing times. , create non-convex hull around count sites, build triangular mesh specifying minimum maximum edge lengths within slightly outside hull.","code":"# make a hull and mesh for spatial model hull <- inla.nonconvex.hull(   points = as.matrix(st_coordinates(count_dat)),   convex = 200, concave = 350 ) mesh <- inla.mesh.2d(   boundary = hull, max.edge = c(100, 600), # km inside and outside   cutoff = 50, offset = c(100, 300) ) # cutoff is min edge  # plot it ggplot() +   gg(data = mesh) +   geom_sf(data = site_map, col = \"darkgreen\", size = 1) +   geom_sf(data = states, fill = NA) +   theme_bw() +   labs(x = \"\", y = \"\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"spde-model-object","dir":"Articles > Web","previous_headings":"","what":"SPDE model object","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create SPDE object define model smoothness, prior distributions variance range parameters, mesh. assume Gaussian random field characterized Matérn covariance function penalized complexity priors (Simpson et al. 2017) practical range (distance spatial correlation approaches 0.1) variation explained function (Fuglstad et al. 2019). prior spatial range set probability range exceeding 500 km 0.5. prior variance explained spatial effect set probability standard deviation exceeding 1 0.5 (Krainski et al. 2018). one wants constrain kind spatial effect integrate zero, constr=TRUE added stage.","code":"# make spde spde <- inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(500, 0.5),   prior.sigma = c(1, 0.5) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"weighted-spatial-effects-in-inlabru","dir":"Articles > Web","previous_headings":"","what":"Weighted spatial effects in inlabru","title":"Spatially Varying Coefficient Models with inlabru","text":"ordinary R-INLA, necessary construct projector matrices model component, include different covariate weightings spatial model component. inlabru, can instead handled either explicitly multiplying spatial random fields spatial covariates model formula expression, specifying weights argument model component specification. use latter approach, since easiest. model, \\(\\epsilon_s\\) spatially varying effect log count effort. Similarly, \\(\\tau_s\\) spatially varying effect year, standardized year (1987 = 0) also specified weights argument. \\(\\alpha_s\\) also SVC, spatially varying intercept. intercepts necessary specify constant weight 1. model component \\(\\kappa_{s}\\) linked observation site modeled mesh. Note current use term ‘weights’ different often encountered defining mixed effect models R. used define covariate value multiplication, opposed importance values likelihoods contexts.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"data-stack-for-model-fitting","dir":"Articles > Web","previous_headings":"Weighted spatial effects in inlabru","what":"Data stack for model fitting","title":"Spatially Varying Coefficient Models with inlabru","text":"plain R-INLA, need bundle model data component projector matrix information using inla.stack() function. inlabru, done automatically, skip step.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"model-formula","dir":"Articles > Web","previous_headings":"","what":"Model formula","title":"Spatially Varying Coefficient Models with inlabru","text":"last required input analysis model formula, includes information prior explained variation unstructured random intercept. define prior \\(\\kappa_s\\) penalized complexity prior (Simpson et al. 2017), set probability standard deviation associated random effect exceeding 1 0.01. Notice one wants constrain spatial spde effect integrate zero, added constr=TRUE SPDE model definition rather component definition. want constrain \\(\\kappa_s\\) non-spatial term can use constr=TRUE corresponding label() component definition , imposes sum--zero constraint. model described translated inlabru modeling syntax : Specifying sf column geometry input causes inlabru textract spatial coordinate information observation locations . Alternatively, specify function st_coordinates instead, extract raw coordinates, potentially losing important coordinate reference system information.. Alternatively, can specify CRS-free information explicitly input, cbind(easting, northing) st_coordinates(.data.). , define response count, remove automatic global intercept -1, specify terms model label() statements. first kappa() statement defines \\(\\kappa_s\\), site effect, normally distributed independent (model=\"iid\"), globally zero-centered (sum zero constr=TRUE), deviation \\(\\alpha_s\\). second alpha() statement defines \\(\\alpha_s\\) spatially varying intercept spatial structure described SPDE object called ‘spde’. Remember one wants constrain kind spatial effect integrate zero, constr=TRUE added SPDE model definition rather label() arguments. third eps() statement defines \\(\\epsilon_s\\) SVC effect count effort, spatial structure also described SPDE object. weights spatially structured random slope specified weights=log_hrs argument. fourth tau() statement defines \\(\\tau_s\\) SVC year effect, spatial structure described SPDE object. weights spatially structured random slope specified weights=std_yr argument.","code":"# iid prior pc_prec <- list(prior = \"pcprec\", param = c(1, 0.1)) # components svc_components <- ~ -1 +   kappa(site_idx, model = \"iid\", constr = TRUE, hyper = list(prec = pc_prec)) +   alpha(geometry, model = spde) +   eps(geometry, weights = log_hrs, model = spde) +   tau(geometry, weights = std_yr, model = spde) # formula, with \".\" meaning \"add all the model components\": svc_formula <- count ~ ."},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"run-model","dir":"Articles > Web","previous_headings":"","what":"Run model","title":"Spatially Varying Coefficient Models with inlabru","text":"estimate model call bru(). First set option use (new) experimental way internal computations, see Van Niekerk et. al. (2022), sake computing speed better numerics. call bru(), give model components, specify observation likelihood model formula negative binomial distribution counts, define estimation data. ask inla() compute WAIC CPO evaluate model fit, save information necessary posterior sampling (config=TRUE, otherwise set default bru(), inlabru::predict() relies posterior sampling prediction). computing speed, choose use simplified laplace approximation strategy Empirical Bayes estimation. inla() run model takes 1 minutes standard laptop computer. Another option use Variational Bayes approximation detailed Van Niekerk Rue (2021) Van Niekerk et. al. (2022).","code":"res <- bru(svc_components,   like(     formula = svc_formula,     family = \"nbinomial\",     data = count_dat   ),   options = list(     control.compute = list(waic = TRUE, cpo = TRUE),     control.inla = list(int.strategy = \"eb\"),     verbose = FALSE   ) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"model-summaries","dir":"Articles > Web","previous_headings":"","what":"Model summaries","title":"Spatially Varying Coefficient Models with inlabru","text":"computation complete, look initial results see things went. First check posterior means hyperparameters model, mainly variance components spatial ranges spatially structured parameters. Next examine summaries random effect estimates, starting \\(\\exp(\\alpha_s)\\), effort-corrected relative abundance year = 0 (1987), given 1 hour count effort (.e., log[1]=0). Note avoid issues due \\(E[\\exp(x)|y]\\neq\\exp[E(x|y)]\\), use posterior median instead posterior mean. summary \\(\\epsilon_s\\) shows variation exponent effort correction function across space. \\(\\tau_s\\) summary shows long-term, log-linear trends robin relative abundance varied across space, annual decreases around 10% annual increases around 10%.","code":"# view results res$summary.hyperpar[-1, c(1, 2)] #>                              mean            sd #> Precision for kappa    2.26232058    0.43632778 #> Range for alpha      971.21148481  311.39455399 #> Stdev for alpha        1.98960402    0.41401747 #> Range for eps       6032.66128780 4285.60010661 #> Stdev for eps          0.41988074    0.30561673 #> Range for tau        794.89204774  328.99859129 #> Stdev for tau          0.06412628    0.01362083 summary(exp(res$summary.random$alp$\"0.5quant\")) # exp(alpha) posterior median #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #>  0.05753  1.18184  3.50846  7.09784  8.69408 53.12578 summary(res$summary.random$eps$mean) # epsilon #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.8134  0.8965  0.9679  0.9577  1.0210  1.0694 summary((exp(res$summary.random$tau$\"0.5quant\") - 1) * 100) # (exp(tau)-1)*100 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> -12.850  -5.085  -1.558  -1.043   2.759  11.036"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"svc-maps","dir":"Articles > Web","previous_headings":"","what":"SVC maps","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create maps \\(\\alpha_s\\), \\(\\epsilon_s\\), \\(\\tau_s\\) inspect spatial structure parameter estimates. start creating 25-km mapping grid, projecting mapping grid modeling mesh. populate mapping grids parameter estimates (posterior median range95), turn raster stack, mask raster stack study area. Finally, plot SVCs following code. plot posterior median 95% uncertainty width (“range95”) \\(\\exp(\\kappa_s)\\), \\(\\exp(\\alpha_s)\\), \\(\\epsilon_s\\), \\(100(\\exp(\\tau_s)-1)\\). map posterior mean \\(\\tau_s\\) shows robins decreased southern part study area increased northern part. demonstrates wintering range robins shifting northward winters become warmer due climate change.","code":"# get easting and northing limits xlim <- range(hull$loc[, 1]) ylim <- range(hull$loc[, 2]) grd_dims <- round(c(x = diff(range(xlim)), y = diff(range(ylim))) / 25)  # make mesh projector to get model summaries from the mesh to the mapping grid mesh_proj <- fm_evaluator(   mesh,   xlim = xlim, ylim = ylim, dims = grd_dims ) # pull data kappa <- data.frame(   median = exp(res$summary.random$kappa$\"0.5quant\"),   range95 = exp(res$summary.random$kappa$\"0.975quant\") -     exp(res$summary.random$kappa$\"0.025quant\") ) alph <- data.frame(   median = exp(res$summary.random$alpha$\"0.5quant\"),   range95 = exp(res$summary.random$alpha$\"0.975quant\") -     exp(res$summary.random$alpha$\"0.025quant\") ) epsi <- data.frame(   median = res$summary.random$eps$\"0.5quant\",   range95 = (res$summary.random$eps$\"0.975quant\" -     res$summary.random$eps$\"0.025quant\") ) taus <- data.frame(   median = (exp(res$summary.random$tau$\"0.5quant\") - 1) * 100,   range95 = (exp(res$summary.random$tau$\"0.975quant\") -     exp(res$summary.random$tau$\"0.025quant\")) * 100 )  # loop to get estimates on a mapping grid pred_grids <- lapply(   list(alpha = alph, epsilon = epsi, tau = taus),   function(x) as.matrix(fm_evaluate(mesh_proj, x)) ) # make a terra raster stack with the posterior median and range95 out_stk <- rast() for (j in 1:3) {   mean_j <- cbind(expand.grid(x = mesh_proj$x, y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 1], grd_dims[1]))   )   mean_j <- rast(mean_j, crs = epsg6703km)   range95_j <- cbind(expand.grid(X = mesh_proj$x, Y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 2], grd_dims[1]))   )   range95_j <- rast(range95_j, crs = epsg6703km)   out_j <- c(mean_j, range95_j)   terra::add(out_stk) <- out_j } names(out_stk) <- c(   \"alpha_median\", \"alpha_range95\", \"epsilon_median\",   \"epsilon_range95\", \"tau_median\", \"tau_range95\" ) out_stk <- terra::mask(out_stk, states, touches = FALSE) make_plot_field <- function(data_stk, scale_label) {   ggplot(states) +     geom_sf(fill = NA) +     coord_sf(datum = NA) +     geom_spatraster(data = data_stk) +     labs(x = \"\", y = \"\") +     scale_fill_distiller(scale_label,       palette = \"Spectral\",       na.value = \"transparent\"     ) +     theme_bw() +     geom_sf(fill = NA) } make_plot_site <- function(data, scale_label) {   ggplot(states) +     geom_sf() +     coord_sf(datum = NA) +     geom_sf(data = data, size = 1, mapping = aes(colour = value)) +     scale_colour_distiller(scale_label, palette = \"Spectral\") +     labs(x = \"\", y = \"\") +     theme_bw() +     geom_sf(fill = NA) }  # medians # fields alpha_s, epsilon_s, tau_s pa <- make_plot_field(   data_stk = out_stk[[\"alpha_median\"]],   scale_label = \"posterior\\nmedian\\nexp(alpha_s)\" ) pe <- make_plot_field(   data_stk = out_stk[[\"epsilon_median\"]],   scale_label = \"posterior\\nmedian\\nepsilon_s\" ) pt <- make_plot_field(   data_stk = out_stk[[\"tau_median\"]],   scale_label = \"posterior\\nmedian\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$median)),   scale_label = \"posterior\\nmedian\\nexp(kappa_s)\" ) # range95 # fields alpha_s, epsilon_s, tau_s pa_range95 <- make_plot_field(   data_stk = out_stk[[\"alpha_range95\"]],   scale_label = \"posterior\\nrange95\\nexp(alpha_s)\" ) pe_range95 <- make_plot_field(   data_stk = out_stk[[\"epsilon_range95\"]],   scale_label = \"posterior\\nrange95\\nepsilon_s\" ) pt_range95 <- make_plot_field(   data_stk = out_stk[[\"tau_range95\"]],   scale_label = \"posterior\\nrange95\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps_range95 <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$range95)),   scale_label = \"posterior\\nrange95\\nexp(kappa_s)\" ) # plot together multiplot(ps, pa, pe, pt, cols = 2) # plot together multiplot(ps_range95, pa_range95, pe_range95, pt_range95, cols = 2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"more-information","dir":"Articles > Web","previous_headings":"","what":"More information","title":"Spatially Varying Coefficient Models with inlabru","text":"information building spatial models using SPDE approach R-INLA can found Lindgren Rue (2015), Blangiardo Camaletti (2015), Bakka et al. (2018), Krainski et al. (2018), Moraga (2019).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/web/svc.html","id":"citations","dir":"Articles > Web","previous_headings":"","what":"Citations","title":"Spatially Varying Coefficient Models with inlabru","text":"Bakka, H., Rue, H., Fuglstad, G.., Riebler, ., Bolin, D., Illian, J., Krainski, E., Simpson, D. Lindgren, F., 2018. Spatial modeling R‐INLA: review. Wiley Interdisciplinary Reviews: Computational Statistics, 10(6), p.e1443. Besag, J., 1974. Spatial interaction statistical analysis lattice systems. Journal Royal Statistical Society: Series B (Methodological), 36(2), pp.192-225. Blangiardo, M., Cameletti, M., Baio, G. Rue, H., 2013. Spatial spatio-temporal models R-INLA. Spatial spatio-temporal epidemiology, 4, pp.33-49. Finley, .O., 2011. Comparing spatially‐varying coefficients models analysis ecological data non‐stationary anisotropic residual dependence. Methods Ecology Evolution, 2(2), pp.143-154. Fuglstad, G.., Simpson, D., Lindgren, F. Rue, H., 2019. Constructing priors penalize complexity Gaussian random fields. Journal American Statistical Association, 114(525), pp.445-452. Gelfand, .E., Kim, H.J., Sirmans, C.F. Banerjee, S., 2003. Spatial modeling spatially varying coefficient processes. Journal American Statistical Association, 98(462), pp.387-396. Gómez-Rubio, V., 2020. Bayesian inference INLA. CRC Press. Krainski, E., Gómez-Rubio, V., Bakka, H., Lenzi, ., Castro-Camilo, D., Simpson, D., Lindgren, F. Rue, H., 2018. Advanced spatial modeling stochastic partial differential equations using R INLA. Chapman Hall/CRC. Lindgren, F., Rue, H. Lindström, J., 2011. explicit link Gaussian fields Gaussian Markov random fields: stochastic partial differential equation approach. Journal Royal Statistical Society: Series B (Statistical Methodology), 73(4), pp.423-498. Lindgren, F. Rue, H., 2015. Bayesian spatial modelling R-INLA. Journal statistical software, 63, pp.1-25. Lindgren, F., Bolin, D. Rue, H., 2022. SPDE approach Gaussian non-Gaussian fields: 10 years still running. Spatial Statistics, p.100599. Link, W.., Sauer, J.R. Niven, D.K., 2006. hierarchical model regional analysis population change using Christmas Bird Count data, application American Black Duck. Condor, 108(1), pp.13-24. Meehan, T.D., Michel, N.L. Rue, H., 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine‐scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707. Moraga, P., 2019. Geospatial health data: Modeling visualization R-INLA shiny. CRC Press. R Core Team (2021). R: language environment statistical computing. R Foundation Statistical Computing, Vienna, Austria. Rue, H., Martino, S. Chopin, N., 2009. Approximate Bayesian inference latent Gaussian models using integrated nested Laplace approximations. Journal royal statistical society: Series b (statistical methodology), 71(2), pp.319-392. Simpson, D., Rue, H., Riebler, ., Martins, T.G. Sørbye, S.H., 2017. Penalising model component complexity: principled, practical approach constructing priors. Statistical science, 32(1), pp.1-28. Soykan, C.U., Sauer, J., Schuetz, J.G., LeBaron, G.S., Dale, K. Langham, G.M., 2016. Population trends North American winter birds based hierarchical models. Ecosphere, 7(5), p.e01351. Van Niekerk, J. Rue, H., 2021. Correcting Laplace Method Variational Bayes. Journal Machine Learning Research, review. Van Niekerk, J. Krainski, E. T. Rustand, D. Rue, H., 2022. new avenue Bayesian inference INLA. Submitted.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/website_examples.html","id":"package-examples","dir":"Articles","previous_headings":"","what":"Package examples","title":"Examples on the inlabru website","text":"potentially long running examples/tutorials available (https://inlabru-org.github.io/inlabru/) LGCPs - example one dimension LGCPs - Spatial covariates LGCPs - Distance sampling LGCPs - Multiple Likelihoods LGCPs - Plot sampling Residual Analysis spatial point process models using Bayesian methods LGCPs - example space time LGCPs - example two dimensions Installation INLA inlabru Apptainer HPC Devel: Model evaluation flowchart Converting inla.spde.make.calls bru_mapper system Publications Random Fields 2D Random Fields One Dimension ‘Spatially Varying Coefficient Models inlabru’","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/website_examples.html","id":"package-vignettes","dir":"Articles","previous_headings":"","what":"Package vignettes","title":"Examples on the inlabru website","text":"package vignettes also available (https://inlabru-org.github.io/inlabru/) Devel: Customised model components bru_mapper system Defining model components Nonlinear model approximation Iterative linearised INLA method Prediction scores Examples inlabru website","code":""},{"path":"https://inlabru-org.github.io/inlabru/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Finn Lindgren. Author, maintainer, copyright holder.            Finn Lindgren continued development main code Fabian E. Bachl. Author, copyright holder.            Fabian Bachl wrote main code David L. Borchers. Contributor, data contributor, copyright holder.            David Borchers wrote code Gorilla data import sampling, multiplot tool Daniel Simpson. Contributor, copyright holder.            Daniel Simpson wrote basic LGCP sampling method Lindesay Scott-Howard. Contributor, data contributor, copyright holder.            Lindesay Scott-Howard provided MRSea data import code Seaton Andy. Contributor.            Andy Seaton provided testing, bugfixes, vignettes Suen Man Ho. Contributor, copyright holder.            Man Ho Suen contributed features aggregated responses vignette updates Roudier Pierre. Contributor, copyright holder.            Pierre Roudier contributed general quantile summaries Meehan Tim. Contributor, copyright holder.            Tim Meehan contributed SVC vignette robins data Reddy Peddinenikalva Niharika. Contributor, copyright holder.            Niharika Peddinenikalva contributed LGCP residuals vignette","code":""},{"path":"https://inlabru-org.github.io/inlabru/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760--766, doi:10.1111/2041-210X.13168 Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whalesAnnals Applied Statistics, 11, 2270--2297, doi:10.1214/17-AOAS1078","code":"@Article{,   title = {{inlabru}: an {R} package for Bayesian spatial modelling from ecological survey data},   author = {Fabian E. Bachl and Finn Lindgren and David L. Borchers and Janine B. Illian},   year = {2019},   journal = {Methods in Ecology and Evolution},   volume = {10},   pages = {760--766},   doi = {10.1111/2041-210X.13168},   publisher = {British Ecological Society}, } @Article{,   author = {{Yuan} and {Yuan} and {Bachl} and Fabian E. and {Lindgren} and {Finn} and {Borchers} and David L. and {Illian} and Janine B. and {Buckland} and Stephen T. and {Rue} and {Håvard} and {Gerrodette} and {Tim}},   doi = {10.1214/17-AOAS1078},   fjournal = {Annals of Applied Statistics},   journal = {Ann. Appl. Stat.},   month = {12},   number = {4},   pages = {2270--2297},   publisher = {The Institute of Mathematical Statistics},   title = {Point process models for spatio-temporal distance sampling data from a large-scale survey of blue whales},   doi = {10.1214/17-AOAS1078},   volume = {11},   year = {2017}, }"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"inlabru","dir":"","previous_headings":"","what":"Bayesian Latent Gaussian Modelling using INLA and Extensions","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"goal inlabru facilitate spatial modeling using integrated nested Laplace approximation via R-INLA package. Additionally, extends GAM-like model class general nonlinear predictor expressions, implements log Gaussian Cox process likelihood modeling univariate spatial point processes based ecological survey data. Model components specified general inputs mapping methods latent variables, predictors specified via general R expressions, separate expressions observation likelihood model multi-likelihood models. prediction method based fast Monte Carlo sampling allows posterior prediction general expressions latent variables. See Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168, citation(\"inlabru\"). inlabru.org website links old tutorials code examples versions 2.1.13. later versions, updated versions tutorials, well new examples, can found https://inlabru-org.github.io/inlabru/articles/","code":""},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"can install current CRAN version inlabru: can install latest bugfix release inlabru GitHub : can install development version inlabru GitHub track development version builds via inlabru-org.r-universe.dev:","code":"install.packages(\"inlabru\") # install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\", ref = \"stable\") # install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\", ref = \"devel\") # Enable universe(s) by inlabru-org options(repos = c(   inlabruorg = \"https://inlabru-org.r-universe.dev\",   INLA = \"https://inla.r-inla-download.org/R/testing\",   CRAN = \"https://cloud.r-project.org\" ))  # Install some packages install.packages(\"inlabru\")"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"basic example shows fit simple spatial Log Gaussian Cox Process (LGCP) predicts intensity:","code":"# Load libraries library(inlabru) library(INLA) #> Loading required package: Matrix #> Loading required package: foreach #> Loading required package: parallel #> This is INLA_23.05.30-1 built 2023-05-30 11:52:19 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - To enable PARDISO sparse library; see inla.pardiso() library(ggplot2) bru_safe_sp(force = TRUE) # Ensures sp works without rgdal installed  # Load the data data(gorillas, package = \"inlabru\")  # Construct latent model components matern <- inla.spde2.pcmatern(gorillas$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.01, 0.01) ) cmp <- ~ mySmooth(coordinates, model = matern) + Intercept(1) # Fit LGCP model # This particular bru/like combination has a shortcut function lgcp() as well fit <- bru(   components = cmp,   like(     formula = coordinates ~ .,     family = \"cp\",     data = gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh)   ),   options = list(control.inla = list(int.strategy = \"eb\")) ) #> Please note that rgdal will be retired during October 2023, #> plan transition to sf/stars/terra functions using GDAL and PROJ #> at your earliest convenience. #> See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution #> rgdal: version: 1.6-7, (SVN revision 1203) #> Geospatial Data Abstraction Library extensions to R successfully loaded #> Loaded GDAL runtime: GDAL 3.4.1, released 2021/12/27 #> Path to GDAL shared files: /usr/share/gdal #> GDAL binary built with GEOS: TRUE  #> Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821] #> Path to PROJ shared files: /home/flindgre/.local/share/proj:/usr/share/proj #> PROJ CDN enabled: FALSE #> Linking to sp version:1.6-1 #> To mute warnings of possible GDAL/OSR exportToProj4() degradation, #> use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.  # Predict Gorilla nest intensity lambda <- predict(   fit,   fm_pixels(gorillas$mesh, mask = gorillas$boundary, format = \"sp\"),   ~ exp(mySmooth + Intercept) )  # Plot the result ggplot() +   gg(lambda) +   gg(gorillas$nests, color = \"red\", size = 0.2) +   coord_equal() +   ggtitle(\"Nest intensity per km squared\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"Point data count data, together intensity function expected counts homogeneous 1-dimensional Poisson process example.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"data(Poisson1_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"data contain following R objects: lambda1_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc1 expected counts gridded data. pts1 locations observed points (data frame one column, named x). countdata1 data frame three columns, containing count data:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson1_1D)   ggplot(countdata1) +     geom_point(data = countdata1, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata1$count)) +     geom_point(data = pts1, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     geom_point(       data = countdata1, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     xlab(expression(bold(s))) +     ylab(\"count\") }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"Point data count data, together intensity function expected counts unimodal nonhomogeneous 1-dimensional Poisson process example.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"data(Poisson2_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"data contain following R objects: lambda2_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). cov2_1D: function gives call 'habitat suitability' covariate 1D space. E_nc2 expected counts gridded data. pts2 locations observed points (data frame one column, named x). countdata2 data frame three columns, containing count data:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson2_1D)   p1 <- ggplot(countdata2) +     geom_point(data = countdata2, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata2$count, E_nc2)) +     geom_point(       data = countdata2, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata2$x, y = E_nc2), aes(x = x),       y = E_nc2, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda2_1D(ss)   p2 <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda),       aes(x = x, y = y), col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1, p2, cols = 1) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"Point data count data, together intensity function expected counts multimodal nonhomogeneous 1-dimensional Poisson process example. Counts given two different gridded data interval widths.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"data(Poisson3_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"data contain following R objects: lambda3_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc3a expected counts gridded data wider bins (10 bins). E_nc3b expected counts gridded data wider bins (20 bins). pts3 locations observed points (data frame one column, named x). countdata3a data frame three columns, containing count data 10-interval case: countdata3b data frame three columns, containing count data 20-interval case:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson3_1D)   # first the plots for the 10-bin case:   p1a <- ggplot(countdata3a) +     geom_point(data = countdata3a, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3a$count, E_nc3a)) +     geom_point(       data = countdata3a, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3a$x, y = E_nc3a),       aes(x = x), y = E_nc3a, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1)    # Then the plots for the 20-bin case:   p1a <- ggplot(countdata3b) +     geom_point(data = countdata3b, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3b$count, E_nc3b)) +     geom_point(       data = countdata3b, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3b$x, y = E_nc3b),       aes(x = x), y = E_nc3b, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1) }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":null,"dir":"Reference","previous_headings":"","what":"Add component input/latent mappers — add_mappers","title":"Add component input/latent mappers — add_mappers","text":"Add missing mappers input data latent variables, based likelihood data Equip component(s) mappers subcomponents predefined mappers. needed, data lhoods used determine appropriate mapper(s).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add component input/latent mappers — add_mappers","text":"","code":"add_mappers(...)  # S3 method for component add_mappers(component, lhoods, ...)  # S3 method for component_list add_mappers(components, lhoods, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add component input/latent mappers — add_mappers","text":"... Parameters passed methods component component object lhoods bru_like_list object components component_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add component input/latent mappers — add_mappers","text":"component object completed mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add component input/latent mappers — add_mappers","text":"","code":"if (FALSE) { if (interactive()) { } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":null,"dir":"Reference","previous_headings":"","what":"1D LGCP bin count simulation and comparison with data — bincount","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"common procedure analyzing distribution 1D points chose binning plot data's histogram respect binning. function compares counts histogram calculates simulations 1D log Gaussian Cox process conditioned number data samples. bin results median number counts well confidence interval. LGCP plausible model observed points histogram counts (number points within bin) within confidence intervals. Note proper comparison  multiple testing problem function solve .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"bincount(   result,   predictor,   observations,   breaks,   nint = 20,   probs = c(0.025, 0.5, 0.975),   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"result result object bru() lgcp() call predictor formula describing prediction 1D LGCP via predict(). observations vector observed values breaks vector bin boundaries nint Number integration points per bin. Increase bins wide probs numeric vector probabilities values [0,1] ... arguments passed predict.bru()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"data.frame ggplot attribute ggp","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"if (FALSE) { if (require(ggplot2)) {   # Load a point pattern   data(Poisson2_1D)    # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model   x <- seq(0, 55, length = 50)   mesh1D <- inla.mesh.1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = inla.spde2.matern(mesh1D)) + Intercept(1)   fit.spde <- lgcp(mdl, pts2, domain = list(x = c(0, 55)))    # Calculate bin statistics   bc <- bincount(     result = fit.spde,     observations = pts2,     breaks = seq(0, max(pts2), length = 12),     predictor = x ~ exp(spde1D + Intercept)   )     # Plot them!   attributes(bc)$ggp } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for mapper lists — bm_list","title":"Methods for mapper lists — bm_list","text":"bru_mapper lists can combined bm_list lists.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for mapper lists — bm_list","text":"","code":"# S3 method for bru_mapper c(...)  # S3 method for bm_list c(...)  # S3 method for bm_list [(x, i)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for mapper lists — bm_list","text":"... Objects combined. x bm_list object extract element(s) indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Methods for mapper lists — bm_list","text":"c(bm_list): ... arguments bm_list objects. [: Extract sub-list","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Methods for mapper lists — bm_list","text":"c(bru_mapper): ... arguments bru_mapper objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for mapper lists — bm_list","text":"","code":"m <- c(A = bru_mapper_const(), B = bru_mapper_scale()) str(m) #> List of 2 #>  $ A: list() #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_const\" \"bru_mapper\" \"list\" #>  $ B:List of 1 #>   ..$ is_linear: logi TRUE #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_scale\" \"bru_mapper\" \"list\" #>  - attr(*, \"class\")= chr [1:2] \"bm_list\" \"list\" str(m[2]) #> List of 1 #>  $ B:List of 1 #>   ..$ is_linear: logi TRUE #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_scale\" \"bru_mapper\" \"list\" #>  - attr(*, \"class\")= chr [1:2] \"bm_list\" \"list\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient model fitting using (iterated) INLA — bru","title":"Convenient model fitting using (iterated) INLA — bru","text":"method wrapper INLA::inla provides multiple enhancements. Easy usage spatial covariates automatic construction inla projection matrices (spatial) SPDE models. feature accessible via components parameter. Practical examples use spatial data means components parameter can also found looking lgcp function's documentation. Constructing multiple likelihoods straight forward. See like information provide additional likelihoods bru using ... parameter list. Support non-linear predictors. See example . Log Gaussian Cox process (LGCP) inference available using cp family (even easier) using lgcp function.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"bru(components = ~Intercept(1), ..., options = list(), .envir = parent.frame())  bru_rerun(result, options = list())"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient model fitting using (iterated) INLA — bru","text":"components formula-like specification latent components. Also used define default linear additive predictor.  See component() details. ... Likelihoods, constructed calling like(), named parameters can passed single like() call. Note arguments evaluated calling like() order detect like objects. means special arguments need evaluated context response_data data (Ntrials) may work way direct calls like(). options bru_options options object list options passed bru_options() .envir Environment component evaluation (non-formula specification used) result previous estimation object class bru","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru returns object class \"bru\". bru object inherits INLA::inla (see inla documentation properties) adds additional information stored bru_info field.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru_rerun Continue optimisation previously computed estimate.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convenient model fitting using (iterated) INLA — bru","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1))    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept, family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #> Current num.threads is '2:1'. #> Setting INLA option num.threads to '1:1'. Previous value '2:1'. #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). #> Warning: The input evaluation 'Intercept' for 'Intercept' failed. Perhaps the data object doesn't contain the needed variables? Falling back to '1'. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.101524 0.04248811   2.016621 2.101524   2.186423 2.101524 #> Intercept 5.011203 0.03003935   4.951176 5.011204   5.071227 5.011204 #>                    kld #> x         5.677998e-06 #> Intercept 5.678133e-06   if (bru_safe_inla(multicore = FALSE)) {    # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\", formula = y ~ x + Intercept, data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.101524 0.04247570   2.016647 2.101524   2.186398 2.101524 #> Intercept 5.011203 0.03003057   4.951194 5.011204   5.071209 5.011204 #>                    kld #> x         5.704203e-06 #> Intercept 5.704337e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla(multicore = FALSE)) {   z <- 2   input.df <- within(input.df, y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1))   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         2.008719 0.006381617   1.995967 2.008719   2.021471 2.008719 #> Intercept 5.025516 0.033630312   4.958313 5.025516   5.092715 5.025516 #>                    kld #> z         5.705088e-06 #> Intercept 5.704932e-06 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional bru options — bru_call_options","title":"Additional bru options — bru_call_options","text":"Construct bru_options object including default global options, converting deprecated option names.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional bru options — bru_call_options","text":"","code":"bru_call_options(...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional bru options — bru_call_options","text":"... Options passed .bru_options()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Additional bru options — bru_call_options","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Additional bru options — bru_call_options","text":"","code":"# \\donttest{  opts <- bru_call_options()  # Print them: opts #> $bru_verbose #> [1] 0 #>  #> $bru_verbose_store #> [1] Inf #>  #> $bru_max_iter #> [1] 10 #>  #> $bru_run #> [1] TRUE #>  #> $bru_int_args #> $bru_int_args$method #> [1] \"stable\" #>  #> $bru_int_args$nsub1 #> [1] 30 #>  #> $bru_int_args$nsub2 #> [1] 9 #>  #>  #> $bru_method #> $bru_method$taylor #> [1] \"pandemic\" #>  #> $bru_method$search #> [1] \"all\" #>  #> $bru_method$factor #> [1] 1.618034 #>  #> $bru_method$rel_tol #> [1] 0.1 #>  #> $bru_method$max_step #> [1] 2 #>  #> $bru_method$lin_opt_method #> [1] \"onestep\" #>  #>  #> $bru_compress_cp #> [1] TRUE #>  #> $bru_debug #> [1] FALSE #>  #> $E #> [1] 1 #>  #> $Ntrials #> [1] 1 #>  #> $control.compute #> $control.compute$config #> [1] TRUE #>  #> $control.compute$dic #> [1] TRUE #>  #> $control.compute$waic #> [1] TRUE #>  #>  #> $control.inla #> $control.inla$int.strategy #> [1] \"auto\" #>  #>  #> $control.fixed #> $control.fixed$expand.factor.strategy #> [1] \"inla\" #>  #>  #> attr(,\"class\") #> [1] \"bru_options\" \"list\"        # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute inlabru model linearisation information — bru_compute_linearisation","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"Compute inlabru model linearisation information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"","code":"bru_compute_linearisation(...)  # S3 method for component bru_compute_linearisation(   cmp,   model,   lhood_expr,   data,   input,   state,   comp_simple,   effects,   pred0,   allow_latent,   allow_combine,   eps,   ... )  # S3 method for bru_like bru_compute_linearisation(   lhood,   model,   data,   input,   state,   comp_simple,   eps,   ... )  # S3 method for bru_like_list bru_compute_linearisation(   lhoods,   model,   input,   state,   comp_simple,   eps = 1e-05,   ... )  # S3 method for bru_model bru_compute_linearisation(model, lhoods, input, state, comp_simple, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"... Parameters passed methods cmp bru_component object model bru_model object lhood_expr predictor expression data Input data input Precomputed component inputs evaluate_inputs() state state information, list named vectors comp_simple Component evaluation information bru_component: bru_mapper_taylor object bru_like: comp_simple_list object components likelihood bru_like_list: comp_simple_list_list object effects bru_component: Precomputed effect list components involved likelihood expression pred0 Precomputed predictor given state allow_latent logical. TRUE, latent state component directly available predictor expression, _latent suffix. allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. eps finite difference step size lhood bru_like object lhoods bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot inlabru convergence diagnostics — bru_convergence_plot","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"Draws four panels convergence diagnostics iterated INLA method estimation","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"","code":"bru_convergence_plot(x)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"x bru object, typically result bru() nonlinear predictor model","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"Requires \"dplyr\", \"ggplot2\", \"magrittr\", \"patchwork\" packages installed.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"","code":"if (FALSE) { fit <- bru(...) bru_convergence_plot(fit) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get access to the internal environment — bru_env_get","title":"Get access to the internal environment — bru_env_get","text":"Get access internal environment","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get access to the internal environment — bru_env_get","text":"","code":"bru_env_get()"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get access to the internal environment — bru_env_get","text":"environment defined 0_inlabru_envir.R loaded first.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill in missing values in Spatial grids — bru_fill_missing","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"Computes nearest-available-value imputation missing values space","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"bru_fill_missing(   data,   where,   values,   layer = NULL,   selector = NULL,   batch_size = 50 )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"data SpatialPointsDataFrame, SpatialPixelsDataFrame, SpatialGridDataFrame, SpatRaster, Raster, sf object containing data use filling , matrix, data.frame, SpatialPoints SpatialPointsDataFrame, sf object, containing locations evaluated values values vector values filled .na(values) TRUE layer, selector Specifies data column columns extract data, see component() details. batch_size Size nearest-neighbour calculation blocks, limit memory computational complexity.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"infilled vector values","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   points <-     sp::SpatialPointsDataFrame(       matrix(1:6, 3, 2),       data = data.frame(val = c(NA, NA, NA))     )   input_coord <- expand.grid(x = 0:7, y = 0:7)   input <-     sp::SpatialPixelsDataFrame(       input_coord,       data = data.frame(val = as.vector(input_coord$y))     )   points$val <- bru_fill_missing(input, points, points$val)   print(points)    # To fill in missing values in a grid:   print(input$val[c(3, 30)])   input$val[c(3, 30)] <- NA # Introduce missing values   input$val <- bru_fill_missing(input, input, input$val)   print(input$val[c(3, 30)]) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract mapper information from INLA model component objects — bru_get_mapper","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"component definitions automatically attempt extract mapper information model object calling generic bru_get_mapper. class method implementation return bru_mapper object suitable given latent model.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"bru_get_mapper(model, ...)  # S3 method for inla.spde bru_get_mapper(model, ...)  # S3 method for inla.rgeneric bru_get_mapper(model, ...)  bru_get_mapper_safely(model, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"model model component object ... Arguments passed methods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_mapper object defined model component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_get_mapper.inla.spde extract indexed mapper model$mesh object contained model object. returns NULL gives warning known mesh type found model object. bru_get_mapper.inla.rgeneric returns mapper given call model$f$rgeneric$definition(\"mapper\"). support inla.rgeneric models, add \"mapper\" option cmd argument rgeneric definition function. need store mapper object well.  Alternative, define model using subclass define corresponding bru_get_mapper.subclass method return corresponding bru_mapper object. bru_get_mapper_safely tries call bru_get_mapper, returns NULL fails (e.g. due available class method). call succeeds returns non-NULL, checks object inherits bru_mapper class, gives error .","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"if (bru_safe_inla(quietly = TRUE)) {   library(INLA)   mesh <- inla.mesh.create(globe = 2)   spde <- inla.spde2.pcmatern(mesh,     prior.range = c(1, 0.5),     prior.sigma = c(1, 0.5)   )   mapper <- bru_get_mapper(spde)   ibm_n(mapper) } #> Loading required package: Matrix #> This is INLA_23.06.15 built 2023-06-15 06:01:53 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #> [1] 42"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_info objects — summary.bru_info","title":"Methods for bru_info objects — summary.bru_info","text":"Methods bru_info objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_info objects — summary.bru_info","text":"","code":"# S3 method for bru_info summary(object, verbose = TRUE, ...)  # S3 method for summary_bru_info print(x, ...)  bru_info(...)  # S3 method for character bru_info(method, ..., inlabru_version = NULL, INLA_version = NULL)  # S3 method for bru bru_info(object, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_info objects — summary.bru_info","text":"object Object operate verbose logical; TRUE, include details component definitions. FALSE, show basic component definition information. Default: TRUE ... Arguments passed methods x summary_bru_info object printed method character; type estimation method used inlabru_version character; inlabru package version. Default: NULL, automatically detecting version INLA_version character; INLA package version. Default: NULL, automatically detecting version","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_int_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration points for polygons inside an inla.mesh — bru_int_polygon","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"Integration points polygons inside inla.mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_int_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"","code":"bru_int_polygon(mesh, method = NULL, samplers = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_int_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"mesh inla.mesh object method integration method use (\"stable\", aggregation mesh vertices, \"direct\") samplers non-NULL, SpatialPolygons* object ... Arguments passed low level integration method (make_triangle_integration)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_int_polygon.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration points for polygons inside an inla.mesh — bru_int_polygon","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility functions for bru likelihood objects — bru_like_inla_family","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"Utility functions bru likelihood objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"","code":"bru_like_inla_family(x, ...)  # S3 method for bru_like bru_like_inla_family(x, ...)  # S3 method for bru_like_list bru_like_inla_family(x, ...)  bru_like_control_family(x, control.family = NULL, ...)  # S3 method for bru_like bru_like_control_family(x, control.family = NULL, ...)  # S3 method for bru_like_list bru_like_control_family(x, control.family = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"x Object bru_like bru_like_list type control.family INLA control.family overrides","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabru log message methods — bru_log_reset","title":"inlabru log message methods — bru_log_reset","text":"Resets inlabru log object Retrieve, add, /print log messages","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"inlabru log message methods — bru_log_reset","text":"","code":"bru_log_reset()  bru_log_get(pretty = FALSE)  bru_log_message(   ...,   domain = NULL,   appendLF = TRUE,   verbosity = 1,   allow_verbose = TRUE,   verbose = NULL,   verbose_store = NULL )  bru_log(txt, verbose = NULL)  bru_log_active(activation = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"inlabru log message methods — bru_log_reset","text":"pretty logical; TRUE, return single string log messages separated terminated line feeds, suitable cat(...). FALSE, return raw log vector strings, suitable cat(..., sep = \"\\n\"). Default: FALSE ... Zero objects passed base::.makeMessage() domain Domain translations, passed base::.makeMessage() appendLF logical; whether add newline message. used verbose output. verbosity numeric value describing verbosity level message allow_verbose Whether allow verbose output. Must set FALSE options object initialised. verbose logical; TRUE, print log message screen message(txt). Default: bru_options_get(\"bru_verbose\") verbose_store verbose, controlling messages stored global log object. Can controlled via bru_verbose_store bru_options_set(). txt character; log message. activation logical; whether activate (TRUE) deactivate (FALSE) inlabru logging system. Default: NULL, keep current activation state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"inlabru log message methods — bru_log_reset","text":"bru_log_get RETURN_VALUE bru_log_message OUTPUT_DESCRIPTION bru_log invisibly returns added log message. bru_log_active returns previous activation state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"inlabru log message methods — bru_log_reset","text":"bru_log_reset() clears log contents. bru_log_message DETAILS log message stored log active, see bru_log_active()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabru log message methods — bru_log_reset","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"inlabru log message methods — bru_log_reset","text":"","code":"if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } code_runner <- function() {   oa <- bru_log_active(TRUE)   on.exit(bru_log_active(oa))   bru_log(\"Test message\") } bru_log_active() #> [1] Inf code_runner() cat(bru_log_get()) #> 2023-06-17 21:19:32.789598: inlabru loaded 2023-06-17 21:19:32.790064: Clear override options 2023-06-17 21:19:38.808168: iinla: Evaluate component inputs 2023-06-17 21:19:38.809522: iinla: Evaluate component linearisations 2023-06-17 21:19:38.984581: iinla: Evaluate component simplifications 2023-06-17 21:19:39.11245: iinla: Evaluate predictor linearisation 2023-06-17 21:19:39.137391: iinla: Construct inla stack 2023-06-17 21:19:39.176359: iinla: Model initialisation completed 2023-06-17 21:19:39.176694: iinla: Iteration 1 [max:1] 2023-06-17 21:19:40.342935: iinla: Evaluate component inputs 2023-06-17 21:19:40.343693: iinla: Evaluate component linearisations 2023-06-17 21:19:40.48634: iinla: Evaluate component simplifications 2023-06-17 21:19:40.6198: iinla: Evaluate predictor linearisation 2023-06-17 21:19:40.634577: iinla: Construct inla stack 2023-06-17 21:19:40.653298: iinla: Model initialisation completed 2023-06-17 21:19:40.653588: iinla: Iteration 1 [max:10] 2023-06-17 21:19:41.384477: iinla: |lin1-lin0| = 424.9 #>        <eta-lin1,delta>/|delta| = 0 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 3.1e-14 2023-06-17 21:19:41.38508: iinla: Evaluate component linearisations 2023-06-17 21:19:41.509314: iinla: Evaluate predictor linearisation 2023-06-17 21:19:41.532441: iinla: Iteration 2 [max:10] 2023-06-17 21:19:42.728789: iinla: Step rescaling: 162%, Expand 2023-06-17 21:19:42.730178: iinla: Step rescaling: 100%, Overstep 2023-06-17 21:19:42.733666: iinla: |lin1-lin0| = 8.893e-07 #>        <eta-lin1,delta>/|delta| = -1.604e-15 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 4.609e-14 2023-06-17 21:19:42.733919: iinla: Evaluate component linearisations 2023-06-17 21:19:42.855971: iinla: Evaluate predictor linearisation 2023-06-17 21:19:42.879743: iinla: Max deviation from previous: 0.232% of SD [stop if: <10%] 2023-06-17 21:19:42.880029: iinla: Convergence criterion met, running final INLA integration with known theta mode. 2023-06-17 21:19:42.88083: iinla: Iteration 3 [max:10] 2023-06-17 21:19:43.703183: iinla: Evaluate component inputs 2023-06-17 21:19:43.704031: iinla: Evaluate component linearisations 2023-06-17 21:19:43.839064: iinla: Evaluate component simplifications 2023-06-17 21:19:43.981193: iinla: Evaluate predictor linearisation 2023-06-17 21:19:43.991162: iinla: Construct inla stack 2023-06-17 21:19:44.009207: iinla: Model initialisation completed 2023-06-17 21:19:44.009423: iinla: Iteration 1 [max:10] 2023-06-17 21:19:44.748256: iinla: Step rescaling: 61.8%, Contract 2023-06-17 21:19:44.749889: iinla: Step rescaling: 38.2%, Contract 2023-06-17 21:19:44.752595: iinla: Step rescaling: 26.93%, Optimisation 2023-06-17 21:19:44.752876: iinla: |lin1-lin0| = 427.8 #>        <eta-lin1,delta>/|delta| = -245.3 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 130.1 2023-06-17 21:19:44.753238: iinla: Step rescaling: 26.9% 2023-06-17 21:19:44.753456: iinla: Evaluate component linearisations 2023-06-17 21:19:44.877739: iinla: Evaluate predictor linearisation 2023-06-17 21:19:44.902153: iinla: Iteration 2 [max:10] 2023-06-17 21:19:45.687182: iinla: Step rescaling: 99.47%, Optimisation 2023-06-17 21:19:45.687783: iinla: |lin1-lin0| = 278.3 #>        <eta-lin1,delta>/|delta| = -1.638 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 15.04 2023-06-17 21:19:45.688048: iinla: Step rescaling: 99.5% 2023-06-17 21:19:45.688264: iinla: Evaluate component linearisations 2023-06-17 21:19:45.816276: iinla: Evaluate predictor linearisation 2023-06-17 21:19:45.83953: iinla: Max deviation from previous: 57700% of SD [stop if: <10%] 2023-06-17 21:19:45.840574: iinla: Iteration 3 [max:10] 2023-06-17 21:19:46.564225: iinla: Step rescaling: 162%, Expand 2023-06-17 21:19:46.565695: iinla: Step rescaling: 100%, Overstep 2023-06-17 21:19:46.568523: iinla: Step rescaling: 101.9%, Optimisation 2023-06-17 21:19:46.56872: iinla: |lin1-lin0| = 15.14 #>        <eta-lin1,delta>/|delta| = -7.074e-05 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 0.02763 2023-06-17 21:19:46.56894: iinla: Step rescaling: 102% 2023-06-17 21:19:46.569109: iinla: Evaluate component linearisations 2023-06-17 21:19:46.691648: iinla: Evaluate predictor linearisation 2023-06-17 21:19:46.714389: iinla: Max deviation from previous: 704% of SD [stop if: <10%] 2023-06-17 21:19:46.715408: iinla: Iteration 4 [max:10] 2023-06-17 21:19:47.456268: iinla: Step rescaling: 162%, Expand 2023-06-17 21:19:47.457705: iinla: Step rescaling: 100%, Overstep 2023-06-17 21:19:47.460232: iinla: Step rescaling: 100%, Optimisation 2023-06-17 21:19:47.460432: iinla: |lin1-lin0| = 0.02758 #>        <eta-lin1,delta>/|delta| = 5.185e-10 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 2.432e-07 2023-06-17 21:19:47.460679: iinla: Evaluate component linearisations 2023-06-17 21:19:47.578247: iinla: Evaluate predictor linearisation 2023-06-17 21:19:47.601639: iinla: Max deviation from previous: 12.6% of SD [stop if: <10%] 2023-06-17 21:19:47.602564: iinla: Iteration 5 [max:10] 2023-06-17 21:19:48.315373: iinla: Step rescaling: 162%, Expand 2023-06-17 21:19:48.317232: iinla: Step rescaling: 100%, Overstep 2023-06-17 21:19:48.320175: iinla: Step rescaling: 100%, Optimisation 2023-06-17 21:19:48.320377: iinla: |lin1-lin0| = 3.277e-07 #>        <eta-lin1,delta>/|delta| = -6.191e-15 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 1.079e-12 2023-06-17 21:19:48.320633: iinla: Evaluate component linearisations 2023-06-17 21:19:48.441532: iinla: Evaluate predictor linearisation 2023-06-17 21:19:48.480063: iinla: Max deviation from previous: 0.0755% of SD [stop if: <10%] 2023-06-17 21:19:48.480425: iinla: Convergence criterion met, running final INLA integration with known theta mode. 2023-06-17 21:19:48.481202: iinla: Iteration 6 [max:10] 2023-06-17 21:19:52.574184: Test message bru_log_active() #> [1] Inf"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an inla data stack from linearisation information — bru_make_stack","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"Combine linearisation multiple likelihoods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"","code":"bru_make_stack(...)  # S3 method for bru_like bru_make_stack(lhood, lin, idx, ...)  # S3 method for bru_like_list bru_make_stack(lhoods, lin, idx, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"... Arguments passed methods lhood bru_like object lin Linearisation information .bru_like, bru_mapper_taylor object .bru_like_list, list bru_mapper_taylor objects idx Output evaluate_index(...) lhoods bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructors for bru_mapper objects — bru_mapper","title":"Constructors for bru_mapper objects — bru_mapper","text":"Constructors bru_mapper objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"bru_mapper(...)  bru_mapper_define(mapper, new_class = NULL, ..., methods = NULL)  # S3 method for default bru_mapper(...)  # S3 method for inla.mesh bru_mapper(mesh, ...)  # S3 method for inla.mesh.1d bru_mapper(mesh, indexed = NULL, ...)  bru_mapper_index(n = 1L, ...)  bru_mapper_taylor(   offset = NULL,   jacobian = NULL,   state0 = NULL,   ...,   values_mapper = NULL )  bru_mapper_linear(...)  bru_mapper_matrix(labels, ...)  bru_mapper_factor(values, factor_mapping, indexed = FALSE, ...)  bru_mapper_const(...)  bru_mapper_scale(mapper = NULL, ...)  bru_mapper_aggregate(rescale = FALSE, n_block = NULL, ...)  bru_mapper_logsumexp(rescale = FALSE, n_block = NULL, ...)  bru_mapper_pipe(mappers, ...)  bru_mapper_multi(mappers, ...)  bru_mapper_collect(mappers, hidden = FALSE, ...)  bru_mapper_harmonics(   order = 1,   scaling = 1,   intercept = TRUE,   interval = c(0, 1),   ... )  bru_mapper_mesh_B(mesh, B, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructors for bru_mapper objects — bru_mapper","text":"... Deprecated, alternative way supply optional method definitions. mapper bru_mapper_define, prototype mapper object, see Details. bru_mapper_scale, mapper scaled. new_class non-NULL, added front class definition methods Deprecated. mesh inla.mesh.1d inla.mesh.2d object use mapper indexed logical; TRUE, ibm_values() method return integer vector instead factor levels. needed e.g. group replicate mappers, since INLA::f() accept factor values. Default: FALSE, works main input mappers. default mapper constructions set required setting. n Size model bru_mapper_index offset bru_mapper_taylor, offset vector evaluated state0. May NULL, interpreted -zero vector length determined non-null Jacobian. jacobian bru_mapper_taylor, Jacobian matrix, evaluated state0, , named list matrices. May NULL empty list, constant mapping. state0 bru_mapper_taylor, state linearisation evaluated , list length matching jacobian list. NULL interpreted 0. values_mapper mapper object used ibm_n ibm_values inla_f=TRUE (experimental, currently unused) labels Column labels matrix mappings values Input values calculated input_eval.bru_input() factor_mapping character; selects type factor mapping. 'contrast' leaving first factor level. 'full' keeping levels. rescale logical; bru_mapper_aggregate bru_mapper_logsumexp, specifies blockwise sums normalised blockwise weight sums : FALSE: (default) Straight weighted sum, rescaling. TRUE: Divide sum weight values within block. useful integration averages, given weights plain integration weights. weights NULL ones, dividing number entries block. n_block Predetermined number output blocks. NULL, overrides maximum block index inputs. mappers list bru_mapper objects hidden logical, set TRUE flag mapper used first level input mapper INLA::f() model requires making first mapper visible INLA::f() INLA::inla.stack(), \"bym2\" models, activated inla_f argument ibm_n, ibm_values, ibm_jacobian. Set FALSE always access full mapper, e.g. rgeneric models order bru_mapper_harmonics, specifies maximum cos/sin order. (Default 1) scaling bru_mapper_harmonics, specifies optional vector scaling factors length intercept + order, common single scalar. intercept logical; bru_mapper_harmonics, TRUE, first basis function constant. (Default TRUE) interval numeric length-2 vector specifying domain interval. Default c(0, 1). B square tall basis conversion matrix","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Constructors for bru_mapper objects — bru_mapper","text":"bru_mapper(default): Calls bru_mapper_define, passing arguments along. Mapper implementations call bru_mapper_define() instead, supply least new_class class name. Use bru_mapper.default method deprecated version 2.7.0. bru_mapper(inla.mesh): Creates mapper 2D inla.mesh objects bru_mapper(inla.mesh.1d): Create mapper inla.mesh.1d object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Constructors for bru_mapper objects — bru_mapper","text":"bru_mapper(): Generic mapper S3 constructor, used constructing mappers special objects. See details default constructor bru_mapper_define() can used define new mappers user code. bru_mapper_define(): Adds new_class \"bru_mapper\" class names inheritance list input mapper object, unless object already inherits . register mapper classes methods scripts, use .S3method() register methods, e.g. .S3method(\"ibm_jacobian\", \"my_mapper_class\", ibm_jacobian.my_mapper_class). packages Suggests: inlabru, add method information delayed registration, e.g.:   method, use @exportS3Method:   etc., semi-automates . bru_mapper_index(): Create indexing mapper bru_mapper_taylor(): Provides pre-computed affine mapping, internally used represent evaluate linearisation information. state0 information indicates state offset evaluated; affine mapper output defined effect(state) = offset + jacobian %*% (state - state0) bru_mapper_linear(): Create mapper linear effects bru_mapper_matrix(): Create matrix mapper, given number columns bru_mapper_factor(): Create factor mapper bru_mapper_const(): Create constant mapper bru_mapper_scale(): Create standalone scaling mapper can used part bru_mapper_pipe. mapper non-null, bru_mapper_scale() constructor returns bru_mapper_pipe(list(mapper = mapper, scale = bru_mapper_scale())) bru_mapper_aggregate(): Constructs mapper aggregates elements input state, can used e.g. weighted summation integration blocks values. bru_mapper_logsumexp(): Constructs mapper aggregates elements exp(state), optional non-negative weighting, takes log(), can used e.g.  \\(v_k=\\log[\\sum_{\\I_k} w_i \\exp(u_i)]\\) \\(v_k=\\log[\\sum_{\\I_k} w_i \\exp(u_i) / \\sum_{\\I_k} w_i]\\) calculations.  Relies input handling methods bru_mapper_aggregate, also allows weights supplied logarithmic scale log_weights. avoid numerical overflow, uses common method internally shifting state blockwise (state-log_weights)[block] - max((state-log_weights)[block]), shifting result back afterwards. bru_mapper_pipe(): Create pipe mapper, mappers list mappers, evaluated output mapper handed state next mapper. input format ibm_eval ibm_jacobian methods list inputs, one mapper. bru_mapper_multi(): Constructs rowwise Kronecker product mapping bru_mapper_collect(): Constructs concatenated collection mapping bru_mapper_harmonics(): Constructs mapper cos/sin functions orders 1 (intercept TRUE, otherwise 0) order. total number basis functions intercept + 2 * order. Optionally, order can given non-unit scaling, via scaling vector, length intercept + order. can used give effective spectral prior. example, let   ,   stochastic properties u1 u2 , scaling^2 determining variance frequency contribution. period first order harmonics shifted scaled match interval.","code":"#' @rawNamespace S3method(inlabru::bru_get_mapper, inla_rspde) #' @rawNamespace S3method(inlabru::ibm_n, bru_mapper_inla_rspde) #' @rawNamespace S3method(inlabru::ibm_values, bru_mapper_inla_rspde) #' @rawNamespace S3method(inlabru::ibm_jacobian, bru_mapper_inla_rspde) #' @exportS3Method inlabru::bru_get_mapper scaling = 1 / (1 + (0:4)^2) x <- seq(0, 1, length.out = 11) bmh1 = bru_mapper_harmonics(order = 4, interval = c(0, 1)) u1 <- ibm_eval(   bmh1,   input = x,   state = rnorm(9, sd = rep(scaling, c(1, 2, 2, 2, 2))) ) bmh2 = bru_mapper_harmonics(order = 4, scaling = scaling) u2 = ibm_eval(bmh2, input = x, state = rnorm(9))"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"mapper <- bru_mapper_index(5) ibm_jacobian(mapper, input = c(1, 3, 4, 5, 2)) #> 5 x 5 sparse Matrix of class \"dgCMatrix\" #>                #> [1,] 1 . . . . #> [2,] . . 1 . . #> [3,] . . . 1 . #> [4,] . . . . 1 #> [5,] . 1 . . ."},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic methods for bru_mapper objects — bru_mapper_generics","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"bru_mapper sub-class implementation must provide ibm_jacobian() method. model size 'n' definition values 'values' stored object , default methods available (see Details). Otherwise ibm_n() ibm_values() methods also need provided.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"","code":"ibm_n(mapper, inla_f = FALSE, ...)  ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, ...)  ibm_values(mapper, inla_f = FALSE, ...)  ibm_amatrix(mapper, input, state = NULL, inla_f = FALSE, ...)  ibm_is_linear(mapper, ...)  ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)  ibm_linear(mapper, input, state = NULL, ...)  ibm_eval(mapper, input, state = NULL, ...)  ibm_names(mapper)  ibm_names(mapper) <- value  ibm_inla_subset(mapper, ...)  ibm_invalid_output(mapper, input, state, ...)  # S3 method for default ibm_n(mapper, inla_f = FALSE, ...)  # S3 method for default ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, ...)  # S3 method for default ibm_values(mapper, inla_f = FALSE, ...)  # S3 method for default ibm_amatrix(mapper, ...)  # S3 method for default ibm_is_linear(mapper, ...)  # S3 method for default ibm_jacobian(mapper, input, state, ...)  # S3 method for default ibm_linear(mapper, input, state, ...)  # S3 method for default ibm_eval(mapper, input, state = NULL, ...)  # S3 method for default ibm_names(mapper, ...)  # S3 method for default ibm_inla_subset(mapper, ...)  # S3 method for default ibm_invalid_output(mapper, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) value character vector length number sub-mappers mapper","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"ibm_n(): Implementations must return size latent vector mapped . ibm_n_output(): Implementations must return integer denoting mapper output length. default implementation returns NROW(input). Mappers bru_mapper_multi bru_mapper_collect, can accept list() inputs require methods implementations. ibm_values(): inla_f=TRUE, implementations must return vector interpretable INLA::f(..., values = ...) specification. exception method bru_mapper_multi, returns multi-column data frame. ibm_amatrix(): become deprecated 2.7.0. Use ibm_jacobian instead. Implementations must return (sparse) matrix size ibm_n_output(...) ibm_n(...). inla_f=TRUE argument affect allowed type input format. ibm_is_linear(): Implementations must return TRUE FALSE. TRUE (returned default method unless mapper contains is_linear variable), users mapper may assume mapper linear. ibm_jacobian(): Implementations must return (sparse) matrix size ibm_n_output(mapper, input, inla_f) ibm_n(mapper, inla_f = FALSE). inla_f=TRUE argument affect allowed type input format. ibm_linear(): Implementations must return bru_mapper_taylor object linearisation information includes offset, jacobian, state0. state information indicates state offset evaluated, NULL meaning -zero. linearised mapper output defined effect(input, state) = offset(input, state0) + jacobian(input, state0) %*% (state - state0). default method calls ibm_eval() ibm_jacobian() generate needed information. ibm_eval(): Implementations must return vector length ibm_n_output(...). input contents must format accepted ibm_jacobian(...) mapper. ibm_names(): Implementations must return character vector sub-mapper names, NULL. Intended providing information multi-mappers mapper collections. ibm_names(mapper) <- value: Set mapper names. ibm_inla_subset(): Implementations must return logical vector TRUE/FALSE subset , given full matrix values output, [, subset, drop = FALSE] values[subset] (values[subset, , drop = FALSE] data.frame values) equal inla_f = TRUE version values. default method uses ibm_values output construct subset indexing. ibm_invalid_output(): Implementations return logical vector length ibm_n_output(mapper, input, state, ...) indicating , , output elements ibm_eval(mapper, input, state, ...) known invalid. multi/collect mappers, list, given multi=TRUE argument. ibm_n(default): Returns non-null element 'n' mapper object, gives error exist. inla_f=TRUE, first checks 'n_inla' element. ibm_n_output(default): Returns NROW(input) ibm_values(default): Returns non-null element 'values' mapper object, seq_len(ibm_n(mapper)) exist. ibm_amatrix(default): Gives error message. Mapper classes must implement ibm_jacobian ibm_amatrix methods. New implementations use ibm_jacobian method. ibm_amatrix may become deprecated future version. ibm_is_linear(default): Returns logical is_linear mapper object exists, otherwise TRUE. ibm_jacobian(default): Calls ibm_amatrix, default gives error. Mapper classes implement ibm_jacobian method. ibm_linear(default): Calls ibm_eval() ibm_jacobian() returns bru_mapper_taylor object. state0 information affine mapper indicates state offset evaluated; affine mapper output defined effect(input, state) = offset(input, state0) + jacobian(input, state0) %*% (state - state0) ibm_eval(default): Verifies mapper linear ibm_is_linear(), computes linear mapping ibm_jacobian(...) %*% state.  state NULL, zero vector length ibm_n_output(...) returned. ibm_names(default): Returns NULL ibm_inla_subset(default): Uses ibm_values output construct inla subset indexing, passing extra arguments multi methods (means supports regular vector values multi=1 data.frame values). ibm_invalid_output(default): Returns -FALSE logical vector.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"","code":"# ibm_names mapper <- bru_mapper_multi(list(   A = bru_mapper_index(2),   B = bru_mapper_index(2) )) ibm_names(mapper) #> [1] \"A\" \"B\" ibm_names(mapper) <- c(\"new\", \"names\") ibm_names(mapper) #> [1] \"new\"   \"names\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_mapper objects — bru_mapper_methods","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"bru_mapper sub-class implementation must provide ibm_jacobian() method. model size 'n' definition values 'values' stored object , default methods available (see Details). Otherwise ibm_n() ibm_values() methods also need provided.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"","code":"# S3 method for bru_mapper_inla_mesh_2d ibm_n(mapper, ...)  # S3 method for bru_mapper_inla_mesh_2d ibm_values(mapper, ...)  # S3 method for bru_mapper_inla_mesh_2d ibm_jacobian(mapper, input, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_n(mapper, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_values(mapper, ...)  # S3 method for bru_mapper_inla_mesh_1d ibm_jacobian(mapper, input, ...)  # S3 method for bru_mapper_index ibm_invalid_output(mapper, input, state, ...)  # S3 method for bru_mapper_index ibm_jacobian(mapper, input, state, ...)  # S3 method for bru_mapper_taylor ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_taylor ibm_n_output(mapper, input, ...)  # S3 method for bru_mapper_taylor ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_taylor ibm_jacobian(mapper, ..., multi = FALSE)  # S3 method for bru_mapper_taylor ibm_eval(mapper, input = NULL, state = NULL, ...)  # S3 method for bru_mapper_linear ibm_n(mapper, ...)  # S3 method for bru_mapper_linear ibm_values(mapper, ...)  # S3 method for bru_mapper_linear ibm_jacobian(mapper, input, ...)  # S3 method for bru_mapper_matrix ibm_n(mapper, ...)  # S3 method for bru_mapper_matrix ibm_values(mapper, ...)  # S3 method for bru_mapper_matrix ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)  # S3 method for bru_mapper_factor ibm_n(mapper, ...)  # S3 method for bru_mapper_factor ibm_values(mapper, ...)  # S3 method for bru_mapper_factor ibm_jacobian(mapper, input, ...)  # S3 method for bru_mapper_const ibm_n(mapper, ...)  # S3 method for bru_mapper_const ibm_values(mapper, ...)  # S3 method for bru_mapper_const ibm_jacobian(mapper, input, ...)  # S3 method for bru_mapper_const ibm_eval(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_scale ibm_n(mapper, ..., state = NULL, n_state = NULL)  # S3 method for bru_mapper_scale ibm_n_output(mapper, input, state = NULL, ..., n_state = NULL)  # S3 method for bru_mapper_scale ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for bru_mapper_scale ibm_jacobian(mapper, input, state = NULL, ..., sub_lin = NULL)  # S3 method for bru_mapper_scale ibm_linear(mapper, input, state, ...)  # S3 method for bru_mapper_scale ibm_eval(mapper, input, state = NULL, ..., sub_lin = NULL)  # S3 method for bru_mapper_aggregate ibm_n(mapper, ..., input = NULL, state = NULL, n_state = NULL)  # S3 method for bru_mapper_aggregate ibm_n_output(mapper, input = NULL, ...)  # S3 method for bru_mapper_aggregate ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for bru_mapper_aggregate ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_aggregate ibm_eval(mapper, input, state = NULL, ..., sub_lin = NULL)  # S3 method for bru_mapper_aggregate ibm_linear(mapper, input, state, ...)  # S3 method for bru_mapper_logsumexp ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_logsumexp ibm_eval(mapper, input, state = NULL, log = TRUE, ..., sub_lin = NULL)  # S3 method for bru_mapper_logsumexp ibm_linear(mapper, input, state, ...)  # S3 method for bru_mapper_pipe ibm_n(mapper, ..., state = NULL)  # S3 method for bru_mapper_pipe ibm_n_output(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_pipe ibm_values(mapper, ...)  # S3 method for bru_mapper_pipe ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_pipe ibm_linear(mapper, input, state, ...)  # S3 method for bru_mapper_pipe ibm_eval(mapper, input, state = NULL, ...)  # S3 method for bru_mapper_multi ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_multi ibm_n_output(mapper, input, ...)  # S3 method for bru_mapper_multi ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_multi ibm_is_linear(mapper, multi = FALSE, ...)  # S3 method for bru_mapper_multi ibm_jacobian(   mapper,   input,   state = NULL,   inla_f = FALSE,   multi = FALSE,   ...,   sub_A = NULL )  # S3 method for bru_mapper_multi ibm_linear(mapper, input, state, inla_f = FALSE, ...)  # S3 method for bru_mapper_multi ibm_eval(mapper, input, state = NULL, inla_f = FALSE, ..., pre_A = NULL)  # S3 method for bru_mapper_multi ibm_invalid_output(mapper, input, state, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_multi [(x, i, drop = TRUE)  # S3 method for bru_mapper_multi ibm_names(mapper)  # S3 method for bru_mapper_multi ibm_names(mapper) <- value  # S3 method for bru_mapper_collect ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_collect ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_collect ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_collect ibm_is_linear(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_collect ibm_jacobian(   mapper,   input,   state = NULL,   inla_f = FALSE,   multi = FALSE,   ...,   sub_lin = NULL )  # S3 method for bru_mapper_collect ibm_eval(   mapper,   input,   state,   inla_f = FALSE,   multi = FALSE,   ...,   sub_lin = NULL )  # S3 method for bru_mapper_collect ibm_linear(mapper, input, state, inla_f = FALSE, ...)  # S3 method for bru_mapper_collect ibm_invalid_output(mapper, input, state, inla_f = FALSE, multi = FALSE, ...)  # S3 method for bru_mapper_collect [(x, i, drop = TRUE)  # S3 method for bru_mapper_collect ibm_names(mapper)  # S3 method for bru_mapper_collect ibm_names(mapper) <- value  # S3 method for bru_mapper_harmonics ibm_n(mapper, inla_f = FALSE, ...)  # S3 method for bru_mapper_harmonics ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)  # S3 method for bru_mapper_mesh_B ibm_n(mapper, ...)  # S3 method for bru_mapper_mesh_B ibm_values(mapper, ...)  # S3 method for bru_mapper_mesh_B ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input values produce mapping matrix state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. multi logical; TRUE (positive), recurse one level sub-mappers n_state integer giving length state vector mappers state dependent output size. sub_lin Internal, optional pre-computed sub-mapper information log logical; control log output. Default TRUE, see ibm_eval() details logsumexp mappers. sub_A Internal; precomputed Jacobian matrices. pre_A Internal; precomputed Jacobian matrix x object extract element(s) indices specifying element(s) extract drop logical; [.bru_mapper_collect, whether extract individual mapper identifies single element. FALSE, list sub-mappers returned (suitable e.g. creating new bru_mapper_collect object). Default: TRUE value character vector length number mappers multi-mapper x","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"[-indexing bru_mapper_multi extracts subset bru_mapper_multi object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element) [-indexing bru_mapper_collect extracts subset bru_mapper_collect object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element) names() method bru_mapper_collect returns names sub-mappers list","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"ibm_eval.bru_mapper_taylor() evaluates linearised mapper information given state. input argument ignored, usual argument order ibm_eval(mapper, input, state) syntax can used, also ibm_eval(mapper, state = state).  mapper named jacobian list, state argument must also named list.  state NULL, -zero assumed. bru_mapper_scale, input values without scale element interpreted scaling. bru_mapper_aggregate, input list elements block weights. block vector length state, NULL, NULL equivalent -1. weights NULL, interpreted -1. bru_mapper_logsumexp, input list elements block weights. block vector length state, NULL, NULL equivalent -1. weights NULL, interpreted -1. ibm_jacobian bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. ibm_invalid_output bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. ibm_jacobian bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. inla_f=TRUE hidden=TRUE mapper definition, input format instead match first, non-hidden, sub-mapper. ibm_invalid_output bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_methods.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Methods for bru_mapper objects — bru_mapper_methods","text":"ibm_eval(bru_mapper_logsumexp): log TRUE (default), ibm_eval() logsumexp returns log-sum-weight-exp value. FALSE, sum-weight-exp value returned. ibm_names(bru_mapper_multi): Returns names sub-mappers list","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"mapper object summaries — summary.bru_mapper","title":"mapper object summaries — summary.bru_mapper","text":"mapper object summaries","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mapper object summaries — summary.bru_mapper","text":"","code":"# S3 method for bru_mapper summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for bru_mapper_multi summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for bru_mapper_pipe summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for bru_mapper_collect summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for summary_bru_mapper print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mapper object summaries — summary.bru_mapper","text":"object bru_mapper object summarise ... Unused arguments prefix character prefix line. Default \"\". initial character prefix first line. Default initial=prefix. depth recursion depth multi/collection/pipe mappers. Default 1, show collection, contents sub-mappers. x Object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mapper object summaries — summary.bru_mapper","text":"","code":"mapper <-   bru_mapper_pipe(     list(       bru_mapper_multi(list(         A = bru_mapper_index(2),         B = bru_mapper_index(3)       )),       bru_mapper_index(2)     )   ) summary(mapper, depth = 2) #> pipe = multi(A = index, B = index) -> index"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an inlabru model object from model components — bru_model","title":"Create an inlabru model object from model components — bru_model","text":"inlabru syntax model formulae different INLA::inla considers valid. inla effects defined adding f(...) expression formula. inlabru f replaced arbitrary (exceptions: const offset) string determine label effect. See Details information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an inlabru model object from model components — bru_model","text":"","code":"bru_model(components, lhoods)  # S3 method for bru_model summary(object, ...)  # S3 method for summary_bru_model print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an inlabru model object from model components — bru_model","text":"components component_list object lhoods list one lhood objects object Object operate ... Arguments passed methods x summary_bru_model object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an inlabru model object from model components — bru_model","text":"bru_model object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an inlabru model object from model components — bru_model","text":"instance y ~ f(myspde, ...) INLA equivalent y ~ myspde(...) inlabru. disadvantage inla way clear separation name covariate label effect. Furthermore, models like SPDE much natural use spatial coordinates covariates rather index SPDE vertices. purpose inlabru provides new main agument. convenience, main argument can used like first argument f function, e.g., first argument component definition. y ~ f(temperature, model = 'linear') equivalent y ~ temperature(temperature, model = 'linear') y ~ temperature(main = temperature, model = 'linear') well y ~ temperature(model = 'linear') sets main = temperature. hand, map can also function mapping, e.g coordinates function sp package : y ~ mySPDE(coordinates, ...) exctract coordinates data object, maps latent field via information given mapper, default extracted model object, case spde model objects. Morevover, main can expression evaluates within data environment. instance, data columns '' 'b', can create fixed effect 'sin(+b)' setting map following way: y ~ myEffect(sin(+b))","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update an options objects — bru_options","title":"Create or update an options objects — bru_options","text":"Create new options object, merge information several objects. _get, _set, _reset functions operate global package options override object. many cases, setting options specific calls bru() recommended instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update an options objects — bru_options","text":"","code":"bru_options(...)  as.bru_options(x = NULL)  bru_options_default()  bru_options_check(options, ignore_null = TRUE)  bru_options_get(name = NULL, include_default = TRUE)  bru_options_set(..., .reset = FALSE)  bru_options_reset()"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update an options objects — bru_options","text":"... collection named options, optionally including one bru_options objects. Options specified later override previous options. x object converted bru_options object. options bru_options object checked ignore_null Ignore missing NULL options. name Either NULL, single option name string, character vector list option names, Default: NULL include_default logical; TRUE, default options included together global override options. Default: TRUE .reset bru_options_set, logical indicating global override options list emptied setting new option(s).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update an options objects — bru_options","text":"bru_options() returns bru_options object. .bru_options(), NULL input returns empty bru_options object, list converted via bru_options(...), bru_options input passed . types input generates error. bru_options_default() returns bru_options object containing default options. bru_options_check() returns logical; TRUE object contains valid options use functions bru_options_get returns either bru_options object, name == NULL, contents single option, name options name string, named list option contents, name list option name strings. bru_options_set() returns copy global override options, invisibly (bru_options_get(include_default = FALSE)).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create or update an options objects — bru_options","text":"bru_options_check checks valid contents bru_options object bru_options_check() produces warnings invalid options. bru_options_set() used set global package options. bru_options_reset() clears global option overrides.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"valid-options","dir":"Reference","previous_headings":"","what":"Valid options","title":"Create or update an options objects — bru_options","text":"bru_options bru_options_set, recognised options : bru_verbose logical numeric; TRUE, log messages verbosity \\(\\le 1\\) printed bru_log_message(). numeric, log messages verbosity \\(\\le\\)bru_verbose printed. line search details, set bru_verbose=2 3. Default: 0, print messages bru_verbose_store logical numeric; TRUE, log messages verbosity \\(\\le 1\\) stored bru_log_message(). numeric, log messages verbosity \\(\\le\\) stored. Default: Inf, store messages. bru_run TRUE, run inference. Otherwise return configuration needed run inference. bru_max_iter maximum number inla iterations, default 10. Also see bru_method$rel_tol related options . bru_initial inla object returned previous calls INLA::inla, bru() lgcp(), list named vectors starting values latent variables. used starting point improvement approximate posterior. bru_int_args List arguments passed way integration method ipoints int.polygon 'cp' family models; method \"stable\" \"direct\". \"stable\" (default) integration points aggregated mesh vertices. nsub1 Number integration points per knot interval 1D. Default 30. nsub2 Number integration points along triangle edge 2D. Default 9. nsub Deprecated parameter overrides nsub1 nsub2 set. Default NULL. bru_method List arguments controlling iterative inlabru method: taylor 'pandemic' (default, version 2.1.15). search Either '' (default), use available line search methods, one 'finite' (reduce step size predictor finite) 'contract' (decrease step size trust hypersphere reached) 'expand' (increase step size improvement) 'optimise' (fast approximate error norm minimisation) disable line search, set empty vector. Line search available taylor=\"legacy\". factor Numeric, \\(> 1\\) determining line search step scaling multiplier. Default \\((1 + \\sqrt{5})/2\\). rel_tol Stop iterations largest change linearisation point (conditional latent state mode) relation estimated posterior standard deviation less rel_tol. Default 0.1 (ten percent). max_step largest allowed line search step factor. Factor 1 full INLA step. Default 2. lin_opt_method method use line search optimisation step. Default \"onestep\", using quadratic approximation based value gradient zero, value current best step length guess. method \"full\" line optimisation full nonlinear predictor; slow intended debugging purposes . bru_compress_cp logical; TRUE, compress \\(\\sum_{=1}^n \\eta_i\\) part Poisson process likelihood (family=\"cp\") single term, \\(y=n\\), predictor mean(eta). Default: TRUE bru_debug logical; TRUE, activate temporary debug features package development. Default: FALSE inla() options options starting bru_ passed inla(), sometimes altering according needs inlabru method. Warning: Due inlabru currently constructs inla() call, mean, prec, mean.intercept, prec.intercept settings control.fixed effect. elegant alternative implemented, use explicit mean.linear prec.linear specifications model=\"linear\" component instead.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update an options objects — bru_options","text":"","code":"if (FALSE) { if (interactive()) {   # Combine global and user options:   options1 <- bru_options(bru_options_get(), bru_verbose = TRUE)   # Create a proto-options object in two equivalent ways:   options2 <- as.bru_options(bru_verbose = TRUE)   options2 <- as.bru_options(list(bru_verbose = TRUE))   # Combine options objects:   options3 <- bru_options(options1, options2) } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   bru_options_check(bru_options(bru_max_iter = \"text\")) } } if (FALSE) { if (interactive()) {   # EXAMPLE1 } } if (FALSE) { if (interactive()) {   bru_options_set(     bru_verbose = TRUE,     verbose = TRUE   ) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":null,"dir":"Reference","previous_headings":"","what":"Load INLA safely for examples and tests — bru_safe_inla","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"Loads INLA package requireNamespace(\"INLA\", quietly = TRUE), optionally checks sets multicore num.threads INLA option.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"bru_safe_inla(multicore = NULL, quietly = FALSE, minimum_version = \"23.1.31\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. FALSE, forces num.threads=\"1:1\". Default: NULL, checks running testthat non-interactively, case sets multicore=FALSE, otherwise TRUE. quietly logical; TRUE, prints diagnostic messages. Default: FALSE. minimum_version character; minimum required INLA version. Default 23.1.31 (always match requirement package DESCRIPTION)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"logical; TRUE INLA loaded safely, otherwise FALSE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   # Run inla dependent calculations } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for potential sp version compatibility issues — bru_safe_sp","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"Loads sp package requireNamespace(\"sp\", quietly = TRUE), checks optionally sets sp evolution status flag rgdal unavailable.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"","code":"bru_safe_sp(quietly = FALSE, force = FALSE, minimum_version = \"1.4-5\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"quietly logical; TRUE, prints diagnostic messages. Default FALSE force logical; rgdal unavailable evolution status less 2L, return FALSE force FALSE. force TRUE, return TRUE package configuration safe, potentially forcing evolution status 2L. Default FALSE minimum_version character; minimum required INLA version. Default 1.4-5 (always match requirement package DESCRIPTION)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"Returns (invisibly) FALSE potential issue detected, give message quietly FALSE. Otherwise returns TRUE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"","code":"if (FALSE) { if (bru_safe_sp()) {   # Run sp dependent calculations } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardise inla hyperparameter names — bru_standardise_names","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"inla hyperparameter output uses parameter names can include whitespace special characters. function replaces characters underscores.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(x)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"x character vector; names standardised","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"character vector standardised names","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(\"Precision for the Gaussian observations\") #>   Precision for the Gaussian observations  #> \"Precision_for_the_Gaussian_observations\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise and annotate data — bru_summarise","title":"Summarise and annotate data — bru_summarise","text":"Summarise annotate data","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(   data,   probs = c(0.025, 0.5, 0.975),   x = NULL,   cbind.only = FALSE,   max_moment = 2 )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise and annotate data — bru_summarise","text":"data list samples, either numeric data.frame probs numeric vector probabilities values [0, 1], passed stats::quantile x data.frame data columns added summary data frame cbind.TRUE, cbind samples return matrix column sample max_moment integer, least 2. Determines largest moment order information include output. max_moment > 2, includes \"skew\" (skewness, E[(x-m)^3/s^3]), max_moment > 3, includes \"ekurtosis\" (excess kurtosis, E[(x-m)^4/s^4] - 3). Default 2. Note Monte Carlo variability ekurtois estimate may large.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise and annotate data — bru_summarise","text":"data.frame Spatial[Points/Pixels]DataFrame summary statistics, \"mean\", \"sd\", paste0(\"q\", probs), \"mean.mc_std_err\", \"sd.mc_std_err\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(matrix(rexp(10000), 10, 1000), max_moment = 4, probs = NULL) #>         mean        sd     skew ekurtosis mean.mc_std_err sd.mc_std_err #> 1  1.0264539 0.9233962 1.481607  2.375315      0.02920035    0.03054655 #> 2  0.9722724 0.9579221 1.837130  4.202650      0.03029216    0.03772758 #> 3  1.0080376 1.0240194 1.862317  4.553486      0.03238234    0.04145536 #> 4  0.9665637 0.9607742 1.882336  4.651270      0.03038235    0.03918402 #> 5  0.9729889 0.9303378 1.715439  3.938632      0.02941986    0.03585313 #> 6  1.0162035 0.9815205 1.818122  4.666241      0.03103840    0.04007514 #> 7  0.9923890 0.9134172 1.531877  2.586947      0.02888479    0.03093825 #> 8  0.9939132 1.0334129 2.154008  7.028607      0.03267939    0.04910236 #> 9  0.9903388 1.0028237 2.184835  7.450053      0.03171207    0.04874810 #> 10 0.9628278 1.0030052 1.902455  4.093730      0.03171781    0.03915490"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":null,"dir":"Reference","previous_headings":"","what":"Transformation tools — bru_forward_transformation","title":"Transformation tools — bru_forward_transformation","text":"Tools transforming N(0,1) variables distributions predictor expressions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transformation tools — bru_forward_transformation","text":"","code":"bru_forward_transformation(qfun, x, ..., tail.split. = 0)  bru_inverse_transformation(pfun, x, ..., tail.split. = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transformation tools — bru_forward_transformation","text":"qfun quantile function object, qexp x Values transformed ... Distribution parameters passed qfun pfun functions tail.split. x-values larger tail.split., upper quantile calculations used internally, smaller values lower quantile calculations used. can avoid lack accuracy distribution tails. NULL, forward calculations split 0, inverse calculations use lower tails , potentially losing accuracy upper tails. pfun CDF function object, pexp","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transformation tools — bru_forward_transformation","text":"bru_forward_transformation, numeric vector bru_inverse_transformation, numeric vector","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transformation tools — bru_forward_transformation","text":"","code":"u <- rnorm(5, 0, 1) y <- bru_forward_transformation(qexp, u, rate = 2) v <- bru_inverse_transformation(pexp, y, rate = 2) rbind(u, y, v) #>       [,1]        [,2]     [,3]        [,4]        [,5] #> u 1.601775 -1.48957260 1.846795 -0.02553184 -1.07918779 #> y 1.453836  0.03530154 1.714977  0.33649131  0.07555798 #> v 1.601775 -1.48957260 1.846795 -0.02553184 -1.07918779"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":null,"dir":"Reference","previous_headings":"","what":"List components used in a model — bru_used","title":"List components used in a model — bru_used","text":"Create extract information components used model, individual observation models. non-NULL labels argument supplied, also calls bru_used_update() bru_used objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List components used in a model — bru_used","text":"","code":"bru_used(x = NULL, ...)  # S3 method for default bru_used(   x = NULL,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for expression bru_used(   x,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for formula bru_used(   x,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for bru bru_used(x, ..., join = TRUE)  # S3 method for list bru_used(x, ..., join = TRUE)  # S3 method for bru_like bru_used(x, ...)  # S3 method for bru_used bru_used(x, labels = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List components used in a model — bru_used","text":"x object contains information used components ... Parameters passed methods effect character; components used effects. NULL, auto-detect components include include components. effect_exclude character; components specifically exclude effect evaluation. NULL, specifically exclude components. latent character; components used _latent _eval(). NULL, auto-detect components. labels character; component labels passed bru_used_update() join Whether join list output single object; Default may depend input object class","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List components used in a model — bru_used","text":"bru_used object (list elements effect latent), list objects (methods join = FALSE)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"List components used in a model — bru_used","text":"bru_used(default): Create bru_used object. bru_used(expression): Create bru_used object expression object. bru_used(formula): Create bru_used object formula. bru_used(bru_used): Convenience method takes existing bru_used object calls bru_used_update() labels non-NULL.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List components used in a model — bru_used","text":"","code":"(used <- bru_used(~.)) #> $effect #> NULL #>  #> $latent #> character(0) #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\"     bru_used(used, labels = c(\"a\", \"c\")) #> $effect #> [1] \"a\" \"c\" #>  #> $latent #> character(0) #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\"     (used <- bru_used(~ a + b + c_latent + d_latent)) #> $effect #> [1] \"a\" \"b\" #>  #> $latent #> [1] \"c\" \"d\" #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\"     bru_used(used, labels = c(\"a\", \"c\")) #> $effect #> [1] \"a\" #>  #> $latent #> [1] \"c\" #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\"     (used <- bru_used(expression(a + b + c_latent + d_latent))) #> $effect #> [1] \"a\" \"b\" #>  #> $latent #> [1] \"c\" \"d\" #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\"     bru_used(used, labels = c(\"a\", \"c\")) #> $effect #> [1] \"a\" #>  #> $latent #> [1] \"c\" #>  #> attr(,\"class\") #> [1] \"bru_used\" \"list\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update used_component information objects — bru_used_update","title":"Update used_component information objects — bru_used_update","text":"Merge available component labels information used components information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update used_component information objects — bru_used_update","text":"","code":"bru_used_update(x, labels, ...)  # S3 method for bru_like_list bru_used_update(x, labels, ...)  # S3 method for bru_like bru_used_update(x, labels, ...)  # S3 method for bru_used bru_used_update(x, labels, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update used_component information objects — bru_used_update","text":"x Object updated labels character vector component labels ... Unused","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract basic variable names from expression — bru_used_vars","title":"Extract basic variable names from expression — bru_used_vars","text":"First replaces $ [[ indexing, internal column/variable names ignored, calls .vars().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract basic variable names from expression — bru_used_vars","text":"","code":"bru_used_vars(expr, functions = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract basic variable names from expression — bru_used_vars","text":"expr expression functions logical; TRUE, include function names","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract basic variable names from expression — bru_used_vars","text":"successful, character vector, otherwise NULL","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/call-stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Call stack utility functions — call-stack","title":"Call stack utility functions — call-stack","text":"Helper functions displaying call stack information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/call-stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call stack utility functions — call-stack","text":"","code":"fm_caller_name(which = 0L, override = NULL)  fm_call_stack(start = 0L, end = 0L, with_numbers = TRUE, ...)  fm_try_callstack(expr)"},{"path":"https://inlabru-org.github.io/inlabru/reference/call-stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call stack utility functions — call-stack","text":"TODO override TODO start TODO end TODO with_numbers TODO ... TODO expr expression evaluate","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/call-stack.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Call stack utility functions — call-stack","text":"fm_call_stack(): fm_try_callstack(): Inspired berryFunctions::tryStack","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert components to R code — code.components","title":"Convert components to R code — code.components","text":"Convert components R code","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert components to R code — code.components","text":"","code":"code.components(components, add = \"\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert components to R code — code.components","text":"components formula describing latent model components.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert components to R code — code.components","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct component linearisations — comp_lin_eval","title":"Construct component linearisations — comp_lin_eval","text":"Constructs linearisation mapper component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct component linearisations — comp_lin_eval","text":"","code":"comp_lin_eval(...)  # S3 method for component comp_lin_eval(component, input = NULL, state = NULL, ...)  # S3 method for component_list comp_lin_eval(components, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct component linearisations — comp_lin_eval","text":"... Optional parameters passed ibm_eval `ibm_jacobian. component component. input Component inputs, input_eval() linearisation evaluation state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct component linearisations — comp_lin_eval","text":"bru_mapper_taylor comp_simple_list object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct component linearisations — comp_lin_eval","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent model component construction — component","title":"Latent model component construction — component","text":"Similar glm(), gam() inla(), bru() models can constructed via formula-like syntax, latent effect specified. However, addition parts syntax compatible INLA::inla, bru components offer additional functionality facilitates modelling, predictor expression can specified separately, allowing complex non-linear predictors defined. formula syntax just way allow model components defined single line code, definitions can optionally split separate component definitions. See Details information. component methods rely component.character() method, defines model component given label/name. user usually need call methods directly, can instead supply formula expression can interpreted component_list.formula() method, called inside bru().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent model component construction — component","text":"","code":"component(...)  # S3 method for character component(   object,   main = NULL,   weights = NULL,   ...,   model = NULL,   mapper = NULL,   main_layer = NULL,   main_selector = NULL,   n = NULL,   values = NULL,   season.length = NULL,   copy = NULL,   weights_layer = NULL,   weights_selector = NULL,   group = 1L,   group_mapper = NULL,   group_layer = NULL,   group_selector = NULL,   ngroup = NULL,   control.group = NULL,   replicate = 1L,   replicate_mapper = NULL,   replicate_layer = NULL,   replicate_selector = NULL,   nrep = NULL,   A.msk = NULL,   .envir = parent.frame(),   envir_extra = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent model component construction — component","text":"... Parameters passed methods object character label component main main takes R expression evaluates latent variables evaluated (coordinates, indices, continuous scalar (rw2 etc)). Arguments starting weights, group, replicate behave similarly main, corresponding features INLA::f(). weights, weights_layer, weights_selector Optional specification effect scaling weights. syntax main. model Either one \"const\" (\"offset\"), \"factor_full\", \"factor_contrast\", \"linear\", \"fixed\", model name object accepted INLA's f function. set NULL, \"linear\" used vector inputs, \"fixed\" matrix input (converted internally iid model fixed precision) mapper Information mapping values evaluated main, latent variables. Auto-detects spde model objects model extracts mesh object use mapper, auto-generates mappers indexed models. (Default: NULL, auto-determination) main_layer, main_selector _layer input evaluate numeric index character name vector layer/variable extract covariate data object given main. (Default: NULL _selector given. Otherwise effect component name, exists covariate object, otherwise first column covariate data frame) _selector value character name variable whose contents determines layer extract covariate data point. (Default: NULL) n number latent variables model. auto-detected models (Default: NULL, auto-detection). error given figure . values Specifies covariate/index values INLA build latent model. Normally generated internally based mapping details. (Default: NULL, auto-determination) season.length Passed INLA::f() model \"seasonal\" (TODO: check parameter still fully handled) copy character; label component component copy . fixed = FALSE, scaling constant estimated, via hyperparameter. fixed = TRUE, component scaling fixed, default 1; fixed scaling, efficient express scaling predictor expression instead making copy component. group, group_mapper, group_layer, group_selector, ngroup Optional specification kronecker/group model indexing. control.group list kronecker/group model parameters, currently passed directly INLA::f replicate, replicate_mapper, replicate_layer, replicate_selector, nrep Optional specification indices independent replication model. syntax main .msk TODO: check/fix/deprecate parameter. Likely work moment, found examples use . .envir Evaluation environment envir_extra TODO: check/fix parameter.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent model component construction — component","text":"shorthand, bru() understand basic additive formulae describing fixed effect models. instance, components specification y ~ x define linear combination effect named x intercept response y respect likelihood family stated calling bru(). Mathematically, linear predictor \\(\\eta\\) written $$\\eta = \\beta * x + c,$$ : \\(c\\) intercept \\(x \\)covariate \\(\\beta\\) latent variable associated \\(x\\) \\(\\psi = \\beta * x \\) called effect \\(x\\) problem arises using kind R formula clearly reflect mathematical formula. instance, providing formula inla, resulting object refer random effect \\(\\psi = \\beta * x \\) x. Hence, clear x refers covariate effect covariate. component.character method inlabru's equivalent INLA's f function adds functionality unique inlabru. Deprecated parameters: map: Use main instead. mesh: Use mapper instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"naming-random-effects","dir":"Reference","previous_headings":"","what":"Naming random effects","title":"Latent model component construction — component","text":"INLA, f() notation used define complex models, simple linear effect model can also expressed formula = y ~ f(x, model = \"linear\"), f() inla specific function set random effects kinds. underlying predictor \\(\\eta = \\beta * x + c\\) result fitting model state x random effect's name. bru allows rewriting formula order explicitly state name random effect name associated covariate. achieved replacing f arbitrary name wish assign effect, e.g. components = y ~ psi(x, model = \"linear\"). able discriminate \\(x\\) \\(\\psi\\) relevant two functionalities bru offers. formula parameters bru() prediction method predict.bru interpreted mathematical sense. instance, predict may used analyze analytical combination covariate \\(x\\) intercept using predict(fit, data.frame(x=2)), ~ exp(psi + Intercept). corresponds mathematical expression e β + c. hand, predict may used look transformation latent variable \\(\\beta_\\psi\\) predict(fit, NULL, ~ exp(psi_latent)). corresponds mathematical expression e β.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Latent model component construction — component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren Finn.Lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent model component construction — component","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  cmp <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(cmp) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) #> Label:\tIntercept #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = 1, group = 1L, replicate = 1L #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(Intercept, model = BRU_Intercept_main_model) # Equivalent shortcuts: cmp <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) cmp <- component_list(~ myLinearEffectOfX(x)) # Individual component cmp <- component(\"myLinearEffectOfX\", main = x, model = \"linear\") summary(cmp) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) # \\donttest{ if (bru_safe_inla(quietly = TRUE)) {   # As an example, let us create a linear component. Here, the component is   # called \"myEffectOfX\" while the covariate the component acts on is called \"x\":    cmp <- component(\"myEffectOfX\", main = x, model = \"linear\")   summary(cmp)    # A more complicated component:   cmp <- component(\"myEffectOfX\",     main = x,     model = INLA::inla.spde2.matern(INLA::inla.mesh.1d(1:10))   )    # Compound fixed effect component, where x and z are in the input data.   # The formula will be passed on to MatrixModels::model.Matrix:   cmp <- component(\"eff\", ~ -1 + x:z, model = \"fixed\")   summary(cmp) } #> Label:\teff #>   Type:\tmain = fixed, group = exchangeable, replicate = iid #>   Input:\tmain = ~-1 + x:z, group = 1L, replicate = 1L #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(eff, model = BRU_eff_main_model, hyper = #>       BRU_eff_main_fixed_hyper) # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component values in predictor expressions — component_eval","title":"Evaluate component values in predictor expressions — component_eval","text":"predictor expressions, name_eval(...) can used evaluate effect component called \"name\".","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"component_eval(   main,   group = NULL,   replicate = NULL,   weights = NULL,   .state = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component values in predictor expressions — component_eval","text":"main, group, replicate, weights Specification evaluate component. four inputs passed joint bru_mapper component,   .state internal component state. Normally supplied automatically internal methods evaluating inlabru predictor expressions.","code":"list(mapper = list(        main = main,        group = group,        replicate = replicate),      scale = weights)"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component values in predictor expressions — component_eval","text":"vector values component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"if (FALSE) { if (bru_safe_inla()) {   mesh <- INLA::inla.mesh.2d(     cbind(0, 0),     offset = 2, max.edge = 0.25   )   spde <- INLA::inla.spde2.pcmatern(mesh,     prior.range = c(0.1, 0.01),     prior.sigma = c(2, 0.01)   )   data <- sp::SpatialPointsDataFrame(     matrix(runif(10), 5, 2),     data = data.frame(z = rnorm(5))   )   fit <- bru(z ~ -1 + field(coordinates, model = spde),     family = \"gaussian\", data = data   )   pred <- predict(     fit,     data = data.frame(x = 0.5, y = 0.5),     formula = ~ field_eval(cbind(x, y))   ) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for inlabru component lists — component_list","title":"Methods for inlabru component lists — component_list","text":"Constructor methods inlabru component lists. Syntax details given component().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for inlabru component lists — component_list","text":"","code":"component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for formula component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for list component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for component_list c(...)  # S3 method for component c(...)  # S3 method for component_list [(x, i)"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for inlabru component lists — component_list","text":"object object operate lhoods bru_like_list object .envir evaluation environment non-formula input ... Parameters passed methods. Also see Details. x component_list object extract sub-list indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for inlabru component lists — component_list","text":"component_list.formula: Convert component formula component_list object component_list.list: Combine list components /component formulas component_list object c.component_list: ... arguments component_list objects. environment first argument applied resulting component_list. c.component: ... arguments component objects. environment first argument applied resulting ``component_list`.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for inlabru component lists — component_list","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for inlabru component lists — component_list","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  eff <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(eff[[1]]) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) # Equivalent shortcuts: eff <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) eff <- component_list(~ myLinearEffectOfX(x)) # Individual component eff <- component(\"myLinearEffectOfX\", main = x, model = \"linear\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/cprod.html","id":null,"dir":"Reference","previous_headings":"","what":"(Blockwise) cross product of integration points — cprod","title":"(Blockwise) cross product of integration points — cprod","text":"Calculates groupwise cross product integration points different dimensions multiplies weights accordingly. object defining points particular dimension weights attached weights assumed 1. Legacy wrapper fm_cprod()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/cprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Blockwise) cross product of integration points — cprod","text":"","code":"cprod(..., na.rm = NULL, .blockwise = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/cprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Blockwise) cross product of integration points — cprod","text":"... data.frame, sf, SpatialPointsDataFrame objects, one usually obtained call fm_int() method. na.rm logical; TRUE, rows weight NA non-overlapping full_join removed; FALSE, set undefined weights NA. NULL (default), act TRUE, warn elements needed removing. .blockwise logical; FALSE, computes full tensor product integration. TRUE, computes within-block tensor product integration (used internally fm_int()). Default FALSE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/cprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Blockwise) cross product of integration points — cprod","text":"data.frame, sf, SpatialPointsDataFrame multidimensional integration points weights","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/cprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Blockwise) cross product of integration points — cprod","text":"","code":"# \\donttest{ # ipoints needs INLA if (bru_safe_inla()) {   # Create integration points in dimension 'myDim' and 'myDiscreteDim'   ips1 <- fm_int(INLA::inla.mesh.1d(0:20),     rbind(c(0, 3), c(3, 8)),     name = \"myDim\"   )   ips2 <- fm_int(domain = c(1, 2, 4), name = \"myDiscreteDim\")    # Calculate the cross product   ips <- cprod(ips1, ips2)    # Plot the integration points   plot(ips$myDim, ips$myDiscreteDim, cex = 10 * ips$weight) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise DIC and WAIC from lgcp objects. — deltaIC","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"Calculates DIC /WAIC differences produces ordered summary.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"deltaIC(..., criterion = \"DIC\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"... Comma-separated objects inheriting class inla obtained run INLA::inla(), bru() lgcp() criterion character vector. includes 'DIC', computes DIC differences; contains 'WAIC', computes WAIC differences. Default: 'DIC'","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"data frame row containing Model name, DIC Delta.DIC, /WAIC Delta.WAIC.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {   # Generate some data   input.df <- data.frame(idx = 1:10, x = cos(1:10))   input.df <- within(     input.df,     y <- rpois(10, 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))   )    # Fit two models   fit1 <- bru(     y ~ x,     family = \"poisson\",     data = input.df,     options = list(control.compute = list(dic = TRUE))   )   fit2 <- bru(     y ~ x + rand(idx, model = \"iid\"),     family = \"poisson\",     data = input.df,     options = list(control.compute = list(dic = TRUE))   )    # Compare DIC    deltaIC(fit1, fit2) } #> Current num.threads is '1:1'. #> No num.threads change needed. #>   Model      DIC  Delta.DIC #> 1  fit2 44.12545 0.00000000 #> 2  fit1 44.13706 0.01161184 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance and correlations measures for prediction components — devel.cvmeasure","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Calculates local integrated variance correlation measures introduced Yuan et al. (2017).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"devel.cvmeasure(joint, prediction1, prediction2, samplers = NULL, mesh = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"joint joint prediction two latent model components. prediction1 prediction first component. prediction2 prediction second component. samplers SpatialPolygon object describing area compute cumulative variance measure. mesh inla.mesh prediction performed (required cumulative Vmeasure).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Variance correlations measures.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Y. Yuan, F. E. Bachl, F. Lindgren, D. L. Brochers, J. B. Illian, S. T. Buckland, H. Rue, T. Gerrodette. 2017. Point process models spatio-temporal distance sampling data large-scale survey blue whales. https://arxiv.org/abs/1604.06013","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE) &&     bru_safe_sp()) {    # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use RColorBrewer    library(RColorBrewer)    # Fit a model with two components:   # 1) A spatial smooth SPDE   # 2) A spatial covariate effect (vegetation)    pcmatern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    cmp <- coordinates ~ vegetation(gorillas$gcov$vegetation, model = \"factor_contrast\") +     spde(coordinates, model = pcmatern) -     Intercept(1)    fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict SPDE and vegetation at the mesh vertex locations    vrt <- fm_vertices(gorillas$mesh, format = \"sp\")   pred <- predict(     fit,     vrt,     ~ list(       joint = spde + vegetation,       field = spde,       veg = vegetation     )   )    # Plot component mean    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Plot component variance    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Calculate variance and correlation measure    vm <- devel.cvmeasure(pred$joint, pred$field, pred$veg)   lprange <- range(vm$var.joint, vm$var1, vm$var2)    # Variance contribution of the components    csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)   boundary <- gorillas$boundary    plot.1 <- ggplot() +     gg(gorillas$mesh, color = vm$var.joint, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"joint\") +     theme(legend.position = \"bottom\")   plot.2 <- ggplot() +     gg(gorillas$mesh, color = vm$var1, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"SPDE\") +     theme(legend.position = \"bottom\")   plot.3 <- ggplot() +     gg(gorillas$mesh, color = vm$var2, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"vegetation\") +     theme(legend.position = \"bottom\")    multiplot(plot.1, plot.2, plot.3, cols = 3)    # Covariance of SPDE field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cov)    # Correlation between field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cor)    # Variance and correlation integrated over space    vm.int <- devel.cvmeasure(pred$joint, pred$field, pred$veg,     samplers = fm_int(gorillas$mesh, gorillas$boundary),     mesh = gorillas$mesh   )   vm.int } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate expressions in the data context — eval_in_data_context","title":"Evaluate expressions in the data context — eval_in_data_context","text":"Evaluate expressions data context","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate expressions in the data context — eval_in_data_context","text":"","code":"eval_in_data_context(   input,   data = NULL,   response_data = NULL,   default = NULL,   .envir = parent.frame() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate expressions in the data context — eval_in_data_context","text":"input expression evaluated data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. response_data Likelihood-specific data models need different size/format inputs response variables, data.frame SpatialPoints[DataFrame] object. default Value used expression evaluated NULL. Default NULL .envir evaluation environment","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate expressions in the data context — eval_in_data_context","text":"result expression evaluation","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate spatial covariates — eval_spatial","title":"Evaluate spatial covariates — eval_spatial","text":"Evaluate spatial covariates","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate spatial covariates — eval_spatial","text":"","code":"eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for SpatialPolygonsDataFrame eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for SpatialPixelsDataFrame eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for SpatialGridDataFrame eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for sf eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for SpatRaster eval_spatial(data, where, layer = NULL, selector = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate spatial covariates — eval_spatial","text":"data Spatial data evaluate data layer data layer extract (integer character). May vector, specifying separate layer item. selector name variable specifying layer information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Evaluate spatial covariates — eval_spatial","text":"eval_spatial(SpatialPolygonsDataFrame): Compatibility wrapper eval_spatial.sf eval_spatial(sf): Supports point--polygon information lookup. combinations untested.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all component linearisations — evaluate_comp_lin","title":"Compute all component linearisations — evaluate_comp_lin","text":"Computes individual bru_mapper_taylor objects included components model likelihood","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all component linearisations — evaluate_comp_lin","text":"","code":"evaluate_comp_lin(model, input, state, inla_f = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all component linearisations — evaluate_comp_lin","text":"model bru_model object input list named lists component inputs state named list component states inla_f Controls input data interpretations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all component linearisations — evaluate_comp_lin","text":"list (class 'comp_simple') named lists (class 'comp_simple_list') bru_mapper_taylor objects, one included component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute simplified component mappings — evaluate_comp_simple","title":"Compute simplified component mappings — evaluate_comp_simple","text":"Computes individual bru_mapper_taylor objects included linear components model likelihood, keeps non-linear mappers intact.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute simplified component mappings — evaluate_comp_simple","text":"","code":"evaluate_comp_simple(...)  # S3 method for component_list evaluate_comp_simple(components, input, inla_f = FALSE, ...)  # S3 method for bru_model evaluate_comp_simple(model, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute simplified component mappings — evaluate_comp_simple","text":"input list named lists component inputs inla_f Controls input data interpretations model bru_model object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute simplified component mappings — evaluate_comp_simple","text":"list (class 'comp_simple_list_list') named lists (class 'comp_simple_list') bru_mapper objects, one included component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"Subsetting comp_simple_list objects, retaining class","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"","code":"# S3 method for comp_simple_list [(x, i)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"x comp_simple_list object extract element(s) indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a component effect — evaluate_effect_single_state","title":"Evaluate a component effect — evaluate_effect_single_state","text":"Calculate latent component effects given data state component's internal random variables.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a component effect — evaluate_effect_single_state","text":"","code":"evaluate_effect_single_state(...)  evaluate_effect_multi_state(...)  # S3 method for bru_mapper evaluate_effect_single_state(component, input, state, ...)  # S3 method for comp_simple_list evaluate_effect_single_state(components, input, state, ...)  # S3 method for comp_simple_list evaluate_effect_multi_state(components, input, state, ...)  # S3 method for component_list evaluate_effect_single_state(components, input, state, ...)  # S3 method for component_list evaluate_effect_multi_state(components, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a component effect — evaluate_effect_single_state","text":"... Optional additional parameters, e.g. inla_f. Normally unused. component bru_component, comp_simple, comp_simple_list. input Pre-evaluated component input state Specification one (evaluate_effect_single_state) several (evaluate_effect_multi_State) latent variable states: evaluate_effect_single_state.bru_mapper: vector latent component state. evaluate_effect_single_state.*_list: list named state vectors. evaluate_effect_multi_state.*_list: list lists named state vectors.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a component effect — evaluate_effect_single_state","text":"evaluate_effect_single_state.component_list: list evaluated component effect values evaluate_effect_multi.comp_simple_list: list lists evaluated component effects, one list state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate a component effect — evaluate_effect_single_state","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all index values — evaluate_index","title":"Compute all index values — evaluate_index","text":"Computes index values matrices included components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all index values — evaluate_index","text":"","code":"evaluate_index(model, lhoods)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all index values — evaluate_index","text":"model bru_model object lhoods bru_like_list object. Deprecated ignored","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all index values — evaluate_index","text":"named list idx_full idx_inla, named list indices, inla_subset, inla_subset, named list logical subset specifications extracting INLA::f() compatible index subsets.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all component inputs — evaluate_inputs","title":"Compute all component inputs — evaluate_inputs","text":"Computes component inputs included components model likelihood","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all component inputs — evaluate_inputs","text":"","code":"evaluate_inputs(model, lhoods, inla_f)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all component inputs — evaluate_inputs","text":"model bru_model object lhoods bru_like_list object inla_f logical","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"Evaluate sample posterior result given model locations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"","code":"evaluate_model(   model,   state,   data = NULL,   input = NULL,   comp_simple = NULL,   predictor = NULL,   format = NULL,   used = NULL,   ... )  evaluate_state(   model,   result,   property = \"mode\",   n = 1,   seed = 0L,   num.threads = NULL,   internal_hyperpar = FALSE,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"model bru model state list state lists, generated evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate predictor. input Precomputed inputs list components comp_simple Precomputed comp_simple_list components predictor formula expression evaluated given posterior sample thereof. default (NULL) returns data.frame containing sampled effects. case formula right hand side used evaluation. format character; determines storage format predictor output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list element contains evaluated predictor expression state. ... Additional arguments passed inla.posterior.sample result bru object bru() lgcp() property Property model components obtain value . Default: \"mode\". options \"mean\", \"0.025quant\", \"0.975quant\", \"sd\" \"sample\". case \"sample\" obtain samples posterior (see n parameter). result NULL, -zero vectors returned component. n Number samples draw. seed seed != 0L, random seed num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" internal_hyperpar logical; TRUE, return hyperparameter properties internal scale. Currently ignored property=\"sample\". Default FALSE. include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"evaluate_model wrapper evaluate model state, -matrices, effects, predictor, one call. evaluate_state evaluates model state properties samples","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component effects or expressions — evaluate_predictor","title":"Evaluate component effects or expressions — evaluate_predictor","text":"Evaluate component effects expressions, based bru model one several states latent variables hyperparameters.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component effects or expressions — evaluate_predictor","text":"","code":"evaluate_predictor(   model,   state,   data,   effects,   predictor,   used = NULL,   format = \"auto\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component effects or expressions — evaluate_predictor","text":"state list element list named latent state information, produced evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate model. effects list element list named evaluated effects, computed evaluate_effect_multi_state.component_list() predictor Either formula expression used bru_used() object, NULL (default) format character; determines storage format output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list column contains evaluated predictor expression state. inla_f logical Default: \"auto\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component effects or expressions — evaluate_predictor","text":"list matrix returned, specified format","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate component effects or expressions — evaluate_predictor","text":"component, e.g. \"name\", state values available name_latent, arbitrary evaluation can done name_eval(...), see component_eval().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand labels — expand_labels","title":"Expand labels — expand_labels","text":"Expand labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand labels — expand_labels","text":"","code":"expand_labels(labels, expand, suffix)"},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand labels — expand_labels","text":"labels character vector; original labels expand character vector; subset labels expand suffix character; suffix add labels selected expand","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand labels — expand_labels","text":"vector labels suffix appended selected labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a summary property from all results of an inla result — extract_property","title":"Extract a summary property from all results of an inla result — extract_property","text":"Extract summary property results inla result","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a summary property from all results of an inla result — extract_property","text":"","code":"extract_property(result, property, internal_hyperpar = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a summary property from all results of an inla result — extract_property","text":"result inla result object property character; \"mean\", \"sd\", \"mode\", column identifier inla result $summary.fixed, $summary.random$label, $summary.hyperpar, \"joint_mode\". \"joint_mode\", joint latent mode extracted, joint hyperparameter mode, internal scale. \"predictor_sd\" posterior standard deviations linear predictor returned. internal_hyperpar logical; TRUE, use internal scale hyperparamter properties. Default FALSE, except property \"joint_mode\" forces internal_hyperpar=TRUE.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a summary property from all results of an inla result — extract_property","text":"named list estimated fixed effect coefficient, random effect vector, hyperparameter. hyperparameter names standardised bru_standardise_names()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a coordinate reference system object — fm_CRS","title":"Create a coordinate reference system object — fm_CRS","text":"Creates either CRS object inla.CRS object, describing coordinate reference system","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a coordinate reference system object — fm_CRS","text":"","code":"fm_CRS(...)  # S3 method for crs fm_CRS(x, ...)  # S3 method for fm_crs fm_CRS(x, ...)  # S3 method for Spatial fm_CRS(x, ...)  # S3 method for inla.CRS fm_CRS(x, ..., crsonly = FALSE)  # S3 method for sf fm_CRS(x, ..., crsonly = FALSE)  # S3 method for sfc fm_CRS(x, ..., crsonly = FALSE)  # S3 method for sfg fm_CRS(x, ..., crsonly = FALSE)  # S3 method for inla.mesh fm_CRS(x, ..., crsonly = FALSE)  # S3 method for inla.mesh.lattice fm_CRS(x, ..., crsonly = FALSE)  # S3 method for inla.mesh.segment fm_CRS(x, ..., crsonly = FALSE)  # S3 method for CRS fm_CRS(x, oblique = NULL, ...)  # S3 method for default fm_CRS(   projargs = NULL,   doCheckCRSArgs = NULL,   args = NULL,   oblique = NULL,   SRS_string = NULL,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a coordinate reference system object — fm_CRS","text":"... Additional parameters. currently use. x Object convert CRS extract CRS information . crsonly logical; TRUE, remove obliqueinformation forinla.CRSclass objects return pureCRSclass object. Default:FALSE`. oblique Vector length 4 rotation angles (degrees) oblique projection, values defaulting zero. values indicate (longitude, latitude, orientation, orbit), explained Details section . projargs Either 1) projection argument string suitable input sp::CRS, 2) existing CRS object, 3) shortcut reference string predefined projection; run names(fm_wkt_predef()) valid predefined projections. doCheckCRSArgs ignored. args optional list name/value pairs add /override PROJ4 arguments projargs.  name=value converted \"+name=value\", name=NA converted \"+name\". SRS_string WKT2 string defining coordinate system; see sp::CRS. takes precedence projargs.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a coordinate reference system object — fm_CRS","text":"Either sp::CRS object inla.CRS object, depending coordinate reference system described parameters can expressed pure sp::CRS object . S3 inla.CRS object list, usually (necessarily) containing least one element: crs basic sp::CRS object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a coordinate reference system object — fm_CRS","text":"first two elements oblique vector (longitude, latitude) coordinates oblique centre point. third value (orientation) counterclockwise rotation angle observer looking centre point outside sphere. fourth value quasi-longitude (orbit angle) rotation along oblique observers equator. Simple oblique: oblique=c(0, 45) Polar: oblique=c(0, 90) Quasi-transversal: oblique=c(0, 0, 90) Satellite orbit viewpoint: oblique=c(lon0-time*v1, 0, orbitangle, orbit0+time*v2), lon0 longitude satellite orbit crosses equator time=0, satellite angle orbit0 along orbit.  orbital angle relative equatorial plane orbitangle, v1 v2 angular velocities planet satellite, respectively. Note \"forward\" satellite's point view \"right\" projection. oblique[2] oblique[3] non-zero, resulting projection correct perfect spheres.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a coordinate reference system object — fm_CRS","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRS_sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a coordinate reference system object — fm_CRS","text":"","code":"crs1 <- fm_CRS(\"longlat_globe\") crs2 <- fm_CRS(\"lambert_globe\") crs3 <- fm_CRS(\"mollweide_norm\") crs4 <- fm_CRS(\"hammer_globe\") crs5 <- fm_CRS(\"sphere\") crs6 <- fm_CRS(\"globe\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":null,"dir":"Reference","previous_headings":"","what":"Show expanded CRS arguments — fm_CRS_as_list","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"Wrappers sp::CRS inla.CRS objects handle coordinate reference system argument string. methods longer used PROJ6/rgdal3; see fm_wkt() fm_proj4string() new approach.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"","code":"fm_CRS_as_list(x, ...)  fm_list_as_CRS(x, ...)  fm_CRSargs(x, ...)  fm_list_as_CRSargs(x, ...)  fm_CRSargs_as_list(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"x sp::CRS inla.CRS object (fm_CRSargs fm_CRS_as_list), character string (fm_CRSargs_as_list), list (fm_list_as_CRS fm_list_as_CRSargs). ... Additional arguments passed methods.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"fm_CRSargs fm_list_as_CRSargs, character string PROJ.4 arguments. fm_CRS_as_list fm_CRSargs_as_list, list name/value pairs. fm_list_as_CRS, CRS inla.CRS object. fm_list_as_CRSargs(), CRS proj4 string name=value pair list fm_CRSargs_as_list(), list name=value pairs CRS proj4 string","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_CRSargs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show expanded CRS arguments — fm_CRS_as_list","text":"","code":"crs0 <- fm_CRS(\"longlat\") #> Warning: Use of old predefined projection 'longlat' is deprecated. Converting to 'longlat_norm' p4s <- fm_proj4string(crs0) lst <- fm_CRSargs_as_list(p4s) crs1 <- fm_list_as_CRS(lst) #> Warning: 'fm_CRS' should be given a SRS_string for PROJ6 or a known keyword for a #>   predefined string given in projargs. Using 'fm_crs()' workaround. lst$a <- 2 crs2 <- fm_CRS(p4s, args = lst) #> Warning: 'fm_CRS' should be given a SRS_string for PROJ6 or a known keyword for a #>   predefined string given in projargs. Using 'fm_crs()' workaround. print(fm_proj4string(crs0)) #> [1] \"+proj=longlat +R=1 +no_defs\" print(fm_proj4string(crs1)) #> [1] \"+proj=longlat +R=1 +no_defs\" print(fm_proj4string(crs2)) #> [1] \"+proj=longlat +R=1 +no_defs\""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_as.html","id":null,"dir":"Reference","previous_headings":"","what":"Coercion methods to and from meshes — fm_as_sp_crs","title":"Coercion methods to and from meshes — fm_as_sp_crs","text":"Coercion methods meshes","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_as.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coercion methods to and from meshes — fm_as_sp_crs","text":"","code":"fm_as_sp_crs(x, ...)  fm_as_sfc(x, ...)  fm_as_inla_mesh_segment(...)  fm_as_inla_mesh(...)  # S3 method for inla.mesh fm_as_sfc(x, ..., multi = FALSE)  # S3 method for sfc_MULTIPOLYGON fm_as_inla_mesh(x, ...)  # S3 method for sfc_POLYGON fm_as_inla_mesh(x, ...)  # S3 method for sfc_POINT fm_as_inla_mesh_segment(x, reverse = FALSE, grp = NULL, is.bnd = TRUE, ...)  # S3 method for sfc_LINESTRING fm_as_inla_mesh_segment(x, join = TRUE, grp = NULL, reverse = FALSE, ...)  # S3 method for sfc_POLYGON fm_as_inla_mesh_segment(x, join = TRUE, grp = NULL, ...)  # S3 method for sfc_MULTIPOLYGON fm_as_inla_mesh_segment(x, join = TRUE, grp = NULL, ...)  # S3 method for sfc_GEOMETRY fm_as_inla_mesh_segment(x, grp = NULL, join = TRUE, ...)  # S3 method for sf fm_as_inla_mesh_segment(x, ...)  # S3 method for sf fm_as_inla_mesh(x, ...)  fm_sp2segment(sp, ...)  # S3 method for matrix fm_as_inla_mesh_segment(   sp,   reverse = FALSE,   grp = NULL,   is.bnd = FALSE,   crs = NULL,   closed = FALSE,   ... )  # S3 method for SpatialPoints fm_as_inla_mesh_segment(   sp,   reverse = FALSE,   grp = NULL,   is.bnd = TRUE,   closed = FALSE,   ... )  # S3 method for SpatialPointsDataFrame fm_as_inla_mesh_segment(sp, ...)  # S3 method for Line fm_as_inla_mesh_segment(sp, reverse = FALSE, grp = NULL, crs = NULL, ...)  # S3 method for Lines fm_as_inla_mesh_segment(sp, join = TRUE, grp = NULL, crs = NULL, ...)  # S3 method for SpatialLines fm_as_inla_mesh_segment(sp, join = TRUE, grp = NULL, ...)  # S3 method for SpatialLinesDataFrame fm_as_inla_mesh_segment(sp, ...)  # S3 method for SpatialPolygons fm_as_inla_mesh_segment(sp, join = TRUE, grp = NULL, ...)  # S3 method for SpatialPolygonsDataFrame fm_as_inla_mesh_segment(sp, ...)  # S3 method for Polygons fm_as_inla_mesh_segment(sp, join = TRUE, crs = NULL, grp = NULL, ...)  # S3 method for Polygon fm_as_inla_mesh_segment(sp, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_as.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coercion methods to and from meshes — fm_as_sp_crs","text":"x object coerced/transformed/converted another class ... Arguments passed methods multi logical; TRUE, attempt sfc_MULTIPOLYGON, otherwise set sfc_POLYGON. Default FALSE reverse logical; TRUE, reverse order input points. Default FALSE grp non-null, integer vector grouping labels one segment. Default NULL .bnd logical; TRUE, set boundary flag segments. Default TRUE join logical; TRUE, join input segments common vertices. Default TRUE sp sp style S4 object converted crs crs object closed logical; whether treat point sequence closed polygon. Default: FALSE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_as.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coercion methods to and from meshes — fm_as_sp_crs","text":"fm_as_sfc: sfc_MULTIPOLYGON sfc_POLYGON object fm_as_inla_mesh: inla.mesh mesh object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract triangle centroids from an inla.mesh — fm_centroids","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"Computes centroids triangles inla.mesh object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"","code":"fm_centroids(x, format = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"x inla.mesh object. format character; \"sf\", \"df\", \"sp\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"sf, data.frame, SpatialPointsDataFrame object, vertex coordinates, .triangle column triangle indices.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_centroids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract triangle centroids from an inla.mesh — fm_centroids","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   vrt <- fm_centroids(mrsea$mesh, format = \"sp\")   ggplot() +     gg(mrsea$mesh) +     gg(vrt, color = \"red\") }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":null,"dir":"Reference","previous_headings":"","what":"Check which mesh triangles are inside a polygon — fm_contains","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"Wrapper sf::st_contains() (previously sp::()) method find triangle centroids vertices inside sf sp polygon objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"","code":"fm_contains(x, y, ...)  # S3 method for Spatial fm_contains(x, y, ...)  # S3 method for sf fm_contains(x, y, ...)  # S3 method for sfc fm_contains(x, y, ..., type = c(\"centroid\", \"vertex\"))"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"x geometry (typically sf sp::SpatialPolygons object) queries y inla.mesh() object ... Passed methods type query type; either 'centroid' (default, triangle centroids), 'vertex' (mesh vertices)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"List vectors triangle indices (type 'centroid') vertex indices (type 'vertex'). list one entry per row sf object. Use unlist(fm_contains(...)) combined union needed.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"Haakon Bakka, bakka@r-inla.org, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_contains.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check which mesh triangles are inside a polygon — fm_contains","text":"","code":"if (bru_safe_inla() &&   bru_safe_sp()) {   # Create a polygon and a mesh   obj <- sp::SpatialPolygons(     list(Polygons(       list(Polygon(rbind(         c(0, 0),         c(50, 0),         c(50, 50),         c(0, 50)       ))),       ID = 1     )),     proj4string = fm_CRS(\"longlat_globe\")   )   mesh <- INLA::inla.mesh.create(globe = 2, crs = fm_crs(\"sphere\"))    ## 3 vertices found in the polygon   fm_contains(obj, mesh, type = \"vertex\")    ## 3 triangles found in the polygon   fm_contains(obj, mesh)    ## Multiple transformations can lead to slightly different results due to edge cases   ## 4 triangles found in the polygon   fm_contains(     obj,     fm_transform(mesh, crs = fm_crs(\"mollweide_norm\"))   ) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)'"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_cprod.html","id":null,"dir":"Reference","previous_headings":"","what":"(Blockwise) cross product of integration points — fm_cprod","title":"(Blockwise) cross product of integration points — fm_cprod","text":"Calculates groupwise cross product integration points different dimensions multiplies weights accordingly. object defining points particular dimension weights attached weights assumed 1.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_cprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Blockwise) cross product of integration points — fm_cprod","text":"","code":"fm_cprod(..., na.rm = NULL, .blockwise = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_cprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Blockwise) cross product of integration points — fm_cprod","text":"... data.frame, sf, SpatialPointsDataFrame objects, one usually obtained call fm_int() method. na.rm logical; TRUE, rows weight NA non-overlapping full_join removed; FALSE, set undefined weights NA. NULL (default), act TRUE, warn elements needed removing. .blockwise logical; FALSE, computes full tensor product integration. TRUE, computes within-block tensor product integration (used internally fm_int()). Default FALSE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_cprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Blockwise) cross product of integration points — fm_cprod","text":"data.frame, sf, SpatialPointsDataFrame multidimensional integration points weights","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_cprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Blockwise) cross product of integration points — fm_cprod","text":"","code":"# \\donttest{ # fm_int needs INLA if (bru_safe_inla()) {   # Create integration points in dimension 'myDim' and 'myDiscreteDim'   ips1 <- fm_int(INLA::inla.mesh.1d(1:20),     rbind(c(0, 3), c(3, 8)),     name = \"myDim\"   )   ips2 <- fm_int(domain = c(1, 2, 4), name = \"myDiscreteDim\")    # Calculate the cross product   ips <- fm_cprod(ips1, ips2)    # Plot the integration points   plot(ips$myDim, ips$myDiscreteDim, cex = 10 * ips$weight) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain coordinate reference system object — fm_crs_is_null","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"Obtain sf::crs fm_crs object spatial object, convert crs information construct new sf::crs object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"","code":"fm_crs_is_null(x)  fm_crs(x, ..., crsonly = FALSE)  fm_crs_oblique(x)  fm_crs_oblique(x) <- value  # S3 method for fm_crs print(x, ...)  # S3 method for default fm_crs(x, ..., crsonly = FALSE)  # S3 method for fm_crs st_crs(x, ...)  # S3 method for fm_crs $(x, name)  # S3 method for fm_crs fm_crs(x, ..., crsonly = FALSE)  # S3 method for inla.CRS fm_crs(x, ..., crsonly = FALSE)  # S3 method for character fm_crs(x, ..., crsonly = FALSE)  # S3 method for Spatial fm_crs(x, ..., crsonly = FALSE)  # S3 method for SpatVector fm_crs(x, ..., crsonly = FALSE)  # S3 method for SpatRaster fm_crs(x, ..., crsonly = FALSE)  # S3 method for sf fm_crs(x, ..., crsonly = FALSE)  # S3 method for sfc fm_crs(x, ..., crsonly = FALSE)  # S3 method for sfg fm_crs(x, ..., crsonly = FALSE)  # S3 method for inla.mesh fm_crs(x, ..., crsonly = FALSE)  # S3 method for inla.mesh.lattice fm_crs(x, ..., crsonly = FALSE)  # S3 method for inla.mesh.segment fm_crs(x, ..., crsonly = FALSE)  fm_wkt_predef()"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"x Object convert crs  extract crs information . character, string suitable sf::st_crs(x), name predefined wkt string ``names(fm_wkt_predef())`. ... Additional parameters. currently use. crsonly logical; TRUE, remove oblique information fm_crs class objects return pure crs class object. Default: FALSE. value Vector length 4 rotation angles (degrees) oblique projection, values defaulting zero. values indicate (longitude, latitude, orientation, orbit), explained Details section . name element name","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"Either sf::crs object fm_crs object, depending coordinate reference system described parameters can expressed pure crs object . crs object (sf::st_crs()) fm_crs object. S3 fm_crs object list elements crs oblique. fm_wkt_predef returns WKT2 string defining projection","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"first two elements oblique vector (longitude, latitude) coordinates oblique centre point. third value (orientation) counterclockwise rotation angle observer looking centre point outside sphere. fourth value quasi-longitude (orbit angle) rotation along oblique observers equator. Simple oblique: oblique=c(0, 45) Polar: oblique=c(0, 90) Quasi-transversal: oblique=c(0, 0, 90) Satellite orbit viewpoint: oblique=c(lon0-time*v1, 0, orbitangle, orbit0+time*v2), lon0 longitude satellite orbit crosses equator time=0, satellite angle orbit0 along orbit.  orbital angle relative equatorial plane orbitangle, v1 v2 angular velocities planet satellite, respectively. Note \"forward\" satellite's point view \"right\" projection. oblique[2] oblique[3] non-zero, resulting projection correct perfect spheres.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"st_crs(fm_crs): st_crs(x, ...) equivalent fm_crs(x, ..., crsonly = TRUE) x fm_crs object. $: fm_crs object x, x$name calls accessor method crs object inside . name \"crs\", internal crs object returned. name \"oblique\", internal oblique angle parameter vector returned.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"fm_crs_is_null(): Check object NULL NA CRS information","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain coordinate reference system object — fm_crs_is_null","text":"","code":"crs1 <- fm_crs(\"longlat_globe\") crs2 <- fm_crs(\"lambert_globe\") crs3 <- fm_crs(\"mollweide_norm\") crs4 <- fm_crs(\"hammer_globe\") crs5 <- fm_crs(\"sphere\") crs6 <- fm_crs(\"globe\") if (FALSE) { names(fm_wkt_predef()) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":null,"dir":"Reference","previous_headings":"","what":"Handling CRS/WKT — fm_crs_wkt","title":"Handling CRS/WKT — fm_crs_wkt","text":"Get set CRS object WKT string properties.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handling CRS/WKT — fm_crs_wkt","text":"","code":"fm_wkt_is_geocent(wkt)  fm_crs_is_geocent(crs)  fm_wkt_get_ellipsoid_radius(wkt)  fm_crs_get_ellipsoid_radius(crs)  fm_ellipsoid_radius(x)  # S3 method for default fm_ellipsoid_radius(x)  # S3 method for character fm_ellipsoid_radius(x)  fm_wkt_set_ellipsoid_radius(wkt, radius)  fm_ellipsoid_radius(x) <- value  # S3 method for character fm_ellipsoid_radius(x) <- value  # S3 method for CRS fm_ellipsoid_radius(x) <- value  # S3 method for inla.CRS fm_ellipsoid_radius(x) <- value  # S3 method for crs fm_ellipsoid_radius(x) <- value  # S3 method for fm_crs fm_ellipsoid_radius(x) <- value  fm_crs_set_ellipsoid_radius(crs, radius)  fm_wkt_unit_params()  fm_wkt_get_lengthunit(wkt)  fm_wkt_set_lengthunit(wkt, unit, params = NULL)  fm_crs_get_lengthunit(crs)  fm_crs_set_lengthunit(crs, unit)  fm_length_unit(x)  # S3 method for default fm_length_unit(x)  # S3 method for character fm_length_unit(x)  fm_length_unit(x) <- value  # S3 method for character fm_length_unit(x) <- value  # S3 method for CRS fm_length_unit(x) <- value  # S3 method for inla.CRS fm_length_unit(x) <- value  # S3 method for crs fm_length_unit(x) <- value  # S3 method for fm_crs fm_length_unit(x) <- value  fm_wkt(crs)  fm_proj4string(crs)  fm_crs_get_wkt(crs)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handling CRS/WKT — fm_crs_wkt","text":"wkt WKT2 character string crs sf::crs, sp::CRS, fm_crs inla.CRS object x crs object extract value assign values radius numeric; new radius value value Value assign unit character, name unit. Supported names \"metre\", \"kilometre\", aliases \"meter\", \"m\", International metre\", \"kilometer\", \"km\", defined fm_wkt_unit_params params argument. (legacy PROJ4 use, \"m\" \"km\" supported) params Length unit definitions, list format produced fm_wkt_unit_params(), Default: NULL, invokes fm_wkt_unit_params()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handling CRS/WKT — fm_crs_wkt","text":"fm_wkt_unit_params, list named unit definitions fm_wkt_get_lengthunit, list length units used wkt string, excluding ellipsoid radius unit. fm_wkt_set_lengthunit, WKT2 string altered length units. Note length unit ellipsoid radius unchanged. fm_crs_get_lengthunit, list length units used wkt string, excluding ellipsoid radius unit. (legacy PROJ4 code, raw units proj4string returned, present.) fm_length_unit<-, crs object altered length units. Note length unit ellipsoid radius unchanged.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Handling CRS/WKT — fm_crs_wkt","text":"fm_wkt(): Returns WKT2 string, input supported fm_crs(). fm_proj4string(): Returns proj4 string, input supported fm_crs().","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Handling CRS/WKT — fm_crs_wkt","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_crs_wkt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Handling CRS/WKT — fm_crs_wkt","text":"","code":"if (FALSE) { c1 <- fm_crs(\"globe\") fm_crs_get_lengthunit(c1) c2 <- fm_crs_set_lengthunit(c1, \"m\") fm_crs_get_lengthunit(c2) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for projecting to/from an inla.mesh — fm_evaluate","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"Calculate evaluation information /evaluate function defined inla.mesh inla.mesh.1d object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"","code":"fm_evaluate(...)  # S3 method for inla.mesh fm_evaluate(mesh, field, ...)  # S3 method for inla.mesh.1d fm_evaluate(mesh, field, ...)  # S3 method for fm_evaluator fm_evaluate(projector, field, ...)  fm_evaluator(...)  fm_evaluator_inla_mesh(mesh, loc = NULL, crs = NULL, ...)  fm_evaluator_inla_mesh_1d(mesh, loc, ...)  fm_evaluator_lattice(   mesh,   xlim = NULL,   ylim = NULL,   dims = c(100, 100),   projection = NULL,   crs = NULL,   ... )  # S3 method for inla.mesh fm_evaluator(mesh, loc = NULL, lattice = NULL, crs = NULL, ...)  # S3 method for inla.mesh.1d fm_evaluator(mesh, loc = NULL, xlim = mesh$interval, dims = 100, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"... Additional arguments passed methods. mesh inla.mesh inla.mesh.1d object. field Basis function weights, one per mesh basis function, describing function evaluated projection locations projector fm_evaluator object. loc Projection locations.  Can matrix, SpatialPoints, SpatialPointsDataFrame, sf, sfc, sfg object. crs optional CRS inla.CRS object associated loc /lattice. xlim X-axis limits lattice. R2 meshes, defaults covering domain. ylim Y-axis limits lattice. R2 meshes, defaults covering domain. dims Lattice dimensions. projection One c(\"default\", \"longlat\", \"longsinlat\", \"mollweide\"). lattice inla.mesh.lattice() object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"fm_evaluate(): Returns field function evaluated locations determined fm_evaluator object. fm_evaluate(mesh, field = field, ...) shortcut fm_evaluate(fm_evaluator(mesh, ...), field = field). fm_evaluator(): Returns fm_evaluator list object evaluation information. proj element contains mapping matrix logical vector ok, indicates locations mappable input mesh. inla.mesh input, proj also contains matrix bary vector t, barycentric coordinates within triangle input location falls . fm_evaluator_lattice(): Creates inla.mesh.lattice, default covering input mesh. fm_evaluator(inla.mesh): ... arguments passed fm_evaluator_lattice() loc lattice provided.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_evaluate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for projecting to/from an inla.mesh — fm_evaluate","text":"","code":"if (bru_safe_inla()) {   n <- 20   loc <- matrix(runif(n * 2), n, 2)   mesh <- INLA::inla.mesh.create(loc, refine = list(max.edge = 0.05))   proj <- fm_evaluator(mesh)   field <- cos(mesh$loc[, 1] * 2 * pi * 3) * sin(mesh$loc[, 2] * 2 * pi * 7)   image(proj$x, proj$y, fm_evaluate(proj, field)) }  # \\donttest{ if (bru_safe_inla() &&   require(rgl)) {   plot(mesh, rgl = TRUE, col = field, draw.edges = FALSE, draw.vertices = FALSE) } #> Loading required package: rgl #> Warning: RGL: unable to open X11 display #> Warning: 'rgl.init' failed, running with 'rgl.useNULL = TRUE'. # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_identical_CRS.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if two CRS objects are identical — fm_identical_CRS","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"Check two CRS objects identical","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_identical_CRS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"","code":"fm_identical_CRS(crs0, crs1, crsonly = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_identical_CRS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"crs0, crs1 Two sf::crs, sp::CRS, fm_crs inla.CRS objects compared. crsonly logical. TRUE crs0 crs1 fm_crs inla.CRS objects, extract compare sf::crs sp::CRS aspects. Default: FALSE","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_identical_CRS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if two CRS objects are identical — fm_identical_CRS","text":"","code":"crs0 <- crs1 <- fm_crs(\"longlat_globe\") fm_crs_oblique(crs1) <- c(0, 90) print(c(   fm_identical_CRS(crs0, crs0),   fm_identical_CRS(crs0, crs1),   fm_identical_CRS(crs0, crs1, crsonly = TRUE) )) #> [1]  TRUE FALSE  TRUE"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-domain integration — fm_int","title":"Multi-domain integration — fm_int","text":"Construct integration points tensor product spaces","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-domain integration — fm_int","text":"","code":"fm_int(domain, samplers = NULL, ...)  # S3 method for list fm_int(domain, samplers = NULL, ...)  # S3 method for numeric fm_int(domain, samplers = NULL, name = \"x\", ...)  # S3 method for character fm_int(domain, samplers = NULL, name = \"x\", ...)  # S3 method for factor fm_int(domain, samplers = NULL, name = \"x\", ...)  # S3 method for SpatRaster fm_int(domain, samplers = NULL, name = \"x\", ...)  # S3 method for inla.mesh.lattice fm_int(domain, samplers = NULL, name = \"x\", ...)  # S3 method for inla.mesh.1d fm_int(domain, samplers = NULL, name = \"x\", int.args = NULL, ...)  # S3 method for inla.mesh fm_int(   domain,   samplers = NULL,   name = NULL,   int.args = NULL,   format = NULL,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-domain integration — fm_int","text":"domain Functional space specification; single domain named list domains samplers single domain fm_int methods, object specifying one subsets domain, optional weighting weight variable. fm_int.list, list sampling definitions, data frame elements may contain information multiple domains, case row represent separate tensor product integration subspace. ... Additional arguments passed methods name single-domain methods, variable name use integration points. Default 'x' int.args List arguments passed line integration methods. method: \"stable\" (aggregate integration weights onto mesh nodes) \"direct\" (construct within triangle/segment integration scheme without aggregating onto mesh nodes) nsub1, nsub2: integers controlling number internal integration points aggregation. Points per triangle: (nsub2+1)^2. Points per knot segment: nsub1 format character; determines output format, either \"sf\" (default sampler NULL) \"sp\". NULL, determined sampler type.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-domain integration — fm_int","text":"data.frame, tibble, sf, SpatialPointsDataFrame 1D 2D integration points, including weight column .block column.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Multi-domain integration — fm_int","text":"fm_int(list): Multi-domain integration fm_int(numeric): Discrete double integer space integration fm_int(character): Discrete character space integration fm_int(factor): Discrete factor space integration fm_int(SpatRaster): SpatRaster integration. yet implemented. fm_int(inla.mesh.lattice): inla.mesh.lattice integration. yet implemented. fm_int(inla.mesh.1d): inla.mesh.1d integration. Supported samplers: NULL integration entire domain; length 2 vector defining interval; 2-column matrix single interval row; tibble named column containing matrix, optionally weight column. fm_int(inla.mesh): inla.mesh integration. sampler class associated fm_int_inla_mesh() method supported.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-domain integration — fm_int","text":"","code":"if (bru_safe_inla() && bru_safe_sp()) {   # Integration on the interval (2, 3.5) with Simpson's rule   ips <- fm_int(INLA::inla.mesh.1d(0:4), samplers = cbind(2, 3.5))   plot(ips)    # Create integration points for the two intervals [0,3] and [5,10]    ips <- fm_int(     INLA::inla.mesh.1d(0:10),     matrix(c(0, 3, 5, 10), nrow = 2, byrow = TRUE)   )   plot(ips)    # Convert a 1D mesh into integration points   mesh <- INLA::inla.mesh.1d(seq(0, 10, by = 1))   ips <- fm_int(mesh, name = \"time\")   plot(ips)     if (require(\"ggplot2\", quietly = TRUE)) {     data(\"gorillas\", package = \"inlabru\")     #' Integrate on a 2D mesh with polygon boundary subset     ips <- fm_int(gorillas$mesh, gorillas$boundary)     ggplot() +       gg(gorillas$mesh) +       gg(gorillas$boundary) +       gg(ips, aes(size = weight)) +       scale_size_area()   } } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)'"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset integration on a mesh — fm_int_inla_mesh","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"Integration methods spatial samplers inla.mesh meshes.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"","code":"fm_int_inla_mesh(samplers, domain, name = NULL, int.args = NULL, ...)  fm_int_inla_mesh_NULL(samplers, domain, name = NULL, int.args = NULL, ...)  # S3 method for sf fm_int_inla_mesh(samplers, domain, name = NULL, int.args = NULL, ...)  # S3 method for sfc_POINT fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_MULTIPOINT fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_LINESTRING fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_MULTILINESTRING fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_POLYGON fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_MULTIPOLYGON fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for sfc_GEOMETRY fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   .weight = rep(1, NROW(samplers)),   ... )  # S3 method for Spatial fm_int_inla_mesh(   samplers,   domain,   name = NULL,   int.args = NULL,   format = NULL,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"samplers single domain fm_int methods, object specifying one subsets domain, optional weighting weight variable. fm_int.list, list sampling definitions, data frame elements may contain information multiple domains, case row represent separate tensor product integration subspace. domain Functional space specification; single domain named list domains name single-domain methods, variable name use integration points. Default 'x' int.args List arguments passed line integration methods. method: \"stable\" (aggregate integration weights onto mesh nodes) \"direct\" (construct within triangle/segment integration scheme without aggregating onto mesh nodes) nsub1, nsub2: integers controlling number internal integration points aggregation. Points per triangle: (nsub2+1)^2. Points per knot segment: nsub1 ... Additional arguments passed methods .weight Optional weight vector sfc_* integration format character; determines output format, either \"sf\" (default sampler NULL) \"sp\". NULL, determined sampler type. .block Optional block grouping vector sfc_* integration","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"sf point object columns weight .block","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"fm_int_inla_mesh(sf): sf integration fm_int_inla_mesh(sfc_POINT): sfc_POINT integration fm_int_inla_mesh(sfc_MULTIPOINT): sfc_MULTIPOINT integration fm_int_inla_mesh(sfc_LINESTRING): sfc_LINESTRING integration fm_int_inla_mesh(sfc_MULTILINESTRING): sfc_MULTILINESTRING integration fm_int_inla_mesh(sfc_POLYGON): sfc_POLYGON integration fm_int_inla_mesh(sfc_MULTIPOLYGON): sfc_MULTIPOLYGON integration fm_int_inla_mesh(sfc_GEOMETRY): sfc_GEOMERY integration fm_int_inla_mesh(Spatial): Spatial integration","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Subset integration on a mesh — fm_int_inla_mesh","text":"fm_int_inla_mesh_NULL(): Full domain integration","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh_core.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","title":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","text":"Integration scheme mesh triangle interiors","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh_core.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","text":"","code":"fm_int_inla_mesh_core(mesh, tri_subset = NULL, nsub = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh_core.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","text":"mesh Mesh integrate tri_subset Optional triangle index vector integration subset mesh triangles (Default NULL) nsub number subdivision points along triangle edge, giving (nsub + 1)^2 proto-integration points used compute vertex weights (default NULL=9, giving 100 integration points triangle)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh_core.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","text":"list elements loc weight integration points mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_inla_mesh_core.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration scheme for mesh triangle interiors — fm_int_inla_mesh_core","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_multi_sampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-domain sampler integration — fm_int_multi_sampler","title":"Multi-domain sampler integration — fm_int_multi_sampler","text":"Combine integration different domains","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_int_multi_sampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-domain sampler integration — fm_int_multi_sampler","text":"","code":"fm_int_multi_sampler(domain, samplers, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_is_within.html","id":null,"dir":"Reference","previous_headings":"","what":"Query if points are inside a mesh — fm_is_within","title":"Query if points are inside a mesh — fm_is_within","text":"Queries whether input point within mesh .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_is_within.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query if points are inside a mesh — fm_is_within","text":"","code":"fm_is_within(x, y, ...)  # S3 method for default fm_is_within(x, y, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_is_within.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query if points are inside a mesh — fm_is_within","text":"x set points class supported fm_evaluator(y, loc = x) y inla.mesh ... Currently unused","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_is_within.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query if points are inside a mesh — fm_is_within","text":"logical vector","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_is_within.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query if points are inside a mesh — fm_is_within","text":"","code":"if (FALSE) { if (bru_safe_inla(quietly = TRUE)) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Check if all Gorilla nests are inside the mesh    all(fm_is_within(gorillas$nests, gorillas$mesh))    # Also works for locations not stored as SpatialPoints object    loc <- coordinates(gorillas$nests)   all(fm_is_within(loc, gorillas$mesh)) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate lattice points covering a mesh — fm_pixels","title":"Generate lattice points covering a mesh — fm_pixels","text":"Generate terra, sf, sp lattice locations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate lattice points covering a mesh — fm_pixels","text":"","code":"fm_pixels(mesh, nx = 150, ny = 150, mask = TRUE, format = \"sf\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate lattice points covering a mesh — fm_pixels","text":"mesh inla.mesh object nx Number pixels x direction ny Number pixels y direction mask logical TRUE, remove pixels outside mesh. mask sf Spatial object, return pixels covered object. format character; \"sf\", \"terra\" \"sp\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate lattice points covering a mesh — fm_pixels","text":"sf, SpatRaster, SpatialPixelsDataFrame covering mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate lattice points covering a mesh — fm_pixels","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_pixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate lattice points covering a mesh — fm_pixels","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   pxl <- fm_pixels(mrsea$mesh,     nx = 50, ny = 50, mask = mrsea$boundary,     format = \"terra\"   )   ggplot() +     gg(pxl, fill = \"grey\", alpha = 0.5) +     gg(mrsea$mesh) } #> Warning: [setValues] values is larger than the size of cells  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_store_points.html","id":null,"dir":"Reference","previous_headings":"","what":"store points in different formats — fm_store_points","title":"store points in different formats — fm_store_points","text":"Convert matrix points different formats.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_store_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"store points in different formats — fm_store_points","text":"","code":"fm_store_points(loc, crs = NULL, info = NULL, format = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_store_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"store points in different formats — fm_store_points","text":"format character; \"sf\", \"df\", \"sp\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_store_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"store points in different formats — fm_store_points","text":"sf, data.frame, SpatialPointsDataFrame object, optional added information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Object coordinate transformation — fm_transform","title":"Object coordinate transformation — fm_transform","text":"Handle transformation various inla objects according coordinate reference systems crs (sf::st_crs()), fm_crs,¬sp::CRS INLA::inla.CRS class.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object coordinate transformation — fm_transform","text":"","code":"fm_transform(x, crs = fm_crs(x), ...)  # S3 method for default fm_transform(x, crs = fm_crs(x), ..., crs0 = NULL)  # S3 method for matrix fm_transform(x, crs = NULL, ..., passthrough = FALSE, crs0 = NULL)  # S3 method for list fm_transform(x, crs = fm_crs(x), ...)  # S3 method for sf fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE)  # S3 method for sfc fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE)  # S3 method for sfg fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE)  # S3 method for Spatial fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE)  # S3 method for inla.mesh fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE, crs0 = fm_crs(x))  # S3 method for inla.mesh.lattice fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE, crs0 = fm_crs(x))  # S3 method for inla.mesh.segment fm_transform(x, crs = fm_crs(x), ..., passthrough = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object coordinate transformation — fm_transform","text":"x object transformed current CRS new CRS crs target crs object ... Potential additional arguments crs0 source crs object spatial classes without crs information passthrough Default FALSE. Setting TRUE allows objects CRS information passed without transformation. Use care!","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertex_projection.html","id":null,"dir":"Reference","previous_headings":"","what":"Project integration points to mesh vertices — fm_vertex_projection","title":"Project integration points to mesh vertices — fm_vertex_projection","text":"Compute information assigning points vertices covering triangle","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertex_projection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project integration points to mesh vertices — fm_vertex_projection","text":"","code":"fm_vertex_projection(points, mesh)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertex_projection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project integration points to mesh vertices — fm_vertex_projection","text":"points SpatialPointsDataFrame, sf, list object mesh inla.mesh object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertex_projection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project integration points to mesh vertices — fm_vertex_projection","text":"SpatialPointsDataFrame, sf, list mesh vertices projected data attached","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract vertex locations from an inla.mesh — fm_vertices","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"Extracts vertices inla.mesh object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"","code":"fm_vertices(x, format = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"x inla.mesh object. format character; \"sf\", \"df\", \"sp\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"sf, data.frame, SpatialPointsDataFrame object, vertex coordinates, .vertex column vertex indices.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/fm_vertices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract vertex locations from an inla.mesh — fm_vertices","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   vrt <- fm_vertices(mrsea$mesh, format = \"sp\")   ggplot() +     gg(mrsea$mesh) +     gg(vrt, color = \"red\") }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate samples from fitted bru models — generate","title":"Generate samples from fitted bru models — generate","text":"Generic function sampling fitted models. function invokes particular methods depend class first argument. Takes fitted bru object produced function bru() produces samples given new set values model covariates original values used model fit. samples can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate samples from fitted bru models — generate","text":"","code":"generate(object, ...)  # S3 method for bru generate(   object,   newdata = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   num.threads = NULL,   include = NULL,   exclude = NULL,   used = NULL,   ...,   data = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate samples from fitted bru models — generate","text":"object bru object obtained calling bru(). ... additional, unused arguments. newdata data.frame SpatialPointsDataFrame covariates needed sampling. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default, 100, rather low provides quick approximate result. seed Random number generator seed passed INLA::inla.posterior.sample num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) newdata provided, otherwise character(0). exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) used Either NULL bru_used() object, overriding include exclude. data Deprecated. Use newdata instead. sampling.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate samples from fitted bru models — generate","text":"form value returned generate() depends data class prediction formula. Normally, data.frame returned, list data.frames (prediction formula generates list) List generated samples","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate samples from fitted bru models — generate","text":"addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate samples from fitted bru models — generate","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE) &&     require(\"sn\", quietly = TRUE)) {    # Generate data for a simple linear model    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit the model    fit <- bru(y ~ xeff(main = x, model = \"linear\"),     family = \"gaussian\", data = input.df   )   summary(fit)    # Generate samples for some predefined x    df <- data.frame(x = seq(-4, 4, by = 0.1))   smp <- generate(fit, df, ~ xeff + Intercept, n.samples = 10)    # Plot the resulting realizations    plot(df$x, smp[, 1], type = \"l\")   for (k in 2:ncol(smp)) points(df$x, smp[, k], type = \"l\")    # We can also draw samples form the joint posterior    df <- data.frame(x = 1)   smp <- generate(fit, df, ~ data.frame(xeff, Intercept), n.samples = 10)   smp[[1]]    # ... and plot them   if (require(ggplot2, quietly = TRUE)) {     plot(do.call(rbind, smp))   } } #> Current num.threads is '1:1'. #> No num.threads change needed. #>  #> Attaching package: ‘sn’ #> The following object is masked from ‘package:stats’: #>  #>     sd   # } # \\donttest{ if (bru_safe_inla(multicore = FALSE) &&     require(\"sn\", quietly = TRUE)) {    # Generate data for a simple linear model    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit the model    fit <- bru(y ~ xeff(main = x, model = \"linear\"),     family = \"gaussian\", data = input.df   )   summary(fit)    # Generate samples for some predefined x    df <- data.frame(x = seq(-4, 4, by = 0.1))   smp <- generate(fit, df, ~ xeff + Intercept, n.samples = 10)    # Plot the resulting realizations    plot(df$x, smp[, 1], type = \"l\")   for (k in 2:ncol(smp)) points(df$x, smp[, k], type = \"l\")    # We can also draw samples form the joint posterior    df <- data.frame(x = 1)   smp <- generate(fit, df, ~ data.frame(xeff, Intercept), n.samples = 10)   smp[[1]]    # ... and plot them   if (require(ggplot2, quietly = TRUE)) {     plot(do.call(rbind, smp))   } } #> Current num.threads is '1:1'. #> No num.threads change needed.   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for RasterLayer objects — gg.RasterLayer","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function takes RasterLayer object, converts SpatialPixelsDataFrame uses geom_tile plot data.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"# S3 method for RasterLayer gg(   data,   mapping = ggplot2::aes(x = .data[[\"x\"]], y = .data[[\"y\"]], fill = .data[[\"layer\"]]),   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"data RasterLayer object. mapping aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"object returned geom_tile","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function requires raster ggplot2 packages.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"if (FALSE) { # Some features require the raster and spatstat.data packages. if (require(\"spatstat.data\", quietly = TRUE) &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   # Load Gorilla data   data(\"gorillas\", package = \"spatstat.data\")    # Convert elevation covariate to RasterLayer    elev <- as(gorillas.extra$elevation, \"RasterLayer\")    # Plot the elevation    ggplot() +     gg(elev) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom wrapper for SpatRaster objects — gg.SpatRaster","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"Convenience wrapper function tidyterra::geom_spatraster(). Requires ggplot2 tidyterra packages.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"","code":"# S3 method for SpatRaster gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"data SpatRaster object. ... Arguments passed geom_spatraster.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"output `geom_spatraster.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"Coerces input SpatialGridDataFrame SpatialPixelsDataFrame calls gg.SpatialPixelsDataFrame() plot . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# S3 method for SpatialGridDataFrame gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"data SpatialGridDataFrame object. ... Arguments passed gg.SpatialPixelsDataFrame().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"geom_tile value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE) &&       bru_safe_sp()) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\", package = \"inlabru\")      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialLines objects — gg.SpatialLines","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"Extracts start end points lines calls geom_segment plot lines . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# S3 method for SpatialLines gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"data SpatialLines SpatialLinesDataFrame object. mapping Aesthetic mappings created ggplot2::aes ggplot2::aes_ used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]], xend = .data[[paste0(\"end.\", coordnames(data)[1])]], yend = .data[[paste0(\"end.\", coordnames(data)[2])]]). crs CRS object defining coordinate system project data plotting. ... Arguments passed ggplot2::geom_segment.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"`geom_segment`` return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE) &&       bru_safe_sp()) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\", package = \"inlabru\")      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixels objects — gg.SpatialPixels","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"Uses geom_point plot pixel centers. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"# S3 method for SpatialPixels gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"data SpatialPixels object. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"geom_tile return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"if (require(\"ggplot2\", quietly = TRUE) &&   bru_safe_sp()) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Turn elevation covariate into SpatialPixels   pxl <- sp::SpatialPixels(sp::SpatialPoints(gorillas$gcov$elevation))    # Plot the pixel centers   ggplot() +     gg(pxl, size = 0.1) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)'"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"Coerces input SpatialPixelsDataFrame data.frame uses geom_tile plot . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# S3 method for SpatialPixelsDataFrame gg(data, mapping = NULL, crs = NULL, mask = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"data SpatialPixelsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]], fill = .data[[names(data)[[1]]]]). crs CRS object defining coordinate system project data plotting. mask SpatialPolygon defining region plotted. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"geom_tile return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE) &&       bru_safe_sp()) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\", package = \"inlabru\")      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPoints objects — gg.SpatialPoints","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"function coerces SpatialPoints data.frame uses geom_point plot points. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# S3 method for SpatialPoints gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"data SpatialPoints object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[coordnames(data)[1]]], y = .data[[coordnames(data)[2]]]). crs CRS object defining coordinate system project data plotting. ... Arguments passed geom_point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"geom_point return value","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE) &&       bru_safe_sp()) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\", package = \"inlabru\")      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPolygons objects — gg.SpatialPolygons","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"Uses ggplot2::fortify() function turn SpatialPolygons objects data.frame. calls geom_polygon plot polygons. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# S3 method for SpatialPolygons gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"data SpatialPolygons SpatialPolygonsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = long, y = lat, group = group). crs CRS object defining coordinate system project data plotting. ... Arguments passed geom_polypath. Unless specified user, arguments colour = \"black\" (polygon colour) alpha = 0.2 (Alpha level polygon filling).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"ggpolypath::geom_polypath object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"Requires ggpolypath package ensure proper plotting, since ggplot::geom_polygon function always handle geometries holes properly.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       require(ggpolypath, quietly = TRUE) &&       bru_safe_sp()) {     # Load Gorilla data      data(\"gorillas\", package = \"inlabru\")      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      data(\"mexdolphin\", package = \"inlabru\")      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for data.frame — gg.data.frame","title":"Geom for data.frame — gg.data.frame","text":"geom constructor simply call gg.prediction data provided.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for data.frame — gg.data.frame","text":"","code":"# S3 method for data.frame gg(...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for data.frame — gg.data.frame","text":"... Arguments passed gg.prediction().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for data.frame — gg.data.frame","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for data.frame — gg.data.frame","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for data.frame — gg.data.frame","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2 geomes for inlabru related objects — gg","title":"ggplot2 geomes for inlabru related objects — gg","text":"gg generic function generating geomes various kinds spatial objects, e.g. Spatial* data, meshes, Raster objects inla/inlabru predictions. function invokes particular methods depend class first argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2 geomes for inlabru related objects — gg","text":"data object generate geom. ... Arguments passed geom method.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot2 geomes for inlabru related objects — gg","text":"form value returned gg depends class argument. See documentation particular methods details produced method.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Invoke ggplot and add geomes for the Gorilla nests and the survey boundary    ggplot() +     gg(gorillas$boundary) +     gg(gorillas$nests) } #> Regions defined for each Polygons"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"function generates geom_point object showing knots (vertices) 1D mesh. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"","code":"# S3 method for inla.mesh.1d gg(   data,   mapping = ggplot2::aes(.data[[\"x\"]], .data[[\"y\"]]),   y = 0,   shape = 4,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"data inla.mesh.1d object. mapping aesthetic mappings created aes. passed geom_point. y Single vector numeric defining y-coordinates mesh knots plot. shape Shape knot markers. ... parameters passed geom_point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"object generated geom_point.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for inla.mesh.1d objects — gg.inla.mesh.1d","text":"","code":"# \\donttest{ # Some features use the INLA package. if (require(\"INLA\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   # Create a 1D mesh    mesh <- inla.mesh.1d(seq(0, 10, by = 0.5))    # Plot it    ggplot() +     gg(mesh)    # Plot it using a different shape and size for the mesh nodes    ggplot() +     gg(mesh, shape = \"|\", size = 5) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for inla.mesh objects — gg.inla.mesh","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"function extracts graph inla.mesh object uses geom_line visualize graph's edges. Alternatively, color argument provided, interpolates colors across set SpatialPixels covering mesh area calls gg.SpatialPixelsDataFrame() plot interpolation. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"","code":"# S3 method for inla.mesh gg(   data,   color = NULL,   alpha = NULL,   edge.color = \"grey\",   edge.linewidth = 0.25,   interior = TRUE,   int.color = \"blue\",   int.linewidth = 0.5,   exterior = TRUE,   ext.color = \"black\",   ext.linewidth = 1,   crs = NULL,   mask = NULL,   nx = 500,   ny = 500,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"data INLA::inla.mesh object. color vector scalar values fill mesh colors. length vector mus correspond number mesh vertices. alternative name colour also recognised. alpha vector scalar values setting alpha value colors provided. edge.color Color regular mesh edges. edge.linewidth Line width regular mesh edges. Default 0.25 interior TRUE, plot interior boundaries mesh. int.color Color used plot interior constraint edges. int.linewidth Line width interior constraint edges. Default 0.5 exterior TRUE, plot exterior boundaries mesh. ext.color Color used plot exterior boundary edges. ext.linewidth Line width exterior boundary edges. Default 1 crs CRS object supported fm_transform() defining coordinate system project mesh plotting. mask SpatialPolygon defining region plotted. nx Number pixels x direction (plotting using color parameter). ny Number pixels y direction (plotting using color parameter). ... ignored arguments (S3 generic compatibility).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"geom_line return values , color argument used, values gg.SpatialPixelsDataFrame().","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.inla.mesh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for inla.mesh objects — gg.inla.mesh","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE) &&     require(ggpolypath, quietly = TRUE)) {    # Load Gorilla data   data(\"gorillas\", package = \"inlabru\")    # Plot mesh using default edge colors    ggplot() +     gg(gorillas$mesh)    # Don't show interior and exterior boundaries    ggplot() +     gg(gorillas$mesh, interior = FALSE, exterior = FALSE)    # Change the edge colors    ggplot() +     gg(gorillas$mesh,       edge.color = \"green\",       int.color = \"black\",       ext.color = \"blue\"     )    # Use the x-coordinate of the vertices to colorize the triangles and   # mask the plotted area by the survey boundary, i.e. only plot the inside    xcoord <- gorillas$mesh$loc[, 1]   ggplot() +     gg(gorillas$mesh, color = (xcoord - 580), mask = gorillas$boundary) +     gg(gorillas$boundary) } #> Regions defined for each Polygons  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for matrix — gg.matrix","title":"Geom for matrix — gg.matrix","text":"Creates tile geom plotting matrix","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for matrix — gg.matrix","text":"","code":"# S3 method for matrix gg(data, mapping = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for matrix — gg.matrix","text":"data matrix object. mapping set aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for matrix — gg.matrix","text":"geom_tile reversed y scale.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for matrix — gg.matrix","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for matrix — gg.matrix","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   A <- matrix(runif(100), nrow = 10)   ggplot() +     gg(A) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for predictions — gg.prediction","title":"Geom for predictions — gg.prediction","text":"geom serves visualize prediction objects usually results call predict.bru(). Predictions objects provide summary statistics (mean, median, sd, ...) one random variables. single variables (requested setting bar = TRUE), boxplot-style geom constructed show statistics. multivariate predictions mean variable (y-axis) plotted agains row number varriable prediction data frame (x-axis) using geom_line. addition, geom_ribbon used show confidence interval. Note: gg.prediction also understands format INLA-style posterior summaries, e.g. fit$summary.fixed inla object fit Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for predictions — gg.prediction","text":"","code":"# S3 method for prediction gg(data, mapping = NULL, ribbon = TRUE, alpha = 0.3, bar = FALSE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for predictions — gg.prediction","text":"data prediction object, usually result predict.bru() call. mapping set aesthetic mappings created aes. passed geom_line. ribbon TRUE, plot ribbon around line based smalles largest quantiles present data, found matching names starting q followed numerical value.  inla()-style numeric+\"quant\" names converted inlabru style matching. alpha ribbons numeric alpha (transparency) level [0,1]. bar TRUE plot boxplot-style summary variable. ... Arguments passed geom_line.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for predictions — gg.prediction","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for predictions — gg.prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a globe using rgl — globe","title":"Plot a globe using rgl — globe","text":"Creates textured sphere lon/lat coordinate annotations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a globe using rgl — globe","text":"","code":"globe(   R = 1,   R.grid = 1.05,   specular = \"black\",   axes = FALSE,   box = FALSE,   xlab = \"\",   ylab = \"\",   zlab = \"\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a globe using rgl — globe","text":"R Radius globe R.grid Radius annotation sphere. specular Light color specular effect. axes TRUE, plot x, y z axes. box TRUE, plot box around globe. xlab, ylab, zlab Axes labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a globe using rgl — globe","text":"value, used plotting side effect.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a globe using rgl — globe","text":"funciton requires rgl sphereplot packages.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a globe using rgl — globe","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialLines.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialLines using RGL — glplot.SpatialLines","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"function calculate cartesian representation lines provided use lines3d() order render .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialLines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"","code":"# S3 method for SpatialLines glplot(object, add = TRUE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialLines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"object SpatialLines SpatialLinesDataFrame object. add TRUE, add lines existing plot. FALSE, create new plot. ... Parameters passed lines3d().","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialLines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialLines using RGL — glplot.SpatialLines","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"function calculate cartesian coordinates points provided use points3d() order render .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"","code":"# S3 method for SpatialPoints glplot(object, add = TRUE, color = \"red\", ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"object SpatialPoints SpatialPointsDataFrame object. add TRUE, add points existing plot. FALSE, create new plot. color vector R color characters. See material3d() details. ... Parameters passed points3d()","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.SpatialPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialPoints using RGL — glplot.SpatialPoints","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Render Spatial* and inla.mesh objects using RGL — glplot","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"glplot generic function renders various kinds spatial objects, .e. Spatial* data inla.mesh objects. function invokes particular methods depend class first argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"","code":"glplot(object, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"object object used select method. ... arguments passed methods.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Render Spatial* and inla.mesh objects using RGL — glplot","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize SpatialPoints using RGL — glplot.inla.mesh","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"function transforms mesh 3D cartesian coordinates uses inla.plot.mesh() rgl=TRUE plot result.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"","code":"# S3 method for inla.mesh glplot(object, add = TRUE, col = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"object inla.mesh object. add TRUE, add lines existing plot. FALSE, create new plot. col Color specification. single named color, vector scalar values, matrix RGB values. ... Parameters passed plot.inla.mesh()","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.inla.mesh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize SpatialPoints using RGL — glplot.inla.mesh","text":"","code":"if (FALSE) { if (bru_safe_inla() &&   require(\"rgl\", quietly = TRUE) &&   require(\"sphereplot\", quietly = TRUE)) {    # Load pantropoical dolphin data    data(\"mexdolphin\", package = \"inlabru\")    # Show the globe    globe()    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh)   glplot(mexdolphin$samplers)   glplot(mexdolphin$points) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gm.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot geom for spatial data — gm","title":"ggplot geom for spatial data — gm","text":"gm wrapper gg method. take first argument transform coordinate system latitude longitude. Thereafter, gg called using transformed data arguments provided via .... gm intended replace gg whenever data supposed plotted spatial map generated gmap, works coordinate system latitude/longitude.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot geom for spatial data — gm","text":"","code":"gm(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot geom for spatial data — gm","text":"data object generate geom. ... Arguments passed gg().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot geom for spatial data — gm","text":"form value returned gm depends class argument. See documentation particular methods details produced method.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot geom for spatial data — gm","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Create a base map centered around the nests and plot the boundary as well as the nests   gmap(gorillas$nests, maptype = \"satellite\") +     gm(gorillas$boundary) +     gm(gorillas$nests, color = \"white\", size = 0.5) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a map using extent of a spatial object — gmap","title":"Plot a map using extent of a spatial object — gmap","text":"Uses get_map() query map services like Google Maps region centered around spatial object provided. calls ggmap() plot map.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a map using extent of a spatial object — gmap","text":"","code":"gmap(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a map using extent of a spatial object — gmap","text":"data Spatial* object. ... Arguments passed get_map().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a map using extent of a spatial object — gmap","text":"ggplot object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a map using extent of a spatial object — gmap","text":"function requires ggmap package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a map using extent of a spatial object — gmap","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Create a base map centred around the nests and plot the boundary as well   # as the nests   ggplot() +     gg(gorillas$boundary) +     gg(gorillas$nests, color = \"white\", size = 0.5)   if (requireNamespace(\"ggmap\", quietly = TRUE)) {     gmap(gorillas$nests, maptype = \"satellite\") +       gm(gorillas$boundary) +       gm(gorillas$nests, color = \"white\", size = 0.5)   } } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla nesting sites — gorillas","title":"Gorilla nesting sites — gorillas","text":"gorillas dataset package spatstat.data, reformatted point process data use inlabru.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla nesting sites — gorillas","text":"","code":"data(gorillas)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gorilla nesting sites — gorillas","text":"data list contains elements: nests: SpatialPointsDataFrame object containing locations gorilla nests. boundary: SpatialPolygonsDataFrame object defining boundary region searched nests. mesh: inla.mesh object containing mesh can used function lgcp fit LGCP nest data. gcov: list SpatialGridDataFrame objects, one spatial covariates: aspect Compass direction terrain slope. Categorical, levels N, NE, E, SE, S, SW, W NW, coded integers 1 8. elevation Digital elevation terrain, metres. heat Heat Load Index point surface (Beer's aspect), discretised. Categorical values Warmest (Beer's aspect 0 0.999), Moderate (Beer's aspect 1 1.999), Coolest (Beer's aspect equals 2). coded integers 1, 2 3, order. slopangle Terrain slope, degrees. slopetype Type slope. Categorical, values Valley, Toe (toe slope), Flat, Midslope, Upper Ridge. coded integers 1 6. vegetation Vegetation type: categorical variable 6 levels coded integers 1 6 (order increasing expected habitat suitability) waterdist Euclidean distance nearest water body, metres. plotsample Plot sample gorilla nests, sampling 9x9 region, 60\\ counts SpatialPointsDataFrame frame elements x, y, count, exposure, x- y-coordinates centre plot, count plot area plot. plots SpatialPolygonsDataFrame defining individual plot boundaries. nests SpatialPointsDataFrame giving locations detected nest.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Gorilla nesting sites — gorillas","text":"Library spatstat.data.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gorilla nesting sites — gorillas","text":"Funwi-Gabga, N. (2008) pastoralist survey fire impact assessment Kagwene Gorilla Sanctuary, Cameroon. M.Sc. thesis, Geology Environmental Science, University Buea, Cameroon. Funwi-Gabga, N. Mateu, J. (2012) Understanding nesting spatial behaviour gorillas Kagwene Sanctuary, Cameroon. Stochastic Environmental Research Risk Assessment 26 (6), 793-811.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gorilla nesting sites — gorillas","text":"","code":"if (bru_safe_inla() &&   bru_safe_sp() &&   require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   data(gorillas, package = \"inlabru\") # get the data    # plot all the nests, mesh and boundary   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$boundary) +     gg(gorillas$nests)    # Plot the elevation covariate   plot(gorillas$gcov$elevation)    # Plot the plot sample   ggplot() +     gg(gorillas$plotsample$plots) +     gg(gorillas$plotsample$nests) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)'"},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":null,"dir":"Reference","previous_headings":"","what":"Iterated INLA — iinla","title":"Iterated INLA — iinla","text":"internal wrapper iterated runs INLA::inla. nonlinear models, linearisation done bru_compute_linearisation, line search method iteration. INLA::inla.stack information setup bru_make_stack().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iterated INLA — iinla","text":"","code":"iinla(model, lhoods, initial = NULL, options)"},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iterated INLA — iinla","text":"model bru_model object lhoods list likelihood objects like() initial previous bru result list named latent variable initial states (missing elements set zero), used starting point, NULL. non-null, overrides options$bru_initial options bru_options object. data data.frame","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iterated INLA — iinla","text":"iinla object inherits INLA::inla, added field bru_iinla elements log diagnostic log messages produced run states list linearisation points, one inla run inla_stack inla.stack object final inla run track list convergence tracking vectors inla run aborted error, returned object also contains element error error object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.gorillas.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla data import — import.gorillas","title":"Gorilla data import — import.gorillas","text":"Gorilla data import","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.gorillas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla data import — import.gorillas","text":"","code":"import.gorillas()  import.gorillas.sf()"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.gorillas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gorilla data import — import.gorillas","text":"gorilla data","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.gorillas.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Gorilla data import — import.gorillas","text":"import.gorillas.sf(): Convert gorillas sf terra format","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.gorillas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gorilla data import — import.gorillas","text":"Fabian E. Bachl bachlfab@gmail.com, David L. Borchers dlb@st-andrews.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Mexdolphin data import — import.mexdolphin","title":"Mexdolphin data import — import.mexdolphin","text":"Load mexdolphins survey data dsm package convert spatial formats defined sp package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mexdolphin data import — import.mexdolphin","text":"","code":"import.mexdolphin()  import.mexdolphin.sf()"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mexdolphin data import — import.mexdolphin","text":"mexdolphin data set","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Mexdolphin data import — import.mexdolphin","text":"import.mexdolphin.sf(): Import mexdolphin data sf","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mexdolphin data import — import.mexdolphin","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mexdolphin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mexdolphin data import — import.mexdolphin","text":"","code":"if (FALSE) { mexdolphin <- import.mexdolphin() }"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mrsea.html","id":null,"dir":"Reference","previous_headings":"","what":"MRSea data import — import.mrsea","title":"MRSea data import — import.mrsea","text":"Load mrsea survey data MRSea package convert spatial formats defined sp package. Requires MRSea package https://github.com/lindesaysh/MRSea, normally run package maintainer. regular inlabru use data, use data(\"MRSea\", package = \"inlabru\"), require MRSea package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mrsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MRSea data import — import.mrsea","text":"","code":"import.mrsea()"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mrsea.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MRSea data import — import.mrsea","text":"mrsea data set","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mrsea.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MRSea data import — import.mrsea","text":"Lindesay Scott-Hayward lass@st-andrews.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.mrsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MRSea data import — import.mrsea","text":"","code":"if (FALSE) { mrsea <- import.mrsea() }"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.seals.html","id":null,"dir":"Reference","previous_headings":"","what":"Seal pup edata import — import.seals","title":"Seal pup edata import — import.seals","text":"Generate Spatial objects raw seal pup survey data (inlcuded inlabru). Note function extract one survey transects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.seals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seal pup edata import — import.seals","text":"","code":"import.seals(   sealfile = \"WestIce2012.csv\",   icefile = \"reflectance_0.0025deg_grid_modis_20120328_1310.tif\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.seals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Seal pup edata import — import.seals","text":"sealfile Character pointing file containing seal counts photo locations icefile Character pointing .tif file containing ice sheet covariate","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.seals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Seal pup edata import — import.seals","text":"seals data set","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.seals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Seal pup edata import — import.seals","text":"Fabian E. Bachl bachlfab@gmail.com Load seal data Turn seal data spatial object avoid confusion remove x-y coordinates created Martin Change CRS Select strip Add total number seals Build mesh. mesh fine photo locations coarse elsewhere plot observed counts Ice Covariate Interpolate ice covariate Add band1 covariate seals data frame Plot seal count ice together Create data set","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.shrimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Shrimp data import — import.shrimp","title":"Shrimp data import — import.shrimp","text":"Load shrimp data stored file gamba.Rdata construct spatial object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.shrimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shrimp data import — import.shrimp","text":"","code":"import.shrimp()"},{"path":"https://inlabru-org.github.io/inlabru/reference/import.shrimp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shrimp data import — import.shrimp","text":"shrimp data set","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/import.shrimp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shrimp data import — import.shrimp","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain indices — index_eval","title":"Obtain indices — index_eval","text":"Indexes components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain indices — index_eval","text":"","code":"index_eval(...)  # S3 method for component index_eval(component, inla_f, ...)  # S3 method for component_list index_eval(components, inla_f, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain indices — index_eval","text":"... Unused. component component. inla_f logical; TRUE, must result values compatible INLA::f(...) specification corresponding INLA::inla.stack(...) constructions.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain indices — index_eval","text":"list indices latent variables compatible component mapper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain indices — index_eval","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla.stack.mjoin.html","id":null,"dir":"Reference","previous_headings":"","what":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"Join stacks intended run different likelihoods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla.stack.mjoin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"","code":"inla.stack.mjoin(   ...,   compress = TRUE,   remove.unused = TRUE,   old.names = \"BRU.response\",   new.name = \"BRU.response\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/inla.stack.mjoin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join stacks intended to be run with different likelihoods — inla.stack.mjoin","text":"... List stacks contain vector observations (existing multi-likelihood observation matrices also permitted) compress TRUE, compress model removing duplicated rows effects, replacing corresponding -matrix columns single column containing sum. remove.unused TRUE, compress model removing rows effects corresponding -zero columns matrix (removing columns). old.names vector strings names observation vector/matrix stack. single string, assumed stacks. (default \"BRU.response\") new.name name used expanded observation matrix, possibly old name. (default \"BRU.response\")","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain inla index subset information — inla_subset_eval","title":"Obtain inla index subset information — inla_subset_eval","text":"Subsets INLA::f() compatible indexing","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain inla index subset information — inla_subset_eval","text":"","code":"inla_subset_eval(...)  # S3 method for component_list inla_subset_eval(components, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain inla index subset information — inla_subset_eval","text":"... Unused. components component list.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain inla index subset information — inla_subset_eval","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in inlabru — stransform","title":"Deprecated functions in inlabru — stransform","text":"functions still attempt job, removed future version.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in inlabru — stransform","text":"","code":"stransform(splist, crs)  init.tutorial()  fm_has_PROJ6()  fm_not_for_PROJ6(fun = NULL)  fm_not_for_PROJ4(fun = NULL)  fm_fallback_PROJ6(fun = NULL)  fm_requires_PROJ6(fun = NULL)  fm_sp_get_crs(x)  fm_spTransform(x, ...)  # S3 method for default fm_spTransform(x, crs0 = NULL, crs1 = NULL, passthrough = FALSE, ...)  # S3 method for SpatialPoints fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for SpatialPointsDataFrame fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh.lattice fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh.segment fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  # S3 method for inla.mesh fm_spTransform(x, CRSobj, passthrough = FALSE, ...)  ibm_valid_input(...)  # S3 method for bru_mapper_inla_mesh_2d ibm_amatrix(...)  # S3 method for bru_mapper_inla_mesh_1d ibm_amatrix(...)  # S3 method for bru_mapper_index ibm_amatrix(...)  # S3 method for bru_mapper_linear ibm_amatrix(...)  # S3 method for bru_mapper_matrix ibm_amatrix(...)  # S3 method for bru_mapper_factor ibm_amatrix(...)  bru_mapper_offset(...)  # S3 method for bru_mapper_offset ibm_n(...)  # S3 method for bru_mapper_offset ibm_values(...)  # S3 method for bru_mapper_offset ibm_amatrix(...)  # S3 method for bru_mapper_multi ibm_amatrix(...)  # S3 method for bru_mapper_collect ibm_amatrix(...)  vertices.inla.mesh(...)  eval_SpatialDF(...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions in inlabru — stransform","text":"splist list Spatial* objects crs Coordinate reference system change fun name function requires PROJ6. Default: NULL, uses name calling function. x object transformed current CRS new CRS ... Potential additional arguments crs0 source sp::CRS inla.CRS object crs1 target sp::CRS inla.CRS object passthrough Default FALSE. Setting TRUE allows objects CRS information passed without transformation. CRSobj target sp::CRS inla.CRS object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deprecated functions in inlabru — stransform","text":"CRS object, NULL valid CRS identified","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deprecated functions in inlabru — stransform","text":"function convenience method workaround PROJ4/PROJ6 differences, lack crs extraction method Spatial objects. newer code, use fm_crs() instead, returns crs objects, use fm_as_sp_crs() convert old style sp::CRS objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Deprecated functions in inlabru — stransform","text":"stransform(): Coordinate transformation spatial objects wrapper spTransform function provided sp package. Given spatial object (list thereof) transform coordinate system according parameter crs. addition usual spatial objects function also capable transforming INLA::inla.mesh objects equipped coordinate system. Returns list Spatial* objects. Deprecated favour fm_transform methods. init.tutorial(): Global setting tutorial sessions. Use bru_options_set() set specific options instead instead.  versions <= 2.1.15, function set INLA integration strategy \"eb\" speed calculations. normally needed since version 2.2.0, since final iteration use \"eb\". fm_has_PROJ6(): Detect whether PROJ6 available fm_not_for_PROJ6(): fm_not_for_PROJ6 called warn using old PROJ4 features even though PROJ6 available fm_not_for_PROJ4(): fm_not_for_PROJ4 called give error calling methods available PROJ6 fm_fallback_PROJ6(): Called warn falling back using old PROJ4 methods PROJ6 method implemented fm_requires_PROJ6(): Called give error PROJ6 required available fm_sp_get_crs(): Wrapper CRS(projargs) (PROJ4) CRS(wkt) sp::Spatial objects. fm_spTransform(): Handle transformation various inla objects according coordinate reference systems sp::CRS INLA::inla.CRS class. fm_spTransform(default): default method handles low level transformation raw coordinates. ibm_valid_input(): Use case changed ibm_invalid_output() ibm_amatrix(bru_mapper_inla_mesh_2d): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_inla_mesh_1d): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_index): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_linear): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_matrix): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_factor): Replaced ibm_jacobian() bru_mapper_offset(): Creates bru_mapper_const() mapper. ibm_n(bru_mapper_offset): Replaced bru_mapper_const methods ibm_values(bru_mapper_offset): Replaced bru_mapper_const methods ibm_amatrix(bru_mapper_offset): Replaced bru_mapper_const methods ibm_amatrix(bru_mapper_multi): Replaced ibm_jacobian() ibm_amatrix(bru_mapper_collect): Replaced ibm_jacobian() vertices.inla.mesh(): Extract vertex locations inla.mesh. Converts vertices inla.mesh object SpatialPointsDataFrame. Deprecated favour fm_vertices() eval_SpatialDF(): Replaced generic eval_spatial()","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deprecated functions in inlabru — stransform","text":"Finn Lindgren finn.lindgren@gmail.com Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deprecated functions in inlabru — stransform","text":"","code":"if (FALSE) { # Note: Only run this if you want to change the inlabru options for this session  # Determine current bru defaults: bo <- bru_options_get()  init.tutorial()  # Check if it worked: bru_options_get(\"control.inla\") }  if (FALSE) { if (interactive()) {   s <- sp::SpatialPoints(matrix(1:6, 3, 2), proj4string = fm_CRS(\"sphere\"))   fm_sp_get_crs(s) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabru — inlabru-package","title":"inlabru — inlabru-package","text":"Convenient model fitting using (iterated) INLA.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"inlabru — inlabru-package","text":"inlabru facilitates Bayesian spatial modelling using integrated nested Laplace approximations. heavily based R-inla (https://www.r-inla.org) adds additional modelling abilities simplified syntax (particular) spatial models. Tutorials information can found https://inlabru-org.github.io/inlabru/ http://www.inlabru.org/. iterative method used non-linear predictors documented method vignette. main function inference using inlabru bru(). general model specification details documented component() like(). Posterior quantities beyond basic summaries can calculated predict() method, documented predict.bru(). point process inference lgcp() can used shortcut bru(..., like(model=\"cp\", ...)). package comes multiple real world data sets, namely gorillas, mexdolphin, seals. Plotting data sets straight forward using inlabru's extensions ggplot2, e.g. gg() function. educational purposes simulated data sets available well, e.g. Poisson1_1D, Poisson2_1D, Poisson2_1D toygroups.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabru — inlabru-package","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain component inputs — input_eval","title":"Obtain component inputs — input_eval","text":"Obtain component inputs","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain component inputs — input_eval","text":"","code":"input_eval(...)  # S3 method for component input_eval(component, data, ...)  # S3 method for component_list input_eval(components, data, ...)  # S3 method for bru_input input_eval(input, data, env = NULL, null.on.fail = FALSE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain component inputs — input_eval","text":"... Unused. component component. data data.frame Spatial* object covariates /point locations. NULL, return component's map.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain component inputs — input_eval","text":"list mapper input values, formatted full component mapper (type bru_mapper_pipe)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"simple-covariates-and-the-map-parameter","dir":"Reference","previous_headings":"","what":"Simple covariates and the map parameter","title":"Obtain component inputs — input_eval","text":"unusual random effect act transformation covariate. frameworks mean transformed covariate calculated advance added data frame usually provided via data parameter. inlabru provides option transformation automatically. instance, one might interested effect covariate \\(x^2\\). inla frameworks require add column xsquared input data frame use formula formula = y ~ f(xsquared, model = \"linear\"), inlabru can achieved several ways using main parameter (map version 2.1.13 earlier), need named. components = y ~ psi(main = x^2, model = \"linear\") components = y ~ psi(x^2, model = \"linear\") components = y ~ psi(mySquareFun(x), model = \"linear\"), components = y ~ psi(myOtherSquareFun, model = \"linear\"), first example inlabru interpret map parameter expression evaluated within data provided. Since \\(x\\) known covariate know calculate . second example expression well uses function called mySquareFun. function defined user accessible within work space setting components. third example provides function myOtherSquareFun. case, inlabru call function myOtherSquareFun(.data.), .data. data provided via like() data parameter. function needs know parts data use construct needed output. example,","code":"myOtherSquareFun <- function(data) {   data[ ,\"x\"]^2 }"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"spatial-covariates","dir":"Reference","previous_headings":"","what":"Spatial Covariates","title":"Obtain component inputs — input_eval","text":"fitting spatial models common work covariates depend space, e.g. sea surface temperature elevation. Although straight forward add data input data frame write covariate function like previous section even convenient way inlabru. Spatial covariates often stored SpatialPixelsDataFrame, SpatialPixelsDataFrame RasterLayer objects. can provided directly via input expressions like() data SpatialPointsDataFrame object. inlabru automatically evaluate /interpolate covariate data locations using code like","code":"components = y ~ psi(mySpatialPixels, model = \"linear\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"coordinates","dir":"Reference","previous_headings":"","what":"Coordinates","title":"Obtain component inputs — input_eval","text":"common spatial modelling component using inla SPDE models. important feature inlabru automatically calculate called -matrix (component model matrix) maps SPDE values mesh vertices values data locations. purpose, input can set coordinates, sp package function extracts point coordinates SpatialPointsDataFrame provided input like(). code look follows:","code":"components = y ~ mySPDE(main = coordinates, model = inla.spde2.matern(...))"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain component inputs — input_eval","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/integration_weight_aggregation.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"Aggregate integration weights onto mesh nodes","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/integration_weight_aggregation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"","code":"integration_weight_aggregation(mesh, integ)"},{"path":"https://inlabru-org.github.io/inlabru/reference/integration_weight_aggregation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"mesh Mesh integrate integ list loc, integration points, weight, integration weights, SpatialPointsDataFrame. coordinates weight column handled.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/integration_weight_aggregation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregate integration weights onto mesh nodes — integration_weight_aggregation","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/intersection_mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"Construct intersection mesh mesh polygon","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/intersection_mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"","code":"intersection_mesh(mesh, poly)"},{"path":"https://inlabru-org.github.io/inlabru/reference/intersection_mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"mesh inla.mesh object intersected poly inla.mesh.segment object closed polygon intersect mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/intersection_mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct the intersection mesh of a mesh and a polygon — intersection_mesh","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate integration points — ipoints","title":"Generate integration points — ipoints","text":"function generates points one two dimensions weight attached point. weighted sum function evaluated points integral function approximated linear basis functions. parameter samplers describes area(s) integrated . case single dimension samplers supposed two-column matrix row describes start end points interval integrate . two-dimensional case samplers can either SpatialPolygon, inla.mesh SpatialLinesDataFrame describing area integrate . SpatialLineDataFrame provided, column called 'weight' order indicate width line. domain parameter inla.mesh.1d inla.mesh object can employed project integration points vertices mesh. reduces final number integration points reduces computational cost integration. projection can also prevent numerical issues spatial LGCP models observed point ideally surrounded three integration point sitting corresponding mesh vertices. controlled int.args$method=\"stable\" (default) \"direct\", latter uses integration points directly, without aggregating mesh vertices. convenience, domain parameter can also single integer setting number equally spaced integration points one-dimensional case.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate integration points — ipoints","text":"","code":"ipoints(   samplers = NULL,   domain = NULL,   name = NULL,   group = NULL,   int.args = NULL,   project = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate integration points — ipoints","text":"samplers Description integration region boundary. 1D, length 2 vector two-column matrix row describes interval, NULL 2D either SpatialPolygon SpatialLinesDataFrame weight column defining width transect line, optionally columns used group argument, NULL.  domain NULL, samplers may also inla.mesh.1d inla.mesh object, treated domain argument instead. domain Either samplers 1D interval(s) definition , domain can single integer number integration points place 1D interval, overriding int.args[[\"nsub1\"]], otherwise samplers NULL, domain can numeric vector points, given integration weight 1 (additional points added ), inla.mesh.1d object continuous 1D integration, inla.mesh.2d object continuous 2D integration. name Character array stating name domains dimension(s). NULL, names taken coordinate names samplers Spatial* objects, otherwise \"x\", \"y\", \"z\" 2D regions \"x\" 1D regions group Column names samplers object (applicable) integration points calculated independently merged aggregating mesh nodes. int.args List arguments passed bru_int_polygon. method: \"stable\" (aggregate integration weights onto mesh nodes) \"direct\" (construct within triangle/segment integration scheme without aggregating onto mesh nodes) nsub1, nsub2: integers controlling number internal integration points aggregation. Points per triangle: (nsub2+1)^2. Points per knot segment: nsub1 poly_method: set \"legacy\", selects old polygon integration method handle holes. used debugging purposes. project Deprecated favour int.args(method=...). TRUE, aggregate integration points mesh vertices. Default: project = (identical(int.args$method, \"stable\"))","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate integration points — ipoints","text":"data.frame, tibble, sf, SpatialPointsDataFrame 1D 2D integration points, including weight column .block column.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate integration points — ipoints","text":"Fabian E. Bachl bachlfab@gmail.com finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/ipoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate integration points — ipoints","text":"","code":"# \\donttest{ if (require(\"INLA\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE) &&   bru_safe_sp()) {   # Create 50 integration points covering the dimension 'myDim' between 0 and 10.    ips <- ipoints(c(0, 10), 50, name = \"myDim\")   plot(ips)     # Create integration points for the two intervals [0,3] and [5,10]    ips <- ipoints(matrix(c(0, 3, 5, 10), nrow = 2, byrow = TRUE), 50)   plot(ips)     # Convert a 1D mesh into integration points   mesh <- inla.mesh.1d(seq(0, 10, by = 1))   ips <- ipoints(mesh, name = \"time\")   plot(ips)     # Obtain 2D integration points from a SpatialPolygon    data(gorillas, package = \"inlabru\")   ips <- ipoints(gorillas$boundary)   ggplot() +     gg(gorillas$boundary) +     gg(ips, aes(size = weight))     #' Project integration points to mesh vertices    ips <- ipoints(gorillas$boundary, domain = gorillas$mesh)   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$boundary) +     gg(ips, aes(size = weight))     # Turn a 2D mesh into integration points    ips <- ipoints(gorillas$mesh)   ggplot() +     gg(gorillas$boundary) +     gg(ips, aes(size = weight)) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":null,"dir":"Reference","previous_headings":"","what":"Query if a point is inside the mesh boundary — is.inside","title":"Query if a point is inside the mesh boundary — is.inside","text":"Query point inside mesh boundary","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query if a point is inside the mesh boundary — is.inside","text":"","code":"is.inside(mesh, loc, mesh.coords = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query if a point is inside the mesh boundary — is.inside","text":"mesh inla.mesh object. loc Points space stored either data.frame, two-column matrix x y coordinates SpatialPoints object. mesh.coords Coordinate names mesh. Use loc data.frame respective column names.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query if a point is inside the mesh boundary — is.inside","text":"Single column matrix Boolean values indicating point inside mesh.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Query if a point is inside the mesh boundary — is.inside","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/is.inside.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query if a point is inside the mesh boundary — is.inside","text":"","code":"if (FALSE) { if (bru_safe_inla(quietly = TRUE)) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Check if all Gorilla nests are inside the mesh    all(is.inside(gorillas$mesh, gorillas$nests))    # Also works for locations not stored as SpatialPoints object    loc <- coordinates(gorillas$nests)   all(is.inside(gorillas$mesh, loc)) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"function performs inference LGCP observed via points residing possibly multiple dimensions. dimensions defined via left hand side formula provided via model parameter. left hand side determines intensity function assumed drive LGCP. may include effects lead thinning (filtering) point process. default, log intensity assumed linear combination effects defined formula's RHS. sophisticated models, e.g. non-linear thinning, can achieved using predictor argument. latter requires multiple runs INLA improving required approximation predictor. many applications LGCP observed subsets dimensions process living . example, spatial point realizations may known sub-areas modelled space. observed subsets LGCP domain called samplers can provided via respective parameter. samplers NULL assumed LGCP's dimensions observed completely.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"lgcp(   components,   data,   samplers = NULL,   domain = NULL,   ips = NULL,   formula = . ~ .,   E = NULL,   ...,   options = list() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"components formula describing latent components data data frame SpatialPoints(DataFrame) object samplers data frame Spatial[Points/Lines/Polygons]DataFrame objects domain Named list domain definitions ips Integration points (overrides samplers) formula NULL, linear combination implied components used predictor point location intensity. (possibly non-linear) expression provided respective Taylor approximation used predictor. Multiple runs INLA required better approximation posterior. E Single numeric used rescale integration weights fixed factor ... arguments passed like() options See bru_options_set()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"bru() object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"# \\donttest{ if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   bru_safe_sp()) {   # Load the Gorilla data   data(gorillas, package = \"inlabru\")    # Plot the Gorilla nests, the mesh and the survey boundary   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed()    # Define SPDE prior   matern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE   # effect and Intercept)   cmp <- coordinates ~ mySmooth(coordinates, model = matern) + Intercept(1)    # Fit the model (with int.strategy=\"eb\" to make the example take less time)   fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict the spatial intensity surface   lambda <- predict(     fit,     fm_pixels(gorillas$mesh, format = \"sp\"),     ~ exp(mySmooth + Intercept)   )    # Plot the intensity   ggplot() +     gg(lambda) +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed() } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood construction for usage with bru() — like","title":"Likelihood construction for usage with bru() — like","text":"Likelihood construction usage bru()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood construction for usage with bru() — like","text":"","code":"like(   formula = . ~ .,   family = \"gaussian\",   data = NULL,   response_data = NULL,   mesh = NULL,   E = NULL,   Ntrials = NULL,   weights = NULL,   samplers = NULL,   ips = NULL,   domain = NULL,   include = NULL,   exclude = NULL,   include_latent = NULL,   used = NULL,   allow_latent = NULL,   allow_combine = NULL,   control.family = NULL,   options = list(),   .envir = parent.frame() )  like_list(...)  # S3 method for list like_list(object, envir = NULL, ...)  # S3 method for bru_like like_list(..., envir = NULL)  # S3 method for bru_like_list [(x, i)"},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood construction for usage with bru() — like","text":"formula formula right hand side general R expression defines predictor used model. family string identifying valid INLA::inla likelihood family. default gaussian identity link. addition likelihoods provided inla (see names(INLA::inla.models()$likelihood)) inlabru supports fitting latent Gaussian Cox processes via family = \"cp\". alternative bru(), lgcp() function provides convenient interface fitting Cox processes. data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. response_data Likelihood-specific data models need different size/format inputs response variables, data.frame SpatialPoints[DataFrame] object. mesh inla.mesh object. Obsolete. E Exposure parameter family = 'poisson' passed INLA::inla. Special case family 'cp': rescale integration weights E. Default taken options$E, normally 1. Ntrials vector containing number trials 'binomial' likelihood. Default taken options$Ntrials, normally 1. weights Fixed (optional) weights parameters likelihood, log-likelihood[] changed weights[] * log_likelihood[]. Default value 1. WARNING: normalizing constant likelihood recomputed, marginals (marginal likelihood) must interpreted great care. samplers Integration domain 'cp' family. ips Integration points 'cp' family. Overrides samplers. domain Named list domain definitions. include Character vector component labels used effects predictor expression; Default: result [.vars()] predictor expression, unless expression \".\", case include=NULL, include components explicitly excluded. bru_used() methods used extract variable names, followed removal non-component names components available. exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) include_latent character vector. Specifies latent state variables directly available predictor expression, _latent suffix. also makes evaluator functions suffix _eval available, taking parameters main, group, replicate, taking values evaluate component effect different defined component definition (see component_eval()). Default NULL auto-detects use _latent _eval predictor expression. used Either NULL bru_used() object, overriding include, exclude, include_latent. allow_latent logical, deprecated. Use include_latent instead. allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. Default FALSE, forced TRUE response_data NULL data list control.family optional list INLA::control.family options options bru_options options object list options passed bru_options() .envir evaluation environment use special arguments (E, Ntrials, weights) found response_data data. Defaults calling environment. ... like_list.bru_like, one bru_like objects object list bru_like objects envir optional environment new bru_like_list object x bru_like_list object extract element(s) indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood construction for usage with bru() — like","text":"likelihood configuration can used parameterise bru().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood construction for usage with bru() — like","text":"like_list: Combine bru_like likelihoods bru_like_list object like_list.list: Combine list bru_like likelihoods bru_like_list object like_list.bru_like: Combine several bru_like likelihoods bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Likelihood construction for usage with bru() — like","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood construction for usage with bru() — like","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE)) {    # The like function's main purpose is to set up models with multiple likelihoods.   # The following example generates some random covariates which are observed through   # two different random effect models with different likelihoods    # Generate the data    set.seed(123)    n1 <- 200   n2 <- 10    x1 <- runif(n1)   x2 <- runif(n2)   z2 <- runif(n2)    y1 <- rnorm(n1, mean = 2 * x1 + 3)   y2 <- rpois(n2, lambda = exp(2 * x2 + z2 + 3))    df1 <- data.frame(y = y1, x = x1)   df2 <- data.frame(y = y2, x = x2, z = z2)    # Single likelihood models and inference using bru are done via    cmp1 <- y ~ -1 + Intercept(1) + x   fit1 <- bru(cmp1, family = \"gaussian\", data = df1)   summary(fit1)    cmp2 <- y ~ -1 + Intercept(1) + x + z   fit2 <- bru(cmp2, family = \"poisson\", data = df2)   summary(fit2)    # A joint model has two likelihoods, which are set up using the like function    lik1 <- like(\"gaussian\", formula = y ~ x + Intercept, data = df1)   lik2 <- like(\"poisson\", formula = y ~ x + z + Intercept, data = df2)    # The union of effects of both models gives the components needed to run bru    jcmp <- ~ x + z + Intercept(1)   jfit <- bru(jcmp, lik1, lik2)    # Compare the estimates    p1 <- ggplot() +     gg(fit1$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 1\")   p2 <- ggplot() +     gg(fit2$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 2\")   pj <- ggplot() +     gg(jfit$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Joint model\")    multiplot(p1, p2, pj) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":null,"dir":"Reference","previous_headings":"","what":"Unit test helpers — local_testthat","title":"Unit test helpers — local_testthat","text":"Local helper functions package unit tests","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unit test helpers — local_testthat","text":"","code":"local_bru_testthat_assign(x, values, envir = parent.frame())  local_bru_testthat_tolerances(   tolerances = c(1e-04, 0.01, 0.1),   envir = parent.frame() )  local_bru_options_set(..., .reset = FALSE, envir = parent.frame())  local_basic_intercept_testdata()  local_basic_fixed_effect_testdata()  local_mrsea_convert(x, use_km = FALSE)  local_bru_safe_inla(multicore = FALSE, quietly = TRUE, envir = parent.frame())  local_bru_testthat_setup(envir = parent.frame())"},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unit test helpers — local_testthat","text":"x character; Name variable assign values object assign x envir environment exit handlers tolerances numeric vector length 3; [lowtol, midtol, hitol] .reset local_bru_options_set, logical indicating global override options list emptied setting new option(s). multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. Default: FALSE, multicore allowed (used examples unit tests). quietly logical; TRUE, prints diagnostic messages. message always printed INLA num.threads option altered, regardless quietly argument. Default: TRUE.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() returns copy global override options (including defaults), invisibly.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() used set global package options.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Unit test helpers — local_testthat","text":"local_bru_testthat_assign(): Assign local variable. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_bru_testthat_tolerances(): Assign test tolerances Assign local tolerance variables. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_bru_options_set(): Calls bru_options_set() reversible way local_bru_safe_inla(): Tests set num.threads = \"1:1\" ensure within-system repeatability calling local_bru_safe_inla(); see also bru_safe_inla() local_bru_testthat_setup(): Initialise environment tests. Assigns tolerance variables. called either top testfile, inside tests. call local_bru_safe_inla(), since may invoke skip called inside test relies INLA.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unit test helpers — local_testthat","text":"","code":"my_fun <- function(val) {   local_bru_options_set(bru_verbose = val)   bru_options_get(\"bru_verbose\") } # Inside the function, the bru_verbose option is changed. # Outside the function, the bru_verbose option is unchanged. print(my_fun(TRUE)) #> [1] TRUE print(bru_options_get(\"bru_verbose\")) #> [1] 0 print(my_fun(FALSE)) #> [1] FALSE print(bru_options_get(\"bru_verbose\")) #> [1] 0"},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern correlation or covariance function approximate credible bands. — materncov.bands","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Evaluate covariance function inla.spde objectPlots posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"","code":"materncov.bands(   manifold,   dist,   log.range,   log.variance = NULL,   alpha = 2,   quantile = 0.95,   n = 64,   S1.L = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"manifold Either \"R1\", \"S1\", \"R2\", \"S2\", mesh$manifold, full inla.mesh inla.mesh.1d object. dist vector distances calculate covariances/correlations log.range scalar list (mean, sd), produced inla.spde.result(...)$summary.log.range.nominal[[1]][c(\"mean\",\"sd\")] log.variance Either NULL, scalar, vector type log.range. NULL, correlations calculated instead covariances. alpha SPDE operator order. Default 2. quantile target credible probability. Default 0.95. n number parameter combinations use approximation. Default 64. S1.L manifold \"S1\", give length cyclic interval","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"list estimated covariance correlation (log.variance NULL) functions: lower approximate lower bound quantile credible region median function approximate median parameters quantile upper approximate upper bound quantile credible region","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Uses Gaussian assumption internal model parameters, finds region parameter space approximately quantile probability.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mesh_triangle_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"Integration scheme mesh triangle interiors","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mesh_triangle_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"","code":"mesh_triangle_integration(mesh, tri_subset = NULL, nsub = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/mesh_triangle_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"mesh Mesh integrate tri_subset Optional triangle index vector integration subset mesh triangles (Default NULL) nsub number subdivision points along triangle edge, giving (nsub + 1)^2 proto-integration points used compute vertex weights (default NULL=9, giving 100 integration points triangle)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mesh_triangle_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"list elements loc weight integration points mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mesh_triangle_integration.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integration scheme for mesh triangle interiors — mesh_triangle_integration","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"version mexdolphins dataset package dsm, reformatted point process data use inlabru. data combination several NOAA shipboard surveys conducted pan-tropical spotted dolphins Gulf Mexico. 47 observations groups dolphins detected. group size recorded, well Beaufort sea state time observation. Transect width 16 km, .e. maximal detection distance 8 km (transect half-width 8 km).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"data(mexdolphin)"},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"list objects: points: SpatialPointsDataFrame object containing locations detected dolphin groups, size attribute. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. ppoly: SpatialPolygonsDataFrame object defining boundary survey region. simulated: SpatialPointsDataFrame object containing locations simulated population dolphin groups. population simulated 'codeinlabru model fitted actual survey data. Note simulated data associated size information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Library dsm.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Halpin, P.N., .J. Read, E. Fujioka, B.D. Best, B. Donnelly, L.J. Hazen, C. Kot, K. Urian, E. LaBrecque, . Dimatteo, J. Cleary, C. Good, L.B. Crowder, K.D. Hyrenbach. 2009. OBIS-SEAMAP: world data center marine mammal, sea bird, sea turtle distributions. Oceanography 22(2):104-115 NOAA Southeast Fisheries Science Center. 1996. Report Cetacean Survey Oceanic Selected Continental Shelf Waters Northern Gulf Mexico aboard NOAA Ship Oregon II (Cruise 220)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"# \\donttest{ if (bru_safe_inla(quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE) &&   require(\"ggpolypath\", quietly = TRUE)) {   data(mexdolphin, package = \"inlabru\")   ggplot() +     gg(mexdolphin$mesh) +     gg(mexdolphin$ppoly, color = \"blue\") +     gg(mexdolphin$samplers) +     gg(mexdolphin$points, aes(size = size), color = \"red\") +     coord_equal()    ggplot() +     gg(mexdolphin$mesh, col = mexdolphin$lambda, mask = mexdolphin$ppoly) +     coord_equal() } #> Regions defined for each Polygons  # } if (FALSE) { if (requireNamespace(\"ggmap\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE) &&   require(\"ggpolypath\", quietly = TRUE)) {   gmap(mexdolphin$depth) +     gm(mexdolphin$ppoly, color = \"blue\") +     gm(mexdolphin$samplers) +     gm(mexdolphin$points, aes(size = size), color = \"red\")    gmap(mexdolphin$depth) +     gm(mexdolphin$depth, aes(col = depth)) +     gm(mexdolphin$ppoly) } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":null,"dir":"Reference","previous_headings":"","what":"Marine renewables strategic environmental assessment — mrsea","title":"Marine renewables strategic environmental assessment — mrsea","text":"Data imported package MRSea, see http://creem2.st-andrews.ac.uk/software/","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"data(mrsea)"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Marine renewables strategic environmental assessment — mrsea","text":"list objects: points: SpatialPointsDataFrame object containing locations XXXXX. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. boundary: SpatialPolygonsDataFrame object defining boundary survey region. covar: SpatialPointsDataFrame containing sea depth estimates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Marine renewables strategic environmental assessment — mrsea","text":"Library MRSea.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marine renewables strategic environmental assessment — mrsea","text":"NONE YET","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   data(mrsea)   ggplot() +     gg(mrsea$mesh) +     gg(mrsea$samplers) +     gg(mrsea$points) +     gg(mrsea$boundary) } #> Regions defined for each Polygons"},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple ggplots on a page. — multiplot","title":"Multiple ggplots on a page. — multiplot","text":"Renders multiple ggplots single page.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple ggplots on a page. — multiplot","text":"","code":"multiplot(..., plotlist = NULL, cols = 1, layout = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Multiple ggplots on a page. — multiplot","text":"http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple ggplots on a page. — multiplot","text":"... Comma-separated ggplot objects. plotlist list ggplot objects - alternative comma-separated argument . cols Number columns plots page. layout matrix specifying layout. present, 'cols' ignored. layout something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE), plot 1 go upper left, 2 go upper right, 3 go way across bottom.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiple ggplots on a page. — multiplot","text":"David L. Borchers dlb@st-andrews.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple ggplots on a page. — multiplot","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   df <- data.frame(x = 1:10, y = 1:10, z = 11:20)   pl1 <- ggplot(data = df) +     geom_line(mapping = aes(x, y), color = \"red\")   pl2 <- ggplot(data = df) +     geom_line(mapping = aes(x, z), color = \"blue\")   multiplot(pl1, pl2, cols = 2) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse inclusion of component labels in a predictor expression — parse_inclusion","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"Parse inclusion component labels predictor expression","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"","code":"parse_inclusion(thenames, include = NULL, exclude = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"thenames Set labels restrict include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":null,"dir":"Reference","previous_headings":"","what":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"Make hierarchical mesh basis functions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"","code":"make_hierarchical_mesh_basis(mesh, forward = TRUE)  inla.spde2.pcmatern_B(mesh, ..., B)"},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"inla.spde2.pcmatern_B(): Construct pcmatern model basis change","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate SpatialPixels covering an inla.mesh — pixels","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"Generate SpatialPixels covering inla.mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"","code":"pixels(mesh, nx = 150, ny = 150, mask = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"mesh inla.mesh object nx Number pixels x direction ny Number pixels y direction mask logical TRUE, remove pixels outside mesh. mask Spatial object, return pixels covered object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"SpatialPixelsDataFrame covering mesh","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate SpatialPixels covering an inla.mesh — pixels","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(\"mrsea\", package = \"inlabru\")   pxl <- fm_pixels(mrsea$mesh,     nx = 50, ny = 50, mask = mrsea$boundary,     format = \"sp\"   )   ggplot() +     gg(pxl, fill = \"grey\", alpha = 0.5) +     gg(mrsea$mesh) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for posterior marginals estimated by bru — plot.bru","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"bru() uses INLA::inla() fit models. latter estimates posterior densities random effects model. function serves access plot posterior densities convenient way. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"# S3 method for bru plot(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"x fitted bru() model. ... character naming effect plot, e.g. \"Intercept\". random effects, adding index = ... plots density single component latent model.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"object class gg","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"if (FALSE) { if (require(\"ggplot2\", quietly = TRUE)) {   # Generate some data and fit a simple model   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))   fit <- bru(y ~ x, family = \"gaussian\", data = input.df)   summary(fit)    # Plot the posterior of the model's x-effect   plot(fit, \"x\") } }"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prediction using ggplot2 — plot.prediction","title":"Plot prediction using ggplot2 — plot.prediction","text":"Generates base ggplot2 using ggplot() adds geom input x using gg.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prediction using ggplot2 — plot.prediction","text":"","code":"# S3 method for prediction plot(x, y = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prediction using ggplot2 — plot.prediction","text":"x prediction object. y Ignored argument required S3 compatibility. ... Arguments passed gg.prediction.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prediction using ggplot2 — plot.prediction","text":"object class gg","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prediction using ggplot2 — plot.prediction","text":"Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prediction using ggplot2 — plot.prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a plot sample. — plotsample","title":"Create a plot sample. — plotsample","text":"Creates plot sample regular grid random start location.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a plot sample. — plotsample","text":"","code":"plotsample(spdf, boundary, x.ppn = 0.25, y.ppn = 0.25, nx = 5, ny = 5)"},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a plot sample. — plotsample","text":"spdf SpatialPointsDataFrame defining points sampled plot sample. boundary SpatialPolygonsDataFrame defining survey boundary within  points occur. x.ppn proportion x=axis included plots. y.ppn proportion y=axis included plots. nx number plots x-dimension. ny number plots y-dimension.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a plot sample. — plotsample","text":"list three components: plots: SpatialPolygonsDataFrame object containing plots sampled. dets: SpatialPointsDataFrame object containing locations points within plots. counts: dataframe containing following columns x: x-coordinates centres plots within boundary. y: y-coordinates centres plots within boundary. n: numbers points plot. area: areas plots within boundary .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a plot sample. — plotsample","text":"","code":"# \\donttest{ # Some features require the raster package if (bru_safe_sp() &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets, pch = \"+\", cex = 2) +     gg(gorillas$boundary) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a plot sample of points into one of counts. — point2count","title":"Convert a plot sample of points into one of counts. — point2count","text":"Converts plot sample locations point within plot, plot sample count within plot.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"point2count(plots, dets)"},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a plot sample of points into one of counts. — point2count","text":"plots SpatialPolygonsDataFrame object containing plots sampled. dets SpatialPointsDataFrame object containing locations points within plots.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a plot sample of points into one of counts. — point2count","text":"SpatialPolygonsDataFrame counts plot contained slot @data$n.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"# \\donttest{ # Some features require the raster package if (bru_safe_sp() &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   p1 <- ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets) +     gg(gorillas$boundary)   countdata <- point2count(plotpts$plots, plotpts$dets)   x <- coordinates(countdata)[, 1]   y <- coordinates(countdata)[, 2]   count <- countdata@data$n   p2 <- ggplot() +     gg(gorillas$boundary) +     gg(plotpts$plots) +     geom_text(aes(label = count, x = x, y = y))   multiplot(p1, p2, cols = 2) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction from fitted bru model — predict.bru","title":"Prediction from fitted bru model — predict.bru","text":"Takes fitted bru object produced function bru() produces predictions given new set values model covariates original values used model fit. predictions can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# S3 method for bru predict(   object,   newdata = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   probs = c(0.025, 0.5, 0.975),   num.threads = NULL,   include = NULL,   exclude = NULL,   used = NULL,   drop = FALSE,   ...,   data = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction from fitted bru model — predict.bru","text":"object object obtained calling bru() lgcp(). newdata data.frame SpatialPointsDataFrame covariates needed prediction. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default rather low provides quick approximate result. seed Random number generator seed passed inla.posterior.sample probs numeric vector probabilities values [0, 1], passed stats::quantile num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: result [.vars()] predictor expression, unless expression \".\", case include=NULL, include components explicitly excluded. bru_used() methods used extract variable names, followed removal non-component names components available. exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) used Either NULL bru_used() object, overriding include exclude. Default NULL drop logical; keep=FALSE, newdata Spatial*DataFrame, prediciton summary number rows newdata, output Spatial*DataFrame object. Default FALSE. ... Additional arguments passed inla.posterior.sample data Deprecated. Use newdata instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction from fitted bru model — predict.bru","text":"data.frame Spatial* object predicted mean values summary statistics attached.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction from fitted bru model — predict.bru","text":"Mean value predictions accompanied standard errors, upper lower 2.5% quantiles, median, variance, coefficient variation well variance minimum maximum sample value drawn course estimating statistics. Internally, method calls generate.bru() order draw samples model. addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). f \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE) &&     bru_safe_sp() &&     require(\"sn\", quietly = TRUE) &&     require(\"ggplot2\", quietly = TRUE)) {    # Load the Gorilla data    data(gorillas, package = \"inlabru\")    # Plot the Gorilla nests, the mesh and the survey boundary    ggplot() +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary) +     coord_fixed()    # Define SPDE prior    matern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE effect and Intercept)    cmp <- coordinates ~ mySmooth(main = coordinates, model = matern) + Intercept(1)    # Fit the model, with \"eb\" instead of full Bayes   fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Once we obtain a fitted model the predict function can serve various purposes.   # The most basic one is to determine posterior statistics of a univariate   # random variable in the model, e.g. the intercept    icpt <- predict(fit, NULL, ~ c(Intercept = Intercept_latent))   plot(icpt)    # The formula argument can take any expression that is valid within the model, for   # instance a non-linear transformation of a random variable    exp.icpt <- predict(fit, NULL, ~ c(     \"Intercept\" = Intercept_latent,     \"exp(Intercept)\" = exp(Intercept_latent)   ))   plot(exp.icpt, bar = TRUE)    # The intercept is special in the sense that it does not depend on other variables   # or covariates. However, this is not true for the smooth spatial effects 'mySmooth'.   # In order to predict 'mySmooth' we have to define where (in space) to predict. For   # this purpose, the second argument of the predict function can take \\code{data.frame}   # objects as well as Spatial objects. For instance, we might want to predict   # 'mySmooth' at the locations of the mesh vertices. Using    vrt <- fm_vertices(gorillas$mesh, format = \"sp\")    # we obtain these vertices as a SpatialPointsDataFrame    ggplot() +     gg(gorillas$mesh) +     gg(vrt, color = \"red\")    # Predicting 'mySmooth' at these locations works as follows    mySmooth <- predict(fit, vrt, ~mySmooth)    # Note that just like the input also the output will be a SpatialPointsDataFrame   # and that the predicted statistics are simply added as columns    class(mySmooth)   head(vrt)   head(mySmooth)    # Plotting the mean, for instance, at the mesh node is straight forward    ggplot() +     gg(gorillas$mesh) +     gg(mySmooth, aes(color = mean), size = 3)    # However, we are often interested in a spatial field and thus a linear interpolation,   # which can be achieved by using the gg mechanism for meshes    ggplot() +     gg(gorillas$mesh, color = mySmooth$mean)    # Alternatively, we can predict the spatial field at a grid of locations, e.g. a   # SpatialPixels object covering the mesh    pxl <- fm_pixels(gorillas$mesh, format = \"sp\")   mySmooth2 <- predict(fit, pxl, ~mySmooth)    # This will give us a SpatialPixelDataFrame with the columns we are looking for    head(mySmooth2)   ggplot() +     gg(mySmooth2) } #> Current num.threads is '1:1'. #> No num.threads change needed. #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.inla.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction from fitted inla model — predict.inla","title":"Prediction from fitted inla model — predict.inla","text":"method supported plain inla objects. Please see predict.bru() instead. method supported plain inla objects. Please see generate.bru() instead. See https://github.com/fbachl/inlabru/issues/78 information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.inla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction from fitted inla model — predict.inla","text":"","code":"# S3 method for inla predict(object, ...)  # S3 method for inla generate(object, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.inla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction from fitted inla model — predict.inla","text":"object inla object obtained calling INLA::inla(). ... additional arguments passed togenerate.bru.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.inla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction from fitted inla model — predict.inla","text":"prediction object. List generated samples","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.inla.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction from fitted inla model — predict.inla","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/refine.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Refine an inla.mesh object — refine.inla.mesh","title":"Refine an inla.mesh object — refine.inla.mesh","text":"Refine inla.mesh object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/refine.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refine an inla.mesh object — refine.inla.mesh","text":"","code":"refine.inla.mesh(mesh, refine = list(max.edge = 1))"},{"path":"https://inlabru-org.github.io/inlabru/reference/refine.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refine an inla.mesh object — refine.inla.mesh","text":"mesh inla.mesh object refine list refinement options passed INLA::inla.mesh.create","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/refine.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refine an inla.mesh object — refine.inla.mesh","text":"mesh refined inla.mesh object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/refine.inla.mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Refine an inla.mesh object — refine.inla.mesh","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"robins_subset — robins_subset","title":"robins_subset — robins_subset","text":"robins_subset dataset, subset full robins data set used demonstrate spatially varying trend coefficient model Meehan et al. 2019. dataset includes American Robin counts, along time, location, effort information, Audubon Christimas Bird Counts (CBC) conducted six US states 1987 2016.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"robins_subset — robins_subset","text":"","code":"data(robins_subset)"},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"robins_subset — robins_subset","text":"data data.frame variables circle: Four-letter code CBC circle. bcr: Numeric code bird conservation region encompassing count circle. state: US state encompassing count circle. year: calendar year count conducted. std_yr: transformed year, 2016 = 0. count: number robins recorded. log_hrs: natural log party hours. lon: longitude count circle centroid. lat: latitude count circle centroid. obs: unique record identifier.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"robins_subset — robins_subset","text":"https://github.com/tmeeha/inlaSVCBC","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"robins_subset — robins_subset","text":"Meehan, T.D., Michel, N.L., Rue, H. 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine-scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"robins_subset — robins_subset","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   data(robins_subset, package = \"inlabru\") # get the data    # plot the counts for one year of data   ggplot(robins_subset[robins_subset$std_yr == 0, ]) +     geom_point(aes(lon, lat, colour = count + 1)) +     scale_colour_gradient(low = \"blue\", high = \"red\", trans = \"log\") }"},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-wise Kronecker products — row_kron","title":"Row-wise Kronecker products — row_kron","text":"Takes two Matrices computes row-wise Kronecker product.  Optionally applies row-wise weights /applies additional 0/1 row-wise Kronecker matrix product.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-wise Kronecker products — row_kron","text":"","code":"row_kron(M1, M2, repl = NULL, n.repl = NULL, weights = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-wise Kronecker products — row_kron","text":"M1 matrix can transformed sparse Matrix. M2 matrix can transformed sparse Matrix. repl optional index vector.  entry, specifies replicate row belongs , sense used INLA::inla.spde.make.n.repl maximum replicate index, sense used INLA::inla.spde.make.(). weights Optional scaling weights applied row-wise resulting matrix.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-wise Kronecker products — row_kron","text":"Matrix::sparseMatrix object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Row-wise Kronecker products — row_kron","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from an inhomogeneous Poisson process — sample.lgcp","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"function provides point samples one- two-dimensional inhomogeneous Poisson processes. log intensity provided via values nodes inla.mesh.1d inla.mesh object. mesh nodes log intensity assumed linear.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"sample.lgcp(   mesh,   loglambda,   strategy = NULL,   R = NULL,   samplers = NULL,   ignore.CRS = FALSE )"},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"mesh INLA::inla.mesh object loglambda vector matrix; vector log intensities mesh vertices (higher order basis functions, e.g. inla.mesh.1d meshes, loglambda given mesh$m basis function weights rather values mesh$n vertices) single scalar expanded vector appropriate length. matrix supplied, one process sample column produced. strategy relevant 2D meshes. One 'triangulated', 'rectangle', 'sliced-spherical', 'spherical'. 'rectangle' method valid CRS-less flat 2D meshes. NULL 'auto', likely fastest method chosen; 'rectangle' flat 2D meshes CRS, 'sliced-spherical' CRS 'longlat' meshes, 'triangulated' meshes. R Numerical value applicable spherical geographical meshes. interpreted R equivalent Earth radius, km, used scale lambda intensity. CRS enabled meshes, default 6371. CRS-less spherical meshes, default 1. samplers SpatialPolygonsDataFrame inla.mesh object. Simulated points fall outside polygons discarded. ignore.CRS logical; TRUE, ignore CRS information mesh. Default FALSE. affects R permitted values strategy.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"data.frame (1D case), SpatialPoints (2D flat 3D spherical surface cases) SpatialPointsDataFrame (2D/3D surface cases multiple samples). multiple samples, data.frame output column 'sample' giving index sample. object point locations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"2D processes sphere R parameter can used adjust sphere's radius implied mesh. intensity high standard strategy \"spherical\" can cause memory issues. Using \"sliced-spherical\" strategy can help case. crs-less meshes R2: Lambda interpreted raw coordinate system. Output NA CRS. crs-less meshes S2: Lambda raw units, scaling mesh radius R, specified. Output given domain mesh, NA CRS. crs meshes R2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh. crs meshes S2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"Daniel Simpson dp.simpson@gmail.com (base rectangle spherical algorithms), Fabian E. Bachl bachlfab@gmail.com (inclusion inlabru, sliced spherical sampling), Finn Lindgren finn.lindgren@gmail.com (extended CRS support, triangulated sampling)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"# \\donttest{ # The INLA package is required if (bru_safe_inla(quietly = TRUE) &&   bru_safe_sp()) {   vertices <- seq(0, 3, by = 0.1)   mesh <- INLA::inla.mesh.1d(vertices)   loglambda <- 5 - 0.5 * vertices   pts <- sample.lgcp(mesh, loglambda)   pts$y <- 0   plot(vertices, exp(loglambda), type = \"l\", ylim = c(0, 150))   points(pts, pch = \"|\") } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }  # \\donttest{ # The INLA package is required if (bru_safe_inla(quietly = TRUE) &&   require(ggplot2, quietly = TRUE) &&   bru_safe_sp()) {   data(\"gorillas\", package = \"inlabru\")   pts <- sample.lgcp(gorillas$mesh,     loglambda = 1.5,     samplers = gorillas$boundary   )   ggplot() +     gg(gorillas$mesh) +     gg(pts) } #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":null,"dir":"Reference","previous_headings":"","what":"Seal pups — seals","title":"Seal pups — seals","text":"single transect aereal photo seal pup survey Greenland Sea","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seal pups — seals","text":"","code":"data(seals)"},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Seal pups — seals","text":"data contain objects: points: SpatialPointsDataFrame Center locations photos mesh: inla.mesh enclosing plane's transect ice.data: SpatialPointsDataFrame MODIS ice concentration estimates ice.cv: covdata object interpolated ice coverage data","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Seal pups — seals","text":"Martin Jullum Martin.Jullum@nr.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Seal pups — seals","text":"Oigard, T. . (2013) pup production quotas: current status harp seals Greenland Sea. ICES Journal Marine Science, doi.10.1093/icesjms/fst155. Oigard, T. . (2014) Current status hooded seals Greenland Sea. Victims climate change predation?, Biological Conservation , 2014, 172, 29 - 36.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Seal pups — seals","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   data(seals, package = \"inlabru\")   ggplot() +     gg(seals$mesh) +     gg(seals$points) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Blue red shrimp Western Mediterranean Sea.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"data(shrimp)"},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"list objects: haul: SpatialPointsDataFrame object containing haul locations mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering haul locations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, Maria Grazia. Personal communication.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, M. G., Paradinas, ., Munoz, F., Illian, J.,Quilez-Lopez, ., Bellido, J.M., Conesa, D. Accounting preferential sampling species distribution models. Ecology Evolution,  Press.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(shrimp, package = \"inlabru\")   ggplot() +     gg(shrimp$mesh) +     gg(shrimp$hauls) +     coord_equal() }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame to SpatialLinesDataFrame — sline","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"line 2D space defined start point, associated 2D coordinates. function takes /codedata.frame input assumes row defines line space. order , data frame must least four columns start.cols end.cols parameters must used point names columns define start end coordinates line. data converted SpatialLinesDataFrame DF. coordinate reference system crs provided attached DF. also .crs provided, coordinate system DF transfromed accordingly. Additional columns input data, e.g. covariates, retained attached DF.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"sline(data, start.cols, end.cols, crs = CRS(as.character(NA)), to.crs = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"data data.frame start.cols Character array poitning columns data hold start points lines end.cols Character array poitning columns data hold end points lines crs Coordinate reference system original data .crs Coordinate reference system SpatialLines ouput.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"SpatialLinesDataFrame","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"# \\donttest{ # Create a data frame defining three lines lns <- data.frame(   xs = c(1, 2, 3), ys = c(1, 1, 1), # start points   xe = c(2, 3, 4), ye = c(2, 2, 2) ) # end points   # Conversion to SpatialLinesDataFrame without CRS spl <- sline(lns,   start.cols = c(\"xs\", \"ys\"),   end.cols = c(\"xe\", \"ye\") )  if (require(ggplot2, quietly = TRUE)) {   # Plot the lines   ggplot() +     gg(spl) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"Spatstat point pattern objects consist points observation windows. function uses SpatialPoints object SpatialPolygon object generate points window. Lastly, ppp() function called create ppp object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"spatial.to.ppp(points, samplers)"},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"points SpatialPoints[DataFrame] object describing point pattern. samplers SpatialPolygons[DataFrame] object describing observation window.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"spatstat spatstat  ppp object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"# \\donttest{ if (require(\"spatstat.geom\") &&   bru_safe_sp()) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use nest locations and survey boundary to create a spatstat ppp object    gp <- spatial.to.ppp(gorillas$nests, gorillas$boundary)   class(gp)    # Plot it    plot(gp) } #> Loading required package: spatstat.geom #> Loading required package: spatstat.data #>  #> Attaching package: ‘spatstat.data’ #> The following object is masked _by_ ‘.GlobalEnv’: #>  #>     gorillas #> spatstat.geom 3.2-1 #> 'sp' version >= 1.6-0 detected, rgdal isn't installed, and evolution status is < 2L. #> This may cause issues with some CRS handling code. To avoid this, use 'sp::set_evolution_status(2L)' # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Calculate posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function. inla.spde.result.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"spde.posterior(result, name, what = \"range\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"result object inheriting inla. name Character stating name SPDE effect, see names(result$summary.random). One \"range\", \"log.range\", \"variance\", \"log.variance\", \"matern.correlation\" \"matern.covariance\".","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"prediction object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {    # Load 1D Poisson process data    data(Poisson2_1D, package = \"inlabru\")     # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model with  and SPDE component    x <- seq(0, 55, length = 20)   mesh1D <- INLA::inla.mesh.1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = INLA::inla.spde2.matern(mesh1D)) + Intercept   fit <- lgcp(mdl, data = pts2, domain = list(x = mesh1D))    # Calculate and plot the posterior range    range <- spde.posterior(fit, \"spde1D\", \"range\")   plot(range)    # Calculate and plot the posterior log range    lrange <- spde.posterior(fit, \"spde1D\", \"log.range\")   plot(lrange)    # Calculate and plot the posterior variance    variance <- spde.posterior(fit, \"spde1D\", \"variance\")   plot(variance)    # Calculate and plot the posterior log variance    lvariance <- spde.posterior(fit, \"spde1D\", \"log.variance\")   plot(lvariance)    # Calculate and plot the posterior Matern correlation    matcor <- spde.posterior(fit, \"spde1D\", \"matern.correlation\")   plot(matcor)    # Calculate and plot the posterior Matern covariance    matcov <- spde.posterior(fit, \"spde1D\", \"matern.covariance\")   plot(matcov) } #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). #> Warning: The input evaluation 'Intercept' for 'Intercept' failed. Perhaps the data object doesn't contain the needed variables? Falling back to '1'.  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/split_lines.html","id":null,"dir":"Reference","previous_headings":"","what":"Split lines at mesh edges — split_lines","title":"Split lines at mesh edges — split_lines","text":"Split lines mesh edges","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/split_lines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split lines at mesh edges — split_lines","text":"","code":"split_lines(mesh, sp, ep, filter.zero.length = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/split_lines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split lines at mesh edges — split_lines","text":"mesh inla.mesh object sp Start points lines ep End points lines filter.zero.length Filter segments zero length? (Bool) ... argments int.quadrature","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/split_lines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split lines at mesh edges — split_lines","text":"List start end points resulting splitting given lines","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/split_lines.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split lines at mesh edges — split_lines","text":"Fabian E. Bachl f.e.bachl@bath.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"polygon can described sequence points defining polygon's boundary. given sequence (anti clockwise!) function creates SpatialPolygonsDataFrame holding polygon decribed. default, first two columns data assumed define x y coordinates points. behavior can ba changed using cols parameter, points names columns holding coordinates. coordinate reference system resulting spatial polygon can set via crs paraemter. Posterior conversion different CRS supported using .crs parameter.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"spoly(data, cols = colnames(data)[1:2], crs = fm_CRS(), to.crs = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"data data.frame points describing boundary polygon cols Column names x y coordinates within data crs Coordinate reference system points .crs Coordinate reference system SpatialLines ouput.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"SpatialPolygonsDataFrame","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"# \\donttest{ # Create data frame of boundary points (anti clockwise!) pts <- data.frame(   x = c(1, 2, 1.7, 1.3),   y = c(1, 1, 2, 2) )  # Convert to SpatialPolygonsDataFrame pol <- spoly(pts)  if (require(ggplot2, quietly = TRUE) &&   require(ggpolypath, quietly = TRUE)) {   # Plot it!   ggplot() +     gg(pol) } #> Regions defined for each Polygons  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for ","title":"Check for ","text":"Check \"XYZ\", \"XYM\" \"XYZM\" sfg classes","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for ","text":"","code":"st_check_dim(sfc)"},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for ","text":"sfc sfc object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_dim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for ","text":"LOGICAL indicating sfg element sfc object class \"XYZ\", \"XYM\" \"XYZM\". Internal function used check 3 4 dimensional objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Check sfg polygon satisfies standards for POLYGON simple features — st_check_polygon","title":"Check sfg polygon satisfies standards for POLYGON simple features — st_check_polygon","text":"seems though st_polygon check . now implements basic check disjoint regions using st_within()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check sfg polygon satisfies standards for POLYGON simple features — st_check_polygon","text":"","code":"st_check_polygon(sfg)"},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check sfg polygon satisfies standards for POLYGON simple features — st_check_polygon","text":"sfg POLYGON sfg object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_check_polygon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check sfg polygon satisfies standards for POLYGON simple features — st_check_polygon","text":"LOGICAL; TRUE sfg holes entirely inside outer ring, disjoint, otherwise FALSE. FALSE, attribute Message set character vector describing detected reasons.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_signed_area.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate signed area for polygon — st_signed_area","title":"Calculate signed area for polygon — st_signed_area","text":"Calculate signed area polygon","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_signed_area.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate signed area for polygon — st_signed_area","text":"","code":"st_signed_area(sfg)"},{"path":"https://inlabru-org.github.io/inlabru/reference/st_signed_area.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate signed area for polygon — st_signed_area","text":"sfg POLYGON sfg object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_signed_area.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate signed area for polygon — st_signed_area","text":"Returns signed area.  Negative values indicate anti-clockwise winding direction.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/st_signed_area.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate signed area for polygon — st_signed_area","text":"Andrew Seaton Andrew.Seaton.2@glasgow.ac.uk Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for an inlabru fit — summary.bru","title":"Summary for an inlabru fit — summary.bru","text":"Takes fitted bru object produced bru() lgcp() creates various summaries .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# S3 method for bru summary(object, verbose = FALSE, ...)  # S3 method for summary_bru print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for an inlabru fit — summary.bru","text":"object object obtained bru() lgcp() call verbose logical; TRUE, include details component definitions. FALSE, show basic component definition information. Default: FALSE ... arguments passed component summary functions, see summary.component(). x summary_bru2 object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# \\donttest{ if (bru_safe_inla(multicore = FALSE)) {    # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1))    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept, family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #> Warning: All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. #>   Implicit latent intercept component specification is deprecated since version 2.1.14. #>   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). #> Warning: The input evaluation 'Intercept' for 'Intercept' failed. Perhaps the data object doesn't contain the needed variables? Falling back to '1'. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         1.965585 0.03387737   1.897889 1.965585   2.033279 1.965585 #> Intercept 4.979864 0.02395150   4.932002 4.979865   5.027724 4.979865 #>                    kld #> x         5.629693e-06 #> Intercept 5.629777e-06   if (bru_safe_inla(multicore = FALSE)) {    # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\", formula = y ~ x + Intercept, data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         1.965585 0.03385483   1.897934 1.965585   2.033233 1.965585 #> Intercept 4.979864 0.02393556   4.932035 4.979865   5.027692 4.979865 #>                    kld #> x         5.689494e-06 #> Intercept 5.689581e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla(multicore = FALSE)) {   z <- 2   input.df <- within(input.df, y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1))   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #> Current num.threads is '1:1'. #> No num.threads change needed. #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         2.003525 0.006289992   1.990956 2.003525   2.016093 2.003525 #> Intercept 4.966085 0.032975732   4.900191 4.966086   5.031976 4.966086 #>                    kld #> z         5.715972e-06 #> Intercept 5.715822e-06 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Print inlabru options — summary.bru_options","title":"Print inlabru options — summary.bru_options","text":"Print inlabru options","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print inlabru options — summary.bru_options","text":"","code":"# S3 method for bru_options summary(   object,   legend = TRUE,   include_global = TRUE,   include_default = TRUE,   ... )  # S3 method for summary_bru_options print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print inlabru options — summary.bru_options","text":"object bru_options object summarised legend logical; TRUE, include explanatory text, Default: TRUE include_global logical; TRUE, include global override options include_default logical; TRUE, include default options ... parameters, currently ignored x summary_bru_options object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print inlabru options — summary.bru_options","text":"","code":"if (interactive()) {   options <- bru_options(verbose = TRUE)    # Don't print options only set in default:   print(options, include_default = FALSE)    # Only include options set in the object:   print(options, include_default = FALSE, include_global = FALSE) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise components — summary.component","title":"Summarise components — summary.component","text":"Summarise components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise components — summary.component","text":"","code":"# S3 method for component summary(object, ..., depth = Inf, verbose = TRUE)  # S3 method for component_list summary(object, verbose = TRUE, ...)  # S3 method for summary_component print(x, ...)  # S3 method for summary_component_list print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise components — summary.component","text":"object component component_list. ... passed summary methods depth depth expand component mapper. Default Inf, traverse entire mapper tree. verbose logical; TRUE, includes details component definitions. FALSE, show basic component definition information.  Default TRUE. x summary object printed.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise components — summary.component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated 1D animal group locations and group sizes — toygroups","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data set serves teach concept modelling species gather groups grouping behaviour depends space.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"data(toygroups)"},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data list contains elements: groups: data.frame group locations x size size df.size: IGNORE df.intensity: data.frame Poisson process intensity d.lambda locations x df.rate: data.frame locations x associated rate parameterized exponential distribution group sizes drawn.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   # Load the data    data(\"toygroups\", package = \"inlabru\")    # The data set is a simulation of animal groups residing in a 1D space. Their   # locations in x-space are sampled from a Cox process with intensity    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda))    # Adding the simulated group locations to this plot we obtain    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda)) +     geom_point(data = toygroups$groups, aes(x, y = 0), pch = \"|\")    # Each group has a size mark attached to it.   # These group sizes are sampled from an exponential distribution   # for which the rate parameter depends on the x-coordinate    ggplot(toygroups$groups) +     geom_point(aes(x = x, y = size))    ggplot(toygroups$df.rate) +     geom_line(aes(x, rate)) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/tsplit.inla.mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"Warning: original triangle edges always preserved. Warning: Works euclidean coordinates. suitable sphere. Warning: Experimental; replaced new method","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/tsplit.inla.mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"","code":"tsplit.inla.mesh(mesh, n = 1)"},{"path":"https://inlabru-org.github.io/inlabru/reference/tsplit.inla.mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"mesh inla.mesh object n number splitting recursions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/tsplit.inla.mesh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"mesh refined inla.mesh object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/tsplit.inla.mesh.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split triangles of a mesh into four triangles — tsplit.inla.mesh","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/wkt_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal WKT handling — fm_wkt_as_wkt_tree","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"Conversion WKT tree representation","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/wkt_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"","code":"fm_wkt_as_wkt_tree(x, ...)  fm_wkt_tree_as_wkt(x, pretty = FALSE, ...)  fm_wkt_tree_get_item(x, item, duplicate = 1)  fm_wkt_tree_set_item(x, item_tree, duplicate = 1)"},{"path":"https://inlabru-org.github.io/inlabru/reference/wkt_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal WKT handling — fm_wkt_as_wkt_tree","text":"x WKT2 string, wkt_tree list structure ... Unused pretty logical; TRUE, use pretty formatting. Default: FALSE item character vector item labels identifying parameter item entry. duplicate items one match, duplicate indicates index number desired version. Default: 1 item_tree item tree identifying parameter item entry","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-development-version","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru (development version)","text":"iterative inla method given sharper internal inla() optimisation criteria iterations (thanks Haavard Rue), relaxed nonlinear iteration stopping criterion; default bru_method$rel_tol values changed 1 10 percent change, relative posterior standard deviation. seems strike useful balance different optimisation criteria, allowing iterations converge faster also detect convergence sooner. logic components needed predictor expression (like() generate()/predict()) updated possible extract list components expression . user can override default necessary, using include/exclude arguments. bru_used() methods used guess needed component names, applied right-hand side formula arguments. allow_latent argument like() deprecated favour include_latent (default auto-detected use _latent _eval). internal information storage handled new bru_used() methods, can also used directly user supplied via used argument like()/generate()/predict(). Add fm_int() integration methods, replacing old ipmaker() ipoints() methods. Supports sf sp sampler objects. Add fm_pixels() methods gridded points. old pixels() method now calls fm_pixels(..., format = \"sp\") eval_spatial support sf objects (point--polygon data lookups) Allow precomputed spatial covariates data point process observations Add edge|int|ext.linewidth arguments gg.inla.mesh #188 Rename predict() generate() data arguments newdata, better compatibility predict() methods. old argument name still accepted, give warning. Code name data argument affected. Note: Coordinate names Spatial* objects inconsistently available predictor expression evaluation. However, due internal conversions might inadvertently change names, can relied , longer made available predictor expression. side effect, change also speeds bru() runs around factor 2, since avoids converting Spatial* regular data.frame time-sensitive core evaluation code. need access raw coordinate values, use explicit calls sp::coordinates(.data.) (e.g. custom spatial covariate evaluation.). possible, use built-covariate evaluation method, eval_spatial(), either implicitly comp(covariate, ...) explicitly, comp(eval_spatial(covariate, = .data.), ...), handles crs information correctly. Also consider transitioning sp sf data storage, using geometry instead raw coordinates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-and-dependency-updates-development-version","dir":"Changelog","previous_headings":"","what":"Bug and dependency updates","title":"inlabru (development version)","text":"Remove rgdal maptools dependencies #178 Add bru_safe_sp() check sp can used safely (checks rgdal availability sp evolution status, optionally forcing use sf) #178 Remove PROJ4 support #178 Change rgl.* functions *3d. Thanks Duncan Murdoch #181 Speed ibm_jacobian.bru_mapper_harmonics large models Add workarounds inconsistent polygon orientation resulting sf::st_* calls don’t account geos canonical representation CW, whereas canonical Simple Features representation CCW. See https://github.com/r-spatial/sf/issues/2096","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-270","dir":"Changelog","previous_headings":"","what":"inlabru 2.7.0","title":"inlabru 2.7.0","text":"CRAN release: 2022-12-02","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-overview-2-7-0","dir":"Changelog","previous_headings":"","what":"Feature overview","title":"inlabru 2.7.0","text":"Added support sf terra inputs methods Expanded geometry mesh handling methods Expanded bru_mapper() system Added convergence diagnostics plot bru_convergence_plot()","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-details-2-7-0","dir":"Changelog","previous_headings":"","what":"Feature details","title":"inlabru 2.7.0","text":"Allow NA input default 1D mappers generate effect zero, like inla(). New expanded methods fm_crs(), fm_CRS(), fm_transform(), fm_ellipsoid_radius(), fm_length_unit() support sf objects. fm_crs() extraction method also supports terra objects. bru_fill_missing() now supports terra SpatRaster data sf locations. New experimental methods fm_evaluator() fm_evaluate(), replacing INLA inla.mesh.projector inla.mesh.project methods. Experimental integration support sphere globe meshes. Allow sf input family=\"cp\" models. bru_mapper() method updates; Deprecated ibm_amatrix() names() methods, replaced ibm_jacobian() ibm_names(). Introduced bru_mapper_pipe(), used link mappers sequence. Introduced bru_mapper_aggregate() bru_mapper_logsumexp(), used blockwise weighted sums log-sum-exp mappings, output[k] = sum(weights[block==k]*state[block==k]))) output[k] = log(sum(weights[block==k]*exp(state[block==k]))), optional weight normalisation within block. Allows providing weights log-weights, uses block-wise shifts avoid potential overflow. summary methods bru_mapper objects (summary.bru_mapper()) Removed methods argument bru_mapper_define(). Implementations register S3 methods instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-7-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.7.0","text":"Remove unused spatstat.core dependency. Fixes #165 Fixed issue plain mapper evaluation ibm_eval.default() ibm_eval.bru_mapper_collect() methods, return zeros instead intended values. main component evaluation estimation code directly affected based bru_mapper_multi() class methods rely Jacobians instead. bug therefore mainly impacted future, yet supported nonlinear mapper extensions. Fix eval_spatial.SpatRaster; Work around inconsistent logic terra::extract(..., layer) length(layer)==1 nrow()==1. Fixes #169 Add indexed logical option bru_mapper_factor(), allow factor inputs mapped index values, needed group replicate. Fixes #174","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-260","dir":"Changelog","previous_headings":"","what":"inlabru 2.6.0","title":"inlabru 2.6.0","text":"CRAN release: 2022-10-24","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-6-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.6.0","text":"Add bru_get_mapper generic, associated methods inla.spde inla.rgeneric objects. allows inlabru automatically extract appropriate bru_mapper object model component, can used hook external packages implementing new INLA object classes. Add weights argument like(), likelihood-specific log-likelihood weights, passed INLA::inla() weights argument. Evaluated data context. <component>_eval() methods available predictor expressions now handle optional scaling weights, like ordinary component effect evaluation. Add terra support covariate inputs component *_layer arguments now evaluated data context, allow dynamic layer selection spatial raster covariates. new generic eval_spatial() provides support grid/pixel based Spatial*DataFrame evaluation, SpatRaster. Expanded support progress. New vignettes bru_mapper system, component definitions, prediction_scores General overhaul bru_mapper linearised predictor system, prepare new features. Add ibm_eval generic evaluating mappers given states. Add bru_mapper_taylor, used internal mapper linearised mappers. ibm_eval aimed future support nonlinear mappers. Associated new generic methods: ibm_{is_linear,jacobian,linear}. New mapper implementations use ibm_jacobian instead ibm_amatrix. allows defining linearised mapper via ibm_eval(input, state0) + ibm_jacobian(input, state0) %*% (state - state0). New mapper class bru_mapper_const, replaces bru_mapper_offset. bru_mapper_offset now deprecated produce warnings.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.6.0","text":"Enable datum/ensemble container ellipsoid information, support epsg:4326. Fixes #154 Make duplicated component names error instead warning. Relates #155 Fix Tsparse assumptions row_kron prepare Matrix 1.5-2. Fixes #162","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-253","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.3","title":"inlabru 2.5.3","text":"CRAN release: 2022-09-05","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-5-3","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.3","text":"Add bru_mapper_harmonics mapper cos sin basis sets. Allow predict() input data list. Allow arbitrary quantile summaries predict() Remove cv, var, smin, smax summaries predict() Add mean.mc_std_err sd.mc_std_err output predict() Add robins_subset data set associated variable coefficient web vignette","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-5-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.3","text":"Propagate multi-likelihood -matrix information instead recomputing. Fixes iteration issue bym2 bru_mapper_collect models. Turn predictor summaries iterations allow inla.mode=\"classic\" use proper line search. Avoid deprecated Matrix (>=1.4-2) class coercion methods Work around lack full Matrix ModelMatrix support unique method. Fixes #145","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-252","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.2","title":"inlabru 2.5.2","text":"CRAN release: 2022-03-30 robust package checks robust namespace INLA availability checks Add package vignette links website examples","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-251","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.1","title":"inlabru 2.5.1","text":"Revert R language features compatible R 4.0.5 Use strategy=\"gaussian\" iterations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-250","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.0","title":"inlabru 2.5.0","text":"CRAN release: 2022-03-21","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-5-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.0","text":"Add bru() timing information $bru_timings $bru_iinla$timings Add SpatialPolygonsDataFrame support gg() methods Allow accessing E Ntrials response_data data (special arguments remain added) deltaIC improvements New transformation helper tools bru_{forward/inverse}_transformation() Experimental support matrix formula component inputs. E.g. ~ name(~ -1 + + b + :b, model = \"fixed\"), covariate fixed effect interaction specifications can made. formula input, MatrixModels::model.Matrix() called construct matrix input used -matrix fixed effects, one per column, added form combined effect. Documentation examples improvements","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.0","text":"Fix -matrix construction evaluate_model() cases inla_f argument matters efficient robust mesh integration code Cleanup environment handling component lists","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-240","dir":"Changelog","previous_headings":"","what":"inlabru 2.4.0","title":"inlabru 2.4.0","text":"CRAN release: 2021-12-19","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-4-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.4.0","text":"Allow predictors different size input data. data argument now allowed list(), new argument response_data allows separate specification component inputs response variables. Add bru_mapper_collect class handling sequential collections mappers, including collections first mapper hidden INLA::f() arguments n values, needed support e.g. “bym2” models. Add control.family direct argument like(). Gives warning control.family argument supplied options argument bru(), least one likelihood control.family information. (Issue #109)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bugfixes-2-4-0","dir":"Changelog","previous_headings":"","what":"Bugfixes","title":"inlabru 2.4.0","text":"Fix support SpatialPointsDataFrame SpatialGridDataFrame input bru_fill_missing() Force explicit model = \"offset\" components instead special options, avoid interfering linearisation system (Issue #123) Make iterations robust resetting internal INLA predictor states initial value zero step","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"miscellaneous-2-4-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"inlabru 2.4.0","text":"Rename option bru_method$stop_at_max_rel_deviation bru_method$rel_tol. Automatic conversion new name, warning given. Add option bru_method$max_step control largest allowed line search scaling factor. See ?bru_options New default option bru_compress_cp set TRUE compress predictor expression family=\"cp\" use single element linear predictor sum.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-231","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.1","title":"inlabru 2.3.1","text":"CRAN release: 2021-03-22 Documentation dependency updates CRAN compatibility See NEWS version 2.3.0 major updates since version 2.1.13","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-230","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.0","title":"inlabru 2.3.0","text":"CRAN release: 2021-03-16","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"breaking-changes-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes since version 2.1.13","title":"inlabru 2.3.0","text":"model component argument map deprecated. Use main specify main component input, ~ elev(main = elevation, model = \"rw2\"). Unlike old map argument, main first one, shorter version ~ elev(elevation, model = \"rw2\") also works. Intercept-like components now explicit inputs, e.g. ~ Intercept(1) avoid accidental confusion variables. argument list bru() simplified, arguments except components options must either outputs calls like(), arguments can sent single like() call. option setting system replaced coherent system; see ?bru_options() details. samplers domain system lgcp models now stricter, requires explicit domain definitions point process dimensions. Alternatively, user-defined integration schemes can supplied via ips argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"new-features-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"New features since version 2.1.13","title":"inlabru 2.3.0","text":"model component input arguments main, group, replicate, weights can now take general R expressions using data inputs. Special cases detected: SpatialPixels/GridDataFrame objects evaluated spatial locations input data SpatialPointsDataFrame object. Functions evaluated data object, e.g. field(coordinates, model = spde) component arguments mapper, group_mapper, replicate_mapper can used precise control mapping inputs latent variables. See ?bru_mapper details. Mapper information automatically extracted INLA::inla.spde2.pcmatern() model objects. R-INLA weights copy features now supported. predictor expressions can access data object directly via .data. data several rows can affect output row, allow_combine = TRUE argument must supplied like() include exclude arguments like(), generate(), predict() can used specify components used given likelihood model predictor expression. can used prevent evaluation components invalid likelihood predictor. Predictor expressions can access latent state model component directly, adding suffix _latent component name, e.g. name_latent. like(), requires allow_latent = TRUE activate needed linearisation code . Predictor expressions can evaluate component effects arbitrary inputs adding suffix _eval access special evaluator functions, e.g. name_eval(1:10). useful evaluating 1D effect spatial covariates. See NEWS item version 2.2.8 details. internal system predictor linearisation iterated INLA inference rewritten faster robust See NEWS entries versions 2.1.14 2.2.8 details new features bug fixes","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-228","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.8","title":"inlabru 2.2.8","text":"Add _eval suffix feature generate.bru predict.bru, provides general evaluator function component, allowing evaluation e.g. nonlinear effects spatial covariates function covariate value instead spatial evaluator used component definition. example, components = ~ covar(spatial_grid_df, model = \"rw1\"), prediction expression can ~ covar_eval(covariate), covariate data column prediction data object. components group replicate features, also need provided _eval function, ..._eval(..., group = ..., replicate = ...) feature built top _latent suffix feature, gives direct access latent state variables component, order use _eval model predictor , must use like(..., allow_latent = TRUE) model definition.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-227","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.7","title":"inlabru 2.2.7","text":"Add support ngroup nrep component definitions Updated mexdolphin mrsea data sets, consistent km units improved mesh designs","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-226","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.6","title":"inlabru 2.2.6","text":"Add predict(..., include) discussion distance sampling vignette, handling non-spatial prediction spatial models. Fix bugs gg.SpatialLines","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-225","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.5","title":"inlabru 2.2.5","text":"Vignette corrections Documentation improvements Fix minor bug Spatial* object handling plotting","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-224","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.4","title":"inlabru 2.2.4","text":"Properly extract joint latent conditional mode instead marginal latent conditional mode","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-222","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.2","title":"inlabru 2.2.2","text":"Fixed issue predict() logic converting output Spatial*DataFrame Use control.mode=list(restart=FALSE) final inla run nonlinear models, avoid unnecessary optimisation. Fix issues pixels() bru_fill_missing() Spatial*DataFrame objects ncol=0 data frame parts.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-221","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.1","title":"inlabru 2.2.1","text":"Fixed code regression bug function input covariates","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-220","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.0","title":"inlabru 2.2.0","text":"Support INLA “copy” feature, comp2(input, copy = \"comp1\") Allow component weights unnamed parameter, comp(input, weights, ...) Direct access data objects component inputs predictor expressions, .data., allowing e.g. covar(fun(.data.), ...) complex covariate extractor method fun() Partial support spherical manifold meshes Uses INLA integration strategy “eb” initial nonlinear iterations, specified integration strategy final iteration, computations faster, uses conditional latent mode linearisation point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2115","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.15","title":"inlabru 2.1.15","text":"New options system New faster linearisation method New line search method make nonlinear inla iterations robust Method updating old stored estimation objects System supplying mappings latent models evaluated effects via bru_mapper objects Improved factor support; Either “contrast 1st level”, via special \"factor_contrast\" model, levels model \"factor_full\". options planned (e.g. simpler options fix precision parameter). estimated coefficients appear random effects inla() output. Interface restructuring support new features keeping backwards compatibility. Change map= main= unnamed first argument; Since main first parameter, doesn’t need named argument. Keep components zero derivative linearisation PROJ6 support Add random seed option posterior sampling Add package unit testing New backend code make extended feature support easier New int.args option control spatial integration resolution, thanks Martin Jullum (martinju)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2113","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.13","title":"inlabru 2.1.13","text":"CRAN release: 2020-02-16 Fix CRAN complaint regarding documentation","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2112","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.12","title":"inlabru 2.1.12","text":"CRAN release: 2019-06-24 Workaround integration points error old (ca pre-2018) INLA versions","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2111","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.11","title":"inlabru 2.1.11","text":"Add CITATION file","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2110","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.10","title":"inlabru 2.1.10","text":"Fix internal sampling bug due INLA changes","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-219","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.9","title":"inlabru 2.1.9","text":"CRAN release: 2018-07-24 Remove unused VignetteBuilder entry DESCRIPTION","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-218","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.8","title":"inlabru 2.1.8","text":"Update default options Prevent int.polygon integrating outside mesh domain, generally robust integration scheme construction. Fix bru() like() parameter logic. (Thanks Peter Vesk bug example)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-217","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.7","title":"inlabru 2.1.7","text":"Added NEWS.md file track changes package. Added inla methods predict() generate() convert inla output bru objects calling bru prediction posterior sample generator. Added protection examples requiring optional packages Fix sample.lgcp output formatting, extended CRS support, efficient sampling algorithm Avoid dense matrices effect mapping","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-214","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.4","title":"inlabru 2.1.4","text":"iinla() tracks convergence fixed random effects","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-213","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.3","title":"inlabru 2.1.3","text":"CRAN release: 2018-02-11 Added matrix geom gg.matrix() Fixed CRAN test issues","code":""}]
