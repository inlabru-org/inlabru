[{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - An example in one dimension","text":"vignette going see fit SPDE one-dimensional point data, .e. data consist points things located, number points area.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in one dimension","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2) library(fmesher)"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - An example in one dimension","text":"Take look point (frequency) data","code":"data(Poisson2_1D, package = \"inlabru\") ggplot(pts2) +   geom_histogram(aes(x = x),     binwidth = 55 / 20,     boundary = 0, fill = NA, color = \"black\"   ) +   geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +   coord_fixed(ratio = 1)"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"fiting-the-model","dir":"Articles","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in one dimension","text":"Build 1D mesh: Make latent components 1D SPDE model, using integrate--zero constraint better identifiability: want fit actual points, inlabru functions used bru() like(..., family = \"cp\"). special case also shortcut function lgcp() (‘Log Gaussian Cox Process’), doesn’t support features. standard way specifying function space integration via domain argument. , formula = x ~ . means observed points x, . denotes linear predictor sum latent components.","code":"x <- seq(0, 55, length.out = 50) mesh1D <- fm_mesh_1d(x, boundary = \"free\") matern <- inla.spde2.pcmatern(mesh1D,   prior.range = c(150, 0.75),   prior.sigma = c(0.1, 0.75),   constr = TRUE ) comp <- ~ spde1D(x, model = matern) + Intercept(1) fit.spde <- bru(   comp,   like(x ~ ., family = \"cp\", data = pts2, domain = list(x = mesh1D)) ) ## Equivalent call for this particular example: # fit.spde <- lgcp(comp, formula = x ~ ., data = pts2, domain = list(x = mesh1D))"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"spde-parameters","dir":"Articles","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in one dimension","text":"can look posterior distributions parameters SPDE using function spde.posterior. returns x y values plot posterior PDF data frame, can printed using plot function. see PDF range parameter, example:  Look help file spde.posterior plot posterior log SPDE range parameter, SPDE variance /log variance, Matern covariance function. Make sure understand difference plotted range variance parameters, covariance function (involves parameters). can get feel sensitivity priors specifying different priors looking posterior plots.","code":"post.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"range\") plot(post.range) post.log.range <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.range\") plot(post.log.range) # SOLUTION post.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"variance\") plot(post.variance) # SOLUTION post.log.variance <- spde.posterior(fit.spde, name = \"spde1D\", what = \"log.variance\") plot(post.log.variance) # SOLUTION post.matcorr <- spde.posterior(fit.spde, name = \"spde1D\", what = \"matern.correlation\") plot(post.matcorr) # SOLUTION"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"predicting-intensity","dir":"Articles","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in one dimension","text":"can also now predict scale want. example, predict ‘response’ scale (.e. intensity function λ(s)\\lambda(s)), call predict thus: predict linear predictor scale (.e. log intensity, log(λ(s))\\log(\\lambda(s))), call predict thus: ’s plot prediction 95% credible interval:  compare underlying intensity function generated data? function lambda2_1D( ) dataset Poission2_1D calculates true intensity used simulating data. order plot , make data frame x- y-coordinates giving true intensity function, λ(s)\\lambda(s). use lots x-values get nice smooth plot (150 values). Plot fitted true intensity functions:","code":"predf <- data.frame(x = seq(0, 55, by = 1)) # Set up a data frame of explanatory values at which to predict pred_spde <- predict(fit.spde, predf, ~ exp(spde1D + Intercept), n.samples = 1000) pred_spde_lp <- predict(fit.spde, predf, ~ spde1D + Intercept, n.samples = 1000) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   xlab(\"x\") + ylab(\"Intensity\") xs <- seq(0, 55, length = 150) true.lambda <- data.frame(x = xs, y = lambda2_1D(xs)) plot(pred_spde, color = \"red\") +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = true.lambda, aes(x, y)) +   xlab(\"x\") + ylab(\"Intensity\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"goodness-of-fit","dir":"Articles","previous_headings":"","what":"Goodness-of-Fit","title":"LGCPs - An example in one dimension","text":"can look goodness--fit mode using inlabru function bincount( ), plots 95% credible intervals specified set bins along x-axis together observed count bin: credible intervals shown red rectangles, mean fitted value short horizontal blue line, observed data black points:","code":"bc <- bincount(   result = fit.spde,   observations = pts2,   breaks = seq(0, max(pts2), length = 12),   predictor = x ~ exp(spde1D + Intercept) )  attributes(bc)$ggp"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"estimating-abundance","dir":"Articles","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in one dimension","text":"Abundance integral intensity space. estimate integrating predicted intensity x. Integration done adding intensity locations x weighted particular weight. locations x weights constructed using fm_int function can look abundance estimate typing mean posterior mean abundance. sd estimated standard error posterior abundance. cv estimated coefficient variation (stander error divided mean). q0.025 q0.975 95% credible interval bounds. q0.5 posterior median abundance quite simple! posterior abundance takes account variance due us knowing parameters intensity function. neglects variance number point locations, given intensity function. include need modify predict( ) follows: calculates statistics calculated Lambda, evey value N 50 250, rather posterior mean N alone: compute 95% prediction interval median follows Compare Lambda Nest plotting: First calculate posterior conditional mean Lambda plot unconditional posterior  differences make sense ?","code":"ips <- fm_int(mesh1D, name = \"x\") head(ips) #>          x    weight .block #> 1 0.000000 0.1870748      1 #> 2 1.122449 0.3741497      1 #> 3 2.244898 0.3741497      1 #> 4 3.367347 0.3741497      1 #> 5 4.489796 0.3741497      1 #> 6 5.612245 0.3741497      1 Lambda <- predict(fit.spde, ips, ~ sum(weight * exp(spde1D + Intercept))) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err mean.mc_std_err #> 1 128.6751 10.15912 112.0583 127.8869 150.7013 127.8869     0.7492933         1.16577 Nest <- predict(   fit.spde, ips,   ~ data.frame(     N = 50:250,     dpois = dpois(50:250,       lambda = sum(weight * exp(spde1D + Intercept))     )   ) ) Nest[Nest$N %in% 100:105, ] #>      N        mean          sd       q0.025         q0.5     q0.975       median sd.mc_std_err #> 51 100 0.003686948 0.005141496 2.721501e-06 0.0009304942 0.01709029 0.0009304942  0.0005456030 #> 52 101 0.004313477 0.005808735 4.052945e-06 0.0011974142 0.01921981 0.0011974142  0.0005829082 #> 53 102 0.005006183 0.006504685 5.976602e-06 0.0015257959 0.02140276 0.0015257959  0.0006155832 #> 54 103 0.005764708 0.007220572 8.727725e-06 0.0019253585 0.02360225 0.0019253585  0.0006425203 #> 55 104 0.006587375 0.007946259 1.262269e-05 0.0024061947 0.02577752 0.0024061947  0.0006627366 #> 56 105 0.007471124 0.008670445 1.808202e-05 0.0029784762 0.02788514 0.0029784762  0.0006754334 #>    mean.mc_std_err #> 51    0.0006232702 #> 52    0.0006974551 #> 53    0.0007735851 #> 54    0.0008505613 #> 55    0.0009271732 #> 56    0.0010021312 inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 101.5053 129.0878 162.3018 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_point(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err     ),     fill = \"grey\",     alpha = 0.5   ) +   geom_point(aes(x = N, y = plugin_estimate, colour = \"Plugin\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\")) +   ylab(\"pmf\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/1d_lgcp.html","id":"comparison-to-gam-fit","dir":"Articles","previous_headings":"","what":"Comparison to GAM fit","title":"LGCPs - An example in one dimension","text":"Now refit GAM count data Poisson2_1D plot estimated intensity function GAM fit, together LGCP fitted true intensity. get plot like (thick line true intensity, thin solid line inlabru fit, dashed line GAM fit:","code":"cd2 <- countdata2 fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd2) dat4pred <- data.frame(x = seq(0, 55, length = 100), exposure = rep(cd2$exposure[1], 100)) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # SOLUTION plot(pred_spde) +   geom_point(data = pts2, aes(x = x), y = 0, pch = \"|\", cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure, colour = \"gam()\"), lty = 2) +   geom_line(data = true.lambda, aes(x, y, colour = \"True\"), lwd = 1.5) +   geom_point(data = cd2, aes(x, y = count / exposure)) +   ylab(\"Intensity\") + xlab(\"x\") # SOLUTION"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - An example in two dimensions","text":"vignette going working dataset obtained R package spatstat. set two-dimensional LGCP estimate Gorilla abundance.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in two dimensions","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - An example in two dimensions","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : dataset list containing number R objects, including locations nests, boundary survey area INLA mesh - see help(gorillas) details. Extract objects need list, objects, don’t keep typing ‘gorillas_sf$’, optionally load covariates disk: Plot points (nests).","code":"data(gorillas_sf, package = \"inlabru\") nests <- gorillas_sf$nests mesh <- gorillas_sf$mesh boundary <- gorillas_sf$boundary gcov <- gorillas_sf_gcov() ggplot() +   gg(mesh) +   geom_sf(data = boundary, alpha = 0.1, fill = \"blue\") +   geom_sf(data = nests) +   ggtitle(\"Points\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"LGCPs - An example in two dimensions","text":"Fit LGCP model locations gorilla nests, predict survey region, produce plot estimated density - look like plot shown . steps specifying, fitting predicting : Specify model, comprising (2D models) geometry left ~ SPDE + Intercept(1) right. Please use SPDE prior specification stated . Call lgcp( ), passing (2D models) model components, sf containing observed points sf defining survey boundary using samplers argument. Call predict( ), passing fitted model 2., locations predict appropriate predictor specification. locations predict can sf covering mesh, obtained calling fm_pixels(mesh, format = \"sf\").","code":"matern <- inla.spde2.pcmatern(   mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.05, 0.01) )  cmp <- geometry ~   mySmooth(geometry, model = matern) +   Intercept(1)  fit <- lgcp(   cmp,   data = nests,   samplers = boundary,   domain = list(geometry = mesh) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"predicting-intensity","dir":"Articles","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in two dimensions","text":"get plot like . gg method sf point data takes optional argument geom = \"tile\" converts plot type used lattice data.  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object lambda).","code":"pred <- predict(   fit,   fm_pixels(mesh, mask = boundary),   ~ data.frame(     lambda = exp(mySmooth + Intercept),     loglambda = mySmooth + Intercept   ) )  pl1 <- ggplot() +   gg(pred$lambda, geom = \"tile\") +   geom_sf(data = boundary, alpha = 0.1) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Response Scale)\")  pl2 <- ggplot() +   gg(pred$loglambda, geom = \"tile\") +   geom_sf(data = boundary, alpha = 0.1) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Linear Predictor Scale)\")  multiplot(pl1, pl2, cols = 2) ggplot() +   gg(     tidyr::pivot_longer(pred$lambda,       c(q0.025, q0.5, q0.975),       names_to = \"quantile\", values_to = \"value\"     ),     aes(fill = value),     geom = \"tile\"   ) +   facet_wrap(~quantile)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"spde-parameters","dir":"Articles","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in two dimensions","text":"Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :","code":"int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp.html","id":"estimating-abundance","dir":"Articles","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in two dimensions","text":"Finally, estimate abundance using predict function. first step need estimate integrated lambda. integration weight values contained fm_int() output. Given generous interval boundaries (500, 800) lambda can estimate posterior abundance distribution via Get quantiles via … mean via plot posteriors:  true number nests 647; mean median posterior distribution abundance close done anything wrong!","code":"Lambda <- predict(   fit,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 675.7464 29.04379 617.9298 674.1335 733.8534 674.1335      2.070766 #>   mean.mc_std_err #> 1        3.318532 Nest <- predict(   fit,   fm_int(mesh, boundary),   ~ data.frame(     N = 500:800,     dpois(500:800,       lambda = sum(weight * exp(mySmooth + Intercept))     )   ) ) inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 598.3876 675.1083 753.3079 inla.emarginal(identity, marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 675.3602 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - Spatial covariates","text":"going fit spatial models gorilla data, using factor continuous explanatory variables practical. fit one using factor variable vegetation, using continuous covariate elevation (Jump bottom practical want start gently 1D example!)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - Spatial covariates","text":"dataset list (see help(gorillas_sf) details. Extract objects need list, convenience:","code":"data(gorillas_sf, package = \"inlabru\") nests <- gorillas_sf$nests mesh <- gorillas_sf$mesh boundary <- gorillas_sf$boundary gcov <- gorillas_sf_gcov()"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"factor-covariates","dir":"Articles","previous_headings":"","what":"Factor covariates","title":"LGCPs - Spatial covariates","text":"Look vegetation type, nests boundary:  , mesh:","code":"ggplot() +   gg(gcov$vegetation) +   gg(boundary, alpha = 0.2) +   gg(nests, color = \"white\", cex = 0.5) ggplot() +   gg(gcov$vegetation) +   gg(mesh) +   gg(boundary, alpha = 0.2) +   gg(nests, color = \"white\", cex = 0.5)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-only","dir":"Articles","previous_headings":"Factor covariates","what":"A model with vegetation type only","title":"LGCPs - Spatial covariates","text":"seems vegetation type might good predictor nearly nests fall vegetation type Primary. construct model vegetation type fixed effect. , need tell ‘lgcp’ find vegetation type point space, creating model components fixed effect call vegetation (call anything), follows: Notes: * need tell ‘lgcp’ factor fixed effect, model=\"factor_full\", giving one coefficient factor level. * need careful overparameterisation using factors. Unlike regression models like ‘lm()’, ‘glm()’ ‘gam()’, ‘lgcp()’, inlabru automatically remove first level absorb intercept. Instead, can either use model=\"factor_full\" without intercept, model=\"factor_contrast\", remove first level. Fit model usual: Predict intensity, plot median intensity surface. (older versions, predicting takes time vegetation values outside mesh ‘inlabru’ needed predict first. Since v2.0.0, vegetation pre-extended.) predict function inlabru takes data argument sf object object supported predictor evaluation code (non-geographical data, typically data.frame). can use inlabru function pixels generate sf object points within boundary, using mask argument, shown .  surprisingly, given nests Primary vegetation, high density vegetation. substantial patches predicted high density nests, areas predicted low density nests. estimated abundance (really 647 nests ):","code":"comp1 <- geometry ~ vegetation(gcov$vegetation, model = \"factor_full\") - 1 comp1alt <- geometry ~ vegetation(gcov$vegetation, model = \"factor_contrast\") + Intercept(1) fit1 <- lgcp(comp1, nests, samplers = boundary, domain = list(geometry = mesh)) pred.df <- fm_pixels(mesh, mask = boundary) int1 <- predict(fit1, pred.df, ~ exp(vegetation))  ggplot() +   gg(int1, geom = \"tile\") + # gg() with sf points and geom = \"tile\" plots a raster   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") ips <- fm_int(mesh, boundary) Lambda1 <- predict(fit1, ips, ~ sum(weight * exp(vegetation))) Lambda1 #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 644.2294 22.66789 605.1315 641.0573 694.4843 641.0573      1.614679 #>   mean.mc_std_err #> 1        2.589724"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"a-model-with-vegetation-type-and-a-spde-type-smoother","dir":"Articles","previous_headings":"Factor covariates","what":"A model with vegetation type and a SPDE type smoother","title":"LGCPs - Spatial covariates","text":"Lets try explain pattern nest distribution captured vegetation covariate, using SPDE: plot posterior median intensity surface  … expected integrated intensity (mean abundance) Look contributions linear predictor SPDE vegetation: function scale_fill_gradientn sets scale plot legend. set span range three linear predictor components plotted (medians plotted default).","code":"pcmatern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.1, 0.01) )  comp2 <- geometry ~   -1 +   vegetation(gcov$vegetation, model = \"factor_full\") +   mySmooth(geometry, model = pcmatern) fit2 <- lgcp(comp2, nests, samplers = boundary, domain = list(geometry = mesh)) int2 <- predict(fit2, pred.df, ~ exp(mySmooth + vegetation), n.samples = 1000)  ggplot() +   gg(int2, aes(fill = q0.5), geom = \"tile\") +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests) Lambda2 <- predict(   fit2,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + vegetation)) ) Lambda2 #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 680.1226 28.12016 628.6774 679.6952 737.5365 679.6952      1.976923 #>   mean.mc_std_err #> 1          3.2074 lp2 <- predict(fit2, pred.df, ~ list(   smooth_veg = mySmooth + vegetation,   smooth = mySmooth,   veg = vegetation )) lprange <- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.lp2 <- ggplot() +   gg(lp2$smooth_veg, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth + vegetation\")  plot.lp2.spde <- ggplot() +   gg(lp2$smooth, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"mySmooth\")  plot.lp2.veg <- ggplot() +   gg(lp2$veg, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"vegetation\")  multiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, cols = 3)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"a-model-with-spde-only","dir":"Articles","previous_headings":"Factor covariates","what":"A model with SPDE only","title":"LGCPs - Spatial covariates","text":"need vegetation ? Fit model SPDE + Intercept, choose models basis DIC, using ‘deltaIC()’.  NOTE: behaviour DIC currently bit unclear, investigated. WAIC related leave-one-cross-validation, appropriate use current current LGCP likelihood implementation. Classic mode: Experimental mode:","code":"comp3 <- geometry ~ mySmooth(geometry, model = pcmatern) + Intercept(1) fit3 <- lgcp(comp3,   data = nests,   samplers = boundary,   domain = list(geometry = mesh) ) int3 <- predict(fit3, pred.df, ~ exp(mySmooth + Intercept))  ggplot() +   gg(int3, geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests) Lambda3 <- predict(   fit3,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda3 #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 675.5626 28.12581 624.2491 675.2428 730.8525 675.2428      1.987928 #>   mean.mc_std_err #> 1        3.210166 knitr::kable(deltaIC(fit1, fit2, fit3, criterion = c(\"DIC\")))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"cv-and-spde-parameters-for-model-2","dir":"Articles","previous_headings":"Factor covariates","what":"CV and SPDE parameters for Model 2","title":"LGCPs - Spatial covariates","text":"going Model fit2. Lets look spatial distribution coefficient variation  Plot vegetation “fixed effect” posteriors. First get names - $marginals.random$vegetation fitted object, contains fixed effect marginal distribution data  Use spde.posterior( ) obtain plot SPDE parameter posteriors Matern correlation covariance functions model.","code":"ggplot() +   gg(int2, aes(fill = sd / mean), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests) flist <- vector(\"list\", NROW(fit2$summary.random$vegetation)) for (i in seq_along(flist)) flist[[i]] <- plot(fit2, \"vegetation\", index = i) multiplot(plotlist = flist, cols = 3) spde.range <- spde.posterior(fit2, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit2, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit2, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"continuous-covariates","dir":"Articles","previous_headings":"","what":"Continuous covariates","title":"LGCPs - Spatial covariates","text":"Now lets try model elevation (continuous) explanatory variable. (First centre elevations stable fitting.)  elevation variable class ‘SpatRaster’, can handled way vegetation covariate, automatic evaluation via eval_spatial() method. However, since cases data may stored differently, methods needed access stored values, ’s post-processing done. cases, can define function knows evaluate covariate arbitrary points survey region, call function component definition. method eval_spatial() method handles automatically, supports terra SpatRaster sf geometry points objects, mismatching coordinate systems well. following evaluator example function, add infilling missing values post-processing step. brevity going consider models elevation , elevation SPDE, SPDE . just fit one elevation SPDE. create model pass lgcp thus: Note elevation effect defined. alternatively use terra grid object directly (causing inlabru automatically call eval_spatial()), like vegetation case: specified like whereas special function method specify covariate like : applications can use automatic method, special function method included example handle complex cases. also now include intercept term model. model fitted usual way: Summary model selection Predict plot density  Now look elevation SPDE effects space. Leave Intercept swamps spatial effects elevation SPDE plots interested comparing effects elevation SPDE. First need predict linear predictor scale. code , similar used vegetation factor variable, produces plots want.  might also want look posteriors fixed effects SPDE. Adapt code used vegetation factor .  Plot SPDE parameter posteriors Matern correlation covariance functions model.   Also estimate abundance. data.frame second call leads inclusion N prediction object, easier plotting. Plot way previous practicals","code":"elev <- gcov$elevation elev <- elev - mean(terra::values(elev), na.rm = TRUE)  ggplot() +   gg(elev, geom = \"tile\") +   gg(boundary, alpha = 0) # Note: this method is usually not needed; the automatic invocation of # `eval_spatial()` method by the component input evaluator is usually sufficient. f.elev <- function(where) {   # Extract the values   v <- eval_spatial(elev, where, layer = \"elevation\")   # Fill in missing values; this example would work for SpatialPixelsDataFrame data   # if (any(is.na(v))) {   #   v <- bru_fill_missing(elev, where, v)   # }   return(v) } matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.1, 0.01) )  ecomp <- geometry ~ elev(f.elev(.data.), model = \"linear\") +   mySmooth(geometry, model = matern) + Intercept(1) elev(elev, model = \"factor_full\") elev(f.elev(.data.), model = \"linear\") efit <- lgcp(ecomp, nests, samplers = boundary, domain = list(geometry = mesh)) summary(efit) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> elev: main = linear(f.elev(.data.)), group = exchangeable(1L), replicate = iid(1L), NULL #> mySmooth: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'cp' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ . #>     Used components: effects[elev, mySmooth, Intercept], latent[] #> Time used: #>     Pre = 0.358, Running = 5.05, Post = 0.314, Total = 5.73  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode kld #> elev      0.004 0.001      0.002    0.004      0.006 0.004   0 #> Intercept 1.125 0.478      0.151    1.136      2.037 1.136   0 #>  #> Random effects: #>   Name     Model #>     mySmooth SPDE2 model #>  #> Model hyperparameters: #>                    mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for mySmooth 1.76 0.217      1.376     1.75       2.23 1.714 #> Stdev for mySmooth 1.00 0.085      0.848     1.00       1.18 0.995 #>  #> Deviance Information Criterion (DIC) ...............: 521.26 #> Deviance Information Criterion (DIC, saturated) ....: 520.43 #> Effective number of parameters .....................: -825.43 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1604.04 #> Effective number of parameters .................: 153.51 #>  #> Marginal log-Likelihood:  -1254.95  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') deltaIC(fit1, fit2, fit3, efit) #>   Model       DIC Delta.DIC #> 1  fit1 -562.5418     0.000 #> 2  efit  521.2574  1083.799 #> 3  fit3  525.1865  1087.728 #> 4  fit2  619.0161  1181.558 e.int <- predict(efit, pred.df, ~ exp(mySmooth + elev + Intercept)) e.int.log <- predict(efit, pred.df, ~ (mySmooth + elev + Intercept))  p1 <- ggplot() +   gg(e.int, aes(fill = log(sd)), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") p2 <- ggplot() +   gg(e.int.log, aes(fill = exp(mean + sd^2 / 2)), geom = \"tile\") +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\") library(patchwork) p1 | p2 e.lp <- predict(   efit,   pred.df,   ~ list(     smooth_elev = mySmooth + elev,     elev = elev,     smooth = mySmooth   ) ) lprange <- range(e.lp$smooth_elev$mean, e.lp$elev$mean, e.lp$smooth$mean)  library(RColorBrewer) csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)  plot.e.lp <- ggplot() +   gg(e.lp$smooth_elev, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE + elevation\")  plot.e.lp.spde <- ggplot() +   gg(e.lp$smooth, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"SPDE\")  plot.e.lp.elev <- ggplot() +   gg(e.lp$elev, mask = boundary, geom = \"tile\") +   csc +   theme(legend.position = \"bottom\") +   gg(boundary, alpha = 0) +   ggtitle(\"elevation\")  multiplot(plot.e.lp,   plot.e.lp.spde,   plot.e.lp.elev,   cols = 3 ) LambdaE <- predict(   efit,   fm_int(mesh, boundary),   ~ sum(weight * exp(Intercept + elev + mySmooth)) ) LambdaE #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 672.6752 33.57636 604.0696 672.6776 735.0576 672.6776      2.214602 #>   mean.mc_std_err #> 1        3.800556 flist <- vector(\"list\", NROW(efit$summary.fixed)) for (i in seq_along(flist)) {   flist[[i]] <- plot(efit, rownames(efit$summary.fixed)[i]) } multiplot(plotlist = flist, cols = 2) spde.range <- spde.posterior(efit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(efit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot) corplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(efit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot) Lambda <- predict(   efit, fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + elev + Intercept)) ) Lambda #>       mean       sd  q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 676.6267 27.16777 626.255 678.0613 727.7798 678.0613      1.654414 #>   mean.mc_std_err #> 1         3.04766  Nest.e <- predict(   efit,   fm_int(mesh, boundary),   ~ data.frame(     N = 200:1000,     density = dpois(200:1000,       lambda = sum(weight * exp(mySmooth + elev + Intercept))     )   ),   n.samples = 2000 ) Nest.e$plugin_estimate <- dpois(Nest.e$N, lambda = Lambda$median) ggplot(data = Nest.e) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"non-spatial-evaluation-of-the-covariate-effect","dir":"Articles","previous_headings":"Continuous covariates","what":"Non-spatial evaluation of the covariate effect","title":"LGCPs - Spatial covariates","text":"previous examples posterior prediction focused spatial prediction. inlabru version 2.2.8, feature available overriding component input value specification component definition. model component can evaluated directly, arbitrary values functions named adding suffix _eval end component name predictor expression, disabling normal component evaluation components include = character(0) (since ’re bypassing normal input elev component, supplying data components). version 2.8.0, inlabru attempts automatically detect model components used expression, include argument can left entirely. Since elevation effect model linear, resulting plot isn’t interesting, method can applied non-linear effects well, combined general R expressions.","code":"elev.pred <- predict(   efit,   data.frame(elevation = seq(0, 100, length.out = 1000)),   formula = ~ elev_eval(elevation)   # include = character(0) # Not needed from version 2.8.0 )  ggplot(elev.pred) +   geom_line(aes(elevation, mean)) +   geom_ribbon(     aes(elevation,       ymin = q0.025,       ymax = q0.975     ),     alpha = 0.2   ) +   geom_ribbon(     aes(elevation,       ymin = mean - 1 * sd,       ymax = mean + 1 * sd     ),     alpha = 0.2   )"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html","id":"a-1d-example","dir":"Articles","previous_headings":"","what":"A 1D Example","title":"LGCPs - Spatial covariates","text":"Try fitting 1-dimensional model point data inlabru dataset Poisson2_1D. comes covariate function called cov2_1D. Try reproduce plot (used lectures) showing effects Intercept + z SPDE. (may find helpful build model fitted previous practical, adding covariate model specification.)","code":"data(Poisson2_1D) ss <- seq(0, 55, length = 200) z <- cov2_1D(ss) x <- seq(1, 55, length = 100) mesh <- fm_mesh_1d(x, degree = 1)  comp <- x ~   beta_z(cov2_1D(x), model = \"linear\") +   spde1D(x, model = inla.spde2.matern(mesh)) +   Intercept(1)  fitcov1D <- lgcp(comp, pts2, domain = list(x = mesh)) pr.df <- data.frame(x = x) prcov1D <- predict(   fitcov1D,   pr.df,   ~ list(     total = exp(beta_z + spde1D + Intercept),     fx = exp(beta_z + Intercept),     spde = exp(spde1D)   ) )  ggplot() +   gg(prcov1D$total, color = \"red\") +   geom_line(aes(x = prcov1D$spde$x, y = prcov1D$spde$median), col = \"blue\", lwd = 1.25) +   geom_line(aes(x = prcov1D$fx$x, y = prcov1D$fx$median), col = \"green\", lwd = 1.25) +   geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +   xlab(expression(bold(s))) +   ylab(expression(hat(lambda)(bold(s)) ~ ~\"and its components\")) +   annotate(geom = \"text\", x = 40, y = 6, label = \"Intensity\", color = \"red\") +   annotate(geom = \"text\", x = 40, y = 5.5, label = \"z-effect\", color = \"green\") +   annotate(geom = \"text\", x = 40, y = 5, label = \"SPDE\", color = \"blue\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - Distance sampling","text":"’re going estimate distribution abundance line transect survey dolphins Gulf Mexico. data also available R package dsm (go name mexdolphins). inlabru data called mexdolphin sp format, mexdolphin_sf sf format.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - Distance sampling","text":"Load libraries","code":"library(inlabru) library(fmesher) library(INLA) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - Distance sampling","text":"’ll start loading data, renaming , extracting mesh (convenience). Plot data (initial code just get rid tick marks, desired)","code":"mexdolphin <- mexdolphin_sf mesh <- mexdolphin$mesh noyticks <- theme(   axis.text.y = element_blank(),   axis.ticks = element_blank() )  noxticks <- theme(   axis.text.x = element_blank(),   axis.ticks = element_blank() )  ggplot() +   gg(mexdolphin$ppoly) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) +   coord_sf(datum = fm_crs(mexdolphin$ppoly))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"spatial-model-with-a-half-normal-detection-function","dir":"Articles","previous_headings":"","what":"Spatial model with a half-normal detection function","title":"LGCPs - Distance sampling","text":"samplers dataset lines, polygons, need tell inlabru strip half-width, W, case data 8. start plotting distances histogram frequencies distance intervals:  need define half-normal detection probability function. must take distance first argument linear predictor sigma parameter second: control prior distribution sigma parameter, use transformation mapper converts N(0,1)N(0, 1) latent variable exponentially distributed variable expectation 8 (somewhat arbitrary value, motivated maximum observation distance W): Specify fit SPDE model data using half-normal detection function form. need define (Matérn) covariance function SPDE: , range probabilistically limited P(range≤50)=0.01P(\\text{range}\\leq 50)=0.01 standard deviation spatial field limited P(sd≤2)=0.01P(\\text{sd}\\leq 2)=0.01. need now separately define components model (SPDE, Intercept detection function parameter sigma) marginal argument sigma component specifies transformation function taking N(0,1) Exponential(1/8). formula, describes components combined form linear predictor (remembering need offset due unknown direction detections!): version 2.9.0.9004, less compact approach used, applying transformation N(0,1) Exponential(1/8) directly predictor expression, requiring corresponding adjustments later predict() calls, etc: fit model, passing components formula (previously formula constructed invisibly inlabru), specify integration domains spatial distance dimensions: Look SPDE parameter posteriors   Predict spatial intensity, plot :  Predict detection function plot , generate plot like one . , make sure doesn’t try evaluate effects components can’t evaluated using given input data. version 2.8.0, inlabru automatically detects components involved. See ?predict.bru information. average detection probability within maximum detection distance estimated 0.7025982. can look posterior expected number dolphins usual: including randomness expected number. case, turns need lots posterior samples, e.g. 2,000 smooth Monte Carlo error posterior, takes little compute:","code":"W <- 8 ggplot(mexdolphin$points) +   geom_histogram(aes(x = distance),     breaks = seq(0, W, length.out = 9),     boundary = 0, fill = NA, color = \"black\"   ) +   geom_point(aes(x = distance), y = 0, pch = \"|\", cex = 4) hn <- function(distance, sigma) {   exp(-0.5 * (distance / sigma)^2) } bru_mapper_marginal(qexp, pexp, dexp, rate = 1 / 8) matern <- inla.spde2.pcmatern(mexdolphin$mesh,   prior.sigma = c(2, 0.01),   prior.range = c(50, 0.01) ) cmp <- ~ mySPDE(main = geometry, model = matern) +   sigma(1,     prec.linear = 1,     marginal = bru_mapper_marginal(qexp, pexp, dexp, rate = 1 / 8)   ) +   Intercept(1) form <- geometry + distance ~ mySPDE +   log(hn(distance, sigma)) +   Intercept + log(2) # sigma_transf <- function(x) { #   bru_forward_transformation(qexp, x, rate = 1 / 8) # } # cmp <- ~ mySPDE(main = geometry, model = matern) + #   sigma_theta(1, prec.linear = 1) + #   Intercept(1) # form <- geometry + distance ~ mySPDE + #   log(hn(distance, sigma_transf(sigma_theta))) + #   Intercept + log(2) fit <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     geometry = mesh,     distance = fm_mesh_1d(seq(0, 8, length.out = 30))   ),   formula = form ) spde.range <- spde.posterior(fit, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pxl <- fm_pixels(mesh, dims = c(200, 100), mask = mexdolphin$ppoly) pr.int <- predict(fit, pxl, ~ exp(mySPDE + Intercept)) ggplot() +   gg(pr.int, geom = \"tile\") +   gg(mexdolphin$ppoly, linewidth = 1, alpha = 0) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) distdf <- data.frame(distance = seq(0, 8, length.out = 100)) dfun <- predict(fit, distdf, ~ hn(distance, sigma)) plot(dfun) predpts <- fm_int(mexdolphin$mesh, mexdolphin$ppoly) Lambda <- predict(fit, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda #>       mean       sd   q0.025    q0.5   q0.975  median sd.mc_std_err #> 1 247.2957 57.65961 164.4866 242.391 393.6306 242.391      4.654349 #>   mean.mc_std_err #> 1         6.69683 Ns <- seq(50, 450, by = 1) Nest <- predict(fit, predpts,   ~ data.frame(     N = Ns,     density = dpois(       Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest <- dplyr::bind_rows(   cbind(Nest, Method = \"Posterior\"),   data.frame(     N = Nest$N,     mean = dpois(Nest$N, lambda = Lambda$mean),     mean.mc_std_err = 0,     Method = \"Plugin\"   ) ) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = Method)) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err,       fill = Method,     ),     alpha = 0.2   ) +   geom_line(aes(x = N, y = mean, colour = Method)) +   ylab(\"Probability mass function\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"hazard-rate-detection-function","dir":"Articles","previous_headings":"","what":"Hazard-rate Detection Function","title":"LGCPs - Distance sampling","text":"Try , use hazard-rate detection function model, prior sigma parameter half-Normal model (parameters aren’t always comparable, example ’s reasonable choice): Solution: Plots:","code":"hr <- function(distance, sigma) {   1 - exp(-(distance / sigma)^-1) } formula1 <- geometry + distance ~ mySPDE +   log(hr(distance, sigma)) +   Intercept + log(2)  fit1 <- lgcp(   components = cmp,   mexdolphin$points,   samplers = mexdolphin$samplers,   domain = list(     geometry = mesh,     distance = fm_mesh_1d(seq(0, 8, length.out = 30))   ),   formula = formula1 ) spde.range <- spde.posterior(fit1, \"mySPDE\", what = \"range\") plot(spde.range) spde.logvar <- spde.posterior(fit1, \"mySPDE\", what = \"log.variance\") plot(spde.logvar) pr.int1 <- predict(fit1, pxl, ~ exp(mySPDE + Intercept))  ggplot() +   gg(pr.int1, geom = \"tile\") +   gg(mexdolphin$ppoly, linewidth = 1, alpha = 0) +   gg(mexdolphin$samplers, color = \"grey\") +   gg(mexdolphin$points, size = 0.2, alpha = 1) +   theme(legend.key.width = unit(x = 0.2, \"cm\"), legend.key.height = unit(x = 0.3, \"cm\")) +   theme(legend.text = element_text(size = 6)) distdf <- data.frame(distance = seq(0, 8, length.out = 100)) dfun1 <- predict(fit1, distdf, ~ hr(distance, sigma)) plot(dfun1) predpts <- fm_int(mexdolphin$mesh, mexdolphin$ppoly) Lambda1 <- predict(fit1, predpts, ~ sum(weight * exp(mySPDE + Intercept))) Lambda1 #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 284.8763 78.71156 162.6603 265.9718 456.8732 265.9718       5.31482 #>   mean.mc_std_err #> 1         8.93412 Ns <- seq(50, 650, by = 1) Nest1 <- predict(   fit1,   predpts,   ~ data.frame(     N = Ns,     density = dpois(       Ns,       lambda = sum(weight * exp(mySPDE + Intercept))     )   ),   n.samples = 2000 )  Nest1 <- dplyr::bind_rows(   cbind(Nest1, Method = \"Posterior\"),   data.frame(     N = Nest1$N,     mean = dpois(Nest1$N, lambda = Lambda1$mean),     mean.mc_std_err = 0,     Method = \"Plugin\"   ) )  ggplot(data = Nest1) +   geom_line(aes(x = N, y = mean, colour = Method)) +   geom_ribbon(     aes(       x = N,       ymin = mean - 2 * mean.mc_std_err,       ymax = mean + 2 * mean.mc_std_err,       fill = Method     ),     alpha = 0.2   ) +   geom_line(aes(x = N, y = mean, colour = Method)) +   ylab(\"Probability mass function\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"comparing-the-models","dir":"Articles","previous_headings":"","what":"Comparing the models","title":"LGCPs - Distance sampling","text":"Look goodness--fit two models distance dimension","code":"bc <- bincount(   result = fit,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length.out = 9),   predictor = distance ~ hn(distance, sigma) ) attributes(bc)$ggp bc1 <- bincount(   result = fit1,   observations = mexdolphin$points$distance,   breaks = seq(0, max(mexdolphin$points$distance), length.out = 9),   predictor = distance ~ hn(distance, sigma) ) attributes(bc1)$ggp"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_distancesampling.html","id":"fit-models-only-to-the-distance-sampling-data","dir":"Articles","previous_headings":"","what":"Fit Models only to the distance sampling data","title":"LGCPs - Distance sampling","text":"Half-normal first Hazard-rate next Plot lines histogram observations. First scale lines area histogram. Half-normal: Hazard-rate: Combine lines single object plotting Plot without 95% credible intervals  Plot 95% credible intervals (without taking count rescaling account)","code":"formula <- distance ~ log(hn(distance, sigma)) + Intercept cmp <- ~ sigma(1,   prec.linear = 1,   marginal = bru_mapper_marginal(qexp, pexp, dexp, rate = 1 / 8) ) +   Intercept(1) dfit <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = fm_mesh_1d(seq(0, 8, length.out = 30))),   formula = formula,   options = list(bru_initial = list(sigma = 1, Intercept = 3)) ) detfun <- predict(dfit, distdf, ~ hn(distance, sigma)) formula1 <- distance ~ log(hr(distance, sigma)) + Intercept cmp <- ~ sigma(1,   prec.linear = 1,   marginal = bru_mapper_marginal(qexp, pexp, dexp, rate = 1 / 8) ) +   Intercept(1) dfit1 <- lgcp(   components = cmp,   mexdolphin$points,   domain = list(distance = fm_mesh_1d(seq(0, 8, length.out = 30))),   formula = formula1 ) detfun1 <- predict(dfit1, distdf, ~ hr(distance, sigma)) hnline <- data.frame(distance = detfun$distance, p = detfun$mean, lower = detfun$q0.025, upper = detfun$q0.975) wts <- diff(hnline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hnarea <- sum(wts * hnline$p) n <- length(mexdolphin$points$distance) scale <- n / hnarea hnline$En <- hnline$p * scale hnline$En.lower <- hnline$lower * scale hnline$En.upper <- hnline$upper * scale hrline <- data.frame(distance = detfun1$distance, p = detfun1$mean, lower = detfun1$q0.025, upper = detfun1$q0.975) wts <- diff(hrline$distance) wts[1] <- wts[1] / 2 wts <- c(wts, wts[1]) hrarea <- sum(wts * hrline$p) n <- length(mexdolphin$points$distance) scale <- n / hrarea hrline$En <- hrline$p * scale hrline$En.lower <- hrline$lower * scale hrline$En.upper <- hrline$upper * scale dlines <- rbind(   cbind(hnline, model = \"Half-normal\"),   cbind(hrline, model = \"Hazard-rate\") ) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length.out = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) ggplot(data.frame(mexdolphin$points)) +   geom_histogram(aes(x = distance), breaks = seq(0, 8, length.out = 9), alpha = 0.3) +   geom_point(aes(x = distance), y = 0.2, shape = \"|\", size = 3) +   geom_line(data = dlines, aes(x = distance, y = En, group = model, col = model)) +   geom_ribbon(     data = dlines, aes(x = distance, ymin = En.lower, ymax = En.upper, group = model, col = model, fill = model),     alpha = 0.2, lty = 2   )"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - Multiple Likelihoods","text":"vignette going working inlabru’s ´gorillas_sf´ dataset originally obtained R package spatstat. data set contains two types gorillas nests marked either major minor. set multi-likelihood model nests creates two spatial LGCPs share common intercept employ different spatial smoothers.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - Multiple Likelihoods","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - Multiple Likelihoods","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : Plot nests visualize group membership (major/minor) color:","code":"data(gorillas_sf, package = \"inlabru\") ggplot() +   gg(gorillas_sf$mesh) +   gg(gorillas_sf$nests, aes(color = group)) +   gg(gorillas_sf$boundary, alpha = 0) +   ggtitle(\"Gorillas nests and group membership\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"fiting-the-model","dir":"Articles","previous_headings":"","what":"Fiting the model","title":"LGCPs - Multiple Likelihoods","text":"First, define components enter joint model. , intercept common LGCPs two different spatial smoothers, one nest group. Given components define linear predictor likelihoods. (Using “.” indicates pure additive model, one can use include/exclude options like() indicate components actively involved model.) Setting Cox process likelihoods easy example. nest types observed within window: … provide ´bru´ function.","code":"matern <- inla.spde2.pcmatern(gorillas_sf$mesh,   prior.range = c(0.1, 0.01),   prior.sigma = c(1, 0.01) )  cmp <- ~   Common(geometry, model = matern) +     Difference(geometry, model = matern) +     Intercept(1) fml.major <- geometry ~ Intercept + Common + Difference / 2 fml.minor <- geometry ~ Intercept + Common - Difference / 2 lik_minor <- like(\"cp\",   formula = fml.major,   data = gorillas_sf$nests[gorillas_sf$nests$group == \"major\", ],   samplers = gorillas_sf$boundary,   domain = list(geometry = gorillas_sf$mesh) ) lik_major <- like(\"cp\",   formula = fml.minor,   data = gorillas_sf$nests[gorillas_sf$nests$group == \"minor\", ],   samplers = gorillas_sf$boundary,   domain = list(geometry = gorillas_sf$mesh) ) jfit <- bru(cmp, lik_major, lik_minor,   options = list(     control.inla = list(int.strategy = \"eb\"),     bru_max_iter = 1   ) ) library(patchwork) pl.major <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"rerunning","dir":"Articles","previous_headings":"","what":"Rerunning","title":"LGCPs - Multiple Likelihoods","text":"Rerunning previous estimate starting point sometimes improves accuracy posterior distribution estimation.","code":"jfit0 <- jfit jfit <- bru_rerun(jfit) library(patchwork) pl.major <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\") summary(jfit0) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> Common: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Difference: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'cp' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ Intercept + Common - Difference/2 #>     Used components: effects[Common, Difference, Intercept], latent[] #>   Family: 'cp' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ Intercept + Common + Difference/2 #>     Used components: effects[Common, Difference, Intercept], latent[] #> Time used: #>     Pre = 0.638, Running = 19.2, Post = 0.169, Total = 20  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> Intercept -0.353 1.362     -3.022   -0.353      2.316 -0.353   0 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     2.937 0.573      2.003    2.872      4.249 2.730 #> Stdev for Common     2.046 0.332      1.488    2.014      2.792 1.941 #> Range for Difference 2.036 2.571      0.176    1.262      8.654 0.469 #> Stdev for Difference 0.159 0.084      0.038    0.144      0.355 0.105 #>  #> Deviance Information Criterion (DIC) ...............: 593.18 #> Deviance Information Criterion (DIC, saturated) ....: 591.54 #> Effective number of parameters .....................: -771.68 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1631.54 #> Effective number of parameters .................: 106.34 #>  #> Marginal log-Likelihood:  -1204.24  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') summary(jfit) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> Common: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Difference: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'cp' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ Intercept + Common - Difference/2 #>     Used components: effects[Common, Difference, Intercept], latent[] #>   Family: 'cp' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: geometry ~ Intercept + Common + Difference/2 #>     Used components: effects[Common, Difference, Intercept], latent[] #> Time used: #>     Pre = 0.49, Running = 9.66, Post = 0.143, Total = 10.3  #> Fixed effects: #>             mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> Intercept -0.355 1.368     -3.036   -0.355      2.326 -0.355   0 #>  #> Random effects: #>   Name     Model #>     Common SPDE2 model #>    Difference SPDE2 model #>  #> Model hyperparameters: #>                       mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for Common     2.935 0.573      1.998    2.871      4.244 2.734 #> Stdev for Common     2.047 0.332      1.486    2.016      2.791 1.946 #> Range for Difference 2.072 2.852      0.139    1.208      9.308 0.370 #> Stdev for Difference 0.159 0.093      0.036    0.139      0.389 0.096 #>  #> Deviance Information Criterion (DIC) ...............: 591.04 #> Deviance Information Criterion (DIC, saturated) ....: 589.39 #> Effective number of parameters .....................: -773.27 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1629.53 #> Effective number of parameters .................: 105.20 #>  #> Marginal log-Likelihood:  -1204.04  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_multilikelihood.html","id":"single-likelihood-version","dir":"Articles","previous_headings":"","what":"Single-likelihood version","title":"LGCPs - Multiple Likelihoods","text":"particular model, can also rewrite problem single point process product domain space group. versions <= 2.7.0, integration domain numeric, convert group variable 0/1 variable, group_major <- group == \"major\", also useful predictor expression: Plotting ratios exp(Common) exp(Difference) new fit old confirms results small numerical differences.","code":"fml.joint <- geometry + group_major ~ Intercept + Common + (group_major - 0.5) * Difference gorillas_sf$nests$group_major <- gorillas_sf$nests$group == \"major\" lik_joint <- like(\"cp\",   formula = fml.joint,   data = gorillas_sf$nests,   samplers = gorillas_sf$boundary,   domain = list(     geometry = gorillas_sf$mesh,     group_major = c(0, 1)   ) ) jfit_joint <- bru(cmp, lik_joint,   options = list(     control.inla = list(int.strategy = \"eb\") # Approximate for faster vignette   ) ) library(patchwork) pl.major <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit_joint$summary.random$Common$mean -       jfit$summary.random$Common$mean)   ) pl.minor <- ggplot() +   gg(gorillas_sf$mesh,     mask = gorillas_sf$boundary,     col = exp(jfit_joint$summary.random$Difference$mean -       jfit$summary.random$Difference$mean)   ) (pl.major + scale_fill_continuous(trans = \"log\")) +   (pl.minor + scale_fill_continuous(trans = \"log\")) &   theme(legend.position = \"right\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_plotsampling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - Plot sampling","text":"practical demonstrates use samplers argument lgcp, need use observed points sample plots survey region.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_plotsampling.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - Plot sampling","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_plotsampling.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - Plot sampling","text":"dataset list (see help(gorillas) details. Extract objects need list, convenience: gorillas data also contains plot sample subset covers 60% survey region.  plot survey, points within rectangles detected, also informative plot points (real plot survey , seen ).","code":"data(gorillas_sf, package = \"inlabru\") nests <- gorillas_sf$nests mesh <- gorillas_sf$mesh boundary <- gorillas_sf$boundary gcov <- gorillas_sf_gcov() sample <- gorillas_sf$plotsample plotdets <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   geom_text(aes(     label = sample$counts$count,     x = sf::st_coordinates(sample$counts)[, 1],     y = sf::st_coordinates(sample$counts)[, 2]   )) +   labs(x = \"Easting\", y = \"Northing\") plot(plotdets) plotwithall <- ggplot() +   gg(boundary) +   gg(sample$plots) +   gg(nests, pch = \"+\", cex = 4, color = \"blue\") +   geom_text(aes(     label = sample$counts$count,     x = sf::st_coordinates(sample$counts)[, 1],     y = sf::st_coordinates(sample$counts)[, 2]   )) +   gg(sample$nests, pch = \"+\", cex = 4, color = \"red\") +   labs(x = \"Easting\", y = \"Northing\") plot(plotwithall)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_plotsampling.html","id":"inference","dir":"Articles","previous_headings":"","what":"Inference","title":"LGCPs - Plot sampling","text":"observed nest locations SpatialPointsDataFrame sample$nests, plots SpatialPolygonsDataFrame sample$plots. , using following SPDE setup: Fit LGCP model SPDE data using samplers= argument function lgcp( ): Plot density surface fitted model  Estimate integrated intensity lambda. compute overall integrated intensity, representative imagined new realisation point process, conditional expectation takes actually observed nests account, recognising complete information surveyed plots. Fit model full dataset (points gorillas_sf$nests), get previous fit, kept . Plot intensity surface estimate integrated intensity plot look like :  values Lambda.empirical, Lambda, Lambda.close plot samples gave sufficient information overall prediction: Now, let’s compare results  understand reason differences posteriors abundance estimates?","code":"matern <- inla.spde2.pcmatern(mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.05, 0.01) ) cmp <- geometry ~ my.spde(geometry, model = matern)  fit <- lgcp(cmp, sample$nests, samplers = sample$plots, domain = list(geometry = mesh)) pxl <- fm_pixels(mesh, mask = boundary) lambda.sample <- predict(fit, pxl, ~ exp(my.spde + Intercept)) lambda.sample.plot <- ggplot() +   gg(lambda.sample, geom = \"tile\") +   gg(sample$plots, alpha = 0) +   gg(boundary, col = \"yellow\", alpha = 0)  lambda.sample.plot Lambda <- predict(fit, fm_int(mesh, boundary), ~ sum(weight * exp(my.spde + Intercept))) Lambda.empirical <- predict(   fit,   rbind(     cbind(fm_int(mesh, boundary), data.frame(all = TRUE)),     cbind(fm_int(mesh, sample$plots), data.frame(all = FALSE))   ),   ~ (sum(weight * exp(my.spde + Intercept) * all) -     sum(weight * exp(my.spde + Intercept) * !all) +     nrow(sample$nests)) ) rbind(   Lambda,   Lambda.empirical ) fit.all <- lgcp(cmp, nests,   samplers = boundary,   domain = list(geometry = mesh) ) lambda.all <- predict(fit.all, pxl, ~ exp(my.spde + Intercept)) Lambda.all <- predict(fit.all, fm_int(mesh, boundary), ~ sum(weight * exp(my.spde + Intercept))) rbind(   Plots = Lambda,   PlotsEmp = Lambda.empirical,   All = Lambda.all,   AllEmp = c(nrow(gorillas$nests), 0, rep(nrow(gorillas$nests), 3), rep(NA, 3)) ) #>              mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> Plots    664.4747 49.14702 583.2452 659.2644 759.9639 659.2644      3.439096 #> PlotsEmp 644.1124 42.19747 566.5296 641.0819 717.7967 641.0819      2.947076 #> All      674.1723 29.26506 630.5175 670.3959 737.9343 670.3959      1.943844 #> AllEmp   647.0000  0.00000 647.0000 647.0000 647.0000       NA            NA #>          mean.mc_std_err #> Plots           5.602521 #> PlotsEmp        4.809163 #> All             3.315275 #> AllEmp                NA library(patchwork) lambda.sample.plot + lambda.all.plot +   plot_layout(guides = \"collect\") &   theme(legend.position = \"left\") &   scale_fill_continuous(limits = range(c(0, 340)))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Point processes useful spatial data analysis wide applications ecology, epidemiology, seismology, computational neuroscience, etc. Residual analysis effective assessment method spatial point processes, commonly takes frequentist approach. vignette, calculate residuals models https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html using Bayesian approach residual methods “Residual Analysis spatial point processes” (Baddeley et al).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"theory-of-residuals-for-spatial-point-process-models","dir":"Articles","previous_headings":"","what":"Theory of Residuals for Spatial point process models","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider spatial point pattern 𝐱={x1,…,xn}\\mathbf{x} = \\{x_1, \\dots, x_n \\} nn points bounded region WW ℝ2\\mathbb{R}^2. model spatial point process 𝐗\\mathbf{X} probability density fθf_{\\theta} parameter θ\\theta, innovation process model defined Iθ(B)=n(𝐗∩B)−∫Bλθ(u)du\\begin{equation}\\label{eq:innovations}     I_{\\theta}(B) = n(\\mathbf{X} \\cap B) - \\int_B \\lambda_{\\theta} (u) \\, du \\end{equation} , ∫Bλθ(u)du\\int_B \\lambda_{\\theta}(u) \\, du expected number points fitted model bounded subset BB. Innovations satisfy 𝔼θ[Iθ(B)]=0\\mathbb{E}_{\\theta} \\left[ I_{\\theta}(B)\\right] = 0 . Given data 𝐱\\mathbf{x} model parameter estimate θ̂\\hat{\\theta}, raw residuals given Rθ̂(B)=n(𝐱∩B)−∫Bλ̂(u)du\\begin{equation}\\label{eq:raw residuals}     R_{\\hat{\\theta}}(B) = n(\\mathbf{x} \\cap B) - \\int_B \\hat{\\lambda}(u) \\,du \\end{equation} Increments innovation process II raw residuals Poisson processes RR analogous errors raw residuals linear models respectively.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"types-of-residuals","dir":"Articles","previous_headings":"Theory of Residuals for Spatial point process models","what":"Types of Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"can scale raw residual scaling increments Rθ̂R_{\\hat{\\theta}}. \\ hh-weighted innovations given (B,h,λ)=∑xi∈𝐗∩Bh(xi)−∫Bh(u)λ(u)du\\begin{equation}\\label{eq:h innovations}     (B, h, \\lambda) = \\sum_{x_i \\\\mathbf{X} \\cap B} h(x_i) -      \\int_B h(u) \\lambda(u) \\,du \\end{equation} leads hh-weighted residuals R(B,ĥ,θ̂)=(B,ĥ,λ̂)=∑xi∈𝐱∩Bh(xi)−∫Bĥ(u)λ̂(u)du\\begin{equation} \\label{eq:h residuals}     R(B, \\hat{h}, \\hat{\\theta}) = (B, \\hat{h}, \\hat{\\lambda}) =      \\sum_{x_i \\\\mathbf{x} \\cap B} h(x_i) - \\int_B \\hat{h}(u) \\hat{\\lambda}(u)\\,du \\end{equation} Since innovation mean 0, true model yield 𝔼[R(B,ĥ,θ̂)]≈0. \\mathbb{E}\\left[R(B, \\hat{h}, \\hat{\\theta})\\right] \\approx 0.  Changing choice weight function hh, yields different types residuals.","code":""},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"pearson-residuals","dir":"Articles","previous_headings":"Theory of Residuals for Spatial point process models > Types of Residuals","what":"Pearson Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":", zero values λ̂(u)\\hat{\\lambda}(u) cause issues calculating residuals set ĥ(u)λ̂(u)=λ̂(u)\\hat{h}(u) \\hat{\\lambda}(u) = \\sqrt{\\hat{\\lambda}(u)} uu. three types residuals : Scaled:R(B,ĥ,θ̂)=n(𝐱∩B)−∫Bλ̂(u)duInverse:R(B,1λ̂,θ̂)=∑xi∈𝐱∩B1λ̂(xi)−∫B𝟏{xi∈𝐱}duPearson:R(B,1λ̂,θ̂)=∑xi∈𝐱∩B1λ̂(xi)−∫Bλ̂(u)du\\begin{eqnarray} \\text{Scaled:} \\qquad & R(B, \\hat{h}, \\hat{\\theta}) & = n(\\mathbf{x} \\cap B) -  \\int_B \\hat{\\lambda}(u) \\,du \\\\ \\text{Inverse:} \\qquad & R\\left(B, \\frac{1}{\\hat{\\lambda}}, \\hat{\\theta}\\right)  & = \\sum_{x_i \\\\mathbf{x} \\cap B} \\frac{1}{\\hat{\\lambda}(x_i)} -  \\int_B \\mathbf{1} \\{ x_i \\\\mathbf{x} \\} \\,du \\\\ \\text{Pearson:} \\qquad &  R\\left( B, \\frac{1}{\\sqrt{\\hat{\\lambda}}},\\hat{\\theta} \\right) & = \\sum_{x_i \\\\mathbf{x} \\cap B} \\frac{1}{\\sqrt{\\hat{\\lambda}(x_i)}} -  \\int_B \\sqrt{\\hat{\\lambda}(u)} \\,du  \\end{eqnarray} Note λ̂(u)\\hat{\\lambda}(u) ĥ(u)\\hat{h}(u) estimates λ(u)\\lambda (u) h(u)h(u) respectively","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"motivation-for-choice-of-residuals","dir":"Articles","previous_headings":"Theory of Residuals for Spatial point process models","what":"Motivation for choice of residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"scaling residuals nothing raw residuals hence depict residual data . However, Pearson residuals use weighted function h(u)=1λ(u)h(u) = \\frac{1}{\\lambda(u)} helps obtain normalised residuals since denominator accounts variance residuals hence makes reliable sample size. use inverse residual project less clear. However, know easier compute residual since GNZ formula estimate value $h(u) = value λ(u)\\lambda(u). notation’s sake discussion, let hs(u),hi(u),hp(u)h_{s}(u), h_{}(u), h_p(u) indicate weight function scaling, inverse Pearson residuals respectively. , hs(u)=𝟏{u∈B},hi(u)=1λ(u),hp(u)=1λ(u)h_s(u) = \\mathbf{1}\\{u \\B\\}, h_i(u) = \\frac{1}{\\lambda(u)}, h_p(u) = \\frac{1}{\\sqrt{\\lambda(u)}}. can also see hs(u)=(hi(u))0h_s(u) = \\left(h_i(u)\\right)^0 hp(u)=(hi(u))1/2h_p(u) = \\left(h_i(u)\\right)^{1/2}, values Pearson residuals lie somewhere two residuals. , case, inverse residuals useful, find easier compute hand terms estimates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"computation-of-residuals","dir":"Articles","previous_headings":"","what":"Computation of Residuals","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"vignette, residuals models https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html computed using Bayesian approach residuals described . done using inlabru package. models used : Model 1 (Vegetation Model): model defined gorilla nests vegetation type fixed covariate. Model 2 (Elevation Model): model defined gorilla nests elevation continuous variable. Model 3 (Intercept Model): model defined gorilla nests constant effect. Model 4 (SPDE Smooth type model): model defined gorilla nests depend SPDE type smooth function. functions used calculate residuals models given Code appendix end vignette.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"loading-gorillas-data","dir":"Articles","previous_headings":"Computation of Residuals","what":"Loading gorillas data","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"vignette uses gorillas dataset “inlabru” package R modelling spatial Poisson processes. , ``inlabru” package uses Latent Gaussian Cox Processes model data using different model definitions. Initially, set BB defines B=WB=W, WW object boundary. function prepare_residual_calculations() defined compute data frame observations xix_i sample points u∈Wu \\W compute residual, matrix A_sum helps calculate summation term residual matrix A_integrate helps calculate integral term residual. function residual_df defined compute three types residuals given model choice BB given set observations.","code":"# Load data data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary gcov <- gorillas$gcov # Define the subset B B <- boundary  # Store the required matrices and data frames for residual computation As <- prepare_residual_calculations(   samplers = B, domain = mesh,   observations = nests )"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"vegetation-model","dir":"Articles","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Vegetation Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model taken https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html . model defined gorilla nests vegetation type fixed covariate. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed B=WB = W.  Note: data frame produced residual_df() originally contains columns Type, mean.mc_std_err, sd.mc_std_err median removed tables vignette highlight essential non-recurring data. editing data frames done function edit_df.","code":"# Define the vegetation model comp1 <- coordinates ~   vegetation(gcov$vegetation, model = \"factor_contrast\") + Intercept(1)  fit1 <- lgcp(comp1, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int1 <- predict(fit1,   newdata = fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(vegetation + Intercept) ) ggplot() +   gg(int1) +   gg(boundary, alpha = 0, lwd = 2) +   gg(nests, color = \"DarkGreen\") # Calculate the residuals for the vegetation model veg_res <- residual_df(   fit1, As$df, expression(exp(vegetation + Intercept)),   As$A_sum, As$A_integrate ) knitr::kable(edit_df(veg_res, c(\"Type\", \"mean.mc_std_err\", \"sd.mc_std_err\", \"median\")))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"elevation-model","dir":"Articles","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Elevation model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html . model defined gorilla nests elevation continuous variable. code chunk shows model defined lgcp() also displays model form plot.  residuals model B=WB = W given :","code":"# Define the Elevation model comp2 <- coordinates ~ elev(elev, model = \"linear\") +   mySmooth(coordinates, model = matern) + Intercept(1)  fit2 <- lgcp(comp2, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int2 <- predict(   fit2,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(elev + mySmooth + Intercept) ) ggplot() +   gg(int2) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"intercept-model","dir":"Articles","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Intercept Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html . model defined gorilla nests constant effect. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed B=WB = W.  residuals model B=WB = W given :","code":"# Define the Intercept model comp3 <- coordinates ~ Intercept(rep(1, nrow(.data.))) fit3 <- lgcp(comp3, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int3 <- predict(   fit3,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(Intercept) ) ggplot() +   gg(int3) +   gg(boundary, alpha = 0) +   gg(nests, shape = \"+\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"smooth-model","dir":"Articles","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Smooth Model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"model also taken https://inlabru-org.github.io/inlabru/articles/2d_lgcp_covars.html . model defined gorilla nests depend SPDE type smooth function. code chunk shows model defined lgcp() also displays model form plot. residuals model also computed B=WB = W.  residuals model B=WB = W given :","code":"# Define the Smooth model comp4 <- coordinates ~ mySmooth(coordinates, model = matern) +   Intercept(1) fit4 <- lgcp(comp4, nests,   samplers = boundary,   domain = list(coordinates = mesh) )  # Display the model int4 <- predict(   fit4,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ exp(mySmooth + Intercept) ) ggplot() +   gg(int4) +   gg(boundary) +   gg(nests, shape = \"+\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"comparing-models","dir":"Articles","previous_headings":"Computation of Residuals > Assessing 4 models with residuals","what":"Comparing models","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Firstly, plots four models, see visual similarities Elevation smooth models appear . , expect two models show similar trends residuals.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"redefining-the-set-b","dir":"Articles","previous_headings":"Computation of Residuals","what":"Redefining the set B","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider defining new type set BB consists two subpolygons within boundary. done partition() function divides polygon grids based number rows columns desired resolution. code chunk demonstrates use function dividing polygon calculating residuals choice BB.  , can seen two lines residual data type residual. signifies residual_df function calculated residuals partition. compare residuals effectively, function residual_plot() defined plots residuals corresponding polygon B. discussed later vignette. Another type partitioning considered three sections region residuals displayed :","code":"# Create a grid for B partitioned into two B1 <- partition(samplers = boundary, nrows = 1, ncols = 2) plot(B1, main = \"Two partitions of B\") As1 <- prepare_residual_calculations(   samplers = B1, domain = mesh,   observations = nests ) # Residuals for the vegetation model veg_res2 <- residual_df(   fit1, As1$df, expression(exp(vegetation + Intercept)),   As1$A_sum, As1$A_integrate ) knitr::kable(edit_df(veg_res2, c(   \"Type\", \"mean.mc_std_err\",   \"sd.mc_std_err\", \"median\" )))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"residuals-of-models-at-different-resolutions","dir":"Articles","previous_headings":"Computation of Residuals","what":"Residuals of models at different resolutions","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Consider two resolutions BB, given plots . use resolution argument instead nrow ncol. Due way terra::rast() interprets arguments, using resolution doesn’t guarantee complete coverage samplers polygon. Using two new choices BB, residuals calculated four models resolutions using residual_df(). functions set_csc() residual_plot() defined plot three types residuals model partition BB. code chunk demonstrates plotting done vegetation model resolution B=B3B = B_3. , useful type residual colour scale resolutions.","code":"# Residuals of Vegetation model Residual_fit1_B3 <- residual_df(   model = fit1, df = As3$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As3$A_sum,   A_integrate = As3$A_integrate )  Residual_fit1_B4 <- residual_df(   model = fit1, df = As4$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  # Colour scales for each model to cover both resolutions fit1_csc <- set_csc(rbind(Residual_fit1_B3, Residual_fit1_B4), rep(\"RdBu\", 3))  # Store plots plotB3_fit1 <- residual_plot(B3, Residual_fit1_B3, fit1_csc, \"Vegetation Model\") plotB4_fit1 <- residual_plot(B4, Residual_fit1_B4, fit1_csc, \"Vegetation Model\")  # comparing the vegetation model ((plotB3_fit1$Scaling | plotB3_fit1$Inverse | plotB3_fit1$Pearson) /   (plotB4_fit1$Scaling | plotB4_fit1$Inverse | plotB4_fit1$Pearson)) +   plot_annotation(title = \"Vegetation Model\") +   plot_layout(guides = \"collect\") &   theme(legend.position = \"bottom\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"comparing-different-types-of-residuals-for-each-model","dir":"Articles","previous_headings":"Computation of Residuals > Residuals of models at different resolutions","what":"Comparing different types of residuals for each model","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Now, plots help compare residuals model two resolutions BB type residual.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"discussion","dir":"Articles","previous_headings":"Computation of Residuals > Residuals of models at different resolutions > Comparing different types of residuals for each model","what":"Discussion","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"section, discuss findings output code. relevant point used repeatedly discussion since colour scales residuals chosen negative positive values hues red blue respectively, negative positive residuals imply overestimation underestimation gorilla nests model respectively. Thus, red regions plot imply overestimation gorilla nests model region blue regions plot imply underestimation gorilla nests model region. common observation models scaling residuals seem highest range among residuals since direct interpretations residuals models. Also, Pearson residuals seem take values scaling inverse residuals resolutions four models. However, almost types residuals model, positive negative residual values extreme B3B_3 resolution corresponding residual values extreme B4B_4 resolution type residual. bias ``experimental” mode explored points project. vegetation intercept model, regions negative positive residuals remain residuals different levels type residual. Also, seems north north-west region models underestimated model remaining regions overestimated model different levels. elevation model, type residual slight variations negative positive residuals corresponding regions fixed resolution. means different residuals suggest particular polygon overestimated underestimated model. However, happens points containing extremes residuals regions. Pearson residuals supposedly reliable case normalised residuals. three types residuals contain larger proportions negative residuals suggest model overestimates gorilla population region (different amounts different regions).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"comparing-different-models-for-each-type-of-residual","dir":"Articles","previous_headings":"Computation of Residuals > Residuals of models at different resolutions","what":"Comparing different models for each type of residual","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Another way compare residuals, consider type residual separately plot residuals four models resolution. helps compare models given type residual choice BB. , useful colour scale 4 models. code chunk demonstrates code plotting “Pearson” residuals B=B4B = B_4. Now, plots help compare 4 models particular choice BB chosen residual type.","code":"# Calculate the residuals for all models at B4 Residual_fit1_B4 <- residual_df(   model = fit1, df = As4$df,   expr = expression(exp(vegetation + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  Residual_fit2_B4 <- residual_df(   model = fit2, df = As4$df,   expr = expression(exp(elev + mySmooth + Intercept)),   A_sum = As4$A_sum, A_integrate = As4$A_integrate )  Residual_fit3_B4 <- residual_df(   model = fit3, df = As4$df,   expr = expression(exp(Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  Residual_fit4_B4 <- residual_df(   model = fit4, df = As4$df,   expr = expression(exp(mySmooth + Intercept)), A_sum = As4$A_sum,   A_integrate = As4$A_integrate )  # Set the colour scale B4res <- rbind(   Residual_fit1_B4, Residual_fit2_B4,   Residual_fit3_B4, Residual_fit4_B4 ) B4csc <- set_csc(B4res, rep(\"RdBu\", 3))  # Plots for residuals of all 4 models with resolution B4 plotB4_veg <- residual_plot(B4, Residual_fit1_B4, B4csc, \"Vegetation Model\") plotB4_elev <- residual_plot(B4, Residual_fit2_B4, B4csc, \"Elevation Model\") plotB4_int <- residual_plot(B4, Residual_fit3_B4, B4csc, \"Intercept Model\") plotB4_smooth <- residual_plot(B4, Residual_fit4_B4, B4csc, \"Smooth Model\")  # Comparing all models for B4 Pearson residuals ((plotB4_veg$Pearson | plotB4_elev$Pearson) /   (plotB4_int$Pearson | plotB4_smooth$Pearson)) +   plot_annotation(\"B4 Pearson Residuals\") +   plot_layout(guides = \"collect\") &   theme(legend.position = \"bottom\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"discussion-1","dir":"Articles","previous_headings":"Computation of Residuals > Residuals of models at different resolutions > Comparing different models for each type of residual","what":"Discussion","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"Firstly, common feature three figures residual plots vegetation intercept models relatively similar elevation smooth models relatively similar well resolutions type residual. Also, fixed type residual chosen model, B3B_3 residuals less extreme compared B4B_4 residuals, plausibly owing bias ``experimental” mode . Another feature three types residuals elevation intercept model less extreme residual values compared vegetation intercept models given type residual. suggest former two better models gorilla nesting given region. residual values wider range B=B4B=B_4 B=B3B = B_3. scaling residuals Pearson residuals, elevation smooth models less extreme values residuals relative vegetation intercept models. suggests elevation smooth models suited estimating gorilla nesting locations WW. Also, significant underestimation north-west areas vegetation intercept models areas underestimated two models. However, explored , residuals calculated ``experimental” mode produces overestimates two models, must kept mind reaching conclusions suitable model nesting locations. inverse residuals, observations hold, except residuals elevation smooth models residuals significantly less extreme relative vegetation intercept models seen case Pearson scaling residuals resolutions B3B_3 B4B_4.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_residuals.html","id":"function-definitions","dir":"Articles","previous_headings":"Code appendix","what":"Function definitions","title":"Residual Analysis of spatial point process models using Bayesian methods","text":"","code":"# Niharika Reddy Peddinenikalva # Vacation Scholarship project  suppressPackageStartupMessages(library(\"INLA\")) suppressPackageStartupMessages(library(\"inlabru\")) suppressPackageStartupMessages(library(\"RColorBrewer\")) suppressPackageStartupMessages(library(\"ggplot2\")) suppressPackageStartupMessages(library(\"dplyr\")) suppressPackageStartupMessages(library(\"lwgeom\")) suppressPackageStartupMessages(library(\"patchwork\")) suppressPackageStartupMessages(library(\"terra\")) suppressPackageStartupMessages(library(\"data.table\")) theme_set(theme_bw())    #' ---------------------------------- #' prepare_residual_calculations #' ---------------------------------- #' #' Computes the A_sum, A_integrate matrices and the data frame used for #' calculating the residuals for the given set of polygons B  #' Input: #' @param samplers A SpatialPolygonDataFrame containing partitions for which #' residuals are to be calculated #' @param domain A mesh object #' @param observations A SpatialPointsDataFrame containing observed data #' #' Output: #' @return A_sum - matrix used to compute the summation term of the residuals #' @return A_integrate - matrix used to compute the integral term #' @return df - SpatialPointsDataFrame containing all the locations 'u' for #' calculating residuals #' prepare_residual_calculations <- function(samplers, domain, observations) {   # Calculate the integration weights for A_integrate   ips <- fm_int(domain = domain, samplers = samplers)    # Set-up the A_integrate matrix   # A_integrate has as many rows as polygons in the samplers,   # as many columns as mesh points   A_integrate <- inla.spde.make.A(     mesh = domain, ips, weights = ips$weight,     block = ips$.block, block.rescale = \"none\"   )     # Set-up the A_sum matrix   # A_sum has as many rows as polygons in the samplers,   # as many columns as observed points   # each row has 1s for the points in the corresponding polygon   idx <- sf::st_within(sf::st_as_sf(observations), sf::st_as_sf(samplers), sparse = TRUE)   A_sum <- sparseMatrix(     i = unlist(idx),     j = rep(       seq_len(nrow(observations)),       vapply(idx, length, 1L)     ),     x = rep(1, length(unlist(idx))),     dims = c(nrow(samplers), nrow(observations))   )     # Setting up the data frame for calculating residuals   observations$obs <- TRUE   df <- sp::SpatialPointsDataFrame(     coords = rbind(domain$loc[, 1:2], sp::coordinates(observations)),     data = bind_rows(data.frame(obs = rep(FALSE, domain$n)), observations@data),     proj4string = fm_CRS(domain)   )    # Return A-sum, A_integrate and the data frame for predicting the residuals   list(A_sum = A_sum, A_integrate = A_integrate, df = df) }    #' ------------ #' residual_df #' ------------ #' #' Computes the three types if residuals and returns a data frame containing #' information about all 3 residuals for each partition of 'B' #' #' Inputs: #' @param model fitted model for which residuals need to be calculated #' @param df SpatialPointsDataFrame object containing all the locations 'u' #' for calculating residuals #' @param expr an expression object containing the formula of the model #' @param A_sum matrix used to compute the summation term of the residuals #' @param A_integrate matrix that computes the integral term of the residuals #' #' Outputs: #' @return Data frame containing residual information for each of the #' partitions of the subset 'B' #'  residual_df <- function(model, df, expr, A_sum, A_integrate) {   # Compute residuals   res <- predict(     object = model,     newdata = df,     ~ {       lambda <- eval(expr)       h1 <- lambda * 0 + 1       h2 <- 1 / lambda       h3 <- 1 / sqrt(lambda)       data.frame(         Scaling_Residuals =           as.vector(A_sum %*% h1[obs]) -             as.vector(A_integrate %*% (h1 * lambda)[!obs]),         Inverse_Residuals =           as.vector(A_sum %*% h2[obs]) -             as.vector(A_integrate %*% (h2 * lambda)[!obs]),         Pearson_Residuals =           as.vector(A_sum %*% h3[obs]) -             as.vector(A_integrate %*% (h3 * lambda)[!obs])       )     },     used = bru_used(expr)   )    # Label the three types of residuals   res$Scaling_Residuals$Type <- \"Scaling Residuals\"   res$Inverse_Residuals$Type <- \"Inverse Residuals\"   res$Pearson_Residuals$Type <- \"Pearson Residuals\"   do.call(rbind, res) }      #' -------------- #' set_csc #' -------------- #' #' Sets the colour scale for the three types of residuals #' #' Inputs: #' @param residuals frame containing residual information for each of the #' partitions of the subset 'B' #' @param col_theme vector of themes for each type of residual #' #' Outputs: #' @return a list of 3 colour scales for each type of residual #'  set_csc <- function(residuals, col_theme) {   # Store data for the colour scale of the plots for each type of residual   cscrange <- data.frame(     residuals %>%       group_by(Type) %>%       summarise(maxabs = max(abs(mean)))   )    # Set the colour scale for all three types of residuals   scaling_csc <-     scale_fill_gradientn(       colours = brewer.pal(9, col_theme[1]),       name = \"Scaling Residual\",       limits =         cscrange[cscrange$Type == \"Scaling Residuals\", 2] *           c(-1, 1)     )    inverse_csc <-     scale_fill_gradientn(       colours = brewer.pal(9, col_theme[2]),       name = \"Inverse Residual\",       limits =         cscrange[cscrange$Type == \"Inverse Residuals\", 2] *           c(-1, 1)     )    pearson_csc <-     scale_fill_gradientn(       colours = brewer.pal(9, col_theme[3]),       name = \"Pearson Residual\",       limits =         cscrange[cscrange$Type == \"Pearson Residuals\", 2] *           c(-1, 1)     )    list(\"Scaling\" = scaling_csc, \"Inverse\" = inverse_csc, \"Pearson\" = pearson_csc) }    #' --------------- #' residual_plot #' --------------- #' #' plots the three types of residuals for each polygon #' #' Input: #' @param samplers A SpatialPolygonsDataFrame containing partitions for which #' residuals are to be calculated #' @param residuals frame containing residual information for each of the #' partitions of the subset 'B' #' @param csc list of three colour scales for the three types of residuals #' @param model_name string containing the name of the model being assessed #' #' Output: #' @return a list of three subplots scaling, inverse and Pearson residuals #' for the different partitions of samplers   residual_plot <- function(samplers, residuals, csc, model_name) {   # Initialise the scaling residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Scaling Residuals\") %>%     pull(mean)   scaling <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Scaling\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Scaling\"))    # Initialise the inverse residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Inverse Residuals\") %>%     pull(mean)   inverse <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Inverse\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Inverse\"))    # Initialise the Pearson residuals plot   samplers$Residual <- residuals %>%     filter(Type == \"Pearson Residuals\") %>%     pull(mean)   pearson <- ggplot() +     gg(samplers, aes(fill = Residual), alpha = 1, colour = NA) +     csc[\"Pearson\"] +     theme(legend.position = \"bottom\") +     labs(subtitle = paste(model_name, \"Pearson\"))    # Return the three plots in a list   list(     Scaling = scaling, Inverse = inverse,     Pearson = pearson   ) }     #' ------------------ #' partition #' ------------------ #' #' Partitions the region based on the given criteria for calculating residuals #' in each partition. Parts of this function are taken from concepts in #' https://rpubs.com/huanfaChen/grid_from_polygon #' #' Input: #' @param samplers A SpatialPolygonsDataFrame containing region for which #' partitions need to be created #' @param resolution resolution of the grids that are required #' @param nrows number of rows of grids that are required #' @param ncols number of columns of grids that are required #' #' Output: #' @return a partitioned SpatialPolygonsDataFrame as required #' #' partition <- function(samplers, resolution = NULL, nrows = NULL, ncols = NULL) {   # Create a grid for the given boundary   if (is.null(resolution)) {     grid <- terra::rast(terra::ext(samplers),       crs = sp::proj4string(samplers),       nrows = nrows, ncols = ncols     )   }    if (is.null(c(nrows, ncols))) {     grid <- terra::rast(terra::ext(samplers),       crs = sp::proj4string(samplers),       resolution = resolution     )   }    gridPolygon <- terra::as.polygons(grid)    # Extract the boundary with subpolygons only   sf::as_Spatial(sf::st_as_sf(terra::intersect(gridPolygon, terra::vect(samplers)))) }   #' ------------------ #' edit_df #' ------------------ #' #' Edits the residual data frames to remove columns that need not be displayed #' #' Input: #' @param df the data frame which needs to be edited #' @param columns a vector of columns that need to be deleted from df #' #' Output: #' @return the edited data frame with only the desired columns #' #' edit_df <- function(df, columns) {   # Remove the columns that are not required   df[, !(colnames(df) %in% columns)] }"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - An example in two dimensions","text":"vignette going working dataset obtained R package spatstat. set two-dimensional LGCP estimate Gorilla abundance.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in two dimensions","text":"Load libraries","code":"library(inlabru) library(INLA) library(mgcv) library(ggplot2) bru_safe_sp(force = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - An example in two dimensions","text":"next practicals going working dataset obtained R package spatstat, contains locations 647 gorilla nests. load dataset like : dataset list containing number R objects, including locations nests, boundary survey area INLA mesh - see help(gorillas) details. Extract objects need list, objects, don’t keep typing ‘gorillas$’: Plot points (nests).","code":"data(gorillas, package = \"inlabru\") nests <- gorillas$nests mesh <- gorillas$mesh boundary <- gorillas$boundary ggplot() +   geom_fm(data = mesh) +   gg(nests) +   gg(boundary, fill = \"red\", alpha = 0.2) +   ggtitle(\"Points\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"fiting-the-model","dir":"Articles","previous_headings":"","what":"Fiting the model","title":"LGCPs - An example in two dimensions","text":"Fit LGCP model locations gorilla nests, predict survey region, produce plot estimated density - look like plot shown . Recall steps specifying, fitting predicting : Specify model, comprising (2D models) coordinates left ~ SPDE + Intercept(1) right. Please use SPDE prior specification stated . Call lgcp( ), passing (2D models) model components, SpatialPointsDataFrame containing observed points SpatialPolygonsDataFrame defining survey boundary using samplers argument. Call predict( ), passing fitted model 2., locations predict appropriate predictor specification. locations predict can SpatialPixelsDataFrame covering mesh, obtained calling fm_pixels(mesh, format = \"sp\").","code":"matern <- inla.spde2.pcmatern(   mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(5, 0.01) )  cmp <- coordinates ~   mySmooth(coordinates, model = matern) +   Intercept(1)  fit <- lgcp(cmp, nests, samplers = boundary, domain = list(coordinates = mesh))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"predicting-intensity","dir":"Articles","previous_headings":"","what":"Predicting intensity","title":"LGCPs - An example in two dimensions","text":"get plot like (command assumes prediction object called lambda):  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object lambda).","code":"pred <- predict(   fit,   fm_pixels(mesh, mask = boundary, format = \"sp\"),   ~ data.frame(     lambda = exp(mySmooth + Intercept),     loglambda = mySmooth + Intercept   ) )  pl1 <- ggplot() +   gg(pred$lambda) +   gg(boundary) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Response Scale)\")  pl2 <- ggplot() +   gg(pred$loglambda) +   gg(boundary, alpha = 0) +   ggtitle(\"LGCP fit to Points\", subtitle = \"(Linear Predictor Scale)\")  multiplot(pl1, pl2, cols = 2) ggplot() +   gg(cbind(pred$lambda, data.frame(property = \"q0.500\")), aes(fill = median)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.025\")), aes(fill = q0.025)) +   gg(cbind(pred$lambda, data.frame(property = \"q0.975\")), aes(fill = q0.975)) +   coord_equal() +   facet_wrap(~property)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"spde-parameters","dir":"Articles","previous_headings":"","what":"SPDE parameters","title":"LGCPs - An example in two dimensions","text":"Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :","code":"int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"mySmooth\", what = \"range\") spde.logvar <- spde.posterior(fit, \"mySmooth\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"mySmooth\", what = \"matern.covariance\")) multiplot(covplot, corplot)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_sp.html","id":"estimating-abundance","dir":"Articles","previous_headings":"","what":"Estimating Abundance","title":"LGCPs - An example in two dimensions","text":"Finally, estimate abundance using predict function. first step need estimate integrated lambda. integration weight values contained fm_int() output. Given generous interval boundaries (500, 800) lambda can estimate posterior abundance distribution via Get quantiles via … mean via plot posteriors:  true number nests 647; mean median posterior distribution abundance close done anything wrong!","code":"Lambda <- predict(   fit,   fm_int(mesh, boundary),   ~ sum(weight * exp(mySmooth + Intercept)) ) Lambda #>       mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err #> 1 671.9777 28.51742 616.9545 673.0148 731.1952 673.0148      1.997607 #>   mean.mc_std_err #> 1        3.251264 Nest <- predict(   fit, fm_int(mesh, boundary),   ~ data.frame(     N = 500:800,     dpois(500:800,       lambda = sum(weight * exp(mySmooth + Intercept))     )   ) ) inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 601.2136 667.4150 746.7010 inla.emarginal(identity, marginal = list(x = Nest$N, y = Nest$mean)) #> [1] 669.243 Nest$plugin_estimate <- dpois(Nest$N, lambda = Lambda$mean) ggplot(data = Nest) +   geom_line(aes(x = N, y = mean, colour = \"Posterior\")) +   geom_line(aes(x = N, y = plugin_estimate, colour = \"Plugin\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_spatiotemporal.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"LGCPs - An example in space and time","text":"vignette going working dataset obtained R package MRSea. set LGCP spatio-temporal SPDE model estimate species distribution.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_spatiotemporal.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"LGCPs - An example in space and time","text":"Load libraries","code":"library(inlabru) library(INLA) library(ggplot2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_spatiotemporal.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"LGCPs - An example in space and time","text":"Load dataset, coordinates UTM kilometres: points (representing animals) sampling regions dataset associated season. Let’s look observed points sampling regions seasons:","code":"mrsea <- inlabru::mrsea_sf ggplot() +   geom_fm(data = mrsea$mesh) +   gg(mrsea$boundary) +   gg(mrsea$samplers) +   gg(mrsea$points, size = 0.5) +   facet_wrap(~season) +   ggtitle(\"MRSea observation seasons\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_spatiotemporal.html","id":"integration-points","dir":"Articles","previous_headings":"","what":"Integration points","title":"LGCPs - An example in space and time","text":"inlabru point process model knows construct numerical integration scheme LGCP likelihood. can also call internal functions directly see integration scheme look like. model take time (season) account construct integration points LGCP accordingly. Using fm_int() can specify product domain space. Note omitting step simply aggregate sampling regions time. Plot integration points:","code":"ips <- fm_int(   domain = list(geometry = mrsea$mesh, season = 1:4),   samplers = mrsea$samplers ) ggplot() +   geom_fm(data = mrsea$mesh) +   gg(ips, aes(size = weight)) +   scale_size_area(max_size = 1) +   facet_wrap(~season)"},{"path":"https://inlabru-org.github.io/inlabru/articles/2d_lgcp_spatiotemporal.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"LGCPs - An example in space and time","text":"Fit LGCP model locations animals. example employ spatio-temporal SPDE. Note group ngroup parameters employed let SPDE model know name time dimension (season) total number distinct points time. Predict plot intensity seasons:","code":"matern <- inla.spde2.pcmatern(mrsea$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(10, 0.01) )  cmp <- geometry + season ~ Intercept(1) +   mySmooth(     geometry,     model = matern,     group = season,     ngroup = 4   )  fit <- lgcp(cmp,   data = mrsea$points,   samplers = mrsea$samplers,   domain = list(     geometry = mrsea$mesh,     season = seq_len(4)   ) ) ppxl <- fm_pixels(mrsea$mesh, mask = mrsea$boundary, format = \"sf\") ppxl_all <- fm_cprod(ppxl, data.frame(season = seq_len(4)))  lambda1 <- predict(   fit,   ppxl_all,   ~ data.frame(season = season, lambda = exp(mySmooth + Intercept)) ) pl1 <- ggplot() +   gg(lambda1, geom = \"tile\", aes(fill = q0.5)) +   gg(mrsea$points, size = 0.3) +   facet_wrap(~season) +   coord_sf() pl1"},{"path":"https://inlabru-org.github.io/inlabru/articles/Apptainer.html","id":"installation-procedures","dir":"Articles","previous_headings":"","what":"Installation Procedures","title":"Installation of INLA and inlabru with Apptainer on HPC","text":"Check Apptainer available HPC. , ask administrator install . Type HPC terminal check version installed. Type code pull rocker/geospatial Singularity Image Format (SIF) file latest R version. illustration, assume file stored ./your_container.sif. shell: R: Put following job script execute R file non-interactively. Note: Use inla.setOption(num.threads = ncpu) limit number threads (ncpu) since INLA set automatically. ncpu also directly links RAM requirements.","code":"apptainer version # To pull the docker image apptainer pull your_container.sif docker://rocker/geospatial:latest # once the sif is downloaded, get into an interactive shell apptainer shell your_container.sif # Inside the interactive shell, one can install INLA on a personal library path R --verbose # Now, in a R environment options(repos = c(   INLA = \"https://inla.r-inla-download.org/R/testing\",   CRAN = \"https://cloud.r-project.org\" )) install.packages(\"INLA\") # One may be asked to create a personal library path. install.packages(\"inlabru\") # quit R q() # To execute an R file with apptainer apptainer exec ./your_container.sif Rscript --no-restore --no-save --verbose file_to_run.R"},{"path":"https://inlabru-org.github.io/inlabru/articles/articles.html","id":"package-examples","dir":"Articles","previous_headings":"","what":"Package examples","title":"Articles list","text":"potentially long running examples/tutorials available (https://inlabru-org.github.io/inlabru/) LGCPs - example one dimension LGCPs - Spatial covariates LGCPs - Distance sampling LGCPs - Multiple Likelihoods LGCPs - Plot sampling Residual Analysis spatial point process models using Bayesian methods LGCPs - example two dimensions LGCPs - example space time LGCPs - example two dimensions Installation INLA inlabru Apptainer HPC Devel: Model evaluation flowchart Converting inla.spde.make.calls bru_mapper system Publications Random Fields 2D Random Fields One Dimension ‘Spatially Varying Coefficient Models inlabru’ ZIP ZAP models","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/articles.html","id":"package-vignettes","dir":"Articles","previous_headings":"","what":"Package vignettes","title":"Articles list","text":"package vignettes also available (https://inlabru-org.github.io/inlabru/) Articles list Devel: Customised model components bru_mapper system Defining model components Nonlinear model approximation Iterative linearised INLA method Prediction scores","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mapper-system-introduction","dir":"Articles","previous_headings":"","what":"Mapper system introduction","title":"Devel: Customised model components with the bru_mapper system","text":"inlabru latent model component generates effect, given latent state vector. purpose mapper system define link state vectors effect vectors. ordinary model component, named cc, link can represented matrix-vector product ηc(uc)=Ac(input)uc, \\eta_c(u_c) = A_c(\\text{input}) u_c,  ucu_c latent state vector, ηc(uc)\\eta_c(u_c) resulting component effect vector, Ac(input)A_c(\\text{input}) component model matrix. matrix depends component inputs (covariates, index information, etc) main, group, replicate, weights component definition. wider scope component definitions discussed component vignette. , focus mapper system , basic building blocks used construct built-mappers, finally construct new mappers. -package documentation mapper methods contained four parts: Regular users normally need methods ?bru_mapper sometimes ?bru_mapper_generics. methods ?bru_mapper_methods provides details allows user query mappers use outside context inlabru model definitions. bru_mapper_define() bru_get_mapper() methods needed implementing mapper class.","code":"?bru_mapper # Mapper constructors ?bru_mapper_generics # Generic and default methods ?bru_mapper_methods # Specialised mapper methods ?bru_get_mapper # Mapper extraction methods"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mappers","dir":"Articles","previous_headings":"","what":"Mappers","title":"Devel: Customised model components with the bru_mapper system","text":"main purpose mapper class allow evaluating component effect, given input latent state, calling mapper associated component definition.","code":"ibm_eval(mapper, input, state)"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"basic-mappers","dir":"Articles","previous_headings":"Mappers","what":"Basic mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Basic mappers take covariate vectors matrices input numeric vectors state. Constructors: bru_mapper_const() bru_mapper_linear() bru_mapper_index(n) bru_mapper_factor(values, factor_mapping) bru_mapper_matrix() bru_mapper_harmonics(order, scaling, intercept, interval)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"const","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"const","title":"Devel: Customised model components with the bru_mapper system","text":"const mapper defines mapping empty state vector. used define offset components, η(u)j=zj\\eta(u)_j = z_j, zz fixed input vector, indexed jj.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"linear","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"linear","title":"Devel: Customised model components with the bru_mapper system","text":"linear mapper defines mapper length 1 state vector. used define ordinary “fixed” covariate effects, linear covariate state variable; η(u)j=zju\\eta(u)_j = z_j u, uu state, zz input covariate vector.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"index","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"index","title":"Devel: Customised model components with the bru_mapper system","text":"index(n) mapper defines direct mapping length n state variable. used structured unstructured “random effect” component effects; η(u)j=uzj\\eta(u)_j = u_{z_j}, uu state vector, zz input index vector.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"factor","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"factor","title":"Devel: Customised model components with the bru_mapper system","text":"factor(values, factor_mapping) mapper defines direct mapping state vector length equal number factor levels values (factor_mapping = \"full\"), one less (factor_mapping = \"contrast\"). factor level represented dummy 0/1 variable, equivalently, input used label index state vector; η(u)j=uzj\\eta(u)_j = u_{z_j}. \"contrast\" case, first factor level removed model, corresponding effect defined zero.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"matrix","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"matrix","title":"Devel: Customised model components with the bru_mapper system","text":"matrix mapper defines direct matrix multiplication pre-computed model matrix AinputA_\\text{input} state vector; η(u)=Ainputu\\eta(u) = A_\\text{input} u. used e.g. linear model formula input, converted component model matrix handing mapper system.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"harmonics","dir":"Articles","previous_headings":"Mappers > Basic mappers","what":"harmonics","title":"Devel: Customised model components with the bru_mapper system","text":"harmonics(order, scaling, intercept, interval) mapper defines sum weighted harmonics real interval (L,U)(L, U), frequency additionally scaled factors determined scale; η(uj)=∑k=11+2pAj,kuk\\eta(u_j) = \\sum_{k=1}^{1+2p} A_{j,k} u_k, Aj,k=skA_{j,k}=s_k k=1k=1, Aj,2k=sk+1cos[2πk(zj−L)/(U−L)]A_{j,2k}=s_{k+1}\\cos[2\\pi k (z_j - L)/(U-L)] k=1,2,…,pk=1,2,\\dots,p, Aj,2k+1=sk+1sin[2πk(zj−L)/(U−L)]A_{j,2k+1}=s_{k+1}\\sin[2\\pi k (z_j - L)/(U-L)] k=1,2,…,pk=1,2,\\dots,p, p=p=order. intercept TRUE, state vector length 1+2p1+2p. intercept FALSE, first, constant, column removed, state vector length 2p2p.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"transformation-mappers","dir":"Articles","previous_headings":"Mappers","what":"Transformation mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Transformation mappers mappers normally combined mappers, steps sequence transformations, individual transformation mappers. bru_mapper_scale() bru_mapper_marginal(qfun, pfun, ...) bru_mapper_aggregate(rescale) bru_mapper_logsumexp(rescale)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"scale","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"scale","title":"Devel: Customised model components with the bru_mapper system","text":"scale mapper multiplies input vector state vector. used INLA models implement weights component scaling, final stage pipe mapper, see .","code":"mapper <- bru_mapper_scale() ibm_eval(mapper,   input = ...,   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"marginal","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"marginal","title":"Devel: Customised model components with the bru_mapper system","text":"marginal mapper transforms state vector standardised Gaussian marginal distribution distribution defined quantile function. can used define components latent marginal N(0,1) distribution non-Gaussian effect.","code":"mapper <- bru_mapper_marginal(qfun = ..., pfun = ..., dfun = ..., ..., inverse = ...) ibm_eval(mapper,   input = NULL, # If a list is given, it overrides the parameter specification   state = ... )  # Examples: mapper <- bru_mapper_marginal(qfun = qexp, rate = 1 / 8) mapper <- bru_mapper_marginal(qfun = qexp, pfun = pexp, dfun = dexp, rate = 1 / 8)"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"aggregate","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"aggregate","title":"Devel: Customised model components with the bru_mapper system","text":"aggregate mapper aggregates state vector elements blockwise summation scaling elements weights. can used summation, integration, averaging (rescale=TRUE).","code":"mapper <- bru_mapper_aggregate(rescale = ...) ibm_eval(mapper,   input = list(block = ..., weights = ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"logsumexp","dir":"Articles","previous_headings":"Mappers > Transformation mappers","what":"logsumexp","title":"Devel: Customised model components with the bru_mapper system","text":"logsumexp mapper aggregates exp(state) vector elements blockwise summation scaling elements weights, takes logarithm. implementation takes care avoid numerical overflow. can used summation, integration, averaging (rescale=TRUE).","code":"mapper <- bru_mapper_logsumexp(rescale = ...) ibm_eval(mapper,   input = list(block = ..., weights = ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"compound-mappers","dir":"Articles","previous_headings":"Mappers","what":"Compound mappers","title":"Devel: Customised model components with the bru_mapper system","text":"Compound mappers define collections chains mappings, can take various forms input. state vector normally numeric vector, can cases list vectors. bru_mapper_collect(mappers, hidden) bru_mapper_multi(mappers) bru_mapper_pipe(mappers)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"collect","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"collect","title":"Devel: Customised model components with the bru_mapper system","text":"collect mapper defines compound mapper Jacobian block-diagonal, block defined separate sub-mapper. hidden = TRUE, can used INLA models user-visible part latent state part internal state, \"bym\" models.","code":"mapper <- bru_mapper_collect(list(name1 = ..., name2 = ..., ...),   hidden = FALSE ) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... ) # If hidden = TRUE, the inla_f=TRUE argument \"hides\" all but the first mapper: ibm_eval(mapper,   input = name1_input,   state = ...,   inla_f = TRUE )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"multi","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"multi","title":"Devel: Customised model components with the bru_mapper system","text":"multi mapper defines compound mapper Jacobian row-wise Kronecker product sub-mapper Jacobians. can used INLA models construct internal mapper main, group, replicate, also user-defined models single rgeneric cgeneric model defined e.g. space-time product domain.","code":"mapper <- bru_mapper_multi(list(name1 = ..., name2 = ..., ...)) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"pipe","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"pipe","title":"Devel: Customised model components with the bru_mapper system","text":"Pipe mappers chain multiple mappers sequence, evaluation result mapper given state vector next mapper.","code":"mapper <- bru_mapper_pipe(list(name1 = ..., name2 = ..., ...)) ibm_eval(mapper,   input = list(name1 = ..., name2 = ..., ...),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"the-core-model-component-mapper","dir":"Articles","previous_headings":"Mappers > Compound mappers","what":"The core model component mapper","title":"Devel: Customised model components with the bru_mapper system","text":"model component mappers currently defined pipe mapper containing multi mapper followed scale mapper:","code":"mapper <-   bru_mapper_pipe(     list(       mapper = bru_mapper_multi(list(main = ..., group = ..., replicate = ...)),       scale = bru_mapper_scale()     )   ) ibm_eval(mapper,   input = list(     mapper = list(main = ..., group = ..., replicate = ...),     scale = ...   ),   state = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"object-mappers","dir":"Articles","previous_headings":"Mappers","what":"Object mappers","title":"Devel: Customised model components with the bru_mapper system","text":"object predefined mapper conversion methods, use bru_mapper(object) obtain suitable mapper object. Current predefined object mappers defined objects classes: fm_mesh_2d inla.mesh; Use bru_mapper(object) fm_mesh_1d inla.mesh.1d; Use bru_mapper(object, indexed) details given .","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"model-object-mappers","dir":"Articles","previous_headings":"Mappers","what":"Model object mappers","title":"Devel: Customised model components with the bru_mapper system","text":"inla model objects predefined mappers, use bru_get_mapper(object) Current predefined model object mappers defined models classes: inla.spde; includes inla.spde2.matern() inla.spde2.pcmatern() models. conversion method calls bru_mapper() appropriate way mesh type used model inla.rgeneric; relies rgeneric definition including \"mapper\" callback argument. less invasive method, works rgeneric cgeneric models, define bru_get_mapper() method class, needs include unique class identifier, e.g. add class(object) <- c(\"my_unique_model_class\", class(object)) define register namespace.","code":"bru_get_mapper.my_unique_model_class <- function(model, ...) {   ... }"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"special-mappers","dir":"Articles","previous_headings":"Mappers","what":"Special mappers","title":"Devel: Customised model components with the bru_mapper system","text":"bru_mapper_taylor()","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mapper-methods","dir":"Articles","previous_headings":"","what":"Mapper methods","title":"Devel: Customised model components with the bru_mapper system","text":"example inla_f argument matters bru_mapper_collect class, hidden=TRUE argument used indicate first mapper used INLA::f() inputs, e.g. \"bym2\" models. inla_f=FALSE (default), ibm_n ibm_values methods return total number latent variables, inla_f=TRUE get values needed INLA::f() instead: bru_mapper_multi class, multi argument provides access inner layers multi-mapper: default ibm_inla_subset method determines inla subset comparing full values information ibm_values(mapper, inla_f = FALSE) inla specific values information ibm_values(mapper, inla_f = TRUE), determine logical vector identifying inla values subset. Custom mappers normally need specialise method.","code":"ibm_n(mapper, inla_f, ...) ibm_n_output(mapper, input, ...) ibm_values(mapper, inla_f, ...) ibm_jacobian(mapper, input, state, ...) ibm_eval(mapper, input, state, ...) ibm_names(mapper, ...) ibm_inla_subset(mapper, ...) mapper <- bru_mapper_collect(   list(     a = bru_mapper_index(3),     b = bru_mapper_index(2)   ),   hidden = TRUE ) ibm_n(mapper) #> [1] 5 ibm_values(mapper) #> [1] 1 2 3 4 5 ibm_n(mapper, inla_f = TRUE) #> [1] 3 ibm_values(mapper, inla_f = TRUE) #> [1] 1 2 3 ibm_n(mapper, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, multi = TRUE) #> $a #> [1] 1 2 3 #>  #> $b #> [1] 1 2 ibm_n(mapper, inla_f = TRUE, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, inla_f = TRUE, multi = TRUE) #> $a #> [1] 1 2 3 #>  #> $b #> [1] 1 2 mapper <- bru_mapper_multi(list(   a = bru_mapper_index(3),   b = bru_mapper_index(2) )) ibm_n(mapper) #> [1] 6 ibm_n(mapper, multi = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper) #> [1] 1 2 3 4 5 6 ibm_values(mapper, multi = TRUE) #>   a b #> 1 1 1 #> 2 2 1 #> 3 3 1 #> 4 1 2 #> 5 2 2 #> 6 3 2 ibm_n(mapper, inla_f = TRUE) #> [1] 6 ibm_n(mapper, multi = TRUE, inla_f = TRUE) #> $a #> [1] 3 #>  #> $b #> [1] 2 ibm_values(mapper, inla_f = TRUE) #> [1] 1 2 3 4 5 6 ibm_values(mapper, multi = TRUE, inla_f = TRUE) #>   a b #> 1 1 1 #> 2 2 1 #> 3 3 1 #> 4 1 2 #> 5 2 2 #> 6 3 2"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"mappers-for-inla-mesh-objects","dir":"Articles","previous_headings":"","what":"Mappers for inla.mesh objects","title":"Devel: Customised model components with the bru_mapper system","text":"component models referenced character label (e.g. \"iid\", \"bym2\", \"rw2\" etc), inlabru construct default mappers, cases replicate default INLA::f() behaviour. fm_mesh_1d, fm_mesh_2d, inla.mesh inla.mesh.1d classes, default mappers can constructed pre-defined bru_mapper S3 methods. 2d meshes (fm_mesh_2d, inla.mesh), 1d meshes (fm_mesh_1d, inla.mesh.1d),","code":"bru_mapper(mesh) # If ibm_values() should return mesh$loc (e.g. for \"rw2\" models # with degree=1 meshes) bru_mapper(mesh, indexed = FALSE) # If ibm_values() should return seq_along(mesh$loc) (e.g. for # inla.spde2.pcmatern() models) bru_mapper(mesh, indexed = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"customised-mappers","dir":"Articles","previous_headings":"","what":"Customised mappers","title":"Devel: Customised model components with the bru_mapper system","text":"mapper object store enough information order ibm_* methods work. simplest case customised mapper just attached new class label front S3 class() information existing mapper, obtain class override standard ibm_* method implementations. commonly, one instead start basic list(), might contain existing mapper object, add methods know use information. cases, bru_mapper_define() method used properly set class information: Implementations can avoid define ibm_n ibm_values methods, instead computing storing n, n_inla, values, values_inla mapper object construction: default ibm_n ibm_values methods checks values available, return appropriate values depending inla_f argument. *_inla values requested available, methods fall back non-inla versions. needed information found, default methods give error message. Note: version 2.6.0, ibm_amatrix used instead ibm_jacobian. Version 2.6.0 still supports , default ibm_jacobian method call ibm_amatrix, give deprecation message later, may removed future version.","code":"bru_mapper_define(mapper, new_class) bru_mapper_define(   mapper = list(n = 10, values = 1:10),   new_class = \"my_bru_mapper_class_name\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/bru_mapper.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Devel: Customised model components with the bru_mapper system","text":"Let’s build mapper class bru_mapper_p_quadratic model component takes input covariates values aija_{ij}, =1,…,mi=1,\\dots,m j=1,…,pj=1,\\dots,p, matrix data.frame evaluates full quadratic expression ηi=x0+∑j=1paijxj+12∑j=1p∑k=1jγj,kaijaikxj,k, \\eta_i = x_0 + \\sum_{j=1}^p a_{ij} x_j +   \\frac{1}{2}\\sum_{j=1}^p\\sum_{k=1}^j \\gamma_{j,k} a_{ij}a_{ik} x_{j,k},  latent component vector 𝐱=[x0,x1,…,xp,x1,1,…,xp,1,x2,2…,xp,p]\\boldsymbol{x}=[x_0,x_1,\\dots,x_p,x_{1,1},\\dots,x_{p,1},x_{2,2}\\dots,x_{p,p}], γj,k={1,j=k,2,j>k. \\gamma_{j,k} = \\begin{cases} 1, & j = k,\\\\ 2, & j > k. \\end{cases} start constructor method. Like bru_mapper_matrix, require user supply vector covariate labels, store character vector. also include min_degree parameter control intercept (min_degree <= 0) linear terms (min_degree <= 1) included model. ibm_n method can compute value nn n=1+p+p(p+1)2n=1+p+\\frac{p(p+1)}{2}: ibm_values, default method sufficient, returning vector [1,…,n][1,\\dots,n] nn obtained ibm_n(mapper). However, clearer result naming, can use character vector, least INLA f() models allow (option argument bru_mapper_p_quadratic constructor control ): approach ibm_n ibm_values works, wasteful recompute n values information call. Instead can use default method check n values stored mapper object, return . change . method definitions _, can end constructor method like , making subsequent method calls faster: Note order matters, since ibm_values_bru_mapper_p_quadratic function calls ibm_n(mapper). can now define main part mapper interface computes model matrix linking latent variables component effect. ’s required NULL input return 00--nn matrix. output mapper different size NROW(input), mapper define ibm_n_output(mapper, input, ...) method return output size given input.","code":"bru_mapper_p_quadratic <- function(labels, min_degree = 0, ...) {   if (is.factor(labels)) {     mapper <- list(       labels = levels(labels),       min_degree = min_degree     )   } else {     mapper <- list(       labels = as.character(labels),       min_degree = min_degree     )   }   bru_mapper_define(mapper, new_class = \"bru_mapper_p_quadratic\") } ibm_n.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   (mapper$min_degree <= 0) + (mapper$min_degree <= 1) * p + p * (p + 1) / 2 } ibm_values.bru_mapper_p_quadratic <- function(mapper, ...) {   p <- length(mapper$labels)   n <- ibm_n(mapper)   jk <- expand.grid(seq_len(p), seq_len(p))   jk <- jk[jk[, 2] <= jk[, 1], , drop = FALSE]   c(     if (mapper$min_degree <= 0) \"Intercept\" else NULL,     if (mapper$min_degree <= 1) mapper$labels else NULL,     paste0(mapper$labels[jk[, 1]], \":\", mapper$labels[jk[, 2]])   ) } bru_mapper_p_quadratic <- function(labels, min_degree = 0, ...) {   ...   mapper <- bru_mapper_define(mapper, new_class = \"bru_mapper_p_quadratic\")   mapper$n <- ibm_n_bru_mapper_p_quadratic(mapper)   mapper$values <- ibm_values_bru_mapper_p_quadratic(mapper)   mapper } ibm_jacobian.bru_mapper_p_quadratic <- function(mapper, input, ...) {   if (is.null(input)) {     return(Matrix::Matrix(0, 0, ibm_n(mapper)))   }   p <- length(mapper$labels)   n <- ibm_n(mapper)   N <- NROW(input)   A <- list()   in_ <- as(input, \"Matrix\")   idx <- 0   if (mapper$min_degree <= 0) {     idx <- idx + 1     A[[idx]] <- Matrix::Matrix(1, N)   }   if (mapper$min_degree <= 1) {     idx <- idx + 1     A[[idx]] <- in_   }   for (k in seq_len(p)) {     idx <- idx + 1     A[[idx]] <- in_[, seq(k, p, by = 1), drop = FALSE] * in_[, k]     A[[idx]][, k] <- A[[idx]][, k] / 2   }   A <- do.call(cbind, A)   colnames(A) <- as.character(ibm_values(mapper))   A }"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"basic-component-features","dir":"Articles","previous_headings":"","what":"Basic component features","title":"Defining model components","text":"Model components defined using formula syntax similar R-INLA differences. basic syntax my_component_name user-chosen label model component. label used model summaries, label relevant parts fitted model object, access model components sampling model using generate() predict(). main argument defines input data component. example, intercept-like component vector ones input. linear effect covariate vector covariate values input. 2-dimensional SPDE effect takes 2-column matrix coordinate locations input. argument can general R expression, details . main argument doesn’t need named. arguments normally named, avoid confusion. type model component specified using model component, (see ?component, ?INLA::inla.list.models()$latent). component type associated bru_mapper method takes main input constructs component design matrix. Users can also specify mapper methods (see ?bru_mapper). syntax replaces INLA::f() function disadvantage clear separation name covariate label effect, user often substantial amount pre-processing data construct relevant inputs. documentation defining model components can viewed ?component. rest vignette goes detail defining model components highlights advantages syntax.","code":"~ my_component_name(   main = ...,   model = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"what-is-a-component-design-matrix","dir":"Articles","previous_headings":"","what":"What is a component design matrix?","title":"Defining model components","text":"linear additive predictor latent Gaussian model can written η(u)=u0+∑k=1Kaikuik, \\begin{equation} \\eta(u)_i = u_0 + \\sum_{k=1}^K a_{ik} u_{ik} , \\end{equation}  uu multivariate Gaussian vector, aka_k input information covariates weights random effects =1,…,ni = 1, \\ldots, n. can also written η(u)=Au\\eta(u) = Au, AA model design matrix ii-th row [1,ai1,…,aiK]\\left[1, a_{i1}, \\ldots, a_{iK}\\right]. can also conceptally think predictor sum DD model components, partition =[(1)⋯(D)]= \\left[^{(1)} \\cdots ^{(D)}\\right], component associated component design matrix (d)^{(d)}. example, component intercept parameter, (d)=[1,…,1]⊺^{(d)} = \\left[1, \\ldots, 1\\right]^\\intercal. component linear effect covariate zz (d)=[z1,…,zn]⊺^{(d)} = \\left[z_1, \\ldots, z_n\\right]^\\intercal. complicated effects, SPDE models, component design matrix maps latent Gaussian parameters predictor (also known “projector” matrix context). construction (d)^{(d)} handled automatically bru_mapper methods, define general (linear) component effects η(d)(u(d))=(d)u(d)\\eta^{(d)}(u^{(d)}) = ^{(d)} u^{(d)}. linear predictor defined η(u(1),…,u(D))=∑d=1Dη(d)(u(d))=∑d=1DA(d)u(d). \\eta(u^{(1)},\\dots,u^{(D)}) = \\sum_{d=1}^D \\eta^{(d)}(u^{(d)}) = \\sum_{d=1}^D ^{(d)} u^{(d)} .  Non-linear predictors defined R expressions component label denotes corresponding component effect.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"mapper-methods","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Mapper methods","title":"Defining model components","text":"component type associated method converting information given component definition component design matrix. full model design matrix used internally call INLA::inla() fit model. advantage specifying mapper methods supports automatic ‘stack building’. key feature inlabru full model stack constructed automatically component definitions. building blocks stack built using bru_mapper methods.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"mapper-example-2d-spde","dir":"Articles","previous_headings":"What is a component design matrix? > Mapper methods","what":"Mapper example: 2D SPDE","title":"Defining model components","text":"mapper 2D SPDE effect takes input 2-column matrix coordinates represent locations evaluate effect. parameters SPDE component defined mesh nodes may locations effect evaluated. appropriate weights required evaluate effect observation locations can constructed using fm_evaluator(). mapper model component takes information component definition, case minimum information required SPDE model object, 2-column matrix main evaluated . mapper calls fm_evaluator() appropriate arguments extracted information. (NOTE: Deliberately going huge detail ; bru_mapper vignette details.)","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"defining-main-group-and-replicate-","dir":"Articles","previous_headings":"What is a component design matrix?","what":"Defining main, group, and replicate.","title":"Defining model components","text":"arguments main, group, replicate can take general R expression input. expression evaluated environment consists named variables data (note: sp objects include column names @coords slot, include columns @data). names found data global environment searched objects name. example, suppose data columns named x y, 2D SPDE model component specified expression cbind(x,y) internally evaluated environment contains columns data, includes variables x y. full data object can accessed using .data. key-word. equivalent way define component keyword allows code written works arbitrarily named input data, rather hardcoding specific name dataset may change future. objects required evaluate R expression found data, global environment searched. allows users access objects global environment, data-structures may different dimension response data. avoids need pre-process everything single data.frame. functionality allowing general R expressions can used extend types data can passed bru(), like() lgcp() functions. basis support spatial data structures sp objects, also experimental support allow users pass data list. inlabru thus readily extendible, given appropriate functions extract relevant information component, associated mappers convert information component design matrix. addition three main inputs, optional weights argument also takes R expression, result used scale component. can used spatially varying coefficient models, weights argument provides covariate values.","code":"~ my_spde_effect(   cbind(x, y),   model = spde_model ) get_xy <- function(df) {   cbind(df$x, df$y) } ~ my_spde_effect(   get_xy(.data.),   model = spde_model )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"inlabru-specific-component-types","dir":"Articles","previous_headings":"What is a component design matrix?","what":"inlabru-specific component types","title":"Defining model components","text":"addition majority latent models can defined using INLA::f() function (see INLA::inla.list.models()$latent)), inlabru also following models: 'linear', 'fixed', 'offset', 'factor_full' 'factor_contrast').","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"shortcuts","dir":"Articles","previous_headings":"","what":"Shortcuts","title":"Defining model components","text":"shortcuts defining model components. Parameters predictor evaluations (intercept-like parameters). Using covariate stored sp Spatial* terra SpatRaster object. Defining linear effects using lm-style syntax. Behaviour main, group replicate function given arguments.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"intercept-like-components","dir":"Articles","previous_headings":"Shortcuts","what":"Intercept-like components","title":"Defining model components","text":"syntax can used shortcut n length predictor vector. Note shortcut makes assumption approriate length predictor. many models can easily deduced inspecting input data, always case, example response covariate data different dimensions joint likelihood models shared components.","code":"~ my_intercept(1) ~ my_intercept(   main = rep(1, n),   model = \"linear\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"spatial-covariates","dir":"Articles","previous_headings":"Shortcuts","what":"Spatial covariates","title":"Defining model components","text":"main, group, replicate, name sf, SpatRaster, Spatial* object stored global R environment, inlabru attempts something intelligent extracting covariate information locations data passed bru() like(). requires data sf SpatialPoints* object. inlabru calling inlabru::eval_spatial() method, supports several covariate storage types. shortcut internally calls eval_spatial() equivalent Note requires a_spatial_object stored global R environment (environment associated model definition code) findable expression internally evaluated inlabru. Also note eval_spatial() function default extracts first column raster object. general situations, one can either specify optional main_layer argument extract another named indexed column, directly use main = eval_spatial(a_spatial_object, .data., layer = some_layer). Note assumes data either sf, st_geometry(.data.) retrieves point locations, sp coordinates(.data.) retrieves coordinates. might sensible thing models! example, input data SpatialPolygonsDataFrame coordinates(.data.) returns centroid polygon. specific input type support developed, support sp gradually deprecated favour sf terra, special cases may given precise meaning. example, a_spatial_object may sf sp polygon object data columns, interpreted spatially piecewise constant covariate.","code":"~ my_sp_effect(   main = a_spatial_object,   model = \"linear\" ) ~ my_sp_effect(   main = eval_spatial(a_spatial_object, .data.),   model = \"linear\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"lm-style-fixed-effect-and-interaction-syntax","dir":"Articles","previous_headings":"Shortcuts","what":"lm-style fixed effect and interaction syntax","title":"Defining model components","text":"Since inlabru version 2.5.0, feature added allow users specify linear fixed effects using formula input. uses model = 'fixed' component type. basic component input model matrix. Alternatively, one can supply formula specification, used generate model matrix automatically, MatrixModels::model.Matrix(formula, data = .data.). want different kind model matrix construction, replace ~ x1 + x2 R code generates needed matrix, using .data. object input. Example syntax: equvalent data columns named x1, x2, x3, x4. allows users define interactions concise way, utilising functionality already supported MatrixModels package. formula interpreted conventional way, x1:x2 interaction covariates x1 x2, including individual fixed effects, x3 * x4 interaction x3 x4 inclusive individual fixed effects x3 x4. Note implementation technical reasons, estimated parameters appear 'summary.random' instead normal 'summary.fixed' part inla/bru output object. alternative using shortcut user define name individual components term formula.","code":"~ my_fixed_effects(   main = ~ x1:x2 + x3 * x4,   model = \"fixed\" ) ~ my_fixed_effects(   main = MatrixModels::model.Matrix(~ x1:x2 + x3 * x4, .data.),   model = \"fixed\" )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"a-function-given-with-no-arguments","dir":"Articles","previous_headings":"Shortcuts","what":"A function given with no arguments","title":"Defining model components","text":"main, group, replicate given function covariates, function applied data. example, equivalent ","code":"~ a_component(   main = a_function,   model = ... ) ~ a_component(   main = a_function(.data.),   model = ... )"},{"path":"https://inlabru-org.github.io/inlabru/articles/component.html","id":"non-linear-predictors","dir":"Articles","previous_headings":"Shortcuts","what":"Non-linear predictors","title":"Defining model components","text":"inlabru supports non-linear predictors, η̃(u,v)\\tilde{\\eta}(u,v) non-linear function ηu\\eta_u ηv\\eta_v. important note mapping component effect vector ηu=(u)u\\eta_u=^{(u)} u happens non-linear function applied. , example, η̃(u,v)=exp(ηu+ηv)\\tilde{\\eta}(u,v) = \\exp(\\eta_u + \\eta_v) evaluated exp((u)u+(v)v)\\exp(^{(u)} u + ^{(v)} v).","code":""},{"path":[]},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/articles/devel_flow.html","id":"component-input-evaluation","dir":"Articles","previous_headings":"","what":"Component input evaluation","title":"Devel: Model evaluation flowchart","text":"<label> main, group, replicate, weights, given expression expr evaluated data context, producing input component mapper. spatial covariate inputs, corresponding <label>_layer expression also evaluated. Red nodes indicate deprecated behaviour retained backwards compatibility.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/devel_flow.html","id":"intergration-point-construction","dir":"Articles","previous_headings":"","what":"Intergration point construction","title":"Devel: Model evaluation flowchart","text":"Flow diagram new integration scheme construction, implemented fm_int(domain, samplers) methods.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"a-small-toy-problem","dir":"Articles","previous_headings":"","what":"A small toy problem","title":"Nonlinear model approximation","text":"Hierarchical model: λ∼𝖤𝗑𝗉(γ)(yi|λ)∼𝖯𝗈(λ), independent across =1,…,n \\begin{aligned} \\lambda &\\sim \\mathsf{Exp}(\\gamma) \\\\ (y_i|\\lambda) &\\sim \\mathsf{Po}(\\lambda), \\text{ independent across $=1,\\dots,n$} \\end{aligned}  y¯=1n∑=1nyi\\overline{y}=\\frac{1}{n}\\sum_{=1}^n y_i, posterior density p(λ|{yi})∝p(λ,y1,…,yn)∝exp(−γλ)exp(−nλ)λny¯=exp{−(γ+n)λ}λny¯, \\begin{aligned} p(\\lambda | \\{y_i\\}) &\\propto p(\\lambda, y_1,\\dots,y_n) \\\\ &\\propto \\exp(-\\gamma\\lambda) \\exp(-n\\lambda) \\lambda^{n\\overline{y}} \\\\ &= \\exp\\{-(\\gamma+n)\\lambda\\} \\lambda^{n\\overline{y}}, \\end{aligned}  density 𝖦𝖺(α=1+ny¯,β=γ+n)\\mathsf{Ga}(\\alpha = 1+n\\overline{y}, \\beta = \\gamma+n) distribution.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"latent-gaussian-predictor-version","dir":"Articles","previous_headings":"","what":"Latent Gaussian predictor version","title":"Nonlinear model approximation","text":"Introducing latent Gaussian variable u∼𝖭(0,1)u\\sim\\mathsf{N}(0,1), model can reformulated λ(u)=−ln{1−Φ(u)}/γ(yi|u)∼𝖯𝗈(λ(u)) \\begin{aligned} \\lambda(u) &=-\\ln\\{1-\\Phi(u)\\}/\\gamma \\\\ (y_i|u) &\\sim \\mathsf{Po}(\\lambda(u)) \\end{aligned}  need derivatives λ\\lambda respect uu: ∂λ(u)∂u=1γϕ(u)1−Φ(u)=λ′(u)∂2λ(u)∂u2=−1γϕ(u)1−Φ(u)(u+ϕ(u)1−Φ(u))=−λ′(u){u−γλ′(u)}∂lnλ(u)∂u=1λ(u)∂λ(u)∂u=1−ln{1−Φ(u)}ϕ(u)1−Φ(u)=λ′(u)λ(u)∂2lnλ(u)∂u2=1λ(u)∂2λ(u)∂u2−1λ(u)2(∂λ(u)∂u)2=−λ′(u){u−γλ′(u)}λ(u)−λ′(u)2λ(u)2=−λ′(u)λ(u){u−γλ′(u)+λ′(u)λ(u)} \\begin{aligned} \\frac{\\partial\\lambda(u)}{\\partial u} &= \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)}   = \\lambda'(u) \\\\ \\frac{\\partial^2\\lambda(u)}{\\partial u^2} &= - \\frac{1}{\\gamma}\\frac{\\phi(u)}{1-\\Phi(u)} \\left( u + \\frac{\\phi(u)}{1-\\Phi(u)} \\right) = -\\lambda'(u)\\left\\{u-\\gamma\\lambda'(u)\\right\\} \\\\ \\frac{\\partial\\ln\\lambda(u)}{\\partial u} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial\\lambda(u)}{\\partial u}   =\\frac{1}{-\\ln\\{1-\\Phi(u)\\}} \\frac{\\phi(u)}{1-\\Phi(u)}   = \\frac{\\lambda'(u)}{\\lambda(u)} \\\\ \\frac{\\partial^2\\ln\\lambda(u)}{\\partial u^2} &=   \\frac{1}{\\lambda(u)} \\frac{\\partial^2\\lambda(u)}{\\partial u^2}   -\\frac{1}{\\lambda(u)^2} \\left(\\frac{\\partial\\lambda(u)}{\\partial u}\\right)^2   = \\frac{-\\lambda'(u)\\{u - \\gamma\\lambda'(u)\\}}{\\lambda(u)}   - \\frac{\\lambda'(u)^2}{\\lambda(u)^2}\\\\   &= -\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{   u - \\gamma\\lambda'(u) +\\frac{\\lambda'(u)}{\\lambda(u)}   \\right\\} \\end{aligned}","code":"lambda <- function(u, gamma) {   -pnorm(u, lower.tail = FALSE, log.p = TRUE) / gamma } lambda_inv <- function(lambda, gamma) {   qnorm(-lambda * gamma, lower.tail = FALSE, log.p = TRUE) } D1lambda <- function(u, gamma) {   exp(dnorm(u, log = TRUE) - pnorm(u, lower.tail = FALSE, log.p = TRUE)) / gamma } D2lambda <- function(u, gamma) {   D1L <- D1lambda(u, gamma)   -D1L * (u - gamma * D1L) } D1log_lambda <- function(u, gamma) {   D1lambda(u, gamma) / lambda(u, gamma) } D2log_lambda <- function(u, gamma) {   D1logL <- D1log_lambda(u, gamma)   -D1logL * (u - gamma * D1lambda(u, gamma = gamma) + D1logL) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"latent-gaussian-posterior-approximations","dir":"Articles","previous_headings":"","what":"Latent Gaussian posterior approximations","title":"Nonlinear model approximation","text":"basic approximation posterior distribution λ\\lambda given yy can defined deterministic transformation Gaussian distribution obtained 2nd order Taylor approximation lnp(u|{yi})\\ln p(u|\\{y_i\\}) posterior mode u0u_0 p(u|{yi})p(u|\\{y_i\\}). needed derivatives ∂lnp(u|{yi})∂u=∂lnϕ(u)∂u−nλ′(u)+ny¯λ′(u)λ(u)=−u+nλ′(u)λ(u){y¯−λ(u)}∂2lnp(u|{yi})∂u2=−1−nλ′(u)λ(u){u−γλ′(u)+λ′(u)λ(u)}{y¯−λ(u)}−nλ′(u)2λ(u) \\begin{aligned} \\frac{\\partial\\ln p(u|\\{y_i\\})}{\\partial u} &= \\frac{\\partial\\ln\\phi(u)}{\\partial u} - n\\lambda'(u) + n\\overline{y}\\frac{\\lambda'(u)}{\\lambda(u)} = -u + n\\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ \\overline{y} - \\lambda(u) \\right\\} \\\\ \\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2} &= -1 - n \\frac{\\lambda'(u)}{\\lambda(u)}\\left\\{ u - \\gamma\\lambda'(u) + \\frac{\\lambda'(u)}{\\lambda(u)} \\right\\} \\left\\{ \\overline{y} - \\lambda(u) \\right\\} - n \\frac{\\lambda'(u)^2}{\\lambda(u)} \\end{aligned}  mode u0u_0, first order derivative zero, ∂2lnp(u|{yi})∂u2|u=u0=−1−{u0−γλ′(u0)+λ′(u0)λ(u0)}u0−nλ′(u0)2λ(u0). \\begin{aligned} \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - \\left\\{ u_0 - \\gamma\\lambda'(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\right\\} u_0 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned}  quadratic approximation log-posterior density mode u0u_0 lnp̆(u|{yi})=const−(u−u0)22[−∂2lnp(u|{yi})∂u2|u=u0] \\ln \\breve{p}(u|\\{y_i\\}) = \\text{const} - \\frac{(u-u_0)^2}{2} \\left[ - \\left.\\frac{\\partial^2\\ln p(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} \\right]  inlabru, approximation first linearises lnλ(u)\\ln \\lambda(u) u0u_0 applying Taylor approximation lnp(u|{yi})\\ln p(u|\\{y_i\\}). linearised log-predictor lnλ¯(u)=lnλ(u0)+λ′(u0)λ(u0)(u−u0) \\ln \\overline{\\lambda}(u) = \\ln \\lambda(u_0) + \\frac{\\lambda'(u_0)}{\\lambda(u_0)}(u - u_0)  λ¯′(u)=λ′(u0)λ(u0)λ¯(u) \\overline{\\lambda}'(u) = \\frac{\\lambda'(u_0)}{\\lambda(u_0)} \\overline{\\lambda}(u)  second order derivative linearised log-posterior density ∂2lnp¯(u|{yi})∂u2|u=u0=−1−nλ′(u0)2λ(u0). \\begin{aligned} \\left.\\frac{\\partial^2\\ln \\overline{p}(u|\\{y_i\\})}{\\partial u^2}\\right|_{u=u_0} &= -1 - n \\frac{\\lambda'(u_0)^2}{\\lambda(u_0)} . \\end{aligned}","code":"log_p <- function(u, y, gamma) {   L <- lambda(u, gamma)   n <- length(y)   dnorm(u, log = TRUE) - n * L + n * mean(y) * log(L) - sum(lgamma(y + 1)) } D1log_p <- function(u, y, gamma) {   n <- length(y)   -u + n * D1log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) } D2log_p <- function(u, y, gamma) {   n <- length(y)   -1 +     n * D2log_lambda(u, gamma) * (mean(y) - lambda(u, gamma)) -     n * D1log_lambda(u, gamma) * D1lambda(u, gamma) } g <- 1 y <- c(0, 1, 2) y <- c(0, 0, 0, 0, 0) y <- rpois(5, 5) mu_quad <- uniroot(   D1log_p,   lambda_inv((1 + sum(y)) / (g + length(y)) * c(1 / 10, 10), gamma = g),   y = y, gamma = g )$root sd_quad <- (-D2log_p(mu_quad, y = y, gamma = g))^-0.5 sd_lin <- (1 + length(y) * D1log_lambda(mu_quad, gamma = g)^2 * lambda(mu_quad, gamma = g))^-0.5 lambda0 <- lambda(mu_quad, gamma = g)"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"posterior-densities","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior densities","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(lambda_inv(x, gamma = g), y = y, gamma = g)) /         D1lambda(lambda_inv(x, gamma = g), gamma = g) / (           exp(log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) /             D1lambda(lambda_inv(lambda0, gamma = g), gamma = g)         ) *         dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin) /         D1lambda(lambda_inv(x, gamma = g), gamma = g)     },     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = (1 + sum(y)) / (g + length(y)),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"Density\") +   geom_function(     fun = function(x) {       exp(log_p(x, y = y, gamma = g) -         log_p(lambda_inv(lambda0, gamma = g), y = y, gamma = g)) *         (dgamma(lambda0, shape = 1 + sum(y), rate = g + length(y)) *           D1lambda(lambda_inv(lambda0, gamma = g), gamma = g))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       dgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y)) *         D1lambda(x, gamma = g)     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = dnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),     gamma = g   ), lty = \"Bayes mean\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(lambda0, gamma = g), lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = lambda_inv(mean(y), gamma = g), lty = \"Plain mean\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/linearapprox.html","id":"posterior-cdfs","dir":"Articles","previous_headings":"Latent Gaussian posterior approximations","what":"Posterior CDFs","title":"Nonlinear model approximation","text":"","code":"ggplot() +   xlim(     lambda(mu_quad - 4 * sd_quad, gamma = g),     lambda(mu_quad + 4 * sd_quad, gamma = g)   ) +   xlab(\"lambda\") +   ylab(\"CDF\") +   geom_function(     fun = pgamma,     args = list(shape = 1 + sum(y), rate = g + length(y)),     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_quad)     },     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = function(x) {       pnorm(lambda_inv(x, gamma = g), mean = mu_quad, sd = sd_lin)     },     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = (1 + sum(y)) / (g + length(y)),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(xintercept = lambda0, lty = \"Bayes mode\")) +   geom_vline(mapping = aes(xintercept = mean(y), lty = \"Plain mean\")) ggplot() +   xlim(     lambda_inv(lambda0, gamma = g) - 4 * sd_quad,     lambda_inv(lambda0, gamma = g) + 4 * sd_quad   ) +   xlab(\"u\") +   ylab(\"CDF\") +   geom_function(     fun = function(x) {       pgamma(lambda(x, gamma = g), shape = 1 + sum(y), rate = g + length(y))     },     mapping = aes(col = \"Theory\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_quad),     mapping = aes(col = \"Quadratic\"),     n = 1000   ) +   geom_function(     fun = pnorm,     args = list(mean = mu_quad, sd = sd_lin),     mapping = aes(col = \"Linearised\"),     n = 1000   ) +   geom_vline(mapping = aes(     xintercept = lambda_inv((1 + sum(y)) / (g + length(y)),       gamma = g     ),     lty = \"Bayes mean\"   )) +   geom_vline(mapping = aes(     xintercept = lambda_inv(lambda0, gamma = g),     lty = \"Bayes mode\"   )) +   geom_vline(mapping = aes(     xintercept = lambda_inv(mean(y), gamma = g),     lty = \"Plain mean\"   ))"},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"traditional INLA code involving inla.mesh objects inla.spde models, inla.spde.make.() function used construct component design matrix maps spatial/spatio-temporal locations latent variables associated mesh basis functions. 2-manifold meshes, flat spherical meshes, implementation one latent variable per mesh node, linked piecewise linear basis functions mesh triangles. 1-manifolds intervals cyclic domains, piecewise linear piecewise quadratic basis functions supported. inla.spde.make.() interface supports variety features, can broken simple building blocks. inlabru bru_mapper system, building blocks easily customised specific uses, aren’t necessarily connected spde models, block feature used aggregate rows design matrix, e.g. construct numerical integration schemes. haven’t already, go read bru_mapper vignette information various bru_mapper classes methods. come back continue.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"converting-the-basic-inla-spde-make-a-calls-into-mappers","dir":"Articles","previous_headings":"","what":"Converting the basic inla.spde.make.A calls into mappers","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"basic inla.spde.make.call map purely spatial points mesh:  basic conversion becomes limited just basic case evaluating mesh. bru_mapper, becomes generally useful","code":"mesh <- fm_mesh_2d_inla(cbind(0, 0), offset = 2, max.edge = 10) loc <- matrix(runif(10) * 2 - 1, 5, 2) ggplot() +   geom_fm(data = mesh) +   geom_point(aes(loc[, 1], loc[, 2])) #> Warning in fm_as_sfc.fm_segm(data): fm_as_sfc currently only supports #> (multi)linestring output A.loc <- inla.spde.make.A(mesh, loc = loc) A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631 A.loc <- fm_basis(mesh, loc = loc) A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631 mapper <- bru_mapper(mesh) A.loc <- ibm_jacobian(mapper, input = loc) A.loc #> 5 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                           #> [1,] . 0.29227293 0.09984048 .         .          .         . . 0.6078866 #> [2,] . 0.02324195 0.36614606 .         .          .         . . 0.6106120 #> [3,] . .          0.11935641 0.1416259 .          .         . . 0.7390177 #> [4,] . .          .          0.3522410 0.08180227 .         . . 0.5659568 #> [5,] . .          .          .         0.19233634 0.2974006 . . 0.5102631"},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"mapping-with-a-precomputed-location-mapping","dir":"Articles","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Mapping with a precomputed location mapping","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"","code":"index <- c(1, 3, 5, 2, 1, 2) inla.spde.make.A(A.loc = A.loc, index = index) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120  mapper <- bru_mapper_taylor(jacobian = A.loc[index, , drop = FALSE]) ibm_jacobian(mapper) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120  # For run-time indexing: mapper <-   bru_mapper_pipe(     list(       matrix = bru_mapper_taylor(jacobian = A.loc),       index = bru_mapper_index(nrow(A.loc))     )   ) ibm_jacobian(mapper, input = list(index = index)) #> 6 x 9 sparse Matrix of class \"dgCMatrix\" #>                                                                          #> [1,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [2,] . .          0.11935641 0.1416259 .         .         . . 0.7390177 #> [3,] . .          .          .         0.1923363 0.2974006 . . 0.5102631 #> [4,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120 #> [5,] . 0.29227293 0.09984048 .         .         .         . . 0.6078866 #> [6,] . 0.02324195 0.36614606 .         .         .         . . 0.6106120"},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"group-mapping-with-a-group-mesh","dir":"Articles","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Group mapping with a group mesh","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"","code":"inla.spde.make.A(..., group = group.values, group.mesh = group.mesh)  mapper <- bru_mapper_multi(list(   main = bru_mapper(mesh),   group = bru_mapper(group.mesh) )) ibm_jacobian(mapper, input = list(main = loc, group = group.values))"},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"blockwise-aggregation","dir":"Articles","previous_headings":"Converting the basic inla.spde.make.A calls into mappers","what":"Blockwise aggregation","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"Blockwise aggregation can implemented bru_mapper_aggregate mapper. Rescaling options: block_rescale = \"none\" corresponds rescale = FALSE block_rescale = \"count\" corresponds rescale = TRUE providing weights, interpreted weights 1, rescaling sum weights equivalent dividing number elements block. block_rescale = \"weights\" corresponds rescale = TRUE block_rescale = \"sum\" supported aggregation mapper.","code":"block_rescale <- \"none\" # one of \"none\", \"count\", \"weights\", \"sum\" inla.spde.make.A(...,   weights = weights,   block = block,   block.rescale = block_rescale,   n.block = n_block ) mapper <- bru_mapper_pipe(   list(     main = bru_mapper_multi(list(main = bru_mapper(mesh), ...)),     block = bru_mapper_aggregate(       rescale = (block_rescale != \"none\"),       n_block = n_block     )   ) ) ibm_jacobian(mapper,   input = list(     main = list(main = loc),     block = list(block = block, weights = weights)   ) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/mesh_mapping.html","id":"inla-spde-make-index","dir":"Articles","previous_headings":"","what":"inla.spde.make.index","title":"Converting inla.spde.make.A calls into the bru_mapper system","text":"benefit mapper approach encapsulates information, mapper needs carried around code needs , doesn’t restrict group replicate mappings integer indices; index mappers can replaced mappers, e.g. allow interpolation group indices, 1d mesh mapper.","code":"ngroup <- 2 nrepl <- 3  summary(   as.data.frame(     inla.spde.make.index(\"field\",       n.spde = mesh$n,       n.group = ngroup,       n.repl = nrepl     )   ) ) #>      field    field.group    field.repl #>  Min.   :1   Min.   :1.0   Min.   :1    #>  1st Qu.:3   1st Qu.:1.0   1st Qu.:1    #>  Median :5   Median :1.5   Median :2    #>  Mean   :5   Mean   :1.5   Mean   :2    #>  3rd Qu.:7   3rd Qu.:2.0   3rd Qu.:3    #>  Max.   :9   Max.   :2.0   Max.   :3  mapper <- bru_mapper_multi(list(   field.main = bru_mapper(mesh),   field.group = bru_mapper_index(ngroup),   field.replicate = bru_mapper_index(nrepl) )) summary(ibm_values(mapper, multi = TRUE, inla_f = TRUE)) #>    field.main  field.group  field.replicate #>  Min.   :1    Min.   :1.0   Min.   :1       #>  1st Qu.:3    1st Qu.:1.0   1st Qu.:1       #>  Median :5    Median :1.5   Median :2       #>  Mean   :5    Mean   :1.5   Mean   :2       #>  3rd Qu.:7    3rd Qu.:2.0   3rd Qu.:3       #>  Max.   :9    Max.   :2.0   Max.   :3"},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"the-inla-method-for-linear-predictors","dir":"Articles","previous_headings":"","what":"The INLA method for linear predictors","title":"Iterative linearised INLA method","text":"INLA method used compute fast approximative posterior distribution Bayesian generalised additive models. hierarchical structure model latent Gaussian components 𝐮\\boldsymbol{u}, covariance parameters 𝛉\\boldsymbol{\\theta}, measured response variables 𝐲\\boldsymbol{y}, can written 𝛉∼p(𝛉)𝐮|𝛉∼𝒩(𝛍u,𝐐(𝛉)−1)𝛈(𝐮)=𝐀𝐮𝐲|𝐮,𝛉∼p(𝐲|𝛈(𝐮),𝛉) \\begin{aligned} \\boldsymbol{\\theta} &\\sim p(\\boldsymbol{\\theta}) \\\\ \\boldsymbol{u}|\\boldsymbol{\\theta} &\\sim \\mathcal{N}\\!\\left(\\boldsymbol{\\mu}_u, \\boldsymbol{Q}(\\boldsymbol{\\theta})^{-1}\\right) \\\\ \\boldsymbol{\\eta}(\\boldsymbol{u}) &= \\boldsymbol{}\\boldsymbol{u} \\\\ \\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta} & \\sim p(\\boldsymbol{y}|\\boldsymbol{\\eta}(\\boldsymbol{u}),\\boldsymbol{\\theta}) \\end{aligned}  typically linear predictor element, ηi(𝐮)\\eta_i(\\boldsymbol{u}), linked location parameter distribution observation yiy_i, ii, via (non-linear) link function g−1(⋅)g^{-1}(\\cdot). R-INLA implementation, observations assumed conditionally independent, given 𝛈\\boldsymbol{\\eta} 𝛉\\boldsymbol{\\theta}.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"approximate-inla-for-non-linear-predictors","dir":"Articles","previous_headings":"","what":"Approximate INLA for non-linear predictors","title":"Iterative linearised INLA method","text":"premise inlabru method non-linear predictors build existing implementation, add linearisation step. properties resulting approximation depend nature non-linearity. Let 𝛈̃(𝐮)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}) non-linear predictor, .e. deterministic function 𝐮\\boldsymbol{u}, 𝛈̃(𝐮)=𝖿𝖼𝗇(𝐮), \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}) = \\textsf{fcn} (\\boldsymbol{u}),  let 𝛈¯(𝐮)\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}) 1st order Taylor approximation 𝐮0\\boldsymbol{u}_0, 𝛈¯(𝐮)=𝛈̃(𝐮0)+𝐁(𝐮−𝐮0)=[𝛈̃(𝐮0)−𝐁𝐮0]+𝐁𝐮, \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}) = \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) + \\boldsymbol{B}(\\boldsymbol{u} - \\boldsymbol{u}_0) = \\left[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0) - \\boldsymbol{B}\\boldsymbol{u}_0\\right] + \\boldsymbol{B}\\boldsymbol{u} ,  𝐁\\boldsymbol{B} derivative matrix non-linear predictor, evaluated 𝐮0\\boldsymbol{u}_0. Hence, define 𝐲|𝐮,𝛉=d𝐲|𝛈̃(𝐮),𝛉∼p(𝐲|g−1[𝛈̃(𝐮)],𝛉) \\begin{aligned} \\boldsymbol{y} | \\boldsymbol{u}, {\\boldsymbol{\\theta}} &\\overset{d}{=} \\boldsymbol{y} | \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}), {\\boldsymbol{\\theta}} \\\\ &\\sim p (\\boldsymbol{y} | g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})], {\\boldsymbol{\\theta}})\\\\ \\end{aligned}  non-linear observation model p(𝐲|g−1[𝛈̃(𝐮)],𝛉)p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) approximated replacing non-linear predictor linearisation, linearised model defined p¯(𝐲|𝐮,𝛉)=p(𝐲|𝛈¯(𝐮),𝛉)=p(𝐲|g−1[𝛈¯(𝐮)],𝛉)≈p(𝐲|g−1[𝛈̃(𝐮)],𝛉)=p(𝐲|𝛈̃(𝐮),𝛉)=p̃(𝐲|𝐮,𝛉) \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|g^{-1}[\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) \\approx p(\\boldsymbol{y}|g^{-1}[\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u})],\\boldsymbol{\\theta}) = p(\\boldsymbol{y}|\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}),\\boldsymbol{\\theta}) = \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})  non-linear model posterior factorised p̃(𝛉,𝐮|𝐲)=p̃(𝛉|𝐲)p̃(𝐮|𝐲,𝛉), \\widetilde{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\widetilde{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}),  linear model approximation factorised p¯(𝛉,𝐮|𝐲)=p¯(𝛉|𝐲)p¯(𝐮|𝐲,𝛉). \\overline{p}(\\boldsymbol{\\theta},\\boldsymbol{u}|\\boldsymbol{y}) = \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"fixed-point-iteration","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors","what":"Fixed point iteration","title":"Iterative linearised INLA method","text":"remaining step approximation choose linearisation point 𝐮*\\boldsymbol{u}_*. given linearisation point 𝐯\\boldsymbol{v}, INLA compute posterior mode 𝛉\\boldsymbol{\\theta}, 𝛉̂𝐯=arg max𝛉p¯𝐯(𝛉|𝐲), \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} \\overline{p}_\\boldsymbol{v} ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ),  joint conditional posterior mode 𝐮\\boldsymbol{u}, 𝐮̂𝐯=arg max𝐮p¯𝐯(𝐮|𝐲,𝛉̂𝐯). \\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} \\overline{p}_\\boldsymbol{v} ( \\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}} ) . Define Bayesian estimation functional1 f(p¯𝐯)=(𝛉̂𝐯,𝐮̂𝐯) f(\\overline{p}_{\\boldsymbol{v}}) = (\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{v}},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{v}})  let f(p)=(𝛉̂,𝐮̂)f(p)=(\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}}) denote corresponding posterior modes true posterior distribution, 𝛉̂=arg max𝛉p(𝛉|𝐲),𝐮̂=arg max𝐮p(𝐮|𝐲,𝛉̂). \\begin{aligned}     \\widehat{{\\boldsymbol{\\theta}}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} p ( {\\boldsymbol{\\theta}} | \\boldsymbol{y} ), \\\\     \\widehat{\\boldsymbol{u}} &= \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{{\\boldsymbol{\\theta}}}). \\end{aligned} fixed point (𝛉*,𝐮*)=f(p¯𝐮*)(\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*}) ideally close (𝛉̂,𝐮̂)(\\widehat{\\boldsymbol{\\theta}},\\widehat{\\boldsymbol{u}}), .e. close true marginal/conditional posterior mode. can achieve conditional latent mode, 𝐮*=arg max𝐮p(𝐮|𝐲,𝛉̂𝐮*)\\boldsymbol{u}_*=\\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{u}} p (\\boldsymbol{u} | \\boldsymbol{y}, \\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*}). therefore seek latent vector 𝐮*\\boldsymbol{u}_* generates fixed point functional, (𝛉*,𝐮*)=f(p¯𝐮*)(\\boldsymbol{\\theta}_*,\\boldsymbol{u}_*)=f(\\overline{p}_{\\boldsymbol{u}_*}). One key fixed point iteration observation model linked 𝐮\\boldsymbol{u} non-linear predictor 𝛈̃(𝐮)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}), since leads simplified line search method . Let 𝐮0\\boldsymbol{u}_0 initial linearisation point latent variables obtained initial INLA call. Iterate following steps k=0,1,2,...k=0,1,2,... Compute predictor linearisation 𝐮0\\boldsymbol{u}_0. Compute linearised INLA posterior p¯𝐮0(𝛉|𝐲)\\overline{p}_{\\boldsymbol{u}_0}(\\boldsymbol{\\theta}|\\boldsymbol{y}). Let (𝛉1,𝐮1)=(𝛉̂𝐮0,𝐮̂𝐮0)=f(p¯𝐮0)(\\boldsymbol{\\theta}_1,\\boldsymbol{u}_1)=(\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_0},\\widehat{\\boldsymbol{u}}_{\\boldsymbol{u}_0})=f(\\overline{p}_{\\boldsymbol{u}_0}) initial candidate new linearisation point. Let 𝐯α=(1−α)𝐮1+α𝐮0\\boldsymbol{v}_\\alpha=(1-\\alpha)\\boldsymbol{u}_1+\\alpha\\boldsymbol{u}_0, find value α\\alpha minimises ∥η̃(𝐯α)−η¯(𝐮1)∥\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\|. Set new linearisation point 𝐮0\\boldsymbol{u}_0 equal 𝐯α\\boldsymbol{v}_\\alpha repeat step 1, unless iteration converged given tolerance. potential improvement step 4 might also take account prior distribution 𝐮\\boldsymbol{u} minimisation penalty, avoid moving indicated full likelihood optimisation.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"line-search","dir":"Articles","previous_headings":"Approximate INLA for non-linear predictors > Fixed point iteration","what":"Line search","title":"Iterative linearised INLA method","text":"step 4, ideally want α\\alpha bearg maxα[lnp(𝐮|𝐲,𝛉1)]𝐮=𝐯α. \\mathop{\\mathrm{arg\\,max}}_{\\alpha} \\left[\\ln p(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)\\right]_{\\boldsymbol{u}=\\boldsymbol{v}_\\alpha}.  However, since requires access internal likelihood prior density evaluation code, instead use simpler alternative. consider norms form ∥η̃(𝐯α)−η¯(𝐮1)∥\\|\\widetilde{\\eta}(\\boldsymbol{v}_\\alpha)-\\overline{\\eta}(\\boldsymbol{u}_1)\\| depend nonlinear linearised predictor expressions, known quantities, given 𝐮0\\boldsymbol{u}_0, current INLA estimate component wise predictor variances. Let σi2=Var𝐮∼p¯(𝐮|𝐲,𝛉1)(𝛈¯(𝐮))\\sigma_i^2 = \\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}_1)}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})) current estimate posterior variance predictor element ii. define inner product space predictor vectors ⟨𝐚,𝐛⟩V=∑iaibiσi2. \\langle \\boldsymbol{},\\boldsymbol{b} \\rangle_V = \\sum_i \\frac{a_i b_i}{\\sigma_i^2} .  squared norm difference predictor vectors 𝛈̃(𝐯α)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha) 𝛈¯(𝐮1)\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1),respect inner product, defined ∥𝛈̃(𝐯α)−𝛈¯(𝐮1)∥V2=∑|𝛈̃(𝐯α)−𝛈¯(𝐮1)|2σi2. \\| \\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1)\\|^2_V = \\sum_i \\frac{|\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{v}_\\alpha)-\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}_1)|^2}{\\sigma_i^2} .  Using norm target loss function line search avoids many potentially expensive evaluations true posterior conditional log-density. evaluate 𝛈̃1=𝛈̃(𝐮1)\\widetilde{\\boldsymbol{\\eta}}_1=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1) make use linearised predictor information. Let 𝛈̃α=𝛈̃(𝐯α)\\widetilde{\\boldsymbol{\\eta}}_\\alpha=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha) 𝛈¯α=𝛈¯(𝐯α)=(1−α)𝛈̃(𝐮0)+α𝛈¯(𝐮1)\\overline{\\boldsymbol{\\eta}}_\\alpha=\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{v}_\\alpha)=(1-\\alpha)\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_0)+\\alpha\\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_1). words, α=0\\alpha=0 corresponds previous linear predictor, α=1\\alpha=1 current estimate INLA. exact line search minimise ∥𝛈̃α−𝛈¯1∥\\|\\widetilde{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|. Instead, define quadratic approximation non-linear predictor function α\\alpha, 𝛈̆α=𝛈¯α+α2(𝛈̃1−𝛈¯1) \\breve{\\boldsymbol{\\eta}}_\\alpha = \\overline{\\boldsymbol{\\eta}}_\\alpha + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1)  minimise quartic polynomial α\\alpha, ∥𝛈̆α−𝛈¯1∥2=∥(α−1)(𝛈¯1−𝛈¯0)+α2(𝛈̃1−𝛈¯1)∥2. \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\alpha^2 (\\widetilde{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_1) \\|^2 . \\end{aligned}  initial expansion contraction steps carried , leading initial guess α=γk\\alpha=\\gamma^k, γ>1\\gamma>1 scaling factor (see ?bru_options, bru_method$factor) kk (signed) number expansions contractions, quadratic expression replaced ∥𝛈̆α−𝛈¯1∥2=∥(α−1)(𝛈¯1−𝛈¯0)+α2γ2k(𝛈̃γk−𝛈¯γk)∥2, \\begin{aligned} \\|\\breve{\\boldsymbol{\\eta}}_\\alpha-\\overline{\\boldsymbol{\\eta}}_1\\|^2 &= \\| (\\alpha-1)(\\overline{\\boldsymbol{\\eta}}_1 - \\overline{\\boldsymbol{\\eta}}_0) + \\frac{\\alpha^2}{\\gamma^{2k}} (\\widetilde{\\boldsymbol{\\eta}}_{\\gamma^k} - \\overline{\\boldsymbol{\\eta}}_{\\gamma^k}) \\|^2 , \\end{aligned}  minimised interval α∈[γk−1,γk+1]\\alpha\\[\\gamma^{k-1},\\gamma^{k+1}].","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"posterior-non-linearity-checks","dir":"Articles","previous_headings":"","what":"Posterior non-linearity checks","title":"Iterative linearised INLA method","text":"Whereas inlabru optimisation method leads estimate ∥𝛈̃(𝐮*)−𝛈¯(𝐮*)∥=0\\| \\widetilde{\\boldsymbol{\\eta}} (\\boldsymbol{u}_*) - \\overline{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*)\\|=0 specific 𝐮*\\boldsymbol{u}_*, overall posterior approximation accuracy depends degree nonlinearity vicinity 𝐮*\\boldsymbol{u}_*. two main options evaluating nonlinearity, using sampling approximate posterior distribution. first option ∑iE𝐮∼p¯(𝐮|𝐲)[|𝛈¯(𝐮)−𝛈̃(𝐮)|2]Var𝐮∼p¯(𝐮|𝐲)(𝛈¯(𝐮)), \\begin{aligned} \\sum_i \\frac{E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}\\left[ |\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})-\\widetilde{\\boldsymbol{\\eta}}_i(\\boldsymbol{u})|^2\\right]}{\\mathrm{Var}_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y})}(\\overline{\\boldsymbol{\\eta}}_i(\\boldsymbol{u}))} , \\end{aligned}  posterior expectation component-wise variance-normalised squared deviation non-linear linearised predictor. Note normalising variance includes variability induced posterior uncertainty 𝛉\\boldsymbol{\\theta}, whereas ∥⋅∥V\\|\\cdot\\|_V norm used line search used posterior mode. Another option E(𝐮,𝛉)∼p¯(𝐮,𝛉|𝐲)[lnp¯(𝐮|𝐲,𝛉)p̃(𝐮|𝐲,𝛉)]=E𝛉∼p¯(𝛉|𝐲){E𝐮∼p¯(𝐮|𝐲,𝛉)[lnp¯(𝐮|𝐲,𝛉)p̃(𝐮|𝐲,𝛉)]} E_{(\\boldsymbol{u},\\boldsymbol{\\theta})\\sim \\overline{p}(\\boldsymbol{u},\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] = E_{\\boldsymbol{\\theta}\\sim \\overline{p}(\\boldsymbol{\\theta}|\\boldsymbol{y})} \\left\\{ E_{\\boldsymbol{u}\\sim \\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})} \\left[\\ln \\frac{\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},{\\boldsymbol{\\theta}})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}})}\\right] \\right\\}  Kullback–Leibler divergence conditional posterior densities, 𝖪𝖫(p¯∥p̃)\\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right), integrated approximate posterior distribution 𝛉\\boldsymbol{\\theta}. Implementing require access likelihood prior distribution details. next section explores detail.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"accuracy","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Accuracy","title":"Iterative linearised INLA method","text":"wish assess accurate approximation . Thus, compare p̃(𝐮|𝐲,𝛉)\\widetilde{p}(\\boldsymbol{u} | \\boldsymbol{y}, \\boldsymbol{\\theta} ) p¯(𝐮|𝐲,𝛉)\\overline{p}(\\boldsymbol{u} |\\boldsymbol{y},\\boldsymbol{\\theta}). Bayes’ theorem, p(𝐮|𝐲,𝛉)=p(𝐮,𝐲|𝛉)p(𝐲|𝛉)=p(𝐲|𝐮,𝛉)p(𝐮|𝛉)p(𝐲|𝛉), \\begin{aligned}     p(\\boldsymbol{u}|\\boldsymbol{y},{\\boldsymbol{\\theta}}) &= \\frac{p(\\boldsymbol{u},\\boldsymbol{y}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})} \\\\     &= \\frac{p(\\boldsymbol{y}|\\boldsymbol{u},{\\boldsymbol{\\theta}}) p(\\boldsymbol{u}|{\\boldsymbol{\\theta}})}{p(\\boldsymbol{y}|{\\boldsymbol{\\theta}})}, \\end{aligned}  p(𝐮|𝛉)p(\\boldsymbol{u}|\\boldsymbol{\\theta}) Gaussian density p(𝐲|𝛉)p(\\boldsymbol{y}|\\boldsymbol{\\theta}) scaling factor doesn’t depend 𝐮\\boldsymbol{u}. can therefore focus behaviour lnp(𝐲|𝛉,𝐮)\\ln p(\\boldsymbol{y}|\\boldsymbol{\\theta},\\boldsymbol{u}) exact linearised observation models. Recall observation likelihood depends 𝐮\\boldsymbol{u} 𝛈\\boldsymbol{\\eta}. Using Taylor expansion respect 𝛈\\boldsymbol{\\eta} 𝛈*=𝛈̃(𝐮*)\\boldsymbol{\\eta}^*=\\widetilde{\\boldsymbol{\\eta}}(\\boldsymbol{u}_*), lnp(𝐲|𝛈,𝛉)=lnp(𝐲|𝛉,𝛈*))+∑∂∂ηilnp(𝐲|𝛉,𝛈)|𝛈*⋅(ηi−ηi*)+12∑,j∂2∂ηi∂ηjlnp(𝐲|𝛉,𝛈)|𝛈*⋅(ηi−ηi*)(ηj−ηj*)+𝒪(∥𝛈−𝛈*∥3), \\begin{aligned}     \\ln p(\\boldsymbol{y}|\\boldsymbol{\\eta},\\boldsymbol{\\theta}) &=     \\ln p (\\boldsymbol{y}|{\\boldsymbol{\\theta}},\\boldsymbol{\\eta}^*))  \\\\      &\\qquad + \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) \\\\     &\\qquad + \\frac{1}{2}\\sum_{,j} \\left.\\frac{\\partial^2}{\\partial\\eta_i\\partial\\eta_j} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot (\\eta_i - \\eta^*_i) (\\eta_j - \\eta^*_j) + \\mathcal{O}(\\|\\boldsymbol{\\eta}-\\boldsymbol{\\eta}^*\\|^3), \\end{aligned}  Similarly, component 𝛈̃\\widetilde{\\boldsymbol{\\eta}}, η̃(𝐮)=ηi*+[∇uη̃(𝐮)|𝐮*]⊤(𝐮−𝐮*)+12(𝐮−𝐮*)⊤[∇u∇u⊤η̃(𝐮)|𝐮*](𝐮−𝐮*)+𝒪(∥𝐮−𝐮*∥3)=ηi*+bi(𝐮)+hi(𝐮)+𝒪(∥𝐮−𝐮*∥3)=η¯(𝐮)+hi(𝐮)+𝒪(∥𝐮−𝐮*∥3) \\begin{aligned} \\widetilde{\\eta}_i(\\boldsymbol{u}) &= \\eta^*_i  +\\left[\\left.\\nabla_{u}\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right]^\\top (\\boldsymbol{u} - \\boldsymbol{u}_*) \\\\&\\quad +\\frac{1}{2}(\\boldsymbol{u} - \\boldsymbol{u}_*)^\\top\\left[\\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*}\\right] (\\boldsymbol{u} - \\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}^*\\|^3) \\\\&= \\eta_i^* + b_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\\\&= \\overline{\\eta}_i(\\boldsymbol{u}) + h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned} ∇u∇u⊤\\nabla_u\\nabla_u^\\top Hessian respect 𝐮\\boldsymbol{u}, bib_i linear 𝐮\\boldsymbol{u}, hih_i quadratic 𝐮\\boldsymbol{u}. Combining two expansions taking difference full linearised log-likelihoods, get lnp̃(𝐲|𝐮,𝛉)−lnp¯(𝐲|𝐮,𝛉)=∑∂∂ηilnp(𝐲|𝛉,𝛈)|𝛈*⋅hi(𝐮)+𝒪(∥𝐮−𝐮*∥3) \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\sum_i \\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}\\cdot h_i(\\boldsymbol{u}) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3) \\end{aligned}  Note log-likelihood Hessian difference contribution involves third order 𝐮\\boldsymbol{u} terms higher, expression includes terms second order. Let gi*=∂∂ηilnp(𝐲|𝛉,𝛈)|𝛈* g_i^*=\\left.\\frac{\\partial}{\\partial\\eta_i} \\ln p (\\boldsymbol{y} | {\\boldsymbol{\\theta}}, \\boldsymbol{\\eta}) \\right|_{\\boldsymbol{\\eta}^*}  𝐇i*=∇u∇u⊤η̃(𝐮)|𝐮*. \\boldsymbol{H}^*_i = \\left.\\nabla_{u}\\nabla_{u}^\\top\\widetilde{\\eta}_i(\\boldsymbol{u})\\right|_{\\boldsymbol{u}_*} .  form sum products, 𝐆=∑igi*𝐇i*\\boldsymbol{G}=\\sum_i g_i^*\\boldsymbol{H}_i^*. lnp̃(𝐲|𝐮,𝛉)−lnp¯(𝐲|𝐮,𝛉)=12∑igi*(𝐮−𝐮*)⊤𝐇i*(𝐮−𝐮*)+𝒪(∥𝐮−𝐮*∥3)=12(𝐮−𝐮*)⊤𝐆(𝐮−𝐮*)+𝒪(∥𝐮−𝐮*∥3). \\begin{aligned}     \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})     &=     \\frac{1}{2}     \\sum_i g_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{H}_i^* (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3)     \\\\&=     \\frac{1}{2}     (\\boldsymbol{u}-\\boldsymbol{u}_*)^\\top \\boldsymbol{G} (\\boldsymbol{u}-\\boldsymbol{u}_*) + \\mathcal{O}(\\|\\boldsymbol{u}-\\boldsymbol{u}_*\\|^3). \\end{aligned}  𝐦=𝖤p¯(𝐮|𝐲,𝛉)\\boldsymbol{m}=\\mathsf{E}_\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}) 𝐐−1=𝖢𝗈𝗏p¯(𝐮,𝐮|𝐲,𝛉)\\boldsymbol{Q}^{-1}=\\mathsf{Cov}_\\overline{p}(\\boldsymbol{u},\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta}), obtain 𝖤p¯[∇𝐮{lnp̃(𝐲|𝐮,𝛉)−lnp¯(𝐲|𝐮,𝛉)}]≈𝐆(𝐦−𝐮*),𝖤p¯[∇𝐮∇𝐮⊤{lnp̃(𝐲|𝐮,𝛉)−lnp¯(𝐲|𝐮,𝛉)}]≈𝐆,𝖤p¯[lnp̃(𝐲|𝐮,𝛉)−lnp¯(𝐲|𝐮,𝛉)]≈12tr(𝐆𝐐−1)+12(𝐦−𝐮*)𝐆(𝐦−𝐮*)⊤. \\begin{aligned} \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right]  &\\approx     \\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[ \\nabla_{\\boldsymbol{u}}\\nabla_{\\boldsymbol{u}}^\\top  \\left\\{\\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right\\}\\right]  &\\approx     \\boldsymbol{G} ,     \\\\ \\mathsf{E}_{\\overline{p}}\\left[    \\ln \\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta}) -     \\ln \\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})\\right]  &\\approx     \\frac{1}{2}     \\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1}) + \\frac{1}{2} (\\boldsymbol{m}-\\boldsymbol{u}_*)\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top . \\end{aligned}  𝛉\\boldsymbol{\\theta} configuration INLA output, can extract 𝐦\\boldsymbol{m} sparse precision matrix 𝐐\\boldsymbol{Q} Gaussian approximation. non-sparsity structure 𝐆\\boldsymbol{G} contained non-sparsity 𝐐\\boldsymbol{Q}, allows use Takahashi recursion (inla.qinv(Q)) compute corresponding 𝐐−1\\boldsymbol{Q}^{-1} values needed evaluate trace tr(𝐆𝐐−1)\\mathop{\\mathrm{tr}}(\\boldsymbol{G}\\boldsymbol{Q}^{-1}). Thus, implement numerical approximation error analysis needs special access log-likelihood derivatives gi*g_i^*, Hi*H_i^* can principle evaluated numerically. given 𝛉\\boldsymbol{\\theta}, 𝖪𝖫(p¯∥p̃)=Ep¯[lnp¯(𝐮|𝐲,𝛉)p̃(𝐮|𝐲,𝛉)]=Ep¯[lnp¯(𝐲|𝐮,𝛉)p̃(𝐲|𝐮,𝛉)]−lnp¯(𝐲|𝛉)p̃(𝐲|𝛉). \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &= E_{\\overline{p}}\\left[\\ln\\frac{\\overline{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{u}|\\boldsymbol{y},\\boldsymbol{\\theta})}\\right] \\\\&= E_{\\overline{p}}\\left[ \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{u},\\boldsymbol{\\theta})} \\right] - \\ln\\frac{\\overline{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})}{\\widetilde{p}(\\boldsymbol{y}|\\boldsymbol{\\theta})} . \\end{aligned}  first term approximated . second term can also approximated using derived quantities (continued…). Summary: form observation likelihood discrepancy shows , given linearised posterior 𝖭(𝐦,𝐐−1)\\mathsf{N}(\\boldsymbol{m},\\boldsymbol{Q}^{-1}), Gaussian approximation nonlinear model posterior, 𝖭(𝐦̃,𝐐̃−1)\\mathsf{N}(\\widetilde{\\boldsymbol{m}},\\widetilde{\\boldsymbol{Q}}^{-1}), can obtained 𝐐̃=𝐐−𝐆\\widetilde{\\boldsymbol{Q}}=\\boldsymbol{Q}-\\boldsymbol{G} 𝐐̃𝐦̃=𝐐𝐦−𝐆𝐮*\\widetilde{\\boldsymbol{Q}}\\widetilde{\\boldsymbol{m}}=\\boldsymbol{Q}\\boldsymbol{m}-\\boldsymbol{G}\\boldsymbol{u}_*. K-L divergence becomes 𝖪𝖫(p¯∥p̃)≈12[lndet(𝐐)−lndet(𝐐−𝐆)−tr(𝐆𝐐−1)+(𝐦−𝐮*)⊤𝐆(𝐐−𝐆)−1𝐆(𝐦−𝐮*)]. \\begin{aligned} \\mathsf{KL}\\left(\\overline{p}\\,\\middle\\|\\,\\widetilde{p}\\right) &\\approx \\frac{1}{2} \\left[ \\ln\\det(\\boldsymbol{Q})- \\ln\\det(\\boldsymbol{Q}-\\boldsymbol{G}) -\\mathop{\\mathrm{tr}}\\left(\\boldsymbol{G}\\boldsymbol{Q}^{-1}\\right) + (\\boldsymbol{m}-\\boldsymbol{u}_*)^\\top\\boldsymbol{G}(\\boldsymbol{Q}-\\boldsymbol{G})^{-1}\\boldsymbol{G}(\\boldsymbol{m}-\\boldsymbol{u}_*) \\right] . \\end{aligned}  INLA posterior mean 𝐦=𝐮*\\boldsymbol{m}=\\boldsymbol{u}_*, e.g. models additive Gaussian observation noise, 𝛉=𝛉̂𝐮*\\boldsymbol{\\theta}=\\widehat{\\boldsymbol{\\theta}}_{\\boldsymbol{u}_*}, last term vanishes. Note: implementing K-L divergence accuracy metric, -product improved posterior estimates based 𝐦̃\\widetilde{\\boldsymbol{m}} 𝐐̃\\widetilde{\\boldsymbol{Q}}.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/method.html","id":"well-posedness-and-initialisation","dir":"Articles","previous_headings":"Posterior non-linearity checks","what":"Well-posedness and initialisation","title":"Iterative linearised INLA method","text":"side note, one might concerned initialisation , convergence , saddle point. Although implemented inlabru, want talk technicality define initial linearisation point u0u_0. Generally speaking, values 𝐮0\\boldsymbol{u}_0 work except case gradient evaluated 𝐮0\\boldsymbol{u}_0 𝟎\\boldsymbol{0} linearisation point never move away prior mean also 𝟎\\boldsymbol{0}. general, tends saddle point problem. cases problem can handled changing predictor parameterisation just changing initialisation point using bru_initial option. However, true saddle point problems, indicates predictor parameterisation may lead multimodal posterior distribution ill-posed way. fundamental problem fixed changing initialisation point. examples, β\\beta 𝐮\\boldsymbol{u} latent Gaussian components, predictors 1, 3, 4 typically safe, predictor 2 fundamentally non-identifiable. 𝛈1=𝐮,𝛈2=β𝐮,𝛈3=eβ𝐮,𝛈4=Fβ−1(Φ(zβ))𝐮,zβ∼𝖭(0,1).  \\begin{aligned} \\boldsymbol{\\eta}_1 &= \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_2 &= \\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_3 &= e^\\beta \\boldsymbol{u}, \\\\ \\boldsymbol{\\eta}_4 &= F_\\beta^{-1} ( \\Phi(z_\\beta)) \\boldsymbol{u}, \\quad z_{\\beta} \\sim \\mathsf{N}(0,1) . \\end{aligned}  Note 𝛈3\\boldsymbol{\\eta}_3 𝛈4\\boldsymbol{\\eta}_4, partial derivatives respect β\\beta zero 𝐮=𝟎\\boldsymbol{u}=\\boldsymbol{0}. However, first inlabru iteration give non-zero estimate 𝐮\\boldsymbol{u}, subsequent iteration involve β\\beta 𝐮\\boldsymbol{u}.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"proper-posterior-prediction-scores","dir":"Articles","previous_headings":"","what":"Proper posterior prediction scores","title":"Prediction scores","text":"prediction score S(F,y)S(F,y) evaluates measure closeness prediction distribution identified FF, observed value yy.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"a-basic-score-and-motivating-remarks","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"A basic score, and motivating remarks","title":"Prediction scores","text":"common score Squared Error, SSE(F,y)=[y−𝔼F(Y)]2, S_\\text{SE}(F,y) = [y - \\mathbb{E}_F(Y)]^2,  like predictions low values SSE(F,y)S_\\text{SE}(F,y), indicating “good” prediction, specific sense puts penalty squared deviation prediction mean true observed value. can imagine constructing scoring functions penalise aspects prediction. score “lower better” called negatively oriented, score “higher better” called positively oriented. One can always turn one type score changing sign, simplify presentation, ’ll make scores negatively oriented, like squared error. often care prediction uncertainty just mean (least care!). Just adding prediction variance penalty squared error wouldn’t useful, construct new, “better”, prediction reducing stated prediction variance zero. understate real prediction uncertainty, wouldn’t fair scoring approach comparing different prediction models. next section, make fairness idea precise.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"proper-and-strictly-proper-scores","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Proper and strictly proper scores","title":"Prediction scores","text":"expected value distribution identified GG denoted S(F,G):=𝔼Y∼F[S(F,Y)]S(F,G):=\\mathbb{E}_{Y\\sim F}[S(F,Y)]. negatively oriented score, seek scoring functions fair, sense one , average, make better prediction generated data. requires S(F,G)≥S(G,G)S(F,G)\\geq S(G,G) predictive distributions FF distribution GG. scores call proper. addition, equality score expectations hold F=GF=G, score strictly proper. Non-strict proper scores ignore aspect prediction, typically sensitive summary information, mean, median, /variance. ’s notable proper scores retain properness affine transformations, just potential changes whether positively negatively oriented. S(F,y)S(F,y) proper score, S′(F,y)=+bS(F,y),,b∈ℝ, S'(F,y) = + b S(F,y),\\quad ,b\\\\mathbb{R},  also proper score, orientation b>0b>0 opposite orientation b<0b<0. degenerate case b=0b=0 gives score aa predictions, technically proper score (better ideal prediction), useless one (ideal prediction better prediction).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"examples","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Examples","title":"Prediction scores","text":"log-score: Slog(F,y)=−log{pF(y)}S_\\text{log}(F,y) = -\\log\\{p_F(y)\\}, pF(y)p_F(y) predictive pdf pmf yy, strictly proper score. Squared Error: SSE(F,y)=[y−𝔼F(Y)]2S_\\text{SE}(F,y) = [y - \\mathbb{E}_F(Y)]^2 proper score Brier score: Binary events: SBrier(F,z)=[z−ℙF(Z=1)]2,S_\\text{Brier}(F,z) = [z - \\mathbb{P}_F(Z = 1)]^2, Z∈{0,1}Z\\\\{0,1\\} binary event indicator, strictly proper score event prediction, non-strict respect underlying outcome yy generating event indicator, e.g. via z=(y=0)z=(y=0). Class indicator events: y∈{1,…,K}y\\\\{1,\\dots,K\\} class category outcome, Brier score can generalised SMultiBrier(F,y)=∑k=1K[(y=k)−ℙF(Y=k)]2S_\\text{MultiBrier}(F,y) = \\sum_{k=1}^K [(y = k) - \\mathbb{P}_F(Y=k)]^2 can seen Squared Error Multinomial prediction model zk=(y=k)z_k=(y=k), {z1,…,zK}∼Multinomial(1,{p1,…,pK})\\{z_1,\\dots,z_K\\}\\sim\\text{Multinomial}(1,\\{p_1,\\dots,p_K\\}), pk=ℙF(Y=k)p_k=\\mathbb{P}_F(Y=k). Sometimes, sum normalised 1/K1/K. generalised Brier score proper score. Dawid-Sebastiani: SDS(F,y)=[y−𝔼F(Y)]2/𝕍F(Y)+log[𝕍F(Y)]S_\\text{DS}(F,y)=[y - \\mathbb{E}_F(Y)]^2 / \\mathbb{V}_F(Y) + \\log[\\mathbb{V}_F(Y)] proper score. ’s derived strictly proper log-score Gaussian prediction, ’s also non-strict proper score distributions. advantage involves predictive mean variance, making computable also cases log-densities hard obtain. Since ’s based symmetric Gaussian distribution, tends affected skewness, applied care cases. Absolute (Median) Error: SAE(F,y)=|y−medianF|S_\\text{AE}(F,y)=|y - \\text{median}_F| proper score, expectation minimised medians FF GG match. Note |y−𝔼F(Y)||y-\\mathbb{E}_F(Y)|, absolute error respect expectation, proper score! Another way expressing |y−mF||y-m_F| proper score respect median, .e. proper mFm_F taken median FF, point prediction. applied literature, distinction often overlooked, predictive mean inserted SE AE scores, making resulting AE score comparisons less clear . CRPS (Continuous Ranked Probability Score): SCRPS(F,y)=∫−∞∞[ℙF(Y≤x)−(y≤x)]2dx S_\\text{CRPS}(F,y)=   \\int_{-\\infty}^\\infty [\\mathbb{P}_F(Y \\leq x) - (y \\leq x)]^2 \\,\\mathrm{d}x  strictly proper score, related absolute error point predictions. scores include Interval score minimised short prediction intervals intended coverage probability, Quantile score, generalises Absolute Median Error quantiles median.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"improper-scores","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Improper scores","title":"Prediction scores","text":"’ve seen scores strictly proper, others proper scores, sensitive specific aspects predictive distribution, mean, median, /variance. contrast, improper scores fulfil fairness idea. scores include aforementioned penalised squared error, [y−𝔼(Y)]2+𝕍F(Y)[y-\\mathbb{E}(Y)]^2+\\mathbb{V}_F(Y), also probability/density function, pF(y)p_F(y). latter might come surprise, log-score proper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"mean-errorscore","dir":"Articles","previous_headings":"Proper posterior prediction scores","what":"Mean error/score","title":"Prediction scores","text":"point, considered individual scores. summarising predictions {Fi}\\{F_i\\} collection observations {yi}\\{y_i\\}, usually compute mean score, S({Fi},{yi})=1N∑=1NS(Fi,yi). S(\\{F_i\\},\\{y_i\\}) = \\frac{1}{N}\\sum_{=1}^N S(F_i,y_i) . comparing two different prediction models FF F′F', scores dependent respect observations yiy_i. means order easily handle score variability comparison, treat paired sample problem. pairwise score differences given S(Fi,F′,yi)=S(Fi,yi)−S(F′,yi). S(F_i,F'_i,y_i) = S(F_i,y_i) - S(F'_i,y_i) .  ’s also much reasonable make conditional independence assumptions differences, plain score values S(Fi,yi)S(F_i,y_i); 𝕍{yi}∼G[1N∑=1NS(Fi,yi)]=1N2∑=1N∑j=1Nℂ{yi}∼G[S(Fi,yi),S(Fj,yj)] \\mathbb{V}_{\\{y_i\\}\\sim G}\\left[\\frac{1}{N}\\sum_{=1}^N S(F_i,y_i)\\right] = \\frac{1}{N^2}\\sum_{=1}^N\\sum_{j=1}^N\\mathbb{C}_{\\{y_i\\}\\sim G}\\left[S(F_i,y_i),S(F_j,y_j)\\right]  𝕍{yi}∼G[1N∑=1NS(Fi,yi)−S(F′,yi)]≈1N2∑=1N𝕍yi∼Gi[S(Fi,yi)−S(F′,yi)]. \\mathbb{V}_{\\{y_i\\}\\sim G}\\left[\\frac{1}{N}\\sum_{=1}^N S(F_i,y_i) - S(F'_i,y_i)\\right] \\approx \\frac{1}{N^2}\\sum_{=1}^N\\mathbb{V}_{y_i\\sim G_i}\\left[ S(F_i,y_i) - S(F'_i,y_i)\\right]. Note taking average prediction scores, averages prediction score differences, quite different assessing summary statistics collection predictions, since scores individual observation; ’re assessing collective value distribution, might misleading. example, consider spatial model estimated procession empirical distribution predictive means matches observed data. Scores based marginal empirical distribution able detect location values maximally different actual locations, whereas averages individual scores sensitive .","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"poisson-model-example","dir":"Articles","previous_headings":"","what":"Poisson model example","title":"Prediction scores","text":"Consider model Poisson outcomes yy, conditionally log-linear predictor λ=exp(η)\\lambda=\\exp(\\eta), η\\eta linear expression latent variables. posterior predictive distributions Poisson mixture distributions across posterior distribution λ\\lambda, p(λ|data)p(\\lambda|\\text{data}).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"moment-scores","dir":"Articles","previous_headings":"Poisson model example","what":"Moment scores","title":"Prediction scores","text":"Squared Error Dawid-Sebastiani scores, ’ll need posterior expectation variance: 𝔼(Y|data)=𝔼[𝔼(Y|λ,data)|data]=𝔼(λ|data)   \\mathbb{E}(Y|\\text{data}) = \\mathbb{E}[\\mathbb{E}(Y|\\lambda,\\text{data}) | \\text{data}] = \\mathbb{E}(\\lambda | \\text{data})  𝕍(Y|data)=𝔼[𝕍(Y|λ,data)|data]+𝕍[𝔼(Y|data)|data]=𝔼[λ|data]+𝕍[λ|data]   \\mathbb{V}(Y|\\text{data}) = \\mathbb{E}[\\mathbb{V}(Y|\\lambda,\\text{data}) | \\text{data}] +     \\mathbb{V}[\\mathbb{E}(Y | \\text{data}) | \\text{data}]      = \\mathbb{E}[\\lambda | \\text{data}] + \\mathbb{V}[\\lambda | \\text{data}]  .e. sum posterior mean variance lambda. SE DS scores therefore relatively easy compute estimating model inlabru. just need estimate posterior mean variance predict() test data point. eta expression linear predictor, newdata holds covariate information prediction points, run","code":"pred <- predict(fit, newdata, formula = ~ exp(eta), n.samples = 2000) post_E <- pred$mean post_Var <- pred$mean + pred$sd^2 SE_score <- (newdata$y - post_E)^2 DS_score <- (newdata$y - post_E)^2 / post_Var + log(post_Var)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"log-probability-and-log-density-scores","dir":"Articles","previous_headings":"Poisson model example","what":"Log-Probability and log-density scores","title":"Prediction scores","text":"full log-score can actually also estimated/computed similar way. seek, fixed observation y, log[ℙ(Y=y|data)]\\log[\\mathbb{P}(Y = y | \\text{data})] probability ℙ(Y=y|data)=𝔼[ℙ(Y=y|λ,data)|data],   \\mathbb{P}(Y = y | \\text{data}) = \\mathbb{E}[\\mathbb{P}(Y = y | \\lambda, \\text{data}) | \\text{data}],  can estimate using predict(): estimate log_score (increase n.samples needed sufficiently small Monte Carlo error).","code":"pred <- predict(fit,   newdata,   formula = ~ dpois(y, rate = exp(eta)),   n.samples = 2000 ) log_score <- log(pred$mean)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"crps","dir":"Articles","previous_headings":"Poisson model example","what":"CRPS","title":"Prediction scores","text":"Yet another option use CRPS, prediction value yiy_i SCRPS(Fi,yi)=∑k=0∞[ℙ(Yi≤k|data)−(yi≤k)]2 S_\\text{CRPS}(F_i,y_i) = \\sum_{k=0}^\\infty [\\mathbb{P}(Y_i \\leq k |\\text{data}) - (y_i \\leq k)]^2  , one first need get ℙ(Y≤k|data)\\mathbb{P}(Y \\leq k | \\text{data}) predict call ppois(k, rate = exp(eta)), vector k=0,1…,Kk=0,1\\dots,K, yiy_i, sufficiently large K>maxiyiK>\\max_i{y_i} remainder negligible. However, avoid repeated predict() calls yiy_i, storage requirements order (K+1)×N×Nsamples(K+1) \\times N\\times N_\\text{samples}. avoid , one option reformulate estimator recursive estimator, batches simulations used iteratively compute estimator. basic estimator can proceed follows: Define K≥K0=maxi(yi)K\\geq K_0=\\max_i(y_i) sufficiently large posterior predictive probability KK negligible. Perhaps value like K=K0+4K0K=K_0+4\\sqrt{K_0} might sufficient. can check afterwards, change needed. Simulate samples λ(j)∼p(λ|data)\\lambda^{(j)}\\sim p(\\lambda|\\text{data}) using generate() (size N×NsamplesN\\times N_\\text{samples}). =1,…,Ni=1,\\dots,N, use samples estimate residuals rik=ℙ(Y≤k|data)−(yi≤k)r_{ik}=\\mathbb{P}(Y\\leq k|\\text{data})-(y_i\\leq k), k∈0,1,2,…,Kk\\0,1,2,\\dots,K, p̂ik=1Nsamples∑j=1Nsamples{ℙ(Y≤k|λi(j))−(yi≤k)}.   \\widehat{p}_{ik} = \\frac{1}{N_\\text{samples}} \\sum_{j=1}^{N_\\text{samples}}   \\{   \\mathbb{P}(Y\\leq k|\\lambda^{(j)}_i)   -   (y_i\\leq k)   \\} .    3. Compute SCRPS(Fi,yi)≈∑k=0Krik2 S_\\text{CRPS}(F_i,y_i) \\approx \\sum_{k=0}^{K} r_{ik}^2","code":"# some large value, so that 1-F(K) is small max_K <- ceiling(max(y)) + 4 * sqrt(max(y)) pred <- generate(fit, newdata,   formula = ~ {     lambda <- exp(eta)     k <- seq(0, max_K)     do.call(       cbind,       lapply(         seq_along(y),         function(i) {           Fpred <- ppois(k, rate = lambda[i])           data.frame(             k = c(k, k),             i = c(i, i),             type = rep(c(\"F\", \"residual\"), each = length(Fpred)),             value = c(Fpred, Fpred - (y[i] <= k))           )         }       )     )   },   n.samples = 2000 ) F_estimate <-   (pred %>%     filter(type == \"F\") %>%     group_by(i) %>%     summarise(F = sum(mean), groups = \"drop\") %>%     pull(\"F\")) crps_score <-   (pred %>%     filter(type == \"residual\") %>%     group_by(i) %>%     summarise(crps = sum(mean^2), groups = \"drop\") %>%     pull(crps)) # Check that the cutoff point K has nearly probability mass 1 below it, # for all i: min(F_estimate)"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"posterior-expectation-of-conditional-scores","dir":"Articles","previous_headings":"","what":"Posterior expectation of conditional scores","title":"Prediction scores","text":"cases, one might tempted consider posterior distribution properties conditional predictive scores, e.g. posterior expectation 𝔼λ|data[S(Fλ,y)]\\mathbb{E}_{\\lambda|\\text{data}}[S(F_\\lambda, y)] S(Fλ,y)S(F_\\lambda, y) posterior distribution λ\\lambda Poisson model. Squared Error, 𝔼λ|data[(y−λ)2]=𝔼λ|data[{y−𝔼(λ|data)+𝔼(λ|data)−λ}2]=[y−𝔼(λ|data)]2+𝔼λ|data(𝔼(λ|data)−λ}2]=[y−𝔼(λ|data)]2+𝕍(λ|data). \\begin{aligned} \\mathbb{E}_{\\lambda|\\text{data}}[(y - \\lambda)^2] &=  \\mathbb{E}_{\\lambda|\\text{data}}[\\{y - \\mathbb{E}(\\lambda|\\text{data}) + \\mathbb{E}(\\lambda|\\text{data}) - \\lambda\\}^2] \\\\ &= [y - \\mathbb{E}(\\lambda|\\text{data})]^2 + \\mathbb{E}_{\\lambda|\\text{data}}(\\mathbb{E}(\\lambda|\\text{data}) - \\lambda\\}^2] \\\\ &= [y - \\mathbb{E}(\\lambda|\\text{data})]^2 + \\mathbb{V}(\\lambda|\\text{data}) . \\end{aligned}  ’s noteworthy similar improper score [y−𝔼(y|data)]2+𝕍(y|data)[y - \\mathbb{E}(y|\\text{data})]^2 + \\mathbb{V}(y|\\text{data}), also new case, one can model artificially small posterior variance smaller expected score, making type construction problematic interpret. However, cases provide alternative approaches compute proper scores full posterior predictive distributions. λij\\lambda_{ij}, j=1,…,Jj=1,\\dots,J samples posterior distribution, one score estimator Ŝ(Fi,yi)=(yi−1J∑j=1Jλij)2, \\widehat{S}(F_i,y_i) = (y_i - \\frac{1}{J}\\sum_{j=1}^J \\lambda_{ij})^2 ,  averaging samples inside quadratic expression, can use instead take advantage new expression , [y−𝔼(λ|data)]2=𝔼λ|data[(y−λ)2]−𝕍(λ|data) [y - \\mathbb{E}(\\lambda|\\text{data})]^2  = \\mathbb{E}_{\\lambda|\\text{data}}[(y - \\lambda)^2] - \\mathbb{V}(\\lambda|\\text{data})  score can estimated particular case, approach unlikely improvement accurate basic estimator.However, scores may potentially practical benefits.","code":"pred <- predict(fit, newdata, formula = ~ exp(eta)) scores <- (y - pred$mean)^2 pred <- predict(fit, newdata, formula = ~ list(   cond_scores = (y - exp(eta))^2,   lambda = exp(eta) )) scores <- pred$cond_scores$mean - pred$lambda$sd^2"},{"path":"https://inlabru-org.github.io/inlabru/articles/prediction_scores.html","id":"an-alternative-estimator-for-crsp","dir":"Articles","previous_headings":"Posterior expectation of conditional scores","what":"An alternative estimator for CRSP","title":"Prediction scores","text":"CRPS score, closed form expressions available distributions, conditionally parameters, full predictive mixture distribution. take similar approach SE, let FF FλF_\\lambda denote unconditional conditional cumulative distribution functions posterior predictive distribution. F(x)=𝔼λ|data[Fλ(x)]F(x)=\\mathbb{E}_{\\lambda|\\text{data}}[F_\\lambda(x)] xx, SCRPS(F,y)=∫−∞∞[F(x)−(y≤x)]2dx=𝔼λ|data[∫−∞∞[Fλ(x)−(y≤x)]2dx]−∫−∞∞{𝔼λ|data[Fλ(x)2]−𝔼λ|data[Fλ(x)]2}dx=𝔼λ|data[SCRPS(Fλ,y)]−∫−∞∞𝕍λ|data[Fλ(x)]dx. \\begin{aligned} S_\\text{CRPS}(F,y) &= \\int_{-\\infty}^\\infty [F(x) - (y\\leq x)]^2 \\,\\mathrm{d}x  \\\\ &= \\mathbb{E}_{\\lambda|\\text{data}}\\left[ \\int_{-\\infty}^\\infty [F_\\lambda(x) - (y\\leq x)]^2 \\,\\mathrm{d}x  \\right] - \\int_{-\\infty}^\\infty \\left\\{\\mathbb{E}_{\\lambda|\\text{data}}\\left[F_\\lambda(x)^2\\right]  - \\mathbb{E}_{\\lambda|\\text{data}}[F_\\lambda(x)]^2\\right\\} \\,\\mathrm{d}x  \\\\ &= \\mathbb{E}_{\\lambda|\\text{data}}\\left[ S_\\text{CRPS}(F_\\lambda,y) \\right] - \\int_{-\\infty}^\\infty \\mathbb{V}_{\\lambda|\\text{data}}[F_\\lambda(x)] \\,\\mathrm{d}x . \\end{aligned}  Note didn’t need use particular model properties , holds predictive model mixture structure, λ\\lambda collection model parameters. also note resemblance alternative expression Squared Error; CRPS can seen integral Brier scores predicting event indicators form z=(y≤x)z=(y\\leq x), probability F(x)F(x). Poisson case, can now estimate CRPS scores like , makes code bit easier previous version needed generate(). However, can shown two approaches nearly identical Monte Carlo variance, previous version likely preferable doesn’t require knowing closed form CRPS expression. Formulas functions Poisson CRPS, well distributions, can found http://cran.nexr.com/web/packages/scoringRules/vignettes/crpsformulas.html#poisson-distribution-pois","code":"poisson_crps <- function(y, rate) {   # compute the CRPS score for a single y, for the given rate paramter. } max_K <- 100 # some large value, so that 1-F(K) is small pred <- predict(fit, newdata,   formula = ~ {     lambda <- exp(eta)     list(       crps = vapply(         seq_along(y),         function(i) poisson_crps(y[i], lambda[i]),         0.0       ),       F = do.call(         cbind,         lapply(           seq_along(y),           function(i) {             data.frame(               i = i,               F = ppois(seq(0, max_K), rate = lambda[i])             )           }         )       )     )   },   n.samples = 2000 ) crps_score <-   pred$crsp$mean -   (pred$F %>%     group_by(i) %>%     summarise(F_var = sum(sd^2), groups = \"drop\") %>%     pull(F_var))"},{"path":"https://inlabru-org.github.io/inlabru/articles/publications.html","id":"articles","dir":"Articles","previous_headings":"","what":"Articles","title":"Publications","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168. Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whales, Annals Applied Statistics, 11, 2270–2297, doi:10.1214/17-AOAS1078, [arXiv, PDF].","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/publications.html","id":"presentations","dir":"Articles","previous_headings":"","what":"Presentations","title":"Publications","text":"F. E. Bachl @ TIES/GRASPA 2017 Conference Climate Ecology, Bergamo, Italy, July 24-26inlabru: Bayesian modeling point procesanalysis ecological data beyond [Abstract, Slides] D. L. Borchers @ South African Statistical Association Conference, Cape Town, South Africa, 28th Nov 1st DecWildlife Survey Models: Thinned spatial point processes unknown thinning probabilities [Slides] F. E. Bachl @ Autumn meeting latent Gaussian Models, Trondheim, Norway, September 17-18Live inlabru demo [HTML, R] F. E. Bachl @ Fifth Workshop Bayesian Inference Latent Gaussian Models Applications, Bath, UK, 14-16 September 2016Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ Smoegen Workshop, Smoegen, August 15-18 2016 Approximate non-linear thinning probabilistic marks log Gaussian Cox process models INLA [Abstract, Slides] F. E. Bachl @ NOAA San Diego, USA, August 2016Spatial point process models distance sampling surveys animals occur groups [Slides] D. L. Borchers @ International Environmetrics Society Conference 2016, Edinburgh, UK, 18-22 July 2016 Wildlife survey models: thinned spatial point processes unknown thinning probabilities Y. Yuan @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Poster: Point process models spatio-temporal distance sampling data [Abstract] F. E. Bachl @ International Statistical Ecology Conference (ISEC 2016), Seattle, USA, June 28th – July 1st, 2016.Spatial point process models distance sampling surveys animals occur groups [Abstract, Slides] Y. Yuan @ National Centre Statistical Ecology Conference, Falmouth, UK, July 2015Spatial point process models distance sampling data Y. Yuan @ Spatial Statistics, Emerging Patterns, Avignon, France, June 2015Spatial point process models distance sampling data","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"Random Fields in One Dimension","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(mgcv) library(ggplot2) library(fmesher) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"get-the-data","dir":"Articles","previous_headings":"","what":"Get the data","title":"Random Fields in One Dimension","text":"Put count data cd (just ‘cd’ less type ‘countdata2’.) Take look count data.  Tip: RStudio > Help > Cheatsheets > Data visualisation ggplot2 useful reference ggplot2 syntax.","code":"data(Poisson2_1D) cd <- countdata2 cd #>            x count exposure #> 1   2.319888     9 4.639776 #> 2   6.959664    13 4.639776 #> 3  11.599439    11 4.639776 #> 4  16.239215    22 4.639776 #> 5  20.878991    20 4.639776 #> 6  25.518766    19 4.639776 #> 7  30.158542    16 4.639776 #> 8  34.798318     8 4.639776 #> 9  39.438093     4 4.639776 #> 10 44.077869     4 4.639776 #> 11 48.717645     4 4.639776 ggplot(cd) +   geom_point(aes(x, y = count)) +   ylim(0, max(cd$count))"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"fitting-a-generalised-additive-model-gam","dir":"Articles","previous_headings":"","what":"Fitting a Generalised Additive Model (GAM)","title":"Random Fields in One Dimension","text":"’re familiar GAMs syntax gam don’t worry, point just provide something can compare inlabru model fit. term s(x,k=10) just specifies nonparametric smooth function fitted data, 10 degrees freedom (df). (larger df, wiggly fitted curve (recall lecture effect spline methods defined, without discretisation dependent penalty); gam selects ‘best’ df.) Notice use offset=. (Refer slides explanation offset.) variable exposure data frame cd size bin count made. can look fitted model using summary( ) want , need understand output, code makes predictions immediately familiar GAMs. Make prediction data frame, get predictions add data frame First make vectors x-values associated (equal) exposures: put data frame: predict Ploting fit data using ggplot2 commands give plot shown ","code":"fit2.gam <- gam(count ~ s(x, k = 10) + offset(log(exposure)), family = poisson(), data = cd) summary(fit2.gam) xs <- seq(0, 55, length = 100) exposures <- rep(cd$exposure[1], 100) dat4pred <- data.frame(x = xs, exposure = exposures) pred2.gam <- predict(fit2.gam, newdata = dat4pred, type = \"response\") dat4pred2 <- cbind(dat4pred, gam = pred2.gam) # add column for prediction in data frame ggplot(dat4pred2) +   geom_line(aes(x = x, y = gam), lty = 2) +   ylim(0, max(dat4pred2$gam, cd$count)) +   geom_point(aes(x = x, y = count), cd)"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"fitting-an-spde-model-with-inlabru","dir":"Articles","previous_headings":"","what":"Fitting an SPDE model with inlabru","title":"Random Fields in One Dimension","text":"Make mesh. avoid boundary effects region interest, let mesh extend outside data range. … see mesh points :","code":"x <- seq(-10, 65, by = 1) # this sets mesh points - try others if you like mesh1D <- fm_mesh_1d(x, boundary = \"free\") ggplot() +   gg(mesh1D)"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"using-function-bru-to-fit-to-count-data","dir":"Articles","previous_headings":"Fitting an SPDE model with inlabru","what":"Using function bru( ) to fit to count data","title":"Random Fields in One Dimension","text":"need specify model components model formula order fit . can done inside call bru( ) bit messy, ’ll store comp first pass bru( ). response variable data frame cd called count model specification needs left ~. add intercept component + Intercept(1) right hand side (models use intercepts), want fit Gaussian random field (GRF), must GRF specification. inlabru GRF specification function, allows GRF calculated point space inlabru calculations. user gets name GRF function. syntax ‘myname(input, model= …)’, : ‘myname’ whatever want call GRF (called field ); input specifies coordinates GRF SPDE ‘lives’. working one dimension, called dimension x set data set. model= designates type effect, SPDE model object INLA function inla.spde2.pcmatern( ), requires mesh passed , pass 1D mesh created , `mesh1D. models adds model components, don’t need specify full predictor formula. Instead, can provide name output left ~ component specification, “.” right hand side, cause add components (unless subset selected via include/exclude arguments like()). Predict values x points used mesh (data argument must data frame, see ?predict.bru): Let’s plot compare fitted model true model. expected counts true model stored variable E_nc2 comes dataset Poisson2_1D. ease use plotting ggplot2 (needs data frame), create data frame call true.lambda, containing x- y variables shown . Given inlabru predictions always intensity function scale, understand divide count cd$exposure? (due course allow predictions count scale well.) ggplot2 commands generate plot shown . shows true intensities short horizontal blue lines, observed intensities black dots, fitted intensity function red curve, 95% credible intervals shown light red band curve.  Compare inlabru fit gam fit:","code":"the_spde <- inla.spde2.pcmatern(mesh1D,   prior.range = c(1, 0.01),   prior.sigma = c(1, 0.01) )  comp <- ~ field(x, model = the_spde) + Intercept(1, prec.linear = 1 / 2^2)  fit2.bru <- bru(   comp,   like(count ~ .,     data = cd,     family = \"poisson\",     E = exposure   ) )  summary(fit2.bru) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> field: main = spde(x), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'poisson' #>     Data class: 'data.frame' #>     Response class: 'integer' #>     Predictor: count ~ . #>     Used components: effects[field, Intercept], latent[] #> Time used: #>     Pre = 0.731, Running = 0.215, Post = 0.121, Total = 1.07  #> Fixed effects: #>            mean    sd 0.025quant 0.5quant 0.975quant  mode   kld #> Intercept 0.978 0.702     -0.008    0.857      3.166 0.812 0.004 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                   mean     sd 0.025quant 0.5quant 0.975quant   mode #> Range for field 35.194 25.649      8.854   28.298    103.364 19.028 #> Stdev for field  0.519  0.163      0.271    0.496      0.905  0.452 #>  #> Deviance Information Criterion (DIC) ...............: 60.06 #> Deviance Information Criterion (DIC, saturated) ....: 14.41 #> Effective number of parameters .....................: 5.49 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 58.21 #> Effective number of parameters .................: 2.84 #>  #> Marginal log-Likelihood:  -36.79  #>  is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') x4pred <- data.frame(x = xs) pred2.bru <- predict(fit2.bru, x4pred, x ~ exp(field + Intercept), n.samples = 1000) true.lambda <- data.frame(x = cd$x, y = E_nc2 / cd$exposure) ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_point(data = true.lambda, aes(x, y), pch = \"_\", cex = 9, col = \"blue\") +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\") ggplot() +   gg(pred2.bru) +   geom_point(data = cd, aes(x = x, y = count / exposure), cex = 2) +   geom_line(data = dat4pred2, aes(x, gam / exposure), lty = 2) +   coord_cartesian(xlim = c(0, 55), ylim = c(0, 6)) +   xlab(\"x\") +   ylab(\"Intensity\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields.html","id":"looking-at-the-posterior-distributions","dir":"Articles","previous_headings":"Fitting an SPDE model with inlabru","what":"Looking at the posterior distributions","title":"Random Fields in One Dimension","text":"can look Intercept posterior using function plot( ), .  know variable called Intercept order use function. see fixed effect parameters’ posterior distributions available plotted, can type tell SPDE parameters, type just tells SPDE fit2.bru called ‘field’, tell associated parameter names . parameters used estimation cryptic – interested range variance Matern covariance funcion, functions internal parameters. can look posterior distributions range parameter log variance parameters follows. (look posterior log variance variance posterior skewed easier view log variance)  can look posterior distributions Matern correlatioin covariance funcitons follows:","code":"plot(fit2.bru, \"Intercept\") names(fit2.bru$marginals.fixed) names(fit2.bru$marginals.random) #> [1] \"field\" spde.range <- spde.posterior(fit2.bru, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit2.bru, \"field\", what = \"log.variance\")  range.plot <- plot(spde.range) var.plot <- plot(spde.logvar) multiplot(range.plot, var.plot) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.correlation\")) plot(spde.posterior(fit2.bru, \"field\", what = \"matern.covariance\"))"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html","id":"setting-things-up","dir":"Articles","previous_headings":"","what":"Setting things up","title":"Random Fields in 2D","text":"Make shortcut nicer colour scale:","code":"library(INLA) library(inlabru) library(fmesher) library(mgcv) library(ggplot2) colsc <- function(...) {   scale_fill_gradientn(     colours = rev(RColorBrewer::brewer.pal(11, \"RdYlBu\")),     limits = range(..., na.rm = TRUE)   ) }"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html","id":"modelling-on-2d-domains","dir":"Articles","previous_headings":"","what":"Modelling on 2D domains","title":"Random Fields in 2D","text":"now construct 2D model, generate sample random field, attempt recover field observations locations. Tomorrow, look general mesh constructions adapt irregular domains. First, build high resolution mesh true field, using low level INLA functions  pointwise standard deviation field? Along straight boundaries, variance twice target variance. corners variance 4 times large.  Generate sample model:   Extract observations random locations:","code":"bnd <- spoly(data.frame(easting = c(0, 10, 10, 0), northing = c(0, 0, 10, 10)),              format = \"sf\") mesh_fine <- fm_mesh_2d_inla(boundary = bnd, max.edge = 0.2) ggplot() +   geom_fm(data = mesh_fine) #> Warning in fm_as_sfc.fm_segm(data): fm_as_sfc currently only supports #> (multi)linestring output # Note: the priors here will not be used in estimation matern_fine <-   inla.spde2.pcmatern(mesh_fine,     prior.sigma = c(1, 0.01),     prior.range = c(1, 0.01)   ) true_range <- 4 true_sigma <- 1 true_Q <- inla.spde.precision(matern_fine, theta = log(c(true_range, true_sigma))) true_sd <- diag(inla.qinv(true_Q))^0.5 ggplot() +   gg(mesh_fine, color = true_sd) +   coord_equal() true_field <- inla.qsample(1, true_Q)[, 1]  truth <- expand.grid(   easting = seq(0, 10, length = 100),   northing = seq(0, 10, length = 100) ) truth <- sf::st_as_sf(truth, coords = c(\"easting\", \"northing\")) truth$field <- fm_evaluate(   mesh_fine,   loc = truth,   field = true_field )  pl_truth <- ggplot() +   gg(truth, aes(fill = field), geom = \"tile\") +   ggtitle(\"True field\") pl_truth ## Or with another colour scale: csc <- colsc(truth$field) multiplot(pl_truth, pl_truth + csc, cols = 2) n <- 200 mydata <- sf::st_as_sf(   data.frame(easting = runif(n, 0, 10), northing = runif(n, 0, 10)),   coords = c(\"easting\", \"northing\") ) mydata$observed <-   fm_evaluate(     mesh_fine,     loc = mydata,     field = true_field   ) +   rnorm(n, sd = 0.4) ggplot() +   gg(mydata, aes(col = observed))"},{"path":"https://inlabru-org.github.io/inlabru/articles/random_fields_2d.html","id":"estimating-the-field","dir":"Articles","previous_headings":"","what":"Estimating the field","title":"Random Fields in 2D","text":"Construct mesh covering data:  Construct SPDE model object Matern model: Specify model components: Fit model inspect results: Predict field lattice, generate single realisation posterior distribution: Compare truth estimated field (posterior mean sample posterior distribution):  Plot SPDE parameter fixed effect parameter posteriors.  Look correlation function want :  can plot median, lower 95% upper 95% density surfaces follows (assuming predicted intensity object pred).","code":"mesh <- fm_mesh_2d_inla(boundary = bnd, max.edge = 0.5) ggplot() +   geom_fm(data = mesh) matern <-   inla.spde2.pcmatern(mesh,     prior.sigma = c(10, 0.01),     prior.range = c(1, 0.01)   ) cmp <- observed ~ field(geometry, model = matern) + Intercept(1) fit <- bru(cmp, mydata, family = \"gaussian\") summary(fit) pix <- fm_pixels(mesh, dims = c(200, 200)) pred <- predict(   fit, pix,   ~ field + Intercept ) samp <- generate(fit, pix,   ~ field + Intercept,   n.samples = 1 ) pred$sample <- samp[, 1] pl_posterior_mean <- ggplot() +   gg(pred, geom = \"tile\") +   gg(bnd, alpha = 0) +   ggtitle(\"Posterior mean\") pl_posterior_sample <- ggplot() +   gg(pred, aes(fill = sample), geom = \"tile\") +   gg(bnd, alpha = 0) +   ggtitle(\"Posterior sample\")  # Common colour scale for the truth and estimate: csc <- colsc(truth$field, pred$mean, pred$sample) multiplot(pl_truth + csc,   pl_posterior_mean + csc,   pl_posterior_sample + csc,   cols = 3 ) int.plot <- plot(fit, \"Intercept\") spde.range <- spde.posterior(fit, \"field\", what = \"range\") spde.logvar <- spde.posterior(fit, \"field\", what = \"log.variance\") range.plot <- plot(spde.range) var.plot <- plot(spde.logvar)  multiplot(range.plot, var.plot, int.plot) corplot <- plot(spde.posterior(fit, \"field\", what = \"matern.correlation\")) covplot <- plot(spde.posterior(fit, \"field\", what = \"matern.covariance\")) multiplot(covplot, corplot) csc <- colsc(   pred[[\"median\"]],   pred[[\"q0.025\"]],   pred[[\"q0.975\"]] ) ## Common colour scale from SpatialPixelsDataFrame  gmedian <- ggplot() +   gg(pred[\"median\"], geom = \"tile\") +   csc glower95 <- ggplot() +   gg(pred[\"q0.025\"], geom = \"tile\") +   csc +   theme(legend.position = \"none\") gupper95 <- ggplot() +   gg(pred[\"q0.975\"], geom = \"tile\") +   csc +   theme(legend.position = \"none\")  multiplot(gmedian, glower95, gupper95,   layout = matrix(c(1, 1, 2, 3), byrow = TRUE, ncol = 2) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Spatially Varying Coefficient Models with inlabru","text":"Spatially varying coefficient models (SVCs, Gelfand et al. 2003) often used model data relationships dependent independent variables uniform across space, common situation exploring phenomena across large spatial extents (Finley 2011). Meehan et al. (2019) described SVC model evaluate continent-scaled variation bird abundance trends. SVC model used analysis employed discrete aerial units (100 km grid cells), spatial structure described neighborhood matrices spatial relationships described intrinsic conditional autoregressive model (Besag 1974). online supplement paper included code building model using R-INLA package (Rue et al. 2009) R statistical programming language (R Core Team 2021). manuscript code can accessed https://github.com/tmeeha/inlaSVCBC. vignette, describe build SVC model similar described Meehan et al. (2019), within continuous-space framework. model computed using stochastic partial differential equation (SPDE) approach Lindgren et al. (2011, 2022), implemented inlabru interface R-INLA package R. SPDE approach employs computationally efficient approximation Gaussian random field parameters directly comparable Matérn covariance function. benefits continuous-space versus discrete-space SVC include potential finer resolution estimation prediction, better understanding range spatial correlation, reduction boundary effects associated discrete-space analyses. build model using subset data described Meehan et al. (2019). Specifically, use counts American Robin (Turdus migratorius) south central North America collected 1987 2016 Audubon Christmas Bird Count (CBC). overall goal analysis produce spatially explicit estimates annual relative abundance well long-term relative abundance trends robins account spatial temporal variation count effort.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"model","dir":"Articles","previous_headings":"","what":"Model","title":"Spatially Varying Coefficient Models with inlabru","text":"model used analyze data assumes counts come negative binomial distribution expected count dispersion parameter. expected count log-linear predictor: log(λst)=κs+αs+ϵslog[Effortst]+τsYearst\\log(\\lambda_{st}) = \\kappa_{s} + \\alpha_s + \\epsilon_{s} \\log[\\text{Effort}_{st}] + \\tau_{s} \\text{Year}_{st} natural log expected count, log(λst)\\log(\\lambda_{st}), site ss year tt, modeled zero-centered, normally distributed intercept per site, κs\\kappa_s, spatially varying intercept, αs\\alpha_s, spatially varying effect log count effort hours, ϵs\\epsilon_s, spatially varying linear effect year, τs\\tau_s. spatially structured effects modeled Gaussian random fields Matérn covariance functions range variance parameters. Model parameters κs\\kappa_s, αs\\alpha_s, ϵs\\epsilon_s τs\\tau_s analogous Meehan et al. (2019). example, κs\\kappa_s included account site-level differences counts, possibly due habitat availability observer experience. αs\\alpha_s can interpreted effort-corrected abundance index year zero. ϵs\\epsilon_s exponent power-law effort-correction function. τs\\tau_s long-term temporal trend given site.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"environment","dir":"Articles","previous_headings":"","what":"Environment","title":"Spatially Varying Coefficient Models with inlabru","text":"get started data analysis, set environment, loading packages, setting options. Next define coordinate reference system (CRS) spatial analysis create base map later use. CRS uses USA Contiguous Albers Equal-Area Conic projection, identified EPSG code 6703. modify CRS slightly units kilometers, distances widespread count sites especially large numbers (Krainski et al. 2018).","code":"# libraries library(maps) library(ggplot2) library(sf) library(terra) library(tidyterra) # raster plotting library(tidyr) library(scales) library(dplyr) library(INLA) library(inlabru) library(fmesher) # Note: the 'splancs' package also needs to be installed, # but doesn't need to be loaded  # set option select <- dplyr::select options(scipen = 99999) options(max.print = 99999) options(stringsAsFactors = FALSE) # define a crs epsg6703km <- paste(   \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5\",   \"+lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83\",   \"+units=km +no_defs\" )  # make a base map states <- maps::map(\"state\", plot = FALSE, fill = TRUE) %>%   sf::st_as_sf() %>%   filter(ID %in% c(     \"texas\", \"oklahoma\", \"kansas\", \"missouri\",     \"arkansas\", \"louisiana\"   )) %>%   sf::st_make_valid() %>%   sf::st_transform(epsg6703km) %>%   sf::st_make_valid()"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next import bird count data GitHub repository associated Meehan et al. (2019), turn data set spatially referenced points. use subset data (30 years, 6 US states) analysis reduce computing time (~ 1 min). Note site selection zero filling, important components trend analyses, already conducted resulting data set. inlabru package contains pregenerated version data subset, called robins_subset, can accessed data(robins_subset), avoid accessing full data online. following code used generate subset: load data, filter observation sites less 20 years data, add index variables uniquely index site year information, transform coordinates epsg6703km CRS: rough view changes robin relative abundance, account variation count effort, can seen plotting raw counts per site year.","code":"robins_subset <- read.csv(paste0(   \"https://raw.github.com/tmeeha/inlaSVCBC\",   \"/master/code/modeling_data.csv\" )) %>%   select(     circle, bcr, state, year, std_yr, count, log_hrs,     lon, lat, obs   ) %>%   mutate(year = year + 1899) %>%   filter(     state %in% c(       \"TEXAS\", \"OKLAHOMA\", \"KANSAS\", \"MISSOURI\",       \"ARKANSAS\", \"LOUISIANA\"     ),     year >= 1987   ) data(robins_subset) count_dat <- robins_subset %>%   mutate(site_idx = as.numeric(factor(paste(circle, lon, lat)))) %>%   group_by(site_idx) %>%   mutate(n_years = n()) %>%   filter(n_years >= 20) %>%   ungroup() %>%   mutate(     std_yr = year - max(year),     obs = seq_len(nrow(.)),     site_idx = as.numeric(factor(paste(circle, lon, lat))),     year_idx = as.numeric(factor(year)),     site_year_idx = as.numeric(factor(paste(circle, lon, lat, year)))   ) %>%   st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326, remove = FALSE) %>%   st_transform(epsg6703km) %>%   mutate(     easting = st_coordinates(.)[, 1],     northing = st_coordinates(.)[, 2]   ) %>%   arrange(circle, year) # map it ggplot() +   geom_sf(     data = count_dat %>% filter(year_idx %in% seq(1, 30, 3)),     aes(col = log(count + 1))   ) +   geom_sf(data = states, fill = NA) +   coord_sf(datum = NA) +   facet_wrap(~year) +   scale_color_distiller(palette = \"Spectral\") +   theme_bw()"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"make-spatial-data","dir":"Articles","previous_headings":"","what":"Make spatial data","title":"Spatially Varying Coefficient Models with inlabru","text":"Next use count data make map distinct count sites save coordinates sites, unique across years, later spatial modeling plotting.","code":"# make a set of distinct study sites for mapping site_map <- count_dat %>%   select(circle, easting, northing) %>%   distinct() %>%   select(circle, easting, northing)"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"spde-components","dir":"Articles","previous_headings":"","what":"SPDE components","title":"Spatially Varying Coefficient Models with inlabru","text":"Computing continuous-space model R-INLA using SPDE approach requires construction four distinct sets data model objects (Blangiardo Cameletti 2015, Krainski et al. 2018). First, create modeling mesh, used provide piecewise linear representation continuous spatial surface, based triangulation modeled region. , mesh get reused spatial terms model. Second, construct SPDE model object specifies properties spatial model. , use SPDE object spatial terms model. plain R-INLA, also need create index vectors projector matrices (matrices often called). However, inlabru, objects created automatically, user need deal directly. works automatic creation bru_mapper object knows map mesh nodes spatial data locations. Thus, two R-INLA functions needed user code SPDE modelling steps fm_mesh_2d_inla() inla.spde2.pcmatern(), inla.spde.make.index() inla.spde.make.() functions called internally inlabru code , rather fm_evaluator() used instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"modeling-mesh","dir":"Articles","previous_headings":"","what":"Modeling mesh","title":"Spatially Varying Coefficient Models with inlabru","text":"various things consider constructing mesh (Lindgren Rue 2015, Blangiardo Cameletti 2015, Krainski et al. 2018, Bakka et al. 2018). constructing one, balance trade-capturing fine-scaled features Gaussian random field computing times. , create two non-convex hulls around count sites, build triangular mesh specifying minimum maximum edge lengths within inner hull, within slightly larger outer hull.","code":"# make a two extension hulls and mesh for spatial model hull <- fm_extensions(   count_dat,   convex = c(200, 500),   concave = c(350, 500) ) mesh <- fm_mesh_2d_inla(   boundary = hull, max.edge = c(100, 600), # km inside and outside   cutoff = 50, offset = c(100, 300),   crs = fm_crs(count_dat) ) # cutoff is min edge  # plot it ggplot() +   gg(data = mesh) +   geom_sf(data = site_map, col = \"darkgreen\", size = 1) +   geom_sf(data = states, fill = NA) +   theme_bw() +   labs(x = \"\", y = \"\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"spde-model-object","dir":"Articles","previous_headings":"","what":"SPDE model object","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create SPDE object define model smoothness, prior distributions variance range parameters, mesh. assume Gaussian random field characterized Matérn covariance function penalized complexity priors (Simpson et al. 2017) practical range (distance spatial correlation approaches 0.1) variation explained function (Fuglstad et al. 2019). prior spatial range set probability range exceeding 500 km 0.5. prior variance explained spatial effect set probability standard deviation exceeding 1 0.5 (Krainski et al. 2018). one wants constrain kind spatial effect integrate zero, constr=TRUE added stage.","code":"# make spde spde <- inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(500, 0.5),   prior.sigma = c(1, 0.5) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"weighted-spatial-effects-in-inlabru","dir":"Articles","previous_headings":"","what":"Weighted spatial effects in inlabru","title":"Spatially Varying Coefficient Models with inlabru","text":"ordinary R-INLA, necessary construct projector matrices model component, include different covariate weightings spatial model component. inlabru, can instead handled either explicitly multiplying spatial random fields spatial covariates model formula expression, specifying weights argument model component specification. use latter approach, since easiest. model, ϵs\\epsilon_s spatially varying effect log count effort. Similarly, τs\\tau_s spatially varying effect year, standardized year (1987 = 0) also specified weights argument. αs\\alpha_s also SVC, spatially varying intercept. intercepts necessary specify constant weight 1. model component κs\\kappa_{s} linked observation site modeled mesh. Note current use term ‘weights’ different often encountered defining mixed effect models R. used define covariate value multiplication, opposed importance values likelihoods contexts.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"data-stack-for-model-fitting","dir":"Articles","previous_headings":"Weighted spatial effects in inlabru","what":"Data stack for model fitting","title":"Spatially Varying Coefficient Models with inlabru","text":"plain R-INLA, need bundle model data component projector matrix information using inla.stack() function. inlabru, done automatically, skip step.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"model-formula","dir":"Articles","previous_headings":"","what":"Model formula","title":"Spatially Varying Coefficient Models with inlabru","text":"last required input analysis model formula, includes information prior explained variation unstructured random intercept. define prior κs\\kappa_s penalized complexity prior (Simpson et al. 2017), set probability standard deviation associated random effect exceeding 1 0.01. Notice one wants constrain spatial spde effect integrate zero, added constr=TRUE SPDE model definition rather component definition. want constrain κs\\kappa_s non-spatial term can use constr=TRUE corresponding label() component definition , imposes sum--zero constraint. model described translated inlabru modeling syntax : Specifying sf column geometry input causes inlabru extract spatial coordinate information observation locations . Alternatively, specify function st_coordinates instead, extract raw coordinates, potentially losing important coordinate reference system information. Alternatively, can specify CRS-free information explicitly input, cbind(easting, northing) st_coordinates(.data.). , define response count, remove automatic global intercept -1, specify terms model label() statements. first kappa() statement defines κs\\kappa_s, site effect, normally distributed independent (model=\"iid\"), globally zero-centred (sum zero constr=TRUE), deviation αs\\alpha_s. second alpha() statement defines αs\\alpha_s spatially varying intercept spatial structure described SPDE object called ‘spde’. Remember one wants constrain kind spatial effect integrate zero, constr=TRUE added SPDE model definition rather label() arguments. third eps() statement defines ϵs\\epsilon_s SVC effect count effort, spatial structure also described SPDE object. weights spatially structured random slope specified weights=log_hrs argument. fourth tau() statement defines τs\\tau_s SVC year effect, spatial structure described SPDE object. weights spatially structured random slope specified weights=std_yr argument.","code":"# iid prior pc_prec <- list(prior = \"pcprec\", param = c(1, 0.1)) # components svc_components <- ~ -1 +   kappa(site_idx, model = \"iid\", constr = TRUE, hyper = list(prec = pc_prec)) +   alpha(geometry, model = spde) +   eps(geometry, weights = log_hrs, model = spde) +   tau(geometry, weights = std_yr, model = spde) # formula, with \".\" meaning \"add all the model components\": svc_formula <- count ~ ."},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"run-model","dir":"Articles","previous_headings":"","what":"Run model","title":"Spatially Varying Coefficient Models with inlabru","text":"estimate model call bru(). First set option use (new) experimental way internal computations, see Van Niekerk et. al. (2022), sake computing speed better numerics. call bru(), give model components, specify observation likelihood model formula negative binomial distribution counts, define estimation data. ask inla() compute WAIC CPO (temporarily disabled) evaluate model fit (also, save information necessary posterior sampling need config=TRUE, automatically set bru(), inlabru::predict() relies posterior sampling prediction). computing speed, choose use simplified Laplace approximation strategy Empirical Bayes estimation. inla() run model takes 1 minutes standard laptop computer. Another option use Variational Bayes approximation detailed Van Niekerk Rue (2021) Van Niekerk et. al. (2022).","code":"res <- bru(   svc_components,   like(     formula = svc_formula,     family = \"nbinomial\",     data = count_dat   ),   options = list(     control.compute = list(waic = TRUE, cpo = FALSE),     control.inla = list(int.strategy = \"eb\"),     verbose = FALSE   ) )"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"model-summaries","dir":"Articles","previous_headings":"","what":"Model summaries","title":"Spatially Varying Coefficient Models with inlabru","text":"computation complete, look initial results see things went. First check posterior means hyperparameters model, mainly variance components spatial ranges spatially structured parameters. Next examine summaries random effect estimates, starting exp(αs)\\exp(\\alpha_s), effort-corrected relative abundance year = 0 (1987), given 1 hour count effort (.e., log[1]=0). Note avoid issues due E[exp(x)|y]≠exp[E(x|y)]E[\\exp(x)|y]\\neq\\exp[E(x|y)], use posterior median instead posterior mean. summary ϵs\\epsilon_s shows variation exponent effort correction function across space. τs\\tau_s summary shows long-term, log-linear trends robin relative abundance varied across space, annual decreases around 10% annual increases around 10%.","code":"# view results res$summary.hyperpar[-1, c(1, 2)] #>                              mean            sd #> Precision for kappa    2.31078350    0.45033448 #> Range for alpha      946.54630408  290.93909439 #> Stdev for alpha        2.00079032    0.39442446 #> Range for eps       5907.86916916 4030.43885257 #> Stdev for eps          0.43993785    0.23635648 #> Range for tau        686.08296959  258.73796551 #> Stdev for tau          0.06437849    0.01467521 summary(exp(res$summary.random$alp$\"0.5quant\")) # exp(alpha) posterior median #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #>  0.04846  1.03193  3.14826  6.68044  8.24730 52.35778 summary(res$summary.random$eps$mean) # epsilon #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.7573  0.8880  0.9858  0.9730  1.0514  1.1787 summary((exp(res$summary.random$tau$\"0.5quant\") - 1) * 100) # (exp(tau)-1)*100 #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> -13.351  -5.663  -1.991  -1.321   2.550  11.636"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"svc-maps","dir":"Articles","previous_headings":"","what":"SVC maps","title":"Spatially Varying Coefficient Models with inlabru","text":"Next create maps αs\\alpha_s, ϵs\\epsilon_s, τs\\tau_s inspect spatial structure parameter estimates. start creating 25-km mapping grid, projecting mapping grid modeling mesh. populate mapping grids parameter estimates (posterior median range95), turn raster stack, mask raster stack study area. Finally, plot SVCs following code. plot posterior median 95% uncertainty width (“range95”) exp(κs)\\exp(\\kappa_s), exp(αs)\\exp(\\alpha_s), ϵs\\epsilon_s, 100(exp(τs)−1)100(\\exp(\\tau_s)-1). map posterior mean τs\\tau_s shows robins decreased southern part study area increased northern part. demonstrates wintering range robins shifting northward winters become warmer due climate change.","code":"# get easting and northing limits bbox <- fm_bbox(hull[[1]]) grd_dims <- round(c(x = diff(bbox[[1]]), y = diff(bbox[[2]])) / 25)  # make mesh projector to get model summaries from the mesh to the mapping grid mesh_proj <- fm_evaluator(   mesh,   xlim = bbox[[1]], ylim = bbox[[2]], dims = grd_dims ) # pull data kappa <- data.frame(   median = exp(res$summary.random$kappa$\"0.5quant\"),   range95 = exp(res$summary.random$kappa$\"0.975quant\") -     exp(res$summary.random$kappa$\"0.025quant\") ) alph <- data.frame(   median = exp(res$summary.random$alpha$\"0.5quant\"),   range95 = exp(res$summary.random$alpha$\"0.975quant\") -     exp(res$summary.random$alpha$\"0.025quant\") ) epsi <- data.frame(   median = res$summary.random$eps$\"0.5quant\",   range95 = (res$summary.random$eps$\"0.975quant\" -     res$summary.random$eps$\"0.025quant\") ) taus <- data.frame(   median = (exp(res$summary.random$tau$\"0.5quant\") - 1) * 100,   range95 = (exp(res$summary.random$tau$\"0.975quant\") -     exp(res$summary.random$tau$\"0.025quant\")) * 100 )  # loop to get estimates on a mapping grid pred_grids <- lapply(   list(alpha = alph, epsilon = epsi, tau = taus),   function(x) as.matrix(fm_evaluate(mesh_proj, x)) ) # make a terra raster stack with the posterior median and range95 out_stk <- rast() for (j in 1:3) {   mean_j <- cbind(expand.grid(x = mesh_proj$x, y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 1], grd_dims[1]))   )   mean_j <- rast(mean_j, crs = epsg6703km)   range95_j <- cbind(expand.grid(X = mesh_proj$x, Y = mesh_proj$y),     Z = c(matrix(pred_grids[[j]][, 2], grd_dims[1]))   )   range95_j <- rast(range95_j, crs = epsg6703km)   out_j <- c(mean_j, range95_j)   terra::add(out_stk) <- out_j } names(out_stk) <- c(   \"alpha_median\", \"alpha_range95\", \"epsilon_median\",   \"epsilon_range95\", \"tau_median\", \"tau_range95\" ) out_stk <- terra::mask(   out_stk,   terra::vect(sf::st_union(states)),   updatevalue = NA,   touches = FALSE ) make_plot_field <- function(data_stk, scale_label) {   ggplot(states) +     geom_sf(fill = NA) +     coord_sf(datum = NA) +     geom_spatraster(data = data_stk) +     labs(x = \"\", y = \"\") +     scale_fill_distiller(scale_label,       palette = \"Spectral\",       na.value = \"transparent\"     ) +     theme_bw() +     geom_sf(fill = NA) } make_plot_site <- function(data, scale_label) {   ggplot(states) +     geom_sf() +     coord_sf(datum = NA) +     geom_sf(data = data, size = 1, mapping = aes(colour = value)) +     scale_colour_distiller(scale_label, palette = \"Spectral\") +     labs(x = \"\", y = \"\") +     theme_bw() +     geom_sf(fill = NA) }  # medians # fields alpha_s, epsilon_s, tau_s pa <- make_plot_field(   data_stk = out_stk[[\"alpha_median\"]],   scale_label = \"posterior\\nmedian\\nexp(alpha_s)\" ) pe <- make_plot_field(   data_stk = out_stk[[\"epsilon_median\"]],   scale_label = \"posterior\\nmedian\\nepsilon_s\" ) pt <- make_plot_field(   data_stk = out_stk[[\"tau_median\"]],   scale_label = \"posterior\\nmedian\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$median)),   scale_label = \"posterior\\nmedian\\nexp(kappa_s)\" ) # range95 # fields alpha_s, epsilon_s, tau_s pa_range95 <- make_plot_field(   data_stk = out_stk[[\"alpha_range95\"]],   scale_label = \"posterior\\nrange95\\nexp(alpha_s)\" ) pe_range95 <- make_plot_field(   data_stk = out_stk[[\"epsilon_range95\"]],   scale_label = \"posterior\\nrange95\\nepsilon_s\" ) pt_range95 <- make_plot_field(   data_stk = out_stk[[\"tau_range95\"]],   scale_label = \"posterior\\nrange95\\n100(exp(tau_s)-1)\" ) # sites kappa_s ps_range95 <- make_plot_site(   data = cbind(site_map, data.frame(value = kappa$range95)),   scale_label = \"posterior\\nrange95\\nexp(kappa_s)\" ) # plot together multiplot(ps, pa, pe, pt, cols = 2) # plot together multiplot(ps_range95, pa_range95, pe_range95, pt_range95, cols = 2)"},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"more-information","dir":"Articles","previous_headings":"","what":"More information","title":"Spatially Varying Coefficient Models with inlabru","text":"information building spatial models using SPDE approach R-INLA can found Lindgren Rue (2015), Blangiardo Camaletti (2015), Bakka et al. (2018), Krainski et al. (2018), Moraga (2019).","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/svc.html","id":"citations","dir":"Articles","previous_headings":"","what":"Citations","title":"Spatially Varying Coefficient Models with inlabru","text":"Bakka, H., Rue, H., Fuglstad, G.., Riebler, ., Bolin, D., Illian, J., Krainski, E., Simpson, D. Lindgren, F., 2018. Spatial modeling R‐INLA: review. Wiley Interdisciplinary Reviews: Computational Statistics, 10(6), p.e1443. Besag, J., 1974. Spatial interaction statistical analysis lattice systems. Journal Royal Statistical Society: Series B (Methodological), 36(2), pp.192-225. Blangiardo, M., Cameletti, M., Baio, G. Rue, H., 2013. Spatial spatio-temporal models R-INLA. Spatial spatio-temporal epidemiology, 4, pp.33-49. Finley, .O., 2011. Comparing spatially‐varying coefficients models analysis ecological data non‐stationary anisotropic residual dependence. Methods Ecology Evolution, 2(2), pp.143-154. Fuglstad, G.., Simpson, D., Lindgren, F. Rue, H., 2019. Constructing priors penalize complexity Gaussian random fields. Journal American Statistical Association, 114(525), pp.445-452. Gelfand, .E., Kim, H.J., Sirmans, C.F. Banerjee, S., 2003. Spatial modeling spatially varying coefficient processes. Journal American Statistical Association, 98(462), pp.387-396. Gómez-Rubio, V., 2020. Bayesian inference INLA. CRC Press. Krainski, E., Gómez-Rubio, V., Bakka, H., Lenzi, ., Castro-Camilo, D., Simpson, D., Lindgren, F. Rue, H., 2018. Advanced spatial modeling stochastic partial differential equations using R INLA. Chapman Hall/CRC. Lindgren, F., Rue, H. Lindström, J., 2011. explicit link Gaussian fields Gaussian Markov random fields: stochastic partial differential equation approach. Journal Royal Statistical Society: Series B (Statistical Methodology), 73(4), pp.423-498. Lindgren, F. Rue, H., 2015. Bayesian spatial modelling R-INLA. Journal statistical software, 63, pp.1-25. Lindgren, F., Bolin, D. Rue, H., 2022. SPDE approach Gaussian non-Gaussian fields: 10 years still running. Spatial Statistics, p.100599. Link, W.., Sauer, J.R. Niven, D.K., 2006. hierarchical model regional analysis population change using Christmas Bird Count data, application American Black Duck. Condor, 108(1), pp.13-24. Meehan, T.D., Michel, N.L. Rue, H., 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine‐scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707. Moraga, P., 2019. Geospatial health data: Modeling visualization R-INLA shiny. CRC Press. R Core Team (2021). R: language environment statistical computing. R Foundation Statistical Computing, Vienna, Austria. Rue, H., Martino, S. Chopin, N., 2009. Approximate Bayesian inference latent Gaussian models using integrated nested Laplace approximations. Journal royal statistical society: Series b (statistical methodology), 71(2), pp.319-392. Simpson, D., Rue, H., Riebler, ., Martins, T.G. Sørbye, S.H., 2017. Penalising model component complexity: principled, practical approach constructing priors. Statistical science, 32(1), pp.1-28. Soykan, C.U., Sauer, J., Schuetz, J.G., LeBaron, G.S., Dale, K. Langham, G.M., 2016. Population trends North American winter birds based hierarchical models. Ecosphere, 7(5), p.e01351. Van Niekerk, J. Rue, H., 2021. Correcting Laplace Method Variational Bayes. Journal Machine Learning Research, review. Van Niekerk, J. Krainski, E. T. Rustand, D. Rue, H., 2022. new avenue Bayesian inference INLA. Submitted.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"count-model","dir":"Articles","previous_headings":"","what":"Count model","title":"ZIP and ZAP models","text":"addition point process models, inlabru capable handling models positive integer responses, abundance models species counts recorded observed location. Count models can considered coarse aggregations point process models. following example utilizes gorillas dataset. obtain count data, rasterize species counts match spatial covariates available ‘gorilla’ data, aggregate pixels cover area 16 times larger (4x4 pixels original covariate raster dimensions). Finally, mask regions outside study area. Counts gorilla nests now need extract coordinates pixels. plot illustrates pixel locations pixels non-zero counts. create mesh study area define prior . can also aggregate relevant spatial covariates level granularity nest counts. vegetation classes quite unbalances, might make sense split class use proportion land cover classes, say classes 2, 3 (Disturbed, Grassland, respectively). Proportion vegetation cover class Mesh count locations","code":"gorillas_sf <- inlabru::gorillas_sf nests <- gorillas_sf$nests mesh <- gorillas_sf$mesh boundary <- gorillas_sf$boundary gcov <- gorillas_sf_gcov() counts_rstr <- terra::rasterize(vect(nests), gcov, fun = sum, background = 0) %>%   terra::aggregate(fact = 4, fun = sum) %>%   mask(vect(sf::st_geometry(boundary))) plot(counts_rstr) counts_rstr <- counts_rstr %>%   cellSize(unit = \"km\") %>%   c(counts_rstr) counts_df <- crds(counts_rstr, df = TRUE, na.rm = TRUE) %>%   bind_cols(values(counts_rstr, mat = TRUE, na.rm = TRUE)) %>%   rename(count = sum) %>%   mutate(present = (count > 0) * 1L) %>%   st_as_sf(coords = c(\"x\", \"y\"), crs = st_crs(nests)) gcov_lvls <- gcov$vegetation %>% levels() gcov_vegetation <- gcov$vegetation %>%   segregate() %>%   terra::aggregate(fact = 4, fun = mean) names(gcov_vegetation) <- gcov_lvls[[1]]$vegetation gcov_vegetation %>% plot() px_mesh <- fm_mesh_2d_inla(   loc = st_intersection(st_as_sfc(counts_df), st_buffer(boundary, -0.05)),   boundary = boundary,   max.edge = c(0.5, 1),   crs = st_crs(counts_df) )  px_matern <- INLA::inla.spde2.pcmatern(px_mesh,   prior.sigma = c(5, 0.01),   prior.range = c(0.1, 0.01) )  ggplot() +   geom_fm(data = px_mesh) +   geom_sf(     data = counts_df[counts_df$count > 0, ],     aes(color = count),     size = 1,     pch = 4   ) +   theme_minimal()"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"poisson-glm","dir":"Articles","previous_headings":"Count model","what":"Poisson GLM","title":"ZIP and ZAP models","text":"Next, can define Poisson model links species count per observation plot (raster cell) spatial covariates, vegetation type elevation.","code":"comps <- ~ veg_disturbed(gcov_vegetation$Disturbed, model = \"linear\") +   veg_grassland(gcov_vegetation$Grassland, model = \"linear\") +   elevation(gcov$elevation, model = \"linear\") +   field(geometry, model = px_matern) + Intercept(1)  fit_poi <- bru(   comps,   like(     family = \"poisson\", data = counts_df,     formula = count ~       veg_disturbed + veg_grassland +       elevation + field + Intercept,     E = area   ) ) summary(fit_poi) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> veg_disturbed: main = linear(gcov_vegetation$Disturbed), group = exchangeable(1L), replicate = iid(1L), NULL #> veg_grassland: main = linear(gcov_vegetation$Grassland), group = exchangeable(1L), replicate = iid(1L), NULL #> elevation: main = linear(gcov$elevation), group = exchangeable(1L), replicate = iid(1L), NULL #> field: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'poisson' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: count ~ veg_disturbed + veg_grassland + elevation + field + Intercept #>     Used components: effects[veg_disturbed, veg_grassland, elevation, field, Intercept], latent[] #> Time used: #>     Pre = 0.344, Running = 2.87, Post = 0.576, Total = 3.79  #> Fixed effects: #>                 mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> veg_disturbed  0.085 0.351     -0.603    0.086      0.773  0.085   0 #> veg_grassland -1.230 0.382     -1.980   -1.230     -0.480 -1.230   0 #> elevation      0.003 0.002      0.000    0.003      0.007  0.003   0 #> Intercept     -6.173 3.464    -13.001   -6.167      0.637 -6.157   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                 mean    sd 0.025quant 0.5quant 0.975quant mode #> Range for field 2.35 0.654       1.38     2.25       3.92 2.04 #> Stdev for field 2.94 0.679       1.88     2.85       4.54 2.66 #>  #> Deviance Information Criterion (DIC) ...............: 1555.96 #> Deviance Information Criterion (DIC, saturated) ....: 826.72 #> Effective number of parameters .....................: 146.78 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1569.57 #> Effective number of parameters .................: 130.84 #>  #> Marginal log-Likelihood:  -844.69  #> CPO, PIT is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')   pred_poi <- predict(   fit_poi, counts_df,   ~ {     expect <- exp( # vegetation +       veg_disturbed + veg_grassland +         elevation + field + Intercept     ) * area     list(       expect = expect,       obs_prob = dpois(count, expect)     )   },   n.samples = 2500 ) # For Poisson, the posterior conditional variance is equal to # the posterior conditional mean, so no need to compute it separately. expect_poi <- pred_poi$expect expect_poi$pred_var <- expect_poi$mean + expect_poi$sd^2 expect_poi$log_score <- -log(pred_poi$obs_prob$mean)  ggplot() +   geom_fm(data = px_mesh) +   gg(expect_poi, aes(fill = mean / area), geom = \"tile\") +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"Nest intensity per ~1.25 ha\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"true-zeroes-and-false-zeroes","dir":"Articles","previous_headings":"Count model","what":"True zeroes and false zeroes","title":"ZIP and ZAP models","text":"Poisson GLM model, zeros can occur locations. referred “true zeros” can explained model associated covariates. hand, “false zeros” align covariates. can arise due issues sampling wrong time place, observer errors, unsuitable environmental conditions, . dataset, number zeros quite substantial, model may struggle account adequately. address , select model capable handling “inflated” number zeros, exceeding standard Poisson model imply. purpose, opt “zero-inflated Poisson model,” commonly abbreviated ZIP.","code":""},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"zip-model","dir":"Articles","previous_headings":"Count model","what":"ZIP model","title":"ZIP and ZAP models","text":"Type 1 Zero-inflated Poisson model defined follows: Prob(y|…)=p×1y=0+(1−p)×Poisson(y) \\text{Prob}(y\\vert\\dots)=p\\times 1_{y=0}+(1-p)\\times \\text{Poisson}(y) , p=logit−1(θ)p=\\text{logit}^{-1}(\\theta) expected value variance counts calculated : E(count)=(1−p)λVar(count)=(1−p)(λ+pλ2) \\begin{gathered} E(count)=(1-p)\\lambda \\\\ Var(count)= (1-p)(\\lambda+p \\lambda^2) \\end{gathered} Predictions zero-inflated model compare performance models diagnostic section .","code":"fit_zip <- bru(   comps,   like(     family = \"zeroinflatedpoisson1\", data = counts_df,     formula = count ~       veg_disturbed + veg_grassland +       elevation + field + Intercept,     E = area   ) )  summary(fit_zip) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> veg_disturbed: main = linear(gcov_vegetation$Disturbed), group = exchangeable(1L), replicate = iid(1L), NULL #> veg_grassland: main = linear(gcov_vegetation$Grassland), group = exchangeable(1L), replicate = iid(1L), NULL #> elevation: main = linear(gcov$elevation), group = exchangeable(1L), replicate = iid(1L), NULL #> field: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'zeroinflatedpoisson1' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: count ~ veg_disturbed + veg_grassland + elevation + field + Intercept #>     Used components: effects[veg_disturbed, veg_grassland, elevation, field, Intercept], latent[] #> Time used: #>     Pre = 0.353, Running = 1.62, Post = 0.128, Total = 2.1  #> Fixed effects: #>                 mean    sd 0.025quant 0.5quant 0.975quant   mode kld #> veg_disturbed -0.005 0.346     -0.681   -0.006      0.678 -0.006   0 #> veg_grassland -1.240 0.377     -1.979   -1.240     -0.501 -1.240   0 #> elevation      0.003 0.002     -0.001    0.003      0.006  0.003   0 #> Intercept     -5.511 3.432    -12.375   -5.482      1.200 -5.480   0 #>  #> Random effects: #>   Name     Model #>     field SPDE2 model #>  #> Model hyperparameters: #>                                                         mean    sd 0.025quant #> zero-probability parameter for zero-inflated poisson_1 0.058 0.036      0.011 #> Range for field                                        2.599 0.751      1.476 #> Stdev for field                                        2.940 0.707      1.845 #>                                                        0.5quant 0.975quant #> zero-probability parameter for zero-inflated poisson_1     0.05      0.147 #> Range for field                                            2.48      4.403 #> Stdev for field                                            2.84      4.611 #>                                                         mode #> zero-probability parameter for zero-inflated poisson_1 0.031 #> Range for field                                        2.253 #> Stdev for field                                        2.632 #>  #> Deviance Information Criterion (DIC) ...............: 1553.47 #> Deviance Information Criterion (DIC, saturated) ....: 784.35 #> Effective number of parameters .....................: 125.16 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1559.24 #> Effective number of parameters .................: 109.70 #>  #> Marginal log-Likelihood:  -845.29  #> CPO, PIT is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')  pred_zip <- predict(   fit_zip, counts_df,   ~ {     scaling_prob <- (1 - zero_probability_parameter_for_zero_inflated_poisson_1)     lambda <- exp( # vegetation +       veg_disturbed + veg_grassland +         elevation + field + Intercept     )     expect_param <- lambda * area     expect <- scaling_prob * expect_param     variance <- scaling_prob * expect_param * (1 + (1 - scaling_prob) * expect_param)     list(       lambda = lambda,       expect = expect,       variance = variance,       obs_prob = (1 - scaling_prob) * (count == 0) + scaling_prob * dpois(count, expect_param)     )   },   n.samples = 2500 ) expect_zip <- pred_zip$expect expect_zip$pred_var <- pred_zip$variance$mean + expect_zip$sd^2 expect_zip$log_score <- -log(pred_zip$obs_prob$mean)  ggplot() +   geom_fm(data = px_mesh) +   gg(expect_zip, aes(fill = mean / area), geom = \"tile\") +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"Nest intensity per ~1.25 ha\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"zap-model","dir":"Articles","previous_headings":"Count model","what":"ZAP model","title":"ZIP and ZAP models","text":"Based distribution nests relation spatial covariates, appears gorillas tend avoid setting nests certain types vegetation. type vegetation may directly influence nest density, play significant role determining presence absence. cases, vegetation covariate included binomial part model Poisson part. process driving presence absence species substantially differs process governing abundance, advisable switch Zero-Adjusted Poisson (ZAP) model, consists binomial truncated Poisson component. zeroinflatedpoisson0 model, defined following observation probability model Prob(y|…)=p×1y=0+(1−p)×Poisson(y|y>0) \\text{Prob}(y\\vert\\dots)=p\\times 1_{y=0}+(1-p)\\times \\text{Poisson}(y\\vert y>0) p=logit−1(θ)p=\\text{logit}^{-1}(\\theta). order allow pp controlled full latent model just single hyperparameter, set want set p=0p=0, handle zero-probability modelling separate binary observation model modelling presence/absence. INLA version 23.10.19-1, done fixing hyperparameter small value. nzpossion model, available INLA version 23.10.19-1 implements Poisson(y|y>0)\\text{Poisson}(y\\vert y>0) model exactly. resulting model, truncated Poisson distribution governs positive counts, absences addressed separate binomial model can covariates. ’s worth noting exclude observations absent nests truncated Poisson part model subsetting data include instances present TRUE. expectation variance computed follows: E(count)=11−exp(−λ)pλVar(count)=11−exp(−λ)p(λ+pλ2)−(11−exp(−λ)pλ)2=E(count)(1+pλ)−E(count)2=E(count)(1+pλ−E(count))=E(count)(1+pλ(1−11−exp(−λ)))=E(count)(1−pλexp(−λ)1−exp(−λ))=E(count)(1−exp(−λ)E(count)) \\begin{aligned} E(count)&=\\frac{1}{1-\\exp(-\\lambda)}p\\lambda \\\\ Var(count)&= \\frac{1}{1-\\exp(-\\lambda)}  p(\\lambda+p \\lambda^2)-\\left(\\frac{1}{1-\\exp(-\\lambda)}p\\lambda\\right)^2 \\\\ &= E(count) (1+p\\lambda) - E(count)^2 \\\\ &= E(count) (1+p\\lambda-E(count)) \\\\ &= E(count) \\left(1+p\\lambda\\left(1-\\frac{1}{1-\\exp(-\\lambda)}\\right)\\right) \\\\ &= E(count) \\left(1-p\\lambda\\frac{\\exp(-\\lambda)}{1-\\exp(-\\lambda)}\\right) \\\\ &= E(count) \\left(1-\\exp(-\\lambda) E(count)\\right) \\end{aligned} Note model, direct link parameters two observation parts, estimate separately. However, example field_count component used predictors, possible use copy argument share component two parts, field_present(geometry, copy = \"field_count\", fixed = TRUE), fixed = TRUE tells bru() estimate scaling parameter instead using linear effect parameter version field. results , see estimated covariance parameters two fields different, sensible share component two parts.","code":"comps <- ~   Intercept_count(1) +     veg_disturbed(gcov_vegetation$Disturbed, model = \"linear\") +     veg_grassland(gcov_vegetation$Grassland, model = \"linear\") +     elevation(gcov$elevation, model = \"linear\") +     field_present(geometry, model = px_matern) +     Intercept_present(1) +     elevation_present(gcov$elevation, model = \"linear\") +     field_count(geometry, model = px_matern)  ## Alternative with a shared field component: #  field_count(geometry, copy = \"field_present\", fixed = FALSE)  truncated_poisson_like <-   if (package_version(getNamespaceVersion(\"INLA\")) < \"23.10.19-1\") {     like(       family = \"zeroinflatedpoisson0\",       data = counts_df[counts_df$present > 0, ],       formula = count ~ elevation + field_count + Intercept_count,       E = area,       control.family = list(hyper = list(theta = list(         initial = -20, fixed = TRUE       )))     )   } else {     like(       family = \"nzpoisson\",       data = counts_df[counts_df$present > 0, ],       formula = count ~ elevation + field_count + Intercept_count,       E = area     )   }  present_like <- like(   family = \"binomial\",   data = counts_df,   formula = present ~ # vegetation +     veg_disturbed + veg_grassland +     elevation_present + field_present + Intercept_present )  fit_zap <- bru(   comps,   present_like,   truncated_poisson_like,   options = list(bru_verbose = 4) ) #> iinla: Evaluate component inputs #> iinla: Evaluate component linearisations #> iinla: Evaluate component simplifications #> iinla: Evaluate predictor linearisation #> iinla: Construct inla stack #> iinla: Model initialisation completed #> iinla: Iteration 1 [max:10] #> iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 220.6, norm1 = 3.482e-14, norm01 = 220.6) #> iinla: Optimisation did not improve on previous solution. #> iinla: |lin1-lin0| = 220.6 #>        <eta-lin1,delta>/|delta| = 1.928e-15 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 3.717e-14 #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Iteration 2 [max:10] #> iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 0.0442, norm1 = 7.424e-12, norm01 = 0.0442) #> iinla: |lin1-lin0| = 0.0442 #>        <eta-lin1,delta>/|delta| = -4.675e-14 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 7.424e-12 #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 0.675% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] #> iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. #> iinla: Iteration 3 [max:10]  summary(fit_zap) #> inlabru version: 2.11.1.9007 #> INLA version: 24.09.14 #> Components: #> veg_disturbed: main = linear(gcov_vegetation$Disturbed), group = exchangeable(1L), replicate = iid(1L), NULL #> veg_grassland: main = linear(gcov_vegetation$Grassland), group = exchangeable(1L), replicate = iid(1L), NULL #> field_present: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept_present: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> elevation_present: main = linear(gcov$elevation), group = exchangeable(1L), replicate = iid(1L), NULL #> Intercept_count: main = linear(1), group = exchangeable(1L), replicate = iid(1L), NULL #> elevation: main = linear(gcov$elevation), group = exchangeable(1L), replicate = iid(1L), NULL #> field_count: main = spde(geometry), group = exchangeable(1L), replicate = iid(1L), NULL #> Likelihoods: #>   Family: 'binomial' #>     Data class: 'sf', 'data.frame' #>     Response class: 'integer' #>     Predictor:  #>         present ~ veg_disturbed + veg_grassland + elevation_present +  #>             field_present + Intercept_present #>     Used components: effects[veg_disturbed, veg_grassland, field_present, Intercept_present, elevation_present], latent[] #>   Family: 'nzpoisson' #>     Data class: 'sf', 'data.frame' #>     Response class: 'numeric' #>     Predictor: count ~ elevation + field_count + Intercept_count #>     Used components: effects[Intercept_count, elevation, field_count], latent[] #> Time used: #>     Pre = 0.505, Running = 4.06, Post = 0.304, Total = 4.87  #> Fixed effects: #>                      mean    sd 0.025quant 0.5quant 0.975quant    mode kld #> veg_disturbed      -1.264 0.549     -2.336   -1.266     -0.179  -1.266   0 #> veg_grassland      -1.443 0.517     -2.460   -1.442     -0.431  -1.442   0 #> Intercept_present -10.561 4.192    -19.044  -10.484     -2.498 -10.480   0 #> elevation_present   0.004 0.002     -0.001    0.004      0.008   0.004   0 #> Intercept_count     2.328 1.441     -0.721    2.371      5.114   2.364   0 #> elevation           0.001 0.001      0.000    0.001      0.003   0.001   0 #>  #> Random effects: #>   Name     Model #>     field_present SPDE2 model #>    field_count SPDE2 model #>  #> Model hyperparameters: #>                          mean    sd 0.025quant 0.5quant 0.975quant  mode #> Range for field_present 2.358 0.729      1.299    2.236      4.136 1.995 #> Stdev for field_present 2.935 0.676      1.870    2.847      4.517 2.660 #> Range for field_count   0.489 0.229      0.202    0.439      1.077 0.355 #> Stdev for field_count   0.703 0.126      0.492    0.691      0.985 0.666 #>  #> Deviance Information Criterion (DIC) ...............: 1605.84 #> Deviance Information Criterion (DIC, saturated) ....: 1161.21 #> Effective number of parameters .....................: 160.56 #>  #> Watanabe-Akaike information criterion (WAIC) ...: 1602.26 #> Effective number of parameters .................: 131.89 #>  #> Marginal log-Likelihood:  -872.57  #> CPO, PIT is computed  #> Posterior summaries for the linear predictor and the fitted values are computed #> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"predict-intensity-on-the-original-raster-locations","dir":"Articles","previous_headings":"","what":"Predict intensity on the original raster locations","title":"ZIP and ZAP models","text":"Predictions zero-adjusted model ensure proper truncation Poisson distribution, included control.family argument parameter theta fixed large negative value. choice ensures transformed logit−1(θ)\\text{logit}^{-1}(\\theta) obtain probability pp, approaches zero.","code":"pred_zap <- predict(   fit_zap,   counts_df,   ~ {     presence_prob <-       plogis( # vegetation +         veg_disturbed + veg_grassland +           elevation_present +           field_present + Intercept_present       )     lambda <- exp(elevation + field_count + Intercept_count)     expect_param <- presence_prob * lambda * area     expect <- expect_param / (1 - exp(-lambda * area))     variance <- expect * (1 - exp(-lambda * area) * expect)     list(       presence = presence_prob,       lambda = lambda,       expect = expect,       variance = variance,       obs_prob = (1 - presence_prob) * (count == 0) +         (count > 0) * presence_prob * dpois(count, expect_param) / (1 - dpois(0, expect_param))     )   },   n.samples = 2500 ) presence_zap <- pred_zap$presence expect_zap <- pred_zap$expect expect_zap$pred_var <- pred_zap$variance$mean + expect_zap$sd^2 expect_zap$log_score <- -log(pred_zap$obs_prob$mean)  p1 <- ggplot() +   geom_fm(data = px_mesh) +   gg(presence_zap, aes(fill = mean), geom = \"tile\") +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"Presence probability\") p2 <- ggplot() +   geom_fm(data = px_mesh) +   gg(expect_zap, aes(fill = mean / area), geom = \"tile\") +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"Expected number of nests per ~1.25 ha\")  patchwork::wrap_plots(p1, p2, nrow = 1)"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"model-comparison","dir":"Articles","previous_headings":"Predict intensity on the original raster locations","what":"Model Comparison","title":"ZIP and ZAP models","text":"variance count predictions can obtained posterior predictions expectations variances previously computed grid box. Let’s denote count expectation grid box mim_i, count variance si2s_i^2, conditioned model predictor ηi\\eta_i. , posterior predictive variance count XiX_i given : V(Xi)=E(V(Xi|ηi))+V(E(Xi|ηi))=E(si2)+V(mi). \\begin{aligned} V(X_i) &= E(V(X_i|\\eta_i)) + V(E(X_i|\\eta_i)) \\\\ &= E(s_i^2) + V(m_i) . \\end{aligned} equation provides posterior predictive variance count XiX_i based expectations variances model predictions mim_i si2s_i^2 grid box, conditioned model predictor ηi\\eta_i. Predictive Integral Transform (PIT) (Marshall Spiegelhalter 2003; Gelman, Meng, Stern 1996; Held, Schrödle, Rue 2010) calculated cumulative distribution function (CDF) observed data predicted value model. Mathematically, observation yiy_i corresponding predicted value ŷ\\hat{y}_i model, PIT calculated follows: PITi=P(Yi≤ŷ|data)PIT_i=P(Y_i\\leq \\hat y_i \\vert data) YiY_i random variable representing observed data iith observation. PIT measures well model’s predicted values align distribution observed data. Ideally, model’s predictions perfect, PIT values follow uniform distribution 0 1. Deviations uniform distribution may indicate issues model calibration overfitting. ’s often used assess reliability model predictions can visualized PIT histograms quantile-quantile (Q-Q) plots. Conditional Predictive Ordinate (CPO) (Pettit 1990) calculated posterior probability observed data observation point, conditional rest data model. observation yiy_i, computed : CPOi=P(yi|data\\yi,model)CPO_i=P(y_i\\vert data \\setminus y_i, model) \\\\setminus means “”, P(yi|data\\yi,model)P(y_i | \\text{data}\\setminus y_i, \\text{model}) represents conditional probability given observed data model. CPO provides measure well model predicts individual observation taking account rest data model. low CPO value suggests model difficulty explaining particular data point, whereas high CPO value indicates good fit observation. practice, CPO values often used identify influential observations, potential outliers, model misspecification. comparing models, following summary CPO often used: −∑=1nlog(CPOi)-\\sum_{=1}^n\\log(CPO_i) smaller values indicate better model fit.","code":"zap_pit <- rep(NA_real_, nrow(counts_df)) zap_pit[counts_df$count > 0] <- fit_zap$cpo$pit[-seq_len(nrow(counts_df))]  df <- data.frame(   count = rep(counts_df$count, times = 3),   pred_mean = c(     expect_poi$mean,     expect_zip$mean,     expect_zap$mean   ),   pred_var = c(     expect_poi$pred_var,     expect_zip$pred_var,     expect_zap$pred_var   ),   pred_median = c(     expect_poi$median,     expect_zip$median,     expect_zap$median   ),   log_score = c(     expect_poi$log_score,     expect_zip$log_score,     expect_zap$log_score   ),   pit = c(     fit_poi$cpo$pit * c(NA_real_, 1)[1 + (counts_df$count > 0)],     fit_zip$cpo$pit * c(NA_real_, 1)[1 + (counts_df$count > 0)],     zap_pit   ),   Model = rep(c(\"Poisson\", \"ZIP\", \"ZAP\"), each = nrow(counts_df)) )  p1 <- ggplot(df) +   geom_point(aes(pred_mean, count - pred_mean, color = Model)) +   ggtitle(\"Residuals\")  p2 <- ggplot(df) +   stat_ecdf(aes(pit, color = Model), na.rm = TRUE) +   scale_x_continuous(expand = c(0, 0)) +   ggtitle(\"PIT\")  patchwork::wrap_plots(p1, p2, nrow = 1, guides = \"collect\")"},{"path":"https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html","id":"prediction-scores","dir":"Articles","previous_headings":"Predict intensity on the original raster locations > Model Comparison","what":"Prediction scores","title":"ZIP and ZAP models","text":"use four distinct prediction scores evaluate model performance: AEi=|yi−mediani|,SEi=[yi−E(Xi|data)]2, andDSi=[yi−E(Xi|data)]2V(Xi|data)+log[V(Xi|data)],LGi=−log[P(Xi=yi|data)]. \\begin{aligned} \\text{AE}_i&=|y_i-\\text{median}_i|,\\\\ \\text{SE}_i&=[y_i-E(X_i|\\text{data})]^2, \\text{ }\\\\ \\text{DS}_i&=\\frac{[y_i-E(X_i|\\text{data})]^2}{V(X_i|\\text{data})} + \\log[V(X_i|\\text{data})], \\\\ \\text{LG}_i&=-\\log[P(X_i = y_i|\\text{data})]. \\end{aligned}  Dawid-Sebastiani score proper scoring rule predictive mean E(Xi)E(X_i) variance V(Xi)V(X_i). AE SE proper scores median expectation, respectively. (negated) Log score strictly proper score (Gneiting Raftery 2007) see average scores similar three models","code":"df <- df %>%   mutate(     AE = abs(count - pred_median),     SE = (count - pred_mean)^2,     DS = (count - pred_mean)^2 / pred_var + log(pred_var),     LG = log_score   )  scores <- df %>%   group_by(Model) %>%   summarise(     MAE = mean(AE),     MSE = sqrt(mean(SE)),     MDS = mean(DS),     MLG = mean(LG)   ) %>%   left_join(     data.frame(       Model = c(\"Poisson\", \"ZIP\", \"ZAP\"),       Order = 1:3     ),     by = \"Model\"   ) %>%   arrange(Order) %>%   select(-Order) knitr::kable(scores) df <- df %>%   tibble::as_tibble() %>%   cbind(geometry = c(counts_df$geometry, counts_df$geometry, counts_df$geometry)) df_ <- df %>%   left_join(     df %>%       filter(Model == \"Poisson\") %>%       select(geometry,         AE_Poisson = AE,         SE_Poisson = SE,         DS_Poisson = DS,         LG_Poisson = LG       ),     by = c(\"geometry\")   ) %>%   sf::st_as_sf() p1 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"Poisson\"), aes(fill = DS), geom = \"tile\") +   scale_fill_distiller(     type = \"seq\",     palette = \"Reds\",     limits = c(-7.5, 25),     direction = 1   ) +   geom_sf(     data = nests,     color = \"firebrick\",     size = 1,     pch = 4,     alpha = 0.2   ) +   ggtitle(\"Poisson Dawid-Sebastiani scores\") +   guides(fill = guide_legend(\"DS\")) p2 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"ZIP\"), aes(fill = DS - DS_Poisson), geom = \"tile\") +   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = c(-5, 5)) +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"ZIP Dawid-Sebastiani score difference\") +   guides(fill = guide_legend(\"DS-DS_poi\")) p3 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"ZAP\"), aes(fill = DS - DS_Poisson), geom = \"tile\") +   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = c(-5, 5)) +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"ZAP Dawid-Sebastiani score difference\") +   guides(fill = guide_legend(\"DS-DS_poi\"))  patchwork::wrap_plots(p1, p2, p3, nrow = 1) p1 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"Poisson\"), aes(fill = LG), geom = \"tile\") +   scale_fill_distiller(     type = \"seq\",     palette = \"Reds\",     limits = c(0, 5),     direction = 1   ) +   geom_sf(     data = nests,     color = \"firebrick\",     size = 1,     pch = 4,     alpha = 0.2   ) +   ggtitle(\"LG score\") +   guides(fill = guide_legend(\"LG\")) p2 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"ZIP\"), aes(fill = LG - LG_Poisson), geom = \"tile\") +   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = c(-2, 2)) +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"ZIP LG score difference\") +   guides(fill = guide_legend(\"LG-LG_poi\")) p3 <- ggplot() +   geom_fm(data = px_mesh) +   gg(df_ %>% filter(Model == \"ZAP\"), aes(fill = LG - LG_Poisson), geom = \"tile\") +   scale_fill_distiller(type = \"div\", palette = \"RdBu\", limits = c(-2, 2)) +   geom_sf(data = nests, color = \"firebrick\", size = 1, pch = 4, alpha = 0.2) +   ggtitle(\"ZAP LG score difference\") +   guides(fill = guide_legend(\"LG-LG_poi\"))  patchwork::wrap_plots(p1, p2, p3, nrow = 1)"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Finn Lindgren. Author, maintainer, copyright holder.            Finn Lindgren continued development main code Fabian E. Bachl. Author, copyright holder.           Fabian Bachl wrote main code David L. Borchers. Contributor, data contributor, copyright holder.           David Borchers wrote code Gorilla data import sampling, multiplot tool Daniel Simpson. Contributor, copyright holder.           Daniel Simpson wrote basic LGCP sampling method Lindesay Scott-Howard. Contributor, data contributor, copyright holder.           Lindesay Scott-Howard provided MRSea data import code Seaton Andy. Contributor.           Andy Seaton provided testing, bugfixes, vignettes Suen Man Ho. Contributor, copyright holder.           Man Ho Suen contributed features aggregated responses vignette updates Roudier Pierre. Contributor, copyright holder.           Pierre Roudier contributed general quantile summaries Meehan Tim. Contributor, copyright holder.           Tim Meehan contributed SVC vignette robins data Reddy Peddinenikalva Niharika. Contributor, copyright holder.           Niharika Peddinenikalva contributed LGCP residuals vignette Perepolkin Dmytro. Contributor, copyright holder.           Dmytro Perepolkin contributed ZIP/ZAP vignette","code":""},{"path":"https://inlabru-org.github.io/inlabru/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760--766, doi:10.1111/2041-210X.13168 Yuan Yuan, Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian, Stephen T. Buckland, Håvard Rue, Tim Gerrodette (2017), Point process models spatio-temporal distance sampling data large-scale survey blue whalesAnnals Applied Statistics, 11, 2270--2297, doi:10.1214/17-AOAS1078","code":"@Article{,   title = {{inlabru}: an {R} package for {Bayesian} spatial modelling from ecological survey data},   author = {Fabian E. Bachl and Finn Lindgren and David L. Borchers and Janine B. Illian},   year = {2019},   journal = {Methods in Ecology and Evolution},   volume = {10},   pages = {760--766},   doi = {10.1111/2041-210X.13168},   publisher = {British Ecological Society}, } @Article{,   author = {{Yuan} and {Yuan} and {Bachl} and Fabian E. and {Lindgren} and {Finn} and {Borchers} and David L. and {Illian} and Janine B. and {Buckland} and Stephen T. and {Rue} and {Håvard} and {Gerrodette} and {Tim}},   doi = {10.1214/17-AOAS1078},   fjournal = {Annals of Applied Statistics},   journal = {Ann. Appl. Stat.},   month = {12},   number = {4},   pages = {2270--2297},   publisher = {The Institute of Mathematical Statistics},   title = {Point process models for spatio-temporal distance sampling data from a large-scale survey of blue whales},   doi = {10.1214/17-AOAS1078},   volume = {11},   year = {2017}, }"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"inlabru","dir":"","previous_headings":"","what":"Bayesian Latent Gaussian Modelling using INLA and Extensions","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"goal inlabru facilitate spatial modeling using integrated nested Laplace approximation via R-INLA package. Additionally, extends GAM-like model class general nonlinear predictor expressions, implements log Gaussian Cox process likelihood modeling univariate spatial point processes based ecological survey data. Model components specified general inputs mapping methods latent variables, predictors specified via general R expressions, separate expressions observation likelihood model multi-likelihood models. prediction method based fast Monte Carlo sampling allows posterior prediction general expressions latent variables. See Fabian E. Bachl, Finn Lindgren, David L. Borchers, Janine B. Illian (2019), inlabru: R package Bayesian spatial modelling ecological survey data, Methods Ecology Evolution, British Ecological Society, 10, 760–766, doi:10.1111/2041-210X.13168, citation(\"inlabru\"). inlabru.org website links old tutorials code examples versions 2.1.13. later versions, updated versions tutorials, well new examples, can found https://inlabru-org.github.io/inlabru/articles/","code":""},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"can install current CRAN version version inlabru:","code":"options(repos = c(   INLA = \"https://inla.r-inla-download.org/R/testing\",   getOption(\"repos\") )) install.packages(\"inlabru\")"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"installation-using-pak","dir":"","previous_headings":"Installation","what":"Installation using pak","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"can install latest bugfix release inlabru GitHub : can install development version inlabru GitHub track development version builds via inlabru-org.r-universe.dev: pick r-universe version recent CRAN version.","code":"# install.packages(\"pak\") pak::repo_add(INLA = \"https://inla.r-inla-download.org/R/testing\") pak::pkg_install(\"inlabru-org/inlabru@stable\") pak::pkg_install(\"inlabru-org/inlabru\") # Enable universe(s) by inlabru-org pak::repo_add(inlabruorg = \"https://inlabru-org.r-universe.dev\") pak::pkg_install(\"inlabru\")"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"installation-using-remotes","dir":"","previous_headings":"Installation","what":"Installation using remotes","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"can install latest bugfix release inlabru GitHub : can install development version inlabru GitHub track development version builds via inlabru-org.r-universe.dev:","code":"# install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\", ref = \"stable\") remotes::install_github(\"inlabru-org/inlabru\", ref = \"devel\") # Enable universe(s) by inlabru-org options(repos = c(   inlabruorg = \"https://inlabru-org.r-universe.dev\",   INLA = \"https://inla.r-inla-download.org/R/testing\",   CRAN = \"https://cloud.r-project.org\" ))  # Install some packages install.packages(\"inlabru\")"},{"path":"https://inlabru-org.github.io/inlabru/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Latent Gaussian Modelling using INLA and Extensions","text":"basic example shows fit simple spatial Log Gaussian Cox Process (LGCP) predicts intensity: Nest intensity per km squared","code":"# Load libraries library(INLA) #> Loading required package: Matrix #> Loading required package: sp #> This is INLA_24.06.27 built 2024-06-27 02:36:04 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - List available models/likelihoods/etc with inla.list.models() #>  - Use inla.doc(<NAME>) to access documentation library(inlabru) #> Loading required package: fmesher library(fmesher) library(ggplot2)  # Construct latent model components matern <- inla.spde2.pcmatern(   gorillas_sf$mesh,   prior.sigma = c(0.1, 0.01),   prior.range = c(0.01, 0.01) ) cmp <- ~ mySmooth(geometry, model = matern) + Intercept(1) # Fit LGCP model # This particular bru/like combination has a shortcut function lgcp() as well fit <- bru(   cmp,   like(     formula = geometry ~ .,     family = \"cp\",     data = gorillas_sf$nests,     samplers = gorillas_sf$boundary,     domain = list(geometry = gorillas_sf$mesh)   ),   options = list(control.inla = list(int.strategy = \"eb\")) )  # Predict Gorilla nest intensity lambda <- predict(   fit,   fm_pixels(gorillas_sf$mesh, mask = gorillas_sf$boundary),   ~ exp(mySmooth + Intercept) ) # Plot the result ggplot() +   geom_fm(data = gorillas_sf$mesh) +   gg(lambda, geom = \"tile\") +   gg(gorillas$nests, color = \"red\", size = 0.5, alpha = 0.5) +   ggtitle(\"Nest intensity per km squared\") +   xlab(\"\") +   ylab(\"\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"Point data count data, together intensity function expected counts homogeneous 1-dimensional Poisson process example.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"data(Poisson1_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"data contain following R objects: lambda1_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc1 expected counts gridded data. pts1 locations observed points (data frame one column, named x). countdata1 data frame three columns, containing count data:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson1_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional Homogeneous Poisson example. — Poisson1_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson1_1D)   ggplot(countdata1) +     geom_point(data = countdata1, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata1$count)) +     geom_point(data = pts1, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     geom_point(       data = countdata1, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     xlab(expression(bold(s))) +     ylab(\"count\") }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"Point data count data, together intensity function expected counts unimodal nonhomogeneous 1-dimensional Poisson process example.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"data(Poisson2_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"data contain following R objects: lambda2_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). cov2_1D: function gives call 'habitat suitability' covariate 1D space. E_nc2 expected counts gridded data. pts2 locations observed points (data frame one column, named x). countdata2 data frame three columns, containing count data:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson2_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson2_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson2_1D)   p1 <- ggplot(countdata2) +     geom_point(data = countdata2, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata2$count, E_nc2)) +     geom_point(       data = countdata2, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata2$x, y = E_nc2), aes(x = x),       y = E_nc2, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length.out = 200)   lambda <- lambda2_1D(ss)   p2 <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda),       aes(x = x, y = y), col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts2, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1, p2, cols = 1) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":null,"dir":"Reference","previous_headings":"","what":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"Point data count data, together intensity function expected counts multimodal nonhomogeneous 1-dimensional Poisson process example. Counts given two different gridded data interval widths.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"data(Poisson3_1D)"},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"data contain following R objects: lambda3_1D: function defining intensity function nonhomogeneous Poisson process. Note function defined interval (0,55). E_nc3a expected counts gridded data wider bins (10 bins). E_nc3b expected counts gridded data wider bins (20 bins). pts3 locations observed points (data frame one column, named x). countdata3a data frame three columns, containing count data 10-interval case: countdata3b data frame three columns, containing count data 20-interval case:","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/Poisson3_1D.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1-Dimensional NonHomogeneous Poisson example. — Poisson3_1D","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(Poisson3_1D)   # first the plots for the 10-bin case:   p1a <- ggplot(countdata3a) +     geom_point(data = countdata3a, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3a$count, E_nc3a)) +     geom_point(       data = countdata3a, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3a$x, y = E_nc3a),       aes(x = x), y = E_nc3a, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length.out = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1)    # Then the plots for the 20-bin case:   p1a <- ggplot(countdata3b) +     geom_point(data = countdata3b, aes(x = x, y = count), col = \"blue\") +     ylim(0, max(countdata3b$count, E_nc3b)) +     geom_point(       data = countdata3b, aes(x = x), y = 0, shape = \"+\",       col = \"blue\", cex = 4     ) +     geom_point(       data = data.frame(x = countdata3b$x, y = E_nc3b),       aes(x = x), y = E_nc3b, shape = \"_\", cex = 5     ) +     xlab(expression(bold(s))) +     ylab(\"count\")   ss <- seq(0, 55, length.out = 200)   lambda <- lambda3_1D(ss)   p2a <- ggplot() +     geom_line(       data = data.frame(x = ss, y = lambda), aes(x = x, y = y),       col = \"blue\"     ) +     ylim(0, max(lambda)) +     geom_point(data = pts3, aes(x = x), y = 0.2, shape = \"|\", cex = 4) +     xlab(expression(bold(s))) +     ylab(expression(lambda(bold(s))))   multiplot(p1a, p2a, cols = 1) }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":null,"dir":"Reference","previous_headings":"","what":"Add component input/latent mappers — add_mappers","title":"Add component input/latent mappers — add_mappers","text":"Add missing mappers input data latent variables, based likelihood data Equip component(s) mappers subcomponents predefined mappers. needed, data lhoods used determine appropriate mapper(s).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add component input/latent mappers — add_mappers","text":"","code":"add_mappers(...)  # S3 method for class 'component' add_mappers(component, lhoods, ...)  # S3 method for class 'component_list' add_mappers(components, lhoods, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add component input/latent mappers — add_mappers","text":"... Parameters passed methods component component object lhoods bru_like_list object components component_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add component input/latent mappers — add_mappers","text":"component object completed mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/add_mappers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add component input/latent mappers — add_mappers","text":"","code":"if (FALSE) { # \\dontrun{ if (interactive()) { } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":null,"dir":"Reference","previous_headings":"","what":"1D LGCP bin count simulation and comparison with data — bincount","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"common procedure analyzing distribution 1D points chose binning plot data's histogram respect binning. function compares counts histogram calculates simulations 1D log Gaussian Cox process conditioned number data samples. bin results median number counts well confidence interval. LGCP plausible model observed points histogram counts (number points within bin) within confidence intervals. Note proper comparison  multiple testing problem function solve .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"bincount(   result,   predictor,   observations,   breaks,   nint = 20,   probs = c(0.025, 0.5, 0.975),   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"result result object bru() lgcp() call predictor formula describing prediction 1D LGCP via predict(). observations vector observed values breaks vector bin boundaries nint Number integration points per bin. Increase bins wide probs numeric vector probabilities values [0,1] ... arguments passed predict.bru()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"data.frame ggplot attribute ggp","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bincount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D LGCP bin count simulation and comparison with data — bincount","text":"","code":"if (FALSE) { # \\dontrun{ if (require(ggplot2) && require(fmesher)) {   # Load a point pattern   data(Poisson2_1D)    # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(       aes(x = x),       binwidth = 55 / 20,       boundary = 0,       fill = NA,       color = \"black\"     ) +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model   x <- seq(0, 55, length.out = 50)   mesh1D <- fm_mesh_1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = inla.spde2.matern(mesh1D)) + Intercept(1)   fit.spde <- lgcp(mdl, pts2, domain = list(x = c(0, 55)))    # Calculate bin statistics   bc <- bincount(     result = fit.spde,     observations = pts2,     breaks = seq(0, max(pts2), length.out = 12),     predictor = x ~ exp(spde1D + Intercept)   )     # Plot them!   attributes(bc)$ggp } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for mapper lists — bm_list","title":"Methods for mapper lists — bm_list","text":"bru_mapper lists can combined bm_list lists.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for mapper lists — bm_list","text":"","code":"# S3 method for class 'bru_mapper' c(...)  # S3 method for class 'bm_list' c(...)  # S3 method for class 'bm_list' x[i]"},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for mapper lists — bm_list","text":"... Objects combined. x bm_list object extract element(s) indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for mapper lists — bm_list","text":"bm_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Methods for mapper lists — bm_list","text":"c(bm_list): ... arguments bm_list objects. [: Extract sub-list","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Methods for mapper lists — bm_list","text":"c(bru_mapper): ... arguments bru_mapper objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bm_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for mapper lists — bm_list","text":"","code":"m <- c(A = bru_mapper_const(), B = bru_mapper_scale()) str(m) #> List of 2 #>  $ A: list() #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_const\" \"bru_mapper\" \"list\" #>  $ B: list() #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_scale\" \"bru_mapper\" \"list\" #>  - attr(*, \"class\")= chr [1:2] \"bm_list\" \"list\" str(m[2]) #> List of 1 #>  $ B: list() #>   ..- attr(*, \"class\")= chr [1:3] \"bru_mapper_scale\" \"bru_mapper\" \"list\" #>  - attr(*, \"class\")= chr [1:2] \"bm_list\" \"list\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient model fitting using (iterated) INLA — bru","title":"Convenient model fitting using (iterated) INLA — bru","text":"method wrapper INLA::inla provides multiple enhancements. Easy usage spatial covariates automatic construction inla projection matrices (spatial) SPDE models. feature accessible via components parameter. Practical examples use spatial data means components parameter can also found looking lgcp function's documentation. Constructing multiple likelihoods straight forward. See like information provide additional likelihoods bru using ... parameter list. Support non-linear predictors. See example . Log Gaussian Cox process (LGCP) inference available using cp family (even easier) using lgcp function.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"bru(components = ~Intercept(1), ..., options = list(), .envir = parent.frame())  bru_rerun(result, options = list())  # S3 method for class 'bru' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient model fitting using (iterated) INLA — bru","text":"components formula-like specification latent components. Also used define default linear additive predictor.  See component() details. ... Likelihoods, constructed calling like(), named parameters can passed single like() call. Note arguments evaluated calling like() order detect like objects. means special arguments need evaluated context response_data data (Ntrials) may work way direct calls like(). options bru_options options object list options passed bru_options() .envir Environment component evaluation (non-formula specification used) result previous estimation object class bru x bru object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru returns object class \"bru\". bru object inherits INLA::inla (see inla documentation properties) adds additional information stored bru_info field.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Convenient model fitting using (iterated) INLA — bru","text":"print(bru): Print summary bru object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convenient model fitting using (iterated) INLA — bru","text":"bru_rerun(): Continue optimisation previously computed estimate. estimation options list can given new values override original settings.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convenient model fitting using (iterated) INLA — bru","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient model fitting using (iterated) INLA — bru","text":"","code":"# \\donttest{ if (bru_safe_inla()) {   # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, {     y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1)   })    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept(1), family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #> Changing INLA option num.threads from '4:1' to '1:1'. #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.027702 0.05210915   1.923574 2.027703   2.131825 2.027703 #> Intercept 4.959784 0.03684149   4.886164 4.959785   5.033398 4.959784 #>                    kld #> x         5.770443e-06 #> Intercept 5.770645e-06   if (bru_safe_inla()) {   # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\",               formula = y ~ x + Intercept,               data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.027702 0.05211308   1.923566 2.027703   2.131833 2.027703 #> Intercept 4.959784 0.03684427   4.886158 4.959785   5.033404 4.959784 #>                    kld #> x         5.766616e-06 #> Intercept 5.766819e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla()) {   z <- 2   input.df <- within(input.df, {     y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1)   })   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         2.000938 0.006940266   1.987069 2.000938   2.014806 2.000938 #> Intercept 5.019976 0.036290839   4.947456 5.019976   5.092490 5.019976 #>                    kld #> z         5.769401e-06 #> Intercept 5.769227e-06 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional bru options — bru_call_options","title":"Additional bru options — bru_call_options","text":"Construct bru_options object including default global options, converting deprecated option names.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional bru options — bru_call_options","text":"","code":"bru_call_options(...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional bru options — bru_call_options","text":"... Options passed .bru_options()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Additional bru options — bru_call_options","text":"bru_options object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Additional bru options — bru_call_options","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_call_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Additional bru options — bru_call_options","text":"","code":"# \\donttest{  opts <- bru_call_options()  # Print them: opts #> $bru_verbose #> [1] 0 #>  #> $bru_verbose_store #> [1] Inf #>  #> $bru_max_iter #> [1] 10 #>  #> $bru_run #> [1] TRUE #>  #> $bru_int_args #> $bru_int_args$method #> [1] \"stable\" #>  #> $bru_int_args$nsub1 #> [1] 30 #>  #> $bru_int_args$nsub2 #> [1] 9 #>  #>  #> $bru_method #> $bru_method$taylor #> [1] \"pandemic\" #>  #> $bru_method$search #> [1] \"all\" #>  #> $bru_method$factor #> [1] 1.618034 #>  #> $bru_method$rel_tol #> [1] 0.1 #>  #> $bru_method$max_step #> [1] 2 #>  #> $bru_method$line_opt_method #> [1] \"onestep\" #>  #>  #> $bru_compress_cp #> [1] TRUE #>  #> $bru_debug #> [1] FALSE #>  #> $E #> [1] 1 #>  #> $Ntrials #> [1] 1 #>  #> $control.compute #> $control.compute$config #> [1] TRUE #>  #> $control.compute$dic #> [1] TRUE #>  #> $control.compute$waic #> [1] TRUE #>  #>  #> $control.inla #> $control.inla$int.strategy #> [1] \"auto\" #>  #>  #> $control.fixed #> $control.fixed$expand.factor.strategy #> [1] \"inla\" #>  #>  #> attr(,\"class\") #> [1] \"bru_options\" \"list\"        # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute inlabru model linearisation information — bru_compute_linearisation","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"Compute inlabru model linearisation information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"","code":"bru_compute_linearisation(...)  # S3 method for class 'component' bru_compute_linearisation(   cmp,   model,   lhood_expr,   data,   input,   state,   comp_simple,   effects,   pred0,   used,   allow_latent,   allow_combine,   eps,   ... )  # S3 method for class 'bru_like' bru_compute_linearisation(   lhood,   model,   data,   input,   state,   comp_simple,   eps,   ... )  # S3 method for class 'bru_like_list' bru_compute_linearisation(   lhoods,   model,   input,   state,   comp_simple,   eps = 1e-05,   ... )  # S3 method for class 'bru_model' bru_compute_linearisation(model, lhoods, input, state, comp_simple, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_compute_linearisation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute inlabru model linearisation information — bru_compute_linearisation","text":"... Parameters passed methods cmp bru_component object model bru_model object lhood_expr predictor expression data Input data input Precomputed component inputs evaluate_inputs() state state information, list named vectors comp_simple Component evaluation information bru_component: bru_mapper_taylor object bru_like: comp_simple_list object components likelihood bru_like_list: comp_simple_list_list object effects bru_component: Precomputed effect list components involved likelihood expression pred0 Precomputed predictor given state used bru_used() object predictor expression allow_latent logical. TRUE, latent state component directly available predictor expression, _latent suffix. allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. eps finite difference step size lhood bru_like object lhoods bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot inlabru convergence diagnostics — bru_convergence_plot","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"Draws four panels convergence diagnostics iterated INLA method estimation","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"","code":"bru_convergence_plot(x, from = 1, to = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"x bru object, typically result bru() nonlinear predictor model , integer values range iterations plot. Default = 1 (start first iteration) = NULL (end last iteration). Set = 0 include initial linearisation point track plot.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"ggplot object four panels convergence diagnostics: Tracks: Mode linearisation values effect Mode - Lin: Difference mode linearisation values effect |Change| / sd: Absolute change mode linearisation values divided standard deviation effect Change & sd: Absolute change mode linearisation values standard deviation effect multidimensional components, overall average, maximum, minimum values shown.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"Requires \"dplyr\", \"ggplot2\", \"magrittr\", \"patchwork\" packages installed.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_convergence_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot inlabru convergence diagnostics — bru_convergence_plot","text":"","code":"if (FALSE) { # \\dontrun{ fit <- bru(...) bru_convergence_plot(fit) } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get access to the internal environment — bru_env_get","title":"Get access to the internal environment — bru_env_get","text":"Get access internal environment","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get access to the internal environment — bru_env_get","text":"","code":"bru_env_get()"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_env_get.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get access to the internal environment — bru_env_get","text":"environment defined 0_inlabru_envir.R loaded first.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill in missing values in Spatial grids — bru_fill_missing","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"Computes nearest-available-value imputation missing values space","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"bru_fill_missing(   data,   where,   values,   layer = NULL,   selector = NULL,   batch_size = deprecated() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"data SpatialPointsDataFrame, SpatialPixelsDataFrame, SpatialGridDataFrame, SpatRaster, Raster, sf object containing data use filling , matrix, data.frame, SpatialPoints SpatialPointsDataFrame, sf object, containing locations evaluated values values vector values filled .na(values) TRUE layer, selector Specifies data column columns extract data, see component() details. batch_size due improved algorithm. Size nearest-neighbour calculation blocks, limit memory computational complexity.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"infilled vector values","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_fill_missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill in missing values in Spatial grids — bru_fill_missing","text":"","code":"if (FALSE) { # \\dontrun{ if (bru_safe_inla()) {   points <-     sp::SpatialPointsDataFrame(       matrix(1:6, 3, 2),       data = data.frame(val = c(NA, NA, NA))     )   input_coord <- expand.grid(x = 0:7, y = 0:7)   input <-     sp::SpatialPixelsDataFrame(       input_coord,       data = data.frame(val = as.vector(input_coord$y))     )   points$val <- bru_fill_missing(input, points, points$val)   print(points)    # To fill in missing values in a grid:   print(input$val[c(3, 30)])   input$val[c(3, 30)] <- NA # Introduce missing values   input$val <- bru_fill_missing(input, input, input$val)   print(input$val[c(3, 30)]) } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract mapper information from INLA model component objects — bru_get_mapper","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"component definitions automatically attempt extract mapper information model object calling generic bru_get_mapper. class method implementation return bru_mapper object suitable given latent model.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"bru_get_mapper(model, ...)  # S3 method for class 'inla.spde' bru_get_mapper(model, ...)  # S3 method for class 'inla.rgeneric' bru_get_mapper(model, ...)  bru_get_mapper_safely(model, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"model model component object ... Arguments passed methods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_mapper object defined model component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"bru_get_mapper.inla.spde extract indexed mapper model$mesh object contained model object. returns NULL gives warning known mesh type found model object. bru_get_mapper.inla.rgeneric returns mapper given call model$f$rgeneric$definition(\"mapper\"). support inla.rgeneric models, add \"mapper\" option cmd argument rgeneric definition function. need store mapper object well.  Alternative, define model using subclass define corresponding bru_get_mapper.subclass method return corresponding bru_mapper object. bru_get_mapper_safely tries call bru_get_mapper, returns NULL fails (e.g. due available class method). call succeeds returns non-NULL, checks object inherits bru_mapper class, gives error .","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_get_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract mapper information from INLA model component objects — bru_get_mapper","text":"","code":"if (bru_safe_inla()) {   library(INLA)   mesh <- fmesher::fm_rcdt_2d_inla(globe = 2)   spde <- inla.spde2.pcmatern(mesh,     prior.range = c(1, 0.5),     prior.sigma = c(1, 0.5)   )   mapper <- bru_get_mapper(spde)   ibm_n(mapper) } #> Loading required package: Matrix #> Loading required package: sp #> This is INLA_24.09.14 built 2024-09-14 13:49:48 UTC. #>  - See www.r-inla.org/contact-us for how to get help. #>  - List available models/likelihoods/etc with inla.list.models() #>  - Use inla.doc(<NAME>) to access documentation #> [1] 42"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_info objects — bru_info","title":"Methods for bru_info objects — bru_info","text":"bru_info class used store metadata bru models.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_info objects — bru_info","text":"","code":"bru_info(...)  # S3 method for class 'character' bru_info(method, ..., inlabru_version = NULL, INLA_version = NULL)  # S3 method for class 'bru' bru_info(object, ...)  # S3 method for class 'bru_info' summary(object, verbose = TRUE, ...)  # S3 method for class 'summary_bru_info' print(x, ...)  # S3 method for class 'bru_info' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_info objects — bru_info","text":"... Arguments passed summary methods method character; type estimation method used inlabru_version character; inlabru package version. Default: NULL, automatically detecting version INLA_version character; INLA package version. Default: NULL, automatically detecting version object Object operate verbose logical; TRUE, include details component definitions. FALSE, show basic component definition information. Default: TRUE x  object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_info.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Methods for bru_info objects — bru_info","text":"bru_info(character): Create bru_info object bru_info(bru): Extract bru_info object estimated bru() result object. default print method show information model components observation models.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mexpand.html","id":null,"dir":"Reference","previous_headings":"","what":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","title":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","text":"Expand observation vectors/matrices stacks multicolumn matrix multiple likelihoods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mexpand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","text":"","code":"bru_inla.stack.mexpand(   ...,   old.names = \"BRU.response\",   new.name = \"BRU.response\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mexpand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","text":"... List stacks contain vector observations (existing multilikelihood observation matrices also permitted) old.names vector strings names observation vector/matrix stack. single string, assumed stacks. (default \"BRU.response\") new.name name used expanded observation matrix, possibly old name. (default \"BRU.response\")","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mexpand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","text":"list modified stacks multicolumn observations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mexpand.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Backwards compatibility to handle mexpand for INLA <= 24.06.02 — bru_inla.stack.mexpand","text":"Fabian E. Bachl f.e.bachl@bath.ac.uk Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mjoin.html","id":null,"dir":"Reference","previous_headings":"","what":"Join stacks intended to be run with different likelihoods — bru_inla.stack.mjoin","title":"Join stacks intended to be run with different likelihoods — bru_inla.stack.mjoin","text":"Helper functions multi-likelihood models","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mjoin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join stacks intended to be run with different likelihoods — bru_inla.stack.mjoin","text":"","code":"bru_inla.stack.mjoin(   ...,   compress = TRUE,   remove.unused = TRUE,   old.names = \"BRU.response\",   new.name = \"BRU.response\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_inla.stack.mjoin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join stacks intended to be run with different likelihoods — bru_inla.stack.mjoin","text":"... List stacks contain vector observations (existing multi-likelihood observation matrices also permitted) compress TRUE, compress model removing duplicated rows effects, replacing corresponding -matrix columns single column containing sum. remove.unused TRUE, compress model removing rows effects corresponding -zero columns matrix (removing columns). old.names vector strings names observation vector/matrix stack. single string, assumed stacks. (default \"BRU.response\") new.name name used expanded observation matrix, possibly old name. (default \"BRU.response\")","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Observation model construction for usage with bru() — like","title":"Observation model construction for usage with bru() — like","text":"Observation model construction usage bru()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observation model construction for usage with bru() — like","text":"","code":"like(   formula = . ~ .,   family = \"gaussian\",   data = NULL,   response_data = NULL,   mesh = deprecated(),   E = NULL,   Ntrials = NULL,   weights = NULL,   scale = NULL,   domain = NULL,   samplers = NULL,   ips = NULL,   include = NULL,   exclude = NULL,   include_latent = NULL,   used = NULL,   allow_latent = deprecated(),   allow_combine = NULL,   control.family = NULL,   options = list(),   .envir = parent.frame() )  like_list(...)  # S3 method for class 'list' like_list(object, envir = NULL, ...)  # S3 method for class 'bru_like' like_list(..., envir = NULL)  # S3 method for class 'bru_like' c(..., envir = NULL)  # S3 method for class 'bru_like_list' c(..., envir = NULL)  # S3 method for class 'bru_like_list' x[i]"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observation model construction for usage with bru() — like","text":"formula formula right hand side general R expression defines predictor used model. family string identifying valid INLA::inla likelihood family. default gaussian identity link. addition likelihoods provided inla (see names(INLA::inla.models()$likelihood)) inlabru supports fitting latent Gaussian Cox processes via family = \"cp\". alternative bru(), lgcp() function provides convenient interface fitting Cox processes. data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. response_data Likelihood-specific data models need different size/format inputs response variables, data.frame SpatialPoints[DataFrame] object. mesh Deprecated. E Exposure parameter family = 'poisson' passed INLA::inla. Special case family 'cp': rescale integration weights scalar E. sampler specific reweighting/effort, use weight column samplers object, see fmesher::fm_int(). Default taken options$E, normally 1. Ntrials vector containing number trials 'binomial' likelihood. Default taken options$Ntrials, normally 1. weights Fixed (optional) weights parameters likelihood, log-likelihood[] changed weights[] * log_likelihood[]. Default value 1. WARNING: normalizing constant likelihood recomputed, marginals (marginal likelihood) must interpreted great care. scale Fixed (optional) scale parameters precision several models, Gaussian student-t response models. domain, samplers, ips Arguments used family=\"cp\". domain Named list domain definitions. samplers Integration subdomain 'cp' family. ips Integration points 'cp' family. Defaults fmesher::fm_int(domain, samplers). explicitly given, overrides domain samplers. include, exclude, include_latent Arguments controlling components effects available use predictor expression. include Character vector component labels used effects predictor expression; NULL (default), bru_used() method used extract variable names formula. exclude Character vector component labels excluded effect list determined include argument. Default NULL; remove components inclusion list. include_latent Character vector. Specifies latent state variables directly available predictor expression, _latent suffix. also makes evaluator functions suffix _eval available, taking parameters main, group, replicate, taking values evaluate component effect different defined component definition (see component_eval()). NULL, bru_used() method auto-detects use _latent _eval predictor expression. used Wither NULL (default) bru_used() object, overrides include, exclude, include_latent arguments. used NULL (default), information effects latent vectors made available predictor evaluation defined   allow_latent logical, deprecated. Use include_latent instead. allow_combine logical; TRUE, predictor expression may involve several rows input data influence row. Default FALSE, forced TRUE response_data non-NULL, data list, likelihood construction requires . control.family optional list INLA::control.family options options bru_options options object list options passed bru_options() .envir evaluation environment use special arguments (E, Ntrials, weights, scale) found response_data data. Defaults calling environment. ... like_list.bru_like, one bru_like objects object list bru_like objects envir optional environment new bru_like_list object x bru_like_list object extract element(s) indices specifying elements extract","code":"used <- bru_used(   formula,   effect = include,   effect_exclude = exclude,   latent = include_latent )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observation model construction for usage with bru() — like","text":"likelihood configuration can used parameterise bru().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Observation model construction for usage with bru() — like","text":"like_list(bru_like): Combine several bru_like likelihoods bru_like_list object c(bru_like): Combine several bru_like likelihoods /bru_like_list objects bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Observation model construction for usage with bru() — like","text":"like_list(): Combine bru_like likelihoods bru_like_list object like_list(list): Combine list bru_like likelihoods bru_like_list object c(bru_like_list): Combine several bru_like likelihoods /bru_like_list objects bru_like_list object","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Observation model construction for usage with bru() — like","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Observation model construction for usage with bru() — like","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE)) {    # The like function's main purpose is to set up models with multiple likelihoods.   # The following example generates some random covariates which are observed through   # two different random effect models with different likelihoods    # Generate the data    set.seed(123)    n1 <- 200   n2 <- 10    x1 <- runif(n1)   x2 <- runif(n2)   z2 <- runif(n2)    y1 <- rnorm(n1, mean = 2 * x1 + 3)   y2 <- rpois(n2, lambda = exp(2 * x2 + z2 + 3))    df1 <- data.frame(y = y1, x = x1)   df2 <- data.frame(y = y2, x = x2, z = z2)    # Single likelihood models and inference using bru are done via    cmp1 <- y ~ -1 + Intercept(1) + x   fit1 <- bru(cmp1, family = \"gaussian\", data = df1)   summary(fit1)    cmp2 <- y ~ -1 + Intercept(1) + x + z   fit2 <- bru(cmp2, family = \"poisson\", data = df2)   summary(fit2)    # A joint model has two likelihoods, which are set up using the like function    lik1 <- like(\"gaussian\", formula = y ~ x + Intercept, data = df1)   lik2 <- like(\"poisson\", formula = y ~ x + z + Intercept, data = df2)    # The union of effects of both models gives the components needed to run bru    jcmp <- ~ x + z + Intercept(1)   jfit <- bru(jcmp, lik1, lik2)    # Compare the estimates    p1 <- ggplot() +     gg(fit1$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 1\")   p2 <- ggplot() +     gg(fit2$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Model 2\")   pj <- ggplot() +     gg(jfit$summary.fixed, bar = TRUE) +     ylim(0, 4) +     ggtitle(\"Joint model\")    multiplot(p1, p2, pj) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility functions for bru likelihood objects — bru_like_inla_family","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"Utility functions bru likelihood objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"","code":"bru_like_inla_family(x, ...)  # S3 method for class 'bru_like' bru_like_inla_family(x, ...)  # S3 method for class 'bru_like_list' bru_like_inla_family(x, ...)  bru_like_control_family(x, control.family = NULL, ...)  # S3 method for class 'bru_like' bru_like_control_family(x, control.family = NULL, ...)  # S3 method for class 'bru_like_list' bru_like_control_family(x, control.family = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"x Object bru_like bru_like_list type control.family list INLA control.family options override","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility functions for bru likelihood objects — bru_like_inla_family","text":"bru_like_inla_family() returns string vector strings bru_like_control_family() returns list INLA::control.family options, list lists, one element per observation model","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_print.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary and print methods for observation models — summary.bru_like","title":"Summary and print methods for observation models — summary.bru_like","text":"Summary print methods observation models","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary and print methods for observation models — summary.bru_like","text":"","code":"# S3 method for class 'bru_like' summary(object, verbose = TRUE, ...)  # S3 method for class 'bru_like_list' summary(object, verbose = TRUE, ...)  # S3 method for class 'summary_bru_like' print(x, ...)  # S3 method for class 'summary_bru_like_list' print(x, ...)  # S3 method for class 'bru_like' print(x, ...)  # S3 method for class 'bru_like_list' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary and print methods for observation models — summary.bru_like","text":"object Object operate verbose logical; TRUE, include details component definitions. FALSE, show basic component definition information. Default: TRUE ... Arguments passed summary methods x Object printed","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_like_print.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary and print methods for observation models — summary.bru_like","text":"","code":"obs <- like(y ~ ., data = data.frame(y = rnorm(10))) summary(obs) #>   Family: 'gaussian' #>     Data class: 'data.frame' #>     Response class: 'numeric' #>     Predictor: y ~ . #>     Used components: effects[], latent[] print(obs) #>   Family: 'gaussian' #>     Data class: 'data.frame' #>     Response class: 'numeric' #>     Predictor: y ~ . #>     Used components: effects[], latent[]"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Access methods for bru_log objects — bru_log","title":"Access methods for bru_log objects — bru_log","text":"Access method bru_log objects. Note: version 2.8.0, bru_log() deprecated alias bru_log_message(). running 2.8.0 earlier, use bru_log_get() access global log, cat(fit$bru_iinla$log, sep = \"\\n\") print stored estimation object log. version 2.8.0, use bru_log() access global log, bru_log(fit) access stored estimation log.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access methods for bru_log objects — bru_log","text":"","code":"bru_log(x = NULL, verbosity = NULL)  # S3 method for class 'character' bru_log(x, verbosity = NULL)  # S3 method for class 'bru_log' bru_log(x, verbosity = NULL)  # S3 method for class 'iinla' bru_log(x, verbosity = NULL)  # S3 method for class 'bru' bru_log(x, verbosity = NULL)  # S3 method for class 'bru_log' print(x, ..., timestamp = TRUE, verbosity = FALSE)  # S3 method for class 'bru_log' as.character(x, ...)  # S3 method for class 'bru_log' x[i]  # S3 method for class 'bru_log' c(...)  # S3 method for class 'bru_log' length(x)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access methods for bru_log objects — bru_log","text":"x object , contains, can converted , bru_log object. NULL, refers global inlabru log. verbosity integer value limiting highest verbosity level returned. ... arguments passed methods. timestamp TRUE, include timestamp message. Default TRUE. indices specifying elements extract. character, denotes sequence bookmark next bookmark (end log last bookmark)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access methods for bru_log objects — bru_log","text":"bru_log bru_log object, containing character vector log messages, potentially vector bookmarks.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Access methods for bru_log objects — bru_log","text":"print(bru_log): Print bru_log object cat(x, sep = \"\\n\"). verbosity TRUE, include verbosity level message. .character(bru_log): Convert bru_log object plain character vector [: Extract subset bru_log object c(bru_log): Concatenate several bru_log character objects bru_log object. length(bru_log): Obtain number log entries bru_log object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Access methods for bru_log objects — bru_log","text":"bru_log(): Extract stored log messages. non-NULL, verbosity argument determines maximum verbosity level messages extract.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access methods for bru_log objects — bru_log","text":"","code":"bru_log(verbosity = 2L) #> 2024-09-18 16:00:48.062188: inlabru loaded #> 2024-09-18 16:00:48.062669: Clear override options #> 2024-09-18 16:00:52.929201: iinla: Iteration 1 [max:1] #> 2024-09-18 16:00:53.653536: iinla: Iteration 1 [max:10] #> 2024-09-18 16:00:54.073147: iinla: Iteration 2 [max:10] #> 2024-09-18 16:00:54.759282: iinla: Max deviation from previous: 0.0645% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:00:54.759747: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. #> 2024-09-18 16:00:54.76066: iinla: Iteration 3 [max:10] #> 2024-09-18 16:00:55.283288: iinla: Iteration 1 [max:10] #> 2024-09-18 16:00:55.64889: iinla: Step rescaling: 27.2% (norm0 = 208.4, norm1 = 256.3, norm01 = 395.2) #> 2024-09-18 16:00:55.680928: iinla: Iteration 2 [max:10] #> 2024-09-18 16:00:56.051434: iinla: Step rescaling: 99.6% (norm0 = 255.3, norm1 = 12.89, norm01 = 256.3) #> 2024-09-18 16:00:56.081985: iinla: Max deviation from previous: 52900% of SD, and line search is active #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:00:56.083107: iinla: Iteration 3 [max:10] #> 2024-09-18 16:00:56.453555: iinla: Step rescaling: 102% (norm0 = 12.89, norm1 = 0.01798, norm01 = 12.89) #> 2024-09-18 16:00:56.490734: iinla: Max deviation from previous: 598% of SD, and line search is active #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:00:56.491789: iinla: Iteration 4 [max:10] #> 2024-09-18 16:00:56.884667: iinla: Max deviation from previous: 10.1% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:00:56.885696: iinla: Iteration 5 [max:10] #> 2024-09-18 16:00:57.28299: iinla: Max deviation from previous: 0.0579% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:00:57.283464: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. #> 2024-09-18 16:00:57.284423: iinla: Iteration 6 [max:10] #> 2024-09-18 16:01:00.057579: iinla: Iteration 1 [max:1] #> 2024-09-18 16:01:00.649593: iinla: Iteration 1 [max:1] #> 2024-09-18 16:01:01.325509: iinla: Iteration 1 [max:10] #> 2024-09-18 16:01:01.805423: iinla: Iteration 2 [max:10] #> 2024-09-18 16:01:02.275868: iinla: Max deviation from previous: 0.146% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] #> 2024-09-18 16:01:02.276368: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. #> 2024-09-18 16:01:02.277392: iinla: Iteration 3 [max:10] print(bru_log(), timestamp = TRUE, verbosity = TRUE) #> 2024-09-18 16:00:48.062188: inlabru loaded (level 1) #> 2024-09-18 16:00:48.062669: Clear override options (level 1) #> 2024-09-18 16:00:52.810445: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:00:52.836252: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:52.867898: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:00:52.883836: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:52.897038: iinla: Construct inla stack (level 3) #> 2024-09-18 16:00:52.928674: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:00:52.929201: iinla: Iteration 1 [max:1] (level 1) #> 2024-09-18 16:00:53.57149: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:00:53.599062: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:53.615659: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:00:53.631449: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:53.640725: iinla: Construct inla stack (level 3) #> 2024-09-18 16:00:53.653035: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:00:53.653536: iinla: Iteration 1 [max:10] (level 1) #> 2024-09-18 16:00:54.040471: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 343.2, norm1 = 0, norm01 = 343.2) (level 3) #> 2024-09-18 16:00:54.041117: iinla: Optimisation did not improve on previous solution. (level 3) #> 2024-09-18 16:00:54.041562: iinla: |lin1-lin0| = 343.2 #>        <eta-lin1,delta>/|delta| = 0 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 0 (level 4) #> 2024-09-18 16:00:54.042436: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:54.057917: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:54.073147: iinla: Iteration 2 [max:10] (level 1) #> 2024-09-18 16:00:54.726194: iinla: Step rescaling: 162%, Expand (norm0 = 2.14e-07, norm1 = 8.175e-08, norm01 = 1.323e-07) (level 3) #> 2024-09-18 16:00:54.727327: iinla: Step rescaling: 100%, Overstep (norm0 = 1.323e-07, norm1 = 3.18e-14, norm01 = 1.323e-07) (level 3) #> 2024-09-18 16:00:54.72892: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 1.323e-07, norm1 = 3.18e-14, norm01 = 1.323e-07) (level 3) #> 2024-09-18 16:00:54.72932: iinla: Optimisation did not improve on previous solution. (level 3) #> 2024-09-18 16:00:54.729716: iinla: |lin1-lin0| = 1.323e-07 #>        <eta-lin1,delta>/|delta| = -2.992e-15 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 3.166e-14 (level 4) #> 2024-09-18 16:00:54.730577: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:54.745665: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:54.759282: iinla: Max deviation from previous: 0.0645% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:00:54.759747: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. (level 1) #> 2024-09-18 16:00:54.76066: iinla: Iteration 3 [max:10] (level 1) #> 2024-09-18 16:00:55.202837: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:00:55.229067: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:55.244123: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:00:55.265481: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:55.271084: iinla: Construct inla stack (level 3) #> 2024-09-18 16:00:55.28277: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:00:55.283288: iinla: Iteration 1 [max:10] (level 1) #> 2024-09-18 16:00:55.645207: iinla: Step rescaling: 61.8%, Contract (norm0 = 2293, norm1 = 2107, norm01 = 395.2) (level 3) #> 2024-09-18 16:00:55.646277: iinla: Step rescaling: 38.2%, Contract (norm0 = 460.2, norm1 = 339.4, norm01 = 395.2) (level 3) #> 2024-09-18 16:00:55.64802: iinla: Step rescaling: 27.2%, Approx Optimisation (norm0 = 208.4, norm1 = 256.3, norm01 = 395.2) (level 3) #> 2024-09-18 16:00:55.648468: iinla: |lin1-lin0| = 395.2 #>        <eta-lin1,delta>/|delta| = -225.8 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 121.3 (level 4) #> 2024-09-18 16:00:55.64889: iinla: Step rescaling: 27.2% (norm0 = 208.4, norm1 = 256.3, norm01 = 395.2) (level 2) #> 2024-09-18 16:00:55.649738: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:55.664836: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:55.680928: iinla: Iteration 2 [max:10] (level 1) #> 2024-09-18 16:00:56.050497: iinla: Step rescaling: 99.6%, Approx Optimisation (norm0 = 255.3, norm1 = 12.89, norm01 = 256.3) (level 3) #> 2024-09-18 16:00:56.051024: iinla: |lin1-lin0| = 256.3 #>        <eta-lin1,delta>/|delta| = -1.292 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 12.82 (level 4) #> 2024-09-18 16:00:56.051434: iinla: Step rescaling: 99.6% (norm0 = 255.3, norm1 = 12.89, norm01 = 256.3) (level 2) #> 2024-09-18 16:00:56.052309: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:56.067279: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:56.081985: iinla: Max deviation from previous: 52900% of SD, and line search is active #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:00:56.083107: iinla: Iteration 3 [max:10] (level 1) #> 2024-09-18 16:00:56.449836: iinla: Step rescaling: 162%, Expand (norm0 = 20.28, norm1 = 7.397, norm01 = 12.89) (level 3) #> 2024-09-18 16:00:56.451063: iinla: Step rescaling: 100%, Overstep (norm0 = 12.67, norm1 = 0.2191, norm01 = 12.89) (level 3) #> 2024-09-18 16:00:56.452666: iinla: Step rescaling: 101.8%, Approx Optimisation (norm0 = 12.89, norm1 = 0.01798, norm01 = 12.89) (level 3) #> 2024-09-18 16:00:56.453149: iinla: |lin1-lin0| = 12.89 #>        <eta-lin1,delta>/|delta| = -2.964e-05 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 0.01798 (level 4) #> 2024-09-18 16:00:56.453555: iinla: Step rescaling: 102% (norm0 = 12.89, norm1 = 0.01798, norm01 = 12.89) (level 2) #> 2024-09-18 16:00:56.454453: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:56.475717: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:56.490734: iinla: Max deviation from previous: 598% of SD, and line search is active #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:00:56.491789: iinla: Iteration 4 [max:10] (level 1) #> 2024-09-18 16:00:56.851105: iinla: Step rescaling: 162%, Expand (norm0 = 0.02909, norm1 = 0.01111, norm01 = 0.01798) (level 3) #> 2024-09-18 16:00:56.852154: iinla: Step rescaling: 100%, Overstep (norm0 = 0.01798, norm1 = 1.149e-07, norm01 = 0.01798) (level 3) #> 2024-09-18 16:00:56.853961: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 0.01798, norm1 = 1.146e-07, norm01 = 0.01798) (level 3) #> 2024-09-18 16:00:56.85442: iinla: |lin1-lin0| = 0.01798 #>        <eta-lin1,delta>/|delta| = 1.965e-10 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 1.146e-07 (level 4) #> 2024-09-18 16:00:56.855298: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:56.870255: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:56.884667: iinla: Max deviation from previous: 10.1% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:00:56.885696: iinla: Iteration 5 [max:10] (level 1) #> 2024-09-18 16:00:57.249601: iinla: Step rescaling: 162%, Expand (norm0 = 2.298e-07, norm1 = 8.778e-08, norm01 = 1.42e-07) (level 3) #> 2024-09-18 16:00:57.250671: iinla: Step rescaling: 100%, Overstep (norm0 = 1.42e-07, norm1 = 6.789e-13, norm01 = 1.42e-07) (level 3) #> 2024-09-18 16:00:57.252408: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 1.42e-07, norm1 = 4.682e-13, norm01 = 1.42e-07) (level 3) #> 2024-09-18 16:00:57.252875: iinla: |lin1-lin0| = 1.42e-07 #>        <eta-lin1,delta>/|delta| = -2.069e-14 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 4.678e-13 (level 4) #> 2024-09-18 16:00:57.253739: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:00:57.268514: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:00:57.28299: iinla: Max deviation from previous: 0.0579% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:00:57.283464: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. (level 1) #> 2024-09-18 16:00:57.284423: iinla: Iteration 6 [max:10] (level 1) #> 2024-09-18 16:00:59.960609: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:00:59.988429: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:01:00.00432: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:01:00.041: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:01:00.04446: iinla: Construct inla stack (level 3) #> 2024-09-18 16:01:00.057076: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:01:00.057579: iinla: Iteration 1 [max:1] (level 1) #> 2024-09-18 16:01:00.529295: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:01:00.572286: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:01:00.596289: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:01:00.628958: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:01:00.633643: iinla: Construct inla stack (level 3) #> 2024-09-18 16:01:00.648082: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:01:00.649593: iinla: Iteration 1 [max:1] (level 1) #> 2024-09-18 16:01:01.130875: iinla: Evaluate component inputs (level 3) #> 2024-09-18 16:01:01.202147: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:01:01.250291: iinla: Evaluate component simplifications (level 3) #> 2024-09-18 16:01:01.289544: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:01:01.301392: iinla: Construct inla stack (level 3) #> 2024-09-18 16:01:01.324977: iinla: Model initialisation completed (level 3) #> 2024-09-18 16:01:01.325509: iinla: Iteration 1 [max:10] (level 1) #> 2024-09-18 16:01:01.735896: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 1073, norm1 = 2.645e-14, norm01 = 1073) (level 3) #> 2024-09-18 16:01:01.736401: iinla: Optimisation did not improve on previous solution. (level 3) #> 2024-09-18 16:01:01.736864: iinla: |lin1-lin0| = 1073 #>        <eta-lin1,delta>/|delta| = 1.212e-15 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 4.556e-14 (level 4) #> 2024-09-18 16:01:01.737743: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:01:01.776185: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:01:01.805423: iinla: Iteration 2 [max:10] (level 1) #> 2024-09-18 16:01:02.207865: iinla: Step rescaling: 100%, Approx Optimisation (norm0 = 0.0008452, norm1 = 1.457e-13, norm01 = 0.0008452) (level 3) #> 2024-09-18 16:01:02.208375: iinla: Optimisation did not improve on previous solution. (level 3) #> 2024-09-18 16:01:02.208822: iinla: |lin1-lin0| = 0.0008452 #>        <eta-lin1,delta>/|delta| = 3.363e-16 #>        |eta-lin0 - delta <delta,eta-lin0>/<delta,delta>| = 1.457e-13 (level 4) #> 2024-09-18 16:01:02.209744: iinla: Evaluate component linearisations (level 3) #> 2024-09-18 16:01:02.247823: iinla: Evaluate predictor linearisation (level 3) #> 2024-09-18 16:01:02.275868: iinla: Max deviation from previous: 0.146% of SD, and line search is inactive #>        [stop if: <10% and line search inactive] (level 1) #> 2024-09-18 16:01:02.276368: iinla: Convergence criterion met. #>        Running final INLA integration step with known theta mode. (level 1) #> 2024-09-18 16:01:02.277392: iinla: Iteration 3 [max:10] (level 1)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_bookmark.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for bru_log bookmarks — bru_log_bookmark","title":"Methods for bru_log bookmarks — bru_log_bookmark","text":"Methods bru_log bookmarks.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_bookmark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for bru_log bookmarks — bru_log_bookmark","text":"","code":"bru_log_bookmark(bookmark = \"\", offset = NULL, x = NULL)  bru_log_bookmarks(x = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_bookmark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for bru_log bookmarks — bru_log_bookmark","text":"bookmark character; label bookmark stored offset. offset integer; position offset log, 0L pointing start log. negative, denotes point abs(offset) elements tail log. bookmark non-NULL, offset applies shift (forwards backwards) bookmark list. x bru_log object. NULL, global inlabru log used.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_bookmark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for bru_log bookmarks — bru_log_bookmark","text":"bru_log_bookmark(): Returns modified bru_log object x non-NULL. bru_log_bookmarks(): Returns bookmark vector associated x","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_bookmark.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Methods for bru_log bookmarks — bru_log_bookmark","text":"bru_log_bookmark(): Set log bookmark. offset NULL (default), bookmark point current end log. bru_log_bookmarks(): Return integer vector named elements bookmarks global inlabru log associated log position offsets.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a log message — bru_log_message","title":"Add a log message — bru_log_message","text":"Adds log message.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a log message — bru_log_message","text":"","code":"bru_log_message(   ...,   domain = NULL,   appendLF = TRUE,   verbosity = 1L,   allow_verbose = TRUE,   verbose = NULL,   verbose_store = NULL,   x = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a log message — bru_log_message","text":"... bru_log_message(), zero objects passed base::.makeMessage() domain Domain translations, passed base::.makeMessage() appendLF logical; whether add newline message. used verbose output. verbosity numeric value describing verbosity level message allow_verbose Whether allow verbose output. Must set FALSE options object initialised. verbose logical, numeric, NULL; local override verbose output. NULL, global option bru_verbose default value used. FALSE, messages printed. TRUE, messages verbosity \\(\\le 1\\) printed. numeric, messages verbosity \\(\\le\\) verbose printed. verbose_store verbose, controlling messages stored global log object. Can controlled via bru_verbose_store bru_options_set(). x bru_log object. NULL, refers global inlabru log.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_message.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a log message — bru_log_message","text":"bru_log_message returns invisible(x), x updated bru_log object, NULL.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_message.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a log message — bru_log_message","text":"","code":"if (interactive()) {   code_runner <- function() {     local_bru_options_set(       # Show messages up to and including level 2 (default 0)       bru_verbose = 2,       # Store messages to an including level 3 (default Inf, storing all)       bru_verbose_store = 3     )      bru_log_bookmark(\"bookmark 1\")     bru_log_message(\"Test message 1\", verbosity = 1)     bru_log_message(\"Test message 2\", verbosity = 2)     bru_log_bookmark(\"bookmark 2\")     bru_log_message(\"Test message 3\", verbosity = 3)     bru_log_message(\"Test message 4\", verbosity = 4)      invisible()   }   message(\"Run code\")   code_runner()   message(\"Check log from bookmark 1\")   print(bru_log()[\"bookmark 1\"])   message(\"Check log from bookmark 2\")   print(bru_log()[\"bookmark 2\"]) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_new.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a bru_log object — bru_log_new","title":"Create a bru_log object — bru_log_new","text":"Create bru_log object, default empty.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a bru_log object — bru_log_new","text":"","code":"bru_log_new(x = NULL, bookmarks = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a bru_log object — bru_log_new","text":"x optional character vector log messages, data.frame columns message, timestamp, verbosity. bookmarks optional integer vector named bookmarks message x.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_new.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a bru_log object — bru_log_new","text":"","code":"x <- bru_log_new() x <- bru_log_message(\"Test message\", x = x) print(x) #> 2024-09-18 16:01:04.810325: Test message"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_offset.html","id":null,"dir":"Reference","previous_headings":"","what":"Position methods for bru_log objects — bru_log_offset","title":"Position methods for bru_log objects — bru_log_offset","text":"Position methods bru_log objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_offset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Position methods for bru_log objects — bru_log_offset","text":"","code":"bru_log_offset(x = NULL, bookmark = NULL, offset = NULL)  bru_log_index(x = NULL, i, verbosity = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_offset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Position methods for bru_log objects — bru_log_offset","text":"x bru_log object. NULL, global inlabru log used. bookmark character; label bookmark stored offset. offset integer; position offset log, 0L pointing start log. negative, denotes point abs(offset) elements tail log. bookmark non-NULL, offset applies shift (forwards backwards) bookmark list. indices specifying elements extract. character, denotes sequence bookmark next bookmark (end log last bookmark) verbosity integer value limiting highest verbosity level returned.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_offset.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Position methods for bru_log objects — bru_log_offset","text":"bru_log_offset(): Utility function computing log position offsets. bru_log_index(): Utility function computing index vectors bru_log objects.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_reset.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear log contents — bru_log_reset","title":"Clear log contents — bru_log_reset","text":"Clears log contents given offset bookmark. Default: clear entire log. x NULL, global inlabru log updated, invisible(NULL) returned. Otherwise updated object returned (invisibly).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_reset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear log contents — bru_log_reset","text":"","code":"bru_log_reset(x = NULL, bookmark = NULL, offset = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_reset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear log contents — bru_log_reset","text":"x bru_log object, cases, object can converted/extracted bru_log object. NULL denotes global inlabru log object. bookmark character; label bookmark stored offset. offset integer; position offset log, 0L pointing start log. negative, denotes point abs(offset) elements tail log. bookmark non-NULL, offset applies shift (forwards backwards) bookmark list.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_reset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear log contents — bru_log_reset","text":"Returns (invisibly) modified bru_log object, NULL (x NULL)","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_log_reset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear log contents — bru_log_reset","text":"","code":"if (FALSE) { # \\dontrun{ if (interactive()) {   bru_log_reset() } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an inla data stack from linearisation information — bru_make_stack","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"Combine linearisation multiple likelihoods","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"","code":"bru_make_stack(...)  # S3 method for class 'bru_like' bru_make_stack(lhood, lin, idx, ..., family_index = 1L)  # S3 method for class 'bru_like_list' bru_make_stack(lhoods, lin, idx, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_make_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an inla data stack from linearisation information — bru_make_stack","text":"... Arguments passed methods lhood bru_like object lin Linearisation information .bru_like, bru_mapper_taylor object .bru_like_list, list bru_mapper_taylor objects idx Output evaluate_index(...) family_index integer specifying family sequence index observation model lhoods bru_like_list object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructors for bru_mapper objects — bru_mapper","title":"Constructors for bru_mapper objects — bru_mapper","text":"Constructors bru_mapper objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"bru_mapper(...)  bru_mapper_define(mapper, new_class = NULL, ..., methods = deprecated())"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructors for bru_mapper objects — bru_mapper","text":"... Arguments passed sub-methods, used special purposes, see details function . mapper bru_mapper_define, prototype mapper object, see Details. bru_mapper_scale, mapper scaled. new_class non-NULL, added front class definition methods Deprecated.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructors for bru_mapper objects — bru_mapper","text":"bru_mapper() returns bru_mapper object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Constructors for bru_mapper objects — bru_mapper","text":"bru_mapper(): Generic mapper S3 constructor, used constructing mappers special objects. See details default constructor bru_mapper_define() can used define new mappers user code. bru_mapper_define(): Adds new_class \"bru_mapper\" class names inheritance list input mapper object, unless object already inherits . register mapper classes methods scripts, use .S3method() register methods, e.g. .S3method(\"ibm_jacobian\", \"my_mapper_class\", ibm_jacobian.my_mapper_class). packages Suggests: inlabru, add method information delayed registration, e.g.:   method, use @exportS3Method:   etc., semi-automates .","code":"#' @rawNamespace S3method(inlabru::bru_get_mapper, inla_rspde) #' @rawNamespace S3method(inlabru::ibm_n, bru_mapper_inla_rspde) #' @rawNamespace S3method(inlabru::ibm_values, bru_mapper_inla_rspde) #' @rawNamespace S3method(inlabru::ibm_jacobian, bru_mapper_inla_rspde) #' @exportS3Method inlabru::bru_get_mapper"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructors for bru_mapper objects — bru_mapper","text":"","code":"mapper <- bru_mapper_index(5) ibm_jacobian(mapper, input = c(1, 3, 4, 5, 2)) #> 5 x 5 sparse Matrix of class \"dgCMatrix\" #>                #> [1,] 1 . . . . #> [2,] . . 1 . . #> [3,] . . . 1 . #> [4,] . . . . 1 #> [5,] . 1 . . ."},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_aggregate.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for aggregation — bru_mapper_aggregate","title":"Mapper for aggregation — bru_mapper_aggregate","text":"Constructs mapper aggregates elements input state, can used e.g. weighted summation integration blocks values.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_aggregate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for aggregation — bru_mapper_aggregate","text":"","code":"bru_mapper_aggregate(rescale = FALSE, n_block = NULL)  # S3 method for class 'bru_mapper_aggregate' ibm_n(mapper, ..., input = NULL, state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_aggregate' ibm_n_output(mapper, input = NULL, ...)  # S3 method for class 'bru_mapper_aggregate' ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_aggregate' ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for class 'bru_mapper_aggregate' ibm_eval(mapper, input, state = NULL, ..., sub_lin = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_aggregate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for aggregation — bru_mapper_aggregate","text":"rescale logical; bru_mapper_aggregate bru_mapper_logsumexp, specifies blockwise sums normalised blockwise weight sums : FALSE: (default) Straight weighted sum, rescaling. TRUE: Divide sum weight values within block. useful integration averages, given weights plain integration weights. weights NULL ones, dividing number entries block. n_block Predetermined number output blocks. NULL, overrides maximum block index inputs. mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) n_state integer giving length state vector mappers state dependent output size. sub_lin Internal, optional pre-computed sub-mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_aggregate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for aggregation — bru_mapper_aggregate","text":"bru_mapper_aggregate, input list elements block weights. block vector length state, NULL, NULL equivalent -1. weights NULL, interpreted -1.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_aggregate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for aggregation — bru_mapper_aggregate","text":"","code":"m <- bru_mapper_aggregate() ibm_eval2(m, list(block = c(1, 2, 1, 2), weights = 1:4), 11:14) #> $offset #> [1] 50 80 #>  #> $jacobian #> 2 x 4 sparse Matrix of class \"dgCMatrix\" #>              #> [1,] 1 . 3 . #> [2,] . 2 . 4 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for concatenated variables — bru_mapper_collect","title":"Mapper for concatenated variables — bru_mapper_collect","text":"Constructs concatenated collection mapping","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for concatenated variables — bru_mapper_collect","text":"","code":"bru_mapper_collect(mappers, hidden = FALSE)  # S3 method for class 'bru_mapper_collect' ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_collect' ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_collect' ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_collect' ibm_is_linear(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_collect' ibm_jacobian(   mapper,   input,   state = NULL,   inla_f = FALSE,   multi = FALSE,   ...,   sub_lin = NULL )  # S3 method for class 'bru_mapper_collect' ibm_eval(   mapper,   input,   state,   inla_f = FALSE,   multi = FALSE,   ...,   sub_lin = NULL )  # S3 method for class 'bru_mapper_collect' ibm_linear(mapper, input, state, inla_f = FALSE, ...)  # S3 method for class 'bru_mapper_collect' ibm_invalid_output(mapper, input, state, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_collect' x[i, drop = TRUE]  # S3 method for class 'bru_mapper_collect' ibm_names(mapper)  # S3 method for class 'bru_mapper_collect' ibm_names(mapper) <- value"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for concatenated variables — bru_mapper_collect","text":"mappers list bru_mapper objects hidden logical, set TRUE flag mapper used first level input mapper INLA::f() model requires making first mapper visible INLA::f() INLA::inla.stack(), \"bym2\" models, activated inla_f argument ibm_n, ibm_values, ibm_jacobian. Set FALSE always access full mapper, e.g. rgeneric models mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. multi logical; TRUE (positive), recurse one level sub-mappers ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) sub_lin Internal, optional pre-computed sub-mapper information x object extract element(s) indices specifying element(s) extract drop logical; [.bru_mapper_collect, whether extract individual mapper identifies single element. FALSE, list sub-mappers returned (suitable e.g. creating new bru_mapper_collect object). Default: TRUE value character vector length number sub-mappers mapper","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mapper for concatenated variables — bru_mapper_collect","text":"[-indexing bru_mapper_collect extracts subset bru_mapper_collect object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element) names() method bru_mapper_collect returns names sub-mappers list","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for concatenated variables — bru_mapper_collect","text":"ibm_jacobian bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. inla_f=TRUE hidden=TRUE mapper definition, input format instead match first, non-hidden, sub-mapper. ibm_invalid_output bru_mapper_collect accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_collect(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_collect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for concatenated variables — bru_mapper_collect","text":"","code":"(m <- bru_mapper_collect(list(   a = bru_mapper_index(2),   b = bru_mapper_index(3) ), hidden = FALSE)) #> collect(a = index, b = index) ibm_eval2(m, list(a = c(1, 2), b = c(1, 3, 2)), 1:5) #> $offset #> [1] 1 2 3 5 4 #>  #> $jacobian #> 5 x 5 sparse Matrix of class \"dgTMatrix\" #>                #> [1,] 1 . . . . #> [2,] . 1 . . . #> [3,] . . 1 . . #> [4,] . . . . 1 #> [5,] . . . 1 . #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_const.html","id":null,"dir":"Reference","previous_headings":"","what":"Constant mapper — bru_mapper_const","title":"Constant mapper — bru_mapper_const","text":"Create constant mapper","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_const.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constant mapper — bru_mapper_const","text":"","code":"bru_mapper_const()  # S3 method for class 'bru_mapper_const' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_const' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_const' ibm_jacobian(mapper, input, ...)  # S3 method for class 'bru_mapper_const' ibm_eval(mapper, input, state = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_const.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constant mapper — bru_mapper_const","text":"mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE)","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_const.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constant mapper — bru_mapper_const","text":"","code":"m <- bru_mapper_const() ibm_eval2(m, input = 1:4) #> $offset #> [1] 1 2 3 4 #>  #> $jacobian #> 4 x 0 sparse Matrix of class \"dgCMatrix\" #>      #> [1,] #> [2,] #> [3,] #> [4,] #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for factor variables — bru_mapper_factor","title":"Mapper for factor variables — bru_mapper_factor","text":"Create factor mapper","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for factor variables — bru_mapper_factor","text":"","code":"bru_mapper_factor(values, factor_mapping, indexed = FALSE)  # S3 method for class 'bru_mapper_factor' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_factor' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_factor' ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for factor variables — bru_mapper_factor","text":"values Input values calculated input_eval.bru_input() factor_mapping character; selects type factor mapping. 'contrast' leaving first factor level. 'full' keeping levels. indexed logical; TRUE, ibm_values() method return integer vector instead factor levels. needed e.g. group replicate mappers, since INLA::f() accept factor values. Default: FALSE, works main input mappers. default mapper constructions set required setting. mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_factor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for factor variables — bru_mapper_factor","text":"","code":"m <- bru_mapper_factor(factor(c(\"a\", \"b\")), \"full\") ibm_eval2(m, input = c(\"b\", \"a\", \"a\", \"b\"), state = c(1, 3)) #> $offset #> [1] 3 1 1 3 #>  #> $jacobian #> 4 x 2 sparse Matrix of class \"dgCMatrix\" #>          #> [1,] . 1 #> [2,] 1 . #> [3,] 1 . #> [4,] . 1 #>   m <- bru_mapper_factor(factor(c(\"a\", \"b\")), \"contrast\") ibm_eval2(m, input = factor(c(\"b\", \"a\", \"a\", \"b\")), state = 2) #> $offset #> [1] 2 0 0 2 #>  #> $jacobian #> 4 x 1 sparse Matrix of class \"dgCMatrix\" #>        #> [1,] 1 #> [2,] . #> [3,] . #> [4,] 1 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","title":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","text":"Create mapper fm_mesh_1d object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","text":"","code":"# S3 method for class 'fm_mesh_1d' bru_mapper(mesh, indexed = NULL, ...)  # S3 method for class 'bru_mapper_fm_mesh_1d' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_fm_mesh_1d' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_fm_mesh_1d' ibm_jacobian(mapper, input, ...)  # S3 method for class 'inla.mesh.1d' bru_mapper(mesh, indexed = NULL, ...)  # S3 method for class 'bru_mapper_inla_mesh_1d' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_inla_mesh_1d' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_inla_mesh_1d' ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","text":"mesh fm_mesh_1d inla.mesh.1d object use mapper indexed logical; TRUE, ibm_values() output integer indexing sequence latent variables (needed spde models). FALSE, knot locations returned (useful interpolator rw2 models similar). Default: NULL, force user specification parameter ... Arguments passed methods mapper mapper S3 object, inheriting bru_mapper. input Data input mapper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_1d.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","text":"bru_mapper(inla.mesh.1d): Create mapper inla.mesh.1d object; converts mesh fo fm_mesh_1d first.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for fm_mesh_1d — bru_mapper.fm_mesh_1d","text":"","code":"m <- bru_mapper(fm_mesh_1d(c(1:3, 5, 7)), indexed = FALSE) ibm_values(m) #> [1] 1 2 3 5 7 ibm_eval(m, 1:7, 1:5) #> [1] 1.0 2.0 3.0 3.5 4.0 4.5 5.0 m <- bru_mapper(fm_mesh_1d(c(1:3, 5, 7)), indexed = TRUE) ibm_values(m) #> [1] 1 2 3 4 5 ibm_eval(m, 1:7, 1:5) #> [1] 1.0 2.0 3.0 3.5 4.0 4.5 5.0"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","title":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","text":"Creates mapper 2D fm_mesh_2d objects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","text":"","code":"# S3 method for class 'fm_mesh_2d' bru_mapper(mesh, ...)  # S3 method for class 'bru_mapper_fm_mesh_2d' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_fm_mesh_2d' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_fm_mesh_2d' ibm_jacobian(mapper, input, ...)  # S3 method for class 'inla.mesh' bru_mapper(mesh, ...)  # S3 method for class 'bru_mapper_inla_mesh_2d' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_inla_mesh_2d' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_inla_mesh_2d' ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","text":"mesh fm_mesh_2d inla.mesh.2d object use mapper ... Arguments passed methods mapper mapper S3 object, inheriting bru_mapper. input Data input mapper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_2d.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","text":"bru_mapper(inla.mesh): Creates mapper 2D inla.mesh objects","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_fm_mesh_2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for fm_mesh_2d — bru_mapper.fm_mesh_2d","text":"","code":"m <- bru_mapper(fmesher::fmexample$mesh) ibm_n(m) #> [1] 279 ibm_eval(m, as.matrix(expand.grid(-2:2, -2:2)), seq_len(ibm_n(m))) #>  [1] 250.74364  79.50113  56.07494  99.08437 272.10681 101.93314 138.22942 #>  [8] 126.04646 184.52763  62.06892 129.09019 139.32017 134.69889 104.56584 #> [15] 146.74441 144.17599 139.89904 164.80512 140.63623 195.96047 117.63412 #> [22] 178.67407 148.32454 169.81494 219.07025"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic methods for bru_mapper objects — bru_mapper_generics","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"bru_mapper sub-class implementation must provide ibm_jacobian() method. model size 'n' definition values 'values' stored object , default methods available (see Details). Otherwise ibm_n() ibm_values() methods also need provided.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"","code":"ibm_n(mapper, inla_f = FALSE, ...)  ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, ...)  ibm_values(mapper, inla_f = FALSE, ...)  ibm_is_linear(mapper, ...)  ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)  ibm_linear(mapper, input, state = NULL, ...)  ibm_simplify(mapper, input = NULL, state = NULL, ...)  ibm_eval(mapper, input, state = NULL, ...)  ibm_eval2(mapper, input, state = NULL, ...)  ibm_names(mapper)  ibm_names(mapper) <- value  ibm_inla_subset(mapper, ...)  ibm_invalid_output(mapper, input, state, ...)  # Default S3 method ibm_n(mapper, inla_f = FALSE, ...)  # Default S3 method ibm_n_output(mapper, input, state = NULL, inla_f = FALSE, ...)  # Default S3 method ibm_values(mapper, inla_f = FALSE, ...)  # Default S3 method ibm_is_linear(mapper, ...)  # Default S3 method ibm_jacobian(mapper, input, state, ...)  # Default S3 method ibm_linear(mapper, input, state, ...)  # Default S3 method ibm_simplify(mapper, input = NULL, state = NULL, ...)  # Default S3 method ibm_eval(mapper, input, state = NULL, ..., jacobian = NULL)  # Default S3 method ibm_eval2(mapper, input, state, ...)  # Default S3 method ibm_names(mapper, ...)  # Default S3 method ibm_inla_subset(mapper, ...)  # Default S3 method ibm_invalid_output(mapper, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) value character vector length number sub-mappers mapper jacobian ibm_eval() methods, optional pre-computed Jacobian, typically supplied internal methods already Jacobian.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"ibm_n(): Implementations must return size latent vector mapped . ibm_n_output(): Implementations must return integer denoting mapper output length. default implementation returns NROW(input). Mappers bru_mapper_multi bru_mapper_collect, can accept list() inputs require methods implementations. ibm_values(): inla_f=TRUE, implementations must return vector interpretable INLA::f(..., values = ...) specification. exception method bru_mapper_multi, returns multi-column data frame. ibm_is_linear(): Implementations must return TRUE FALSE. TRUE (returned default method unless mapper contains is_linear variable), users mapper may assume mapper linear. ibm_jacobian(): Implementations must return (sparse) matrix size ibm_n_output(mapper, input, inla_f) ibm_n(mapper, inla_f = FALSE). inla_f=TRUE argument affect allowed type input format. ibm_linear(): Implementations must return bru_mapper_taylor object linearisation information includes offset, jacobian, state0. state information indicates state offset evaluated, NULL meaning -zero. linearised mapper output defined effect(input, state) = offset(input, state0) + jacobian(input, state0) %*% (state - state0). default method calls ibm_eval() ibm_jacobian() generate needed information. ibm_simplify(): Implementations must return bru_mapper object. default method returns ibm_linear(...) linear mappers, original mapper non-linear mappers. ibm_eval(): Implementations must return vector length ibm_n_output(...). input contents must format accepted ibm_jacobian(...) mapper. ibm_eval2(): Implementations must return list elements offset jacobian. input contents must format accepted ibm_jacobian(...) mapper. ibm_names(): Implementations must return character vector sub-mapper names, NULL. Intended providing information multi-mappers mapper collections. ibm_names(mapper) <- value: Set mapper names. ibm_inla_subset(): Implementations must return logical vector TRUE/FALSE subset , given full matrix values output, [, subset, drop = FALSE] values[subset] (values[subset, , drop = FALSE] data.frame values) equal inla_f = TRUE version values. default method uses ibm_values output construct subset indexing. ibm_invalid_output(): Implementations return logical vector length ibm_n_output(mapper, input, state, ...) indicating , , output elements ibm_eval(mapper, input, state, ...) known invalid. multi/collect mappers, list, given multi=TRUE argument. ibm_n(default): Returns non-null element 'n' mapper object, gives error exist. inla_f=TRUE, first checks 'n_inla' element. ibm_n_output(default): Returns NROW(input) ibm_values(default): Returns non-null element 'values' mapper object, seq_len(ibm_n(mapper)) exist. ibm_is_linear(default): Returns logical is_linear mapper object exists, otherwise TRUE. ibm_jacobian(default): Mapper classes must implement ibm_jacobian method. ibm_linear(default): Calls ibm_eval() ibm_jacobian() returns bru_mapper_taylor object. state0 information affine mapper indicates state offset evaluated; affine mapper output defined effect(input, state) = offset(input, state0) + jacobian(input, state0) %*% (state - state0) ibm_simplify(default): Calls ibm_linear() linear mappers, returns original mapper non-linear mappers. ibm_eval(default): Verifies mapper linear ibm_is_linear(), computes linear mapping ibm_jacobian(...) %*% state.  state NULL, zero vector length ibm_n_output(...) returned. ibm_eval2(default): Calls jacobian <- ibm_jacobian(...) offset <- ibm_eval(..., jacobian = jacobian) returns list elements offset jacobian, needed ibm_linear.default() similar methods. Mapper classes can implement ibm_eval2 method joint construction evaluation Jacobian efficient separate sequential construction. ibm_names(default): Returns NULL ibm_inla_subset(default): Uses ibm_values output construct inla subset indexing, passing extra arguments multi methods (means supports regular vector values multi=1 data.frame values). ibm_invalid_output(default): Returns -FALSE logical vector.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_generics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic methods for bru_mapper objects — bru_mapper_generics","text":"","code":"# ibm_names mapper <- bru_mapper_multi(list(   A = bru_mapper_index(2),   B = bru_mapper_index(2) )) ibm_names(mapper) #> [1] \"A\" \"B\" ibm_names(mapper) <- c(\"new\", \"names\") ibm_names(mapper) #> [1] \"new\"   \"names\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_harmonics.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for cos/sin functions — bru_mapper_harmonics","title":"Mapper for cos/sin functions — bru_mapper_harmonics","text":"Constructs mapper cos/sin functions orders 1 (intercept TRUE, otherwise 0) order. total number basis functions intercept + 2 * order. Optionally, order can given non-unit scaling, via scaling vector, length intercept + order. can used give effective spectral prior. example, let   ,   stochastic properties u1 u2 , scaling^2 determining variance frequency contribution. period first order harmonics shifted scaled match interval.","code":"scaling = 1 / (1 + (0:4)^2) x <- seq(0, 1, length.out = 11) bmh1 = bru_mapper_harmonics(order = 4, interval = c(0, 1)) u1 <- ibm_eval(   bmh1,   input = x,   state = rnorm(9, sd = rep(scaling, c(1, 2, 2, 2, 2))) ) bmh2 = bru_mapper_harmonics(order = 4, scaling = scaling) u2 = ibm_eval(bmh2, input = x, state = rnorm(9))"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_harmonics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for cos/sin functions — bru_mapper_harmonics","text":"","code":"bru_mapper_harmonics(   order = 1,   scaling = 1,   intercept = TRUE,   interval = c(0, 1) )  # S3 method for class 'bru_mapper_harmonics' ibm_n(mapper, inla_f = FALSE, ...)  # S3 method for class 'bru_mapper_harmonics' ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_harmonics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for cos/sin functions — bru_mapper_harmonics","text":"order bru_mapper_harmonics, specifies maximum cos/sin order. (Default 1) scaling bru_mapper_harmonics, specifies optional vector scaling factors length intercept + order, common single scalar. intercept logical; bru_mapper_harmonics, TRUE, first basis function constant. (Default TRUE) interval numeric length-2 vector specifying domain interval. Default c(0, 1). mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE)","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_harmonics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for cos/sin functions — bru_mapper_harmonics","text":"","code":"m <- bru_mapper_harmonics(2) ibm_eval2(m, input = c(0, pi / 4, pi / 2, 3 * pi / 4), 1:5) #> $offset #> [1]  7.000000 -7.247183  4.306719 -3.678570 #>  #> $jacobian #> 4 x 5 Matrix of class \"dgeMatrix\" #>      [,1]       [,2]       [,3]       [,4]       [,5] #> [1,]    1  1.0000000  0.0000000  1.0000000  0.0000000 #> [2,]    1  0.2205840 -0.9753680 -0.9026854 -0.4303012 #> [3,]    1 -0.9026854 -0.4303012  0.6296817  0.7768532 #> [4,]    1 -0.6188200  0.7855328 -0.2341236 -0.9722068 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for indexed variables — bru_mapper_index","title":"Mapper for indexed variables — bru_mapper_index","text":"Create indexing mapper","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for indexed variables — bru_mapper_index","text":"","code":"bru_mapper_index(n = 1L, ...)  # S3 method for class 'bru_mapper_index' ibm_invalid_output(mapper, input, state, ...)  # S3 method for class 'bru_mapper_index' ibm_jacobian(mapper, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for indexed variables — bru_mapper_index","text":"n Size model bru_mapper_index ... Arguments passed methods mapper mapper S3 object, inheriting bru_mapper. input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE)","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for indexed variables — bru_mapper_index","text":"","code":"m <- bru_mapper_index(4) ibm_eval(m, -2:6, 1:4) #> [1] 0 0 0 1 2 3 4 0 0"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for a linear effect — bru_mapper_linear","title":"Mapper for a linear effect — bru_mapper_linear","text":"Create mapper linear effects","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for a linear effect — bru_mapper_linear","text":"","code":"bru_mapper_linear()  # S3 method for class 'bru_mapper_linear' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_linear' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_linear' ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for a linear effect — bru_mapper_linear","text":"mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for a linear effect — bru_mapper_linear","text":"","code":"m <- bru_mapper_linear() ibm_eval(m, input = 1:4, state = 2) #> [1] 2 4 6 8"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"Constructs mapper aggregates elements exp(state), optional non-negative weighting, takes log(), can used e.g.  \\(v_k=\\log[\\sum_{\\I_k} w_i \\exp(u_i)]\\) \\(v_k=\\log[\\sum_{\\I_k} w_i \\exp(u_i) / \\sum_{\\I_k} w_i]\\) calculations.  Relies input handling methods bru_mapper_aggregate, also allows weights supplied logarithmic scale log_weights. avoid numerical overflow, uses common method internally shifting state blockwise; \\(v_k=s_k+\\log[\\sum_{\\I_k} \\exp(u_i + \\log(w_i)- s_k)]\\), \\(s_k=\\max_{\\I_k} u_i + \\log(w_i)\\) shift block \\(k\\).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"","code":"bru_mapper_logsumexp(rescale = FALSE, n_block = NULL)  # S3 method for class 'bru_mapper_logsumexp' ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for class 'bru_mapper_logsumexp' ibm_eval(mapper, input, state = NULL, log = TRUE, ..., sub_lin = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"rescale logical; bru_mapper_aggregate bru_mapper_logsumexp, specifies blockwise sums normalised blockwise weight sums : FALSE: (default) Straight weighted sum, rescaling. TRUE: Divide sum weight values within block. useful integration averages, given weights plain integration weights. weights NULL ones, dividing number entries block. n_block Predetermined number output blocks. NULL, overrides maximum block index inputs. mapper mapper S3 object, inheriting bru_mapper. input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) ... Arguments passed methods log logical; control log output. Default TRUE, see ibm_eval() details logsumexp mappers. sub_lin Internal, optional pre-computed sub-mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"bru_mapper_logsumexp, input list elements block weights. block vector length state, NULL, NULL equivalent -1. weights NULL, interpreted -1.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"ibm_eval(bru_mapper_logsumexp): log TRUE (default), ibm_eval() logsumexp returns log-sum-weight-exp value. FALSE, sum-weight-exp value returned.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for log-sum-exp aggregation — bru_mapper_logsumexp","text":"","code":"m <- bru_mapper_logsumexp() ibm_eval2(m, list(block = c(1, 2, 1, 2), weights = 1:4), 11:14) #> $offset #> [1] 14.14274 15.45177 #>  #> $jacobian #> 2 x 4 sparse Matrix of class \"dgCMatrix\" #>                                                #> [1,] 0.04316453 .          0.9568355 .         #> [2,] .          0.06337894 .         0.9366211 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for marginal distribution transformation — bru_mapper_marginal","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"Constructs mapper transforms marginal distribution state \\(\\textrm{N}(0,1)\\) distribution given (continuous) quantile function. ... arguments used parameter arguments qfun, pfun, dfun, dqfun.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"","code":"bru_mapper_marginal(   qfun,   pfun = NULL,   dfun = NULL,   dqfun = NULL,   ...,   inverse = FALSE )  # S3 method for class 'bru_mapper_marginal' ibm_n(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_marginal' ibm_n_output(mapper, input, state = NULL, ..., n_state = NULL)  # S3 method for class 'bru_mapper_marginal' ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_marginal' ibm_jacobian(mapper, input, state = NULL, ..., reverse = FALSE)  # S3 method for class 'bru_mapper_marginal' ibm_eval(mapper, input, state = NULL, ..., reverse = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"qfun quantile function, supporting lower.tail log.p arguments, like stats::qnorm(). pfun CDF, supporting lower.tail log.p arguments, like stats::pnorm().  needed used xor(mapper[[\"inverse\"]], reverse) TRUE method call. Default NULL dfun pdf, supporting log argument, like stats::dnorm(). NULL (default), uses finite differences qfun pfun instead. dqfun function evaluating reciprocal derivative qfun. NULL (default), uses dfun(qfun(...),...) finite differences qfun pfun instead. ... Arguments passed methods inverse logical; FALSE (default), bru_mapper_marginal() defines mapping standard Normal specified distribution. TRUE, defines mapping specified distribution standard Normal. mapper mapper S3 object, inheriting bru_mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) n_state integer giving length state vector mappers state dependent output size. input Data input mapper. reverse logical; control bru_mapper_marginal evaluation. Default FALSE. TRUE, reverses direction mapping, see details marginal mappers.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"bru_mapper_marginal, non-NULL input values interpreted parameter list qfun, overriding mapper .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"ibm_eval(bru_mapper_marginal): xor(mapper[[\"inverse\"]], reverse) FALSE, ibm_eval() marginal returns qfun(pnorm(x), param), evaluated numerically stable way. Otherwise, evaluates inverse qnorm(pfun(x, param)) instead.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_marginal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for marginal distribution transformation — bru_mapper_marginal","text":"","code":"m <- bru_mapper_marginal(qexp, pexp, rate = 1 / 8) (val <- ibm_eval(m, state = -5:5)) #>  [1] 2.293213e-06 2.533739e-04 1.080648e-02 1.841033e-01 1.382030e+00 #>  [6] 5.545177e+00 1.472817e+01 3.026547e+01 5.286181e+01 8.288081e+01 #> [11] 1.205200e+02 ibm_eval(m, state = val, reverse = TRUE) #>  [1] -5 -4 -3 -2 -1  0  1  2  3  4  5 m <- bru_mapper_marginal(qexp, pexp, dexp, rate = 1 / 8) ibm_eval2(m, state = -3:3) #> $offset #> [1]  0.01080648  0.18410327  1.38203023  5.54517744 14.72817316 30.26547467 #> [7] 52.86180977 #>  #> $jacobian #> 7 x 7 diagonal matrix of class \"ddiMatrix\" #>      [,1]       [,2]      [,3]   [,4]     [,5]     [,6]     [,7]     #> [1,] 0.03550271         .      .        .        .        .        . #> [2,]          . 0.4419829      .        .        .        .        . #> [3,]          .         . 2.3008        .        .        .        . #> [4,]          .         .      . 6.383076        .        .        . #> [5,]          .         .      .        . 12.20108        .        . #> [6,]          .         .      .        .        . 18.98572        . #> [7,]          .         .      .        .        .        . 26.26479 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for matrix multiplication — bru_mapper_matrix","title":"Mapper for matrix multiplication — bru_mapper_matrix","text":"Create matrix mapper, given number columns","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for matrix multiplication — bru_mapper_matrix","text":"","code":"bru_mapper_matrix(labels)  # S3 method for class 'bru_mapper_matrix' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_matrix' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_matrix' ibm_jacobian(mapper, input, state = NULL, inla_f = FALSE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for matrix multiplication — bru_mapper_matrix","text":"labels Column labels matrix mappings; Can factor, character, single integer specifying number columns integer column indexing. mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for matrix multiplication — bru_mapper_matrix","text":"","code":"m <- bru_mapper_matrix(labels = c(\"a\", \"b\")) ibm_values(m) #> [1] a b #> Levels: a b ibm_eval2(m, input = matrix(1:6, 3, 2), state = 2:3) #> $offset #> [1] 14 19 24 #>  #> $jacobian #> 3 x 2 Matrix of class \"dgeMatrix\" #>      a b #> [1,] 1 4 #> [2,] 2 5 #> [3,] 3 6 #>   m <- bru_mapper_matrix(labels = 2L) ibm_values(m) #> [1] 1 2 ibm_eval2(m, input = matrix(1:6, 3, 2), state = 2:3) #> $offset #> [1] 14 19 24 #>  #> $jacobian #> 3 x 2 Matrix of class \"dgeMatrix\" #>      1 2 #> [1,] 1 4 #> [2,] 2 5 #> [3,] 3 6 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_mesh_B.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for basis conversion — bru_mapper_mesh_B","title":"Mapper for basis conversion — bru_mapper_mesh_B","text":"Creates mapper handling basis conversions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_mesh_B.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for basis conversion — bru_mapper_mesh_B","text":"","code":"bru_mapper_mesh_B(mesh, B)  # S3 method for class 'bru_mapper_mesh_B' ibm_n(mapper, ...)  # S3 method for class 'bru_mapper_mesh_B' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_mesh_B' ibm_jacobian(mapper, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_mesh_B.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for basis conversion — bru_mapper_mesh_B","text":"mesh object supported bru_mapper, typically fm_mesh_2d fm_mesh_1d B square tall basis conversion matrix mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input values produce mapping matrix","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for tensor product domains — bru_mapper_multi","title":"Mapper for tensor product domains — bru_mapper_multi","text":"Constructs rowwise Kronecker product mapping","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for tensor product domains — bru_mapper_multi","text":"","code":"bru_mapper_multi(mappers)  # S3 method for class 'bru_mapper_multi' ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_multi' ibm_n_output(mapper, input, ...)  # S3 method for class 'bru_mapper_multi' ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_multi' ibm_is_linear(mapper, multi = FALSE, ...)  # S3 method for class 'bru_mapper_multi' ibm_jacobian(   mapper,   input,   state = NULL,   inla_f = FALSE,   multi = FALSE,   ...,   sub_A = NULL )  # S3 method for class 'bru_mapper_multi' ibm_linear(mapper, input, state, inla_f = FALSE, ...)  # S3 method for class 'bru_mapper_multi' ibm_eval(   mapper,   input,   state = NULL,   inla_f = FALSE,   ...,   jacobian = NULL,   pre_A = deprecated() )  # S3 method for class 'bru_mapper_multi' ibm_invalid_output(mapper, input, state, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_multi' x[i, drop = TRUE]  # S3 method for class 'bru_mapper_multi' ibm_names(mapper)  # S3 method for class 'bru_mapper_multi' ibm_names(mapper) <- value"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for tensor product domains — bru_mapper_multi","text":"mappers list bru_mapper objects mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. multi logical; TRUE (positive), recurse one level sub-mappers ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) sub_A Internal; precomputed Jacobian matrices. jacobian ibm_eval() methods, optional pre-computed Jacobian, typically supplied internal methods already Jacobian. pre_A favour jacobian. x object extract element(s) indices specifying element(s) extract drop logical; [.bru_mapper_multi, whether extract individual mapper identifies single element. FALSE, list sub-mappers returned (suitable e.g. creating new bru_mapper_multi object). Default: TRUE value character vector length number mappers multi-mapper x","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mapper for tensor product domains — bru_mapper_multi","text":"[-indexing bru_mapper_multi extracts subset bru_mapper_multi object (drop FALSE) individual sub-mapper (drop TRUE, identifies single element)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for tensor product domains — bru_mapper_multi","text":"ibm_jacobian bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns. ibm_invalid_output bru_mapper_multi accepts list named entries, list unnamed ordered elements. names must match sub-mappers, see ibm_names.bru_mapper_multi(). list element take format accepted corresponding sub-mapper. case element vector, input can given data.frame named columns, matrix named columns, matrix unnamed ordered columns.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Mapper for tensor product domains — bru_mapper_multi","text":"ibm_names(bru_mapper_multi): Returns names sub-mappers list","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for tensor product domains — bru_mapper_multi","text":"","code":"(m <- bru_mapper_multi(list(   a = bru_mapper_index(2),   b = bru_mapper_index(3) ))) #> multi(a = index, b = index) ibm_eval2(m, list(a = c(1, 2, 1), b = c(1, 3, 2)), 1:6) #> $offset #> [1] 1 6 3 #>  #> $jacobian #> 3 x 6 sparse Matrix of class \"dgCMatrix\" #>                  #> [1,] 1 . . . . . #> [2,] . . . . . 1 #> [3,] . . 1 . . . #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for linking several mappers in sequence — bru_mapper_pipe","title":"Mapper for linking several mappers in sequence — bru_mapper_pipe","text":"Create pipe mapper, mappers list mappers, evaluated output mapper handed state next mapper. input format ibm_eval ibm_jacobian methods list inputs, one mapper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for linking several mappers in sequence — bru_mapper_pipe","text":"","code":"bru_mapper_pipe(mappers)  # S3 method for class 'bru_mapper_pipe' ibm_n(mapper, ..., input = NULL, state = NULL)  # S3 method for class 'bru_mapper_pipe' ibm_n_output(mapper, input, state = NULL, ..., n_state = NULL)  # S3 method for class 'bru_mapper_pipe' ibm_values(mapper, ...)  # S3 method for class 'bru_mapper_pipe' ibm_jacobian(mapper, input, state = NULL, ...)  # S3 method for class 'bru_mapper_pipe' ibm_eval(mapper, input, state = NULL, ...)  # S3 method for class 'bru_mapper_pipe' ibm_eval2(mapper, input, state = NULL, ...)  # S3 method for class 'bru_mapper_pipe' ibm_simplify(   mapper,   input = NULL,   state = NULL,   inla_f = FALSE,   ...,   n_state = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for linking several mappers in sequence — bru_mapper_pipe","text":"mappers list bru_mapper objects mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) n_state integer giving length state vector mappers state dependent output size. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_pipe.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Mapper for linking several mappers in sequence — bru_mapper_pipe","text":"ibm_simplify(bru_mapper_pipe): Constructs simplified pipe mapper. fully linear pipes, calls ibm_linear(). partially non-linear pipes, replaces sequence linear mappers single bru_mapper_taylor() mapper, keeping full list original mapper names, allowing original input structure used also simplified mappers, since taylor mappers dependent inputs.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_pipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for linking several mappers in sequence — bru_mapper_pipe","text":"","code":"m <- bru_mapper_pipe(list(   scale = bru_mapper_scale(),   shift = bru_mapper_shift() )) ibm_eval2(m, input = list(scale = 2, shift = 1:4), state = 1:4) #> $offset #> [1]  3  6  9 12 #>  #> $jacobian #> 4 x 4 diagonal matrix of class \"ddiMatrix\" #>      [,1] [,2] [,3] [,4] #> [1,]    2    .    .    . #> [2,]    .    2    .    . #> [3,]    .    .    2    . #> [4,]    .    .    .    2 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for element-wise scaling — bru_mapper_scale","title":"Mapper for element-wise scaling — bru_mapper_scale","text":"Create standalone scaling mapper can used part bru_mapper_pipe. mapper non-null, bru_mapper_scale() constructor returns bru_mapper_pipe(list(mapper = mapper, scale = bru_mapper_scale()))","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for element-wise scaling — bru_mapper_scale","text":"","code":"bru_mapper_scale(mapper = NULL)  # S3 method for class 'bru_mapper_scale' ibm_n(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_scale' ibm_n_output(mapper, input, state = NULL, ..., n_state = NULL)  # S3 method for class 'bru_mapper_scale' ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_scale' ibm_jacobian(mapper, input, state = NULL, ..., sub_lin = NULL)  # S3 method for class 'bru_mapper_scale' ibm_eval(mapper, input, state = NULL, ..., sub_lin = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for element-wise scaling — bru_mapper_scale","text":"mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) n_state integer giving length state vector mappers state dependent output size. input Data input mapper. sub_lin Internal, optional pre-computed sub-mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_scale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for element-wise scaling — bru_mapper_scale","text":"bru_mapper_scale, input NULL values interpreted scaling.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_scale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for element-wise scaling — bru_mapper_scale","text":"","code":"m <- bru_mapper_scale() ibm_eval2(m, c(1, 2, 1, 2), 1:4) #> $offset #> [1] 1 4 3 8 #>  #> $jacobian #> 4 x 4 diagonal matrix of class \"ddiMatrix\" #>      [,1] [,2] [,3] [,4] #> [1,]    1    .    .    . #> [2,]    .    2    .    . #> [3,]    .    .    1    . #> [4,]    .    .    .    2 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_shift.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for element-wise shifting — bru_mapper_shift","title":"Mapper for element-wise shifting — bru_mapper_shift","text":"Create standalone shift mapper can used part bru_mapper_pipe. mapper non-null, bru_mapper_shift() constructor returns bru_mapper_pipe(list(mapper = mapper, shift = bru_mapper_shift()))","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_shift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for element-wise shifting — bru_mapper_shift","text":"","code":"bru_mapper_shift(mapper = NULL)  # S3 method for class 'bru_mapper_shift' ibm_n(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_shift' ibm_n_output(mapper, input, state = NULL, ..., n_state = NULL)  # S3 method for class 'bru_mapper_shift' ibm_values(mapper, ..., state = NULL, n_state = NULL)  # S3 method for class 'bru_mapper_shift' ibm_jacobian(mapper, input, state = NULL, ..., sub_lin = NULL)  # S3 method for class 'bru_mapper_shift' ibm_eval(mapper, input, state = NULL, ..., sub_lin = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_shift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for element-wise shifting — bru_mapper_shift","text":"mapper mapper S3 object, inheriting bru_mapper. ... Arguments passed methods state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE) n_state integer giving length state vector mappers state dependent output size. input Data input mapper. sub_lin Internal, optional pre-computed sub-mapper information","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_shift.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for element-wise shifting — bru_mapper_shift","text":"bru_mapper_shift, input NULL values interpreted shift.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_shift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for element-wise shifting — bru_mapper_shift","text":"","code":"m <- bru_mapper_shift() ibm_eval2(m, c(1, 2, 1, 2), 1:4) #> $offset #> [1] 2 4 4 6 #>  #> $jacobian #> 4 x 4 diagonal matrix of class \"ddiMatrix\" #>      [,1] [,2] [,3] [,4] #> [1,]    1    .    .    . #> [2,]    .    1    .    . #> [3,]    .    .    1    . #> [4,]    .    .    .    1 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"mapper object summaries — summary.bru_mapper","title":"mapper object summaries — summary.bru_mapper","text":"mapper object summaries","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mapper object summaries — summary.bru_mapper","text":"","code":"# S3 method for class 'bru_mapper' summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for class 'bru_mapper_multi' summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for class 'bru_mapper_pipe' summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for class 'bru_mapper_collect' summary(object, ..., prefix = \"\", initial = prefix, depth = 1)  # S3 method for class 'summary_bru_mapper' print(x, ...)  # S3 method for class 'bru_mapper' print(x, ..., prefix = \"\", initial = prefix, depth = 1)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mapper object summaries — summary.bru_mapper","text":"object bru_mapper object summarise ... Unused arguments prefix character prefix line. Default \"\". initial character prefix first line. Default initial=prefix. depth recursion depth multi/collection/pipe mappers. Default 1, show collection, contents sub-mappers. x Object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mapper object summaries — summary.bru_mapper","text":"","code":"mapper <-   bru_mapper_pipe(     list(       bru_mapper_multi(list(         A = bru_mapper_index(2),         B = bru_mapper_index(3)       )),       bru_mapper_index(2)     )   ) summary(mapper, depth = 2) #> pipe = multi(A = index, B = index) -> index"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_taylor.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapper for linear Taylor approximations — bru_mapper_taylor","title":"Mapper for linear Taylor approximations — bru_mapper_taylor","text":"Provides pre-computed affine mapping, internally used represent evaluate linearisation information. state0 information indicates state offset evaluated; affine mapper output defined effect(state) = offset + jacobian %*% (state - state0)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_taylor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapper for linear Taylor approximations — bru_mapper_taylor","text":"","code":"bru_mapper_taylor(   offset = NULL,   jacobian = NULL,   state0 = NULL,   values_mapper = NULL )  # S3 method for class 'bru_mapper_taylor' ibm_n(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_taylor' ibm_n_output(mapper, input, ...)  # S3 method for class 'bru_mapper_taylor' ibm_values(mapper, inla_f = FALSE, multi = FALSE, ...)  # S3 method for class 'bru_mapper_taylor' ibm_jacobian(mapper, ..., multi = FALSE)  # S3 method for class 'bru_mapper_taylor' ibm_eval(mapper, input = NULL, state = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_taylor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapper for linear Taylor approximations — bru_mapper_taylor","text":"offset bru_mapper_taylor, offset vector evaluated state0. May NULL, interpreted -zero vector length determined non-null Jacobian. jacobian bru_mapper_taylor(), Jacobian matrix, evaluated state0, , named list matrices. May NULL empty list, constant mapping. state0 bru_mapper_taylor, state linearisation evaluated , list length matching jacobian list. NULL interpreted 0. values_mapper mapper object used ibm_n ibm_values inla_f=TRUE (experimental, currently unused) mapper mapper S3 object, inheriting bru_mapper. inla_f logical; TRUE ibm_n() ibm_values(), result must compatible INLA::f(...) corresponding INLA::inla.stack(...) constructions.  ibm_{eval,jacobian,linear}, input interpretation may different. Implementations normally need anything different, except mappers type needed hidden multicomponent models \"bym2\", can handled bru_mapper_collect. multi logical; TRUE (positive), recurse one level sub-mappers ... Arguments passed methods input Data input mapper. state vector latent state values mapping, length ibm_n(mapper, inla_f = FALSE)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_taylor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapper for linear Taylor approximations — bru_mapper_taylor","text":"ibm_eval.bru_mapper_taylor() evaluates linearised mapper information given state. input argument ignored, usual argument order ibm_eval(mapper, input, state) syntax can used, also ibm_eval(mapper, state = state).  mapper named jacobian list, state argument must also named list.  state NULL, -zero assumed.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_mapper_taylor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapper for linear Taylor approximations — bru_mapper_taylor","text":"","code":"m <- bru_mapper_taylor(   offset = rep(2, 3),   jacobian = matrix(1:6, 3, 2),   state0 = c(1, 2) ) ibm_eval2(m, state = 2:3) #> $offset #> [1]  7  9 11 #>  #> $jacobian #>      [,1] [,2] #> [1,]    1    4 #> [2,]    2    5 #> [3,]    3    6 #>"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an inlabru model object from model components — bru_model","title":"Create an inlabru model object from model components — bru_model","text":"inlabru syntax model formulae different INLA::inla considers valid. inla effects defined adding f(...) expression formula. inlabru f replaced arbitrary (exceptions: const offset) string determine label effect. See Details information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an inlabru model object from model components — bru_model","text":"","code":"bru_model(components, lhoods)  # S3 method for class 'bru_model' summary(object, ...)  # S3 method for class 'summary_bru_model' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an inlabru model object from model components — bru_model","text":"components component_list object lhoods list one lhood objects object Object operate ... Arguments passed methods x summary_bru_model object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an inlabru model object from model components — bru_model","text":"bru_model object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an inlabru model object from model components — bru_model","text":"instance y ~ f(myspde, ...) INLA equivalent y ~ myspde(...) inlabru. disadvantage inla way clear separation name covariate label effect. Furthermore, models like SPDE much natural use spatial coordinates covariates rather index SPDE vertices. purpose inlabru provides main argument. convenience, main argument can used like first argument f function, e.g., first argument component definition. INLA model formula y ~ f(temperature, model = 'linear') equivalent inlabru component formula definition y ~ temperature(temperature, model = 'linear') y ~ temperature(main = temperature, model = 'linear') well y ~ temperature(model = 'linear') sets main = temperature. hand, main can also function mapping, e.g sp::coordinates() function: y ~ mySPDE(coordinates, ...) extracts coordinates data object, maps latent field via information given mapper, default extracted model object, case spde model objects. Morevover, main can expression evaluates within data environment. instance, data columns '' 'b', can create fixed effect 'sin(+b)' setting map following way: y ~ myEffect(sin(+b))","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update an options objects — bru_options","title":"Create or update an options objects — bru_options","text":"Create new options object, merge information several objects. _get, _set, _reset functions operate global package options override object. many cases, setting options specific calls bru() recommended instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update an options objects — bru_options","text":"","code":"bru_options(...)  as.bru_options(x = NULL)  bru_options_default()  bru_options_check(options, ignore_null = TRUE)  bru_options_get(name = NULL, include_default = TRUE)  bru_options_set(..., .reset = FALSE)  bru_options_reset()"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update an options objects — bru_options","text":"... collection named options, optionally including one bru_options objects. Options specified later override previous options. x object converted bru_options object. options bru_options object checked ignore_null Ignore missing NULL options. name Either NULL, single option name string, character vector list option names, Default: NULL include_default logical; TRUE, default options included together global override options. Default: TRUE .reset bru_options_set, logical indicating global override options list emptied setting new option(s).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update an options objects — bru_options","text":"bru_options() returns bru_options object. .bru_options(), NULL input returns empty bru_options object, list converted via bru_options(...), bru_options input passed . types input generates error. bru_options_default() returns bru_options object containing default options. bru_options_check() returns logical; TRUE object contains valid options use functions bru_options_get returns either bru_options object, name == NULL, contents single option, name options name string, named list option contents, name list option name strings. bru_options_set() returns copy global override options, invisibly (bru_options_get(include_default = FALSE)).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create or update an options objects — bru_options","text":".bru_options(): Coerces inputs bru_options object. bru_options_default(): Returns default options. bru_options_check(): Checks valid contents bru_options object, produces warnings invalid options. bru_options_get(): Used access global package options. bru_options_set(): Used set global package options. bru_options_reset(): Clears global option overrides.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"valid-options","dir":"Reference","previous_headings":"","what":"Valid options","title":"Create or update an options objects — bru_options","text":"bru_options bru_options_set, recognised options : bru_verbose logical numeric; TRUE, log messages verbosity \\(\\le 1\\) printed bru_log_message(). numeric, log messages verbosity \\(\\le\\)bru_verbose printed. line search details, set bru_verbose=2 3. Default: 0, print messages bru_verbose_store logical numeric; TRUE, log messages verbosity \\(\\le 1\\) stored bru_log_message(). numeric, log messages verbosity \\(\\le\\) stored. Default: Inf, store messages. bru_run TRUE, run inference. Otherwise return configuration needed run inference. bru_max_iter maximum number inla iterations, default 10. Also see bru_method$rel_tol related options . bru_initial inla object returned previous calls INLA::inla, bru() lgcp(), list named vectors starting values latent variables. used starting point improvement approximate posterior. bru_int_args List arguments passed way integration method ipoints int.polygon 'cp' family models; method \"stable\" \"direct\". \"stable\" (default) integration points aggregated mesh vertices. nsub1 Number integration points per knot interval 1D. Default 30. nsub2 Number integration points along triangle edge 2D. Default 9. nsub Deprecated parameter overrides nsub1 nsub2 set. Default NULL. bru_method List arguments controlling iterative inlabru method: taylor 'pandemic' (default, version 2.1.15). search Either '' (default), use available line search methods, one 'finite' (reduce step size predictor finite) 'contract' (decrease step size trust hypersphere reached) 'expand' (increase step size improvement) 'optimise' (fast approximate error norm minimisation) disable line search, set empty vector. Line search available taylor=\"legacy\". factor Numeric, \\(> 1\\) determining line search step scaling multiplier. Default \\((1 + \\sqrt{5})/2\\). rel_tol Stop iterations largest change linearisation point (conditional latent state mode) relation estimated posterior standard deviation less rel_tol. Default 0.1 (ten percent). max_step largest allowed line search step factor. Factor 1 full INLA step. Default 2. line_opt_method method use line search optimisation step. Default \"onestep\", using quadratic approximation based value gradient zero, value current best step length guess. method \"full\" line optimisation full nonlinear predictor; slow intended debugging purposes . bru_compress_cp logical; TRUE, compress \\(\\sum_{=1}^n \\eta_i\\) part Poisson process likelihood (family=\"cp\") single term, \\(y=n\\), predictor mean(eta). Default: TRUE bru_debug logical; TRUE, activate temporary debug features package development. Default: FALSE inla() options options starting bru_ passed inla(), sometimes altering according needs inlabru method. Warning: Due inlabru currently constructs inla() call, mean, prec, mean.intercept, prec.intercept settings control.fixed effect. elegant alternative implemented, use explicit mean.linear prec.linear specifications model=\"linear\" component instead.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update an options objects — bru_options","text":"","code":"if (FALSE) { # \\dontrun{ if (interactive()) {   # Combine global and user options:   options1 <- bru_options(bru_options_get(), bru_verbose = TRUE)   # Create a proto-options object in two equivalent ways:   options2 <- as.bru_options(bru_verbose = TRUE)   options2 <- as.bru_options(list(bru_verbose = TRUE))   # Combine options objects:   options3 <- bru_options(options1, options2) } } # } if (FALSE) { # \\dontrun{ if (interactive()) {   bru_options_check(bru_options(bru_max_iter = \"text\")) } } # } bru_options_get(\"bru_verbose\") #> [1] 0 if (FALSE) { # \\dontrun{ if (interactive()) {   bru_options_set(     bru_verbose = TRUE,     verbose = TRUE   ) } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":null,"dir":"Reference","previous_headings":"","what":"Load INLA safely for examples and tests — bru_safe_inla","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"Loads INLA package requireNamespace(\"INLA\", quietly = TRUE), optionally checks sets multicore num.threads INLA option.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"bru_safe_inla(multicore = NULL, quietly = FALSE, minimum_version = \"23.1.31\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. FALSE, forces num.threads=\"1:1\". Default: NULL, checks running testthat non-interactively, case sets multicore=FALSE, otherwise TRUE. quietly logical; FALSE multicore FALSE, prints message num.threads option already \"1.1\" alert user change. Default: FALSE. minimum_version character; minimum required INLA version. Default 23.1.31 (always match requirement package DESCRIPTION)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"logical; TRUE INLA loaded safely, otherwise FALSE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_inla.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load INLA safely for examples and tests — bru_safe_inla","text":"","code":"if (FALSE) { # \\dontrun{ if (bru_safe_inla()) {   # Run inla dependent calculations } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for potential sp version compatibility issues — bru_safe_sp","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"Loads sp package requireNamespace(\"sp\", quietly = TRUE), checks optionally sets sp evolution status flag rgdal unavailable.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"","code":"bru_safe_sp(quietly = FALSE, force = FALSE, minimum_version = \"1.4-5\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"quietly logical; TRUE, prints diagnostic messages. Default FALSE force logical; rgdal unavailable evolution status less 2L, return FALSE force FALSE. force TRUE, return TRUE package configuration safe, potentially forcing evolution status 2L. Default FALSE minimum_version character; minimum required INLA version. Default 1.4-5 (always match requirement package DESCRIPTION)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"Returns (invisibly) FALSE potential issue detected, give message quietly FALSE. Otherwise returns TRUE","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_safe_sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for potential sp version compatibility issues — bru_safe_sp","text":"","code":"if (FALSE) { # \\dontrun{ if (bru_safe_sp() &&   require(\"sp\")) {   # Run sp dependent calculations } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardise inla hyperparameter names — bru_standardise_names","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"inla hyperparameter output uses parameter names can include whitespace special characters. function replaces characters underscores.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(x)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"x character vector; names standardised","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"character vector standardised names","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_standardise_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardise inla hyperparameter names — bru_standardise_names","text":"","code":"bru_standardise_names(\"Precision for the Gaussian observations\") #>   Precision for the Gaussian observations  #> \"Precision_for_the_Gaussian_observations\""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise and annotate data — bru_summarise","title":"Summarise and annotate data — bru_summarise","text":"Summarise annotate data","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(   data,   probs = c(0.025, 0.5, 0.975),   x = NULL,   cbind.only = FALSE,   max_moment = 2 )"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise and annotate data — bru_summarise","text":"data list samples, either numeric data.frame probs numeric vector probabilities values [0, 1], passed stats::quantile x data.frame data columns added summary data frame cbind.TRUE, cbind samples return matrix column sample max_moment integer, least 2. Determines largest moment order information include output. max_moment > 2, includes \"skew\" (skewness, E[(x-m)^3/s^3]), max_moment > 3, includes \"ekurtosis\" (excess kurtosis, E[(x-m)^4/s^4] - 3). Default 2. Note Monte Carlo variability ekurtois estimate may large.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise and annotate data — bru_summarise","text":"data.frame Spatial[Points/Pixels]DataFrame summary statistics, \"mean\", \"sd\", paste0(\"q\", probs), \"mean.mc_std_err\", \"sd.mc_std_err\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise and annotate data — bru_summarise","text":"","code":"bru_summarise(matrix(rexp(10000), 10, 1000), max_moment = 4, probs = NULL) #>         mean        sd     skew ekurtosis sd.mc_std_err mean.mc_std_err #> 1  0.9995932 1.0149492 2.189996  7.361487    0.04910584      0.03520124 #> 2  0.9540890 0.9201174 1.585627  2.643641    0.03135712      0.03107987 #> 3  0.9980144 0.9979156 2.020478  6.243391    0.04530744      0.03442236 #> 4  1.0114649 0.9645428 1.703108  3.602452    0.03610424      0.03278495 #> 5  0.9753642 0.9624584 1.673127  3.036774    0.03415974      0.03259606 #> 6  1.0063036 1.0566728 2.312000  7.835825    0.05240348      0.03672921 #> 7  0.9588076 0.9443360 1.985021  5.565812    0.04107540      0.03246036 #> 8  1.0644205 1.0493831 1.865895  4.795969    0.04326072      0.03592046 #> 9  1.0545010 1.1236405 2.329021  8.144608    0.05659237      0.03911185 #> 10 1.0302886 0.9924727 1.619795  2.774872    0.03429734      0.03355390"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract timing information from fitted bru object — bru_timings","title":"Extract timing information from fitted bru object — bru_timings","text":"Extracts data.frame tibble information Time (CPU), System, Elapsed time step bru() run.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract timing information from fitted bru object — bru_timings","text":"","code":"bru_timings(object, ...)  # S3 method for class 'bru' bru_timings(object, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract timing information from fitted bru object — bru_timings","text":"object fitted bru object ... unused","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot inlabru iteration timings — bru_timings_plot","title":"Plot inlabru iteration timings — bru_timings_plot","text":"Draws time per iteration preprocessing (including linearisation), inla() calls, line search. Iteration 0 time used defining model structure.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot inlabru iteration timings — bru_timings_plot","text":"","code":"bru_timings_plot(x)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot inlabru iteration timings — bru_timings_plot","text":"x bru object, typically result bru() nonlinear predictor model","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot inlabru iteration timings — bru_timings_plot","text":"Requires \"ggplot2\" package installed.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_timings_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot inlabru iteration timings — bru_timings_plot","text":"","code":"if (FALSE) { # \\dontrun{ fit <- bru(...) bru_timings_plot(fit) } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":null,"dir":"Reference","previous_headings":"","what":"Transformation tools — bru_transformation","title":"Transformation tools — bru_transformation","text":"Tools transforming N(0,1) variables distributions predictor expressions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transformation tools — bru_transformation","text":"","code":"bru_forward_transformation(qfun, x, ..., tail.split. = 0)  bru_inverse_transformation(pfun, x, ..., tail.split. = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transformation tools — bru_transformation","text":"qfun quantile function object, qexp x Values transformed ... Distribution parameters passed qfun pfun functions tail.split. x-values larger tail.split., upper quantile calculations used internally, smaller values lower quantile calculations used. can avoid lack accuracy distribution tails. NULL, forward calculations split 0, inverse calculations use lower tails , potentially losing accuracy upper tails. pfun CDF function object, pexp","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transformation tools — bru_transformation","text":"bru_forward_transformation, numeric vector bru_inverse_transformation, numeric vector","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_transformation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transformation tools — bru_transformation","text":"","code":"u <- rnorm(5, 0, 1) y <- bru_forward_transformation(qexp, u, rate = 2) v <- bru_inverse_transformation(pexp, y, rate = 2) rbind(u, y, v) #>          [,1]        [,2]        [,3]      [,4]       [,5] #> u -1.65033134 -0.97938791 -1.10782537 0.6109105 -0.4277990 #> y  0.02535073  0.08938046  0.07191707 0.6535024  0.2035322 #> v -1.65033134 -0.97938791 -1.10782537 0.6109105 -0.4277990"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":null,"dir":"Reference","previous_headings":"","what":"List components used in a model — bru_used","title":"List components used in a model — bru_used","text":"Create extract information components used model, individual observation models. non-NULL labels argument supplied, also calls bru_used_update() bru_used objects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List components used in a model — bru_used","text":"","code":"bru_used(x = NULL, ...)  # Default S3 method bru_used(   x = NULL,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for class 'character' bru_used(   x,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for class 'expression' bru_used(   x,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for class 'formula' bru_used(   x,   ...,   effect = NULL,   effect_exclude = NULL,   latent = NULL,   labels = NULL )  # S3 method for class 'bru' bru_used(x, ..., join = TRUE)  # S3 method for class 'list' bru_used(x, ..., join = TRUE)  # S3 method for class 'bru_like' bru_used(x, ...)  # S3 method for class 'bru_used' bru_used(x, labels = NULL, ...)  # S3 method for class 'bru_used' format(x, ...)  # S3 method for class 'bru_used' summary(object, ...)  # S3 method for class 'bru_used' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List components used in a model — bru_used","text":"x object contains information used components ... Parameters passed methods effect character; components used effects. NULL, auto-detect components include include components. effect_exclude character; components specifically exclude effect evaluation. NULL, specifically exclude components. latent character; components used _latent _eval(). NULL, auto-detect components. labels character; component labels passed bru_used_update() join Whether join list output single object; Default may depend input object class","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List components used in a model — bru_used","text":"bru_used object (list elements effect latent), list objects (methods join = FALSE)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"List components used in a model — bru_used","text":"bru_used(default): Create bru_used object. bru_used(character): Create bru_used object character representation expression. bru_used(expression): Create bru_used object expression object. bru_used(formula): Create bru_used object formula (right-hand side used). bru_used(bru_used): Convenience method takes existing bru_used object calls bru_used_update() labels non-NULL.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"List components used in a model — bru_used","text":"format(bru_used): Text formatting method bru_used objects. summary(bru_used): Summary method bru_used objects. print(bru_used): Print method bru_used objects.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List components used in a model — bru_used","text":"","code":"(used <- bru_used(~.)) #> Used effects[], latent[] bru_used(used, labels = c(\"a\", \"c\")) #> Used effects[a, c], latent[] (used <- bru_used(~ a + b + c_latent + d_latent)) #> Used effects[a, b], latent[c, d] bru_used(used, labels = c(\"a\", \"c\")) #> Used effects[a], latent[c] (used <- bru_used(expression(a + b + c_latent + d_latent))) #> Used effects[a, b], latent[c, d] bru_used(used, labels = c(\"a\", \"c\")) #> Used effects[a], latent[c]"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update used_component information objects — bru_used_update","title":"Update used_component information objects — bru_used_update","text":"Merge available component labels information used components information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update used_component information objects — bru_used_update","text":"","code":"bru_used_update(x, labels, ...)  # S3 method for class 'bru_like_list' bru_used_update(x, labels, ...)  # S3 method for class 'bru_like' bru_used_update(x, labels, ...)  # S3 method for class 'bru_used' bru_used_update(x, labels, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update used_component information objects — bru_used_update","text":"x Object updated labels character vector component labels ... Unused","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update used_component information objects — bru_used_update","text":"updated version x","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract basic variable names from expression — bru_used_vars","title":"Extract basic variable names from expression — bru_used_vars","text":"Extracts variable names R expression pre- post-processing around .vars(). First replaces $ [[ indexing, internal column/variable names ignored, calls .vars().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract basic variable names from expression — bru_used_vars","text":"","code":"bru_used_vars(x, functions = FALSE)  # S3 method for class 'character' bru_used_vars(x, functions = FALSE)  # S3 method for class 'expression' bru_used_vars(x, functions = FALSE)  # S3 method for class 'formula' bru_used_vars(x, functions = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract basic variable names from expression — bru_used_vars","text":"x formula, expression, character functions logical; TRUE, include function names","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract basic variable names from expression — bru_used_vars","text":"successful, character vector, otherwise NULL","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Extract basic variable names from expression — bru_used_vars","text":"bru_used_vars(formula): right-hand side used.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/bru_used_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract basic variable names from expression — bru_used_vars","text":"","code":"bru_used_vars(~.) #> NULL bru_used_vars(~ a + b + c_latent + d_eval()) #> [1] \"a\"        \"b\"        \"c_latent\" bru_used_vars(expression(a + b + c_latent + d_eval())) #> [1] \"a\"        \"b\"        \"c_latent\"  bru_used_vars(~., functions = TRUE) #> NULL bru_used_vars(~ a + b + c_latent + d_eval(), functions = TRUE) #> [1] \"+\"        \"a\"        \"b\"        \"c_latent\" \"d_eval\"   bru_used_vars(expression(a + b + c_latent + d_eval()), functions = TRUE) #> [1] \"expression\" \"+\"          \"a\"          \"b\"          \"c_latent\"   #> [6] \"d_eval\"      bru_used_vars(a ~ b) #> [1] \"b\" bru_used_vars(expression(a ~ b)) #> [1] \"a\" \"b\""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert components to R code — code.components","title":"Convert components to R code — code.components","text":"Convert components R code","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert components to R code — code.components","text":"","code":"code.components(components, add = \"\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert components to R code — code.components","text":"components formula describing latent model components.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/code.components.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert components to R code — code.components","text":"Fabian E. Bachl bachlfab@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct component linearisations — comp_lin_eval","title":"Construct component linearisations — comp_lin_eval","text":"Constructs linearisation mapper component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct component linearisations — comp_lin_eval","text":"","code":"comp_lin_eval(...)  # S3 method for class 'component' comp_lin_eval(component, input = NULL, state = NULL, ...)  # S3 method for class 'component_list' comp_lin_eval(components, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct component linearisations — comp_lin_eval","text":"... Optional parameters passed ibm_eval `ibm_jacobian. component component. input Component inputs, input_eval() state linearisation evaluation state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct component linearisations — comp_lin_eval","text":"bru_mapper_taylor comp_simple_list object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/comp_lin_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Construct component linearisations — comp_lin_eval","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent model component construction — component","title":"Latent model component construction — component","text":"Similar glm(), gam() inla(), bru() models can constructed via formula-like syntax, latent effect specified. However, addition parts syntax compatible INLA::inla, bru components offer additional functionality facilitates modelling, predictor expression can specified separately, allowing complex non-linear predictors defined. formula syntax just way allow model components defined single line code, definitions can optionally split separate component definitions. See Details information. component methods rely component.character() method, defines model component given label/name. user usually need call methods directly, can instead supply formula expression can interpreted component_list.formula() method, called inside bru().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent model component construction — component","text":"","code":"component(...)  # S3 method for class 'character' component(   object,   main = NULL,   weights = NULL,   ...,   model = NULL,   mapper = NULL,   main_layer = NULL,   main_selector = NULL,   n = NULL,   values = NULL,   season.length = NULL,   copy = NULL,   weights_layer = NULL,   weights_selector = NULL,   group = 1L,   group_mapper = NULL,   group_layer = NULL,   group_selector = NULL,   ngroup = NULL,   control.group = NULL,   replicate = 1L,   replicate_mapper = NULL,   replicate_layer = NULL,   replicate_selector = NULL,   nrep = NULL,   marginal = NULL,   A.msk = deprecated(),   .envir = parent.frame(),   envir_extra = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent model component construction — component","text":"... Parameters passed methods object character label component main main takes R expression evaluates latent variables evaluated (coordinates, indices, continuous scalar (rw2 etc)). Arguments starting weights, group, replicate behave similarly main, corresponding features INLA::f(). weights, weights_layer, weights_selector Optional specification effect scaling weights. syntax main. model Either one \"const\" (\"offset\"), \"factor_full\", \"factor_contrast\", \"linear\", \"fixed\", model name object accepted INLA's f function. set NULL, \"linear\" used vector inputs, \"fixed\" matrix input (converted internally iid model fixed precision) mapper Information mapping values evaluated main, latent variables. Auto-detects spde model objects model extracts mesh object use mapper, auto-generates mappers indexed models. (Default: NULL, auto-determination) main_layer, main_selector _layer input evaluate numeric index character name vector layer/variable extract covariate data object given main. (Default: NULL _selector given. Otherwise effect component name, exists covariate object, otherwise first column covariate data frame) _selector value character name variable whose contents determines layer extract covariate data point. (Default: NULL) n number latent variables model. auto-detected models (Default: NULL, auto-detection). error given figure . values Specifies covariate/index values INLA build latent model. Normally generated internally based mapping details. (Default: NULL, auto-determination) season.length Passed INLA::f() model \"seasonal\" (TODO: check parameter still fully handled) copy character; label component component copy . fixed = FALSE, scaling constant estimated, via hyperparameter. fixed = TRUE, component scaling fixed, default 1; fixed scaling, efficient express scaling predictor expression instead making copy component. group, group_mapper, group_layer, group_selector, ngroup Optional specification kronecker/group model indexing. control.group list kronecker/group model parameters, currently passed directly INLA::f replicate, replicate_mapper, replicate_layer, replicate_selector, nrep Optional specification indices independent replication model. syntax main marginal May specify bru_mapper_marginal() mapper, applied scaling weights. .msk effect. .envir Evaluation environment envir_extra TODO: check/fix parameter.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent model component construction — component","text":"shorthand, bru() understand basic additive formulae describing fixed effect models. instance, components specification y ~ x define linear combination effect named x intercept response y respect likelihood family stated calling bru(). Mathematically, linear predictor \\(\\eta\\) written $$\\eta = \\beta * x + c,$$ : \\(c\\) intercept \\(x\\) covariate \\(\\beta\\) latent variable associated \\(x\\) \\(\\psi = \\beta * x\\) called effect \\(x\\) problem arises using kind R formula clearly reflect mathematical formula. instance, providing formula inla, resulting object refer random effect \\(\\psi = \\beta * x \\) x. Hence, clear x refers covariate effect covariate. component.character method inlabru's equivalent INLA's f function adds functionality unique inlabru. Deprecated parameters: map: Use main instead. mesh: Use mapper instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"naming-random-effects","dir":"Reference","previous_headings":"","what":"Naming random effects","title":"Latent model component construction — component","text":"INLA, f() notation used define complex models, simple linear effect model can also expressed formula = y ~ f(x, model = \"linear\"), f() inla specific function set random effects kinds. underlying predictor \\(\\eta = \\beta * x + c\\) result fitting model state x random effect's name. bru allows rewriting formula order explicitly state name random effect name associated covariate. achieved replacing f arbitrary name wish assign effect, e.g. components = y ~ psi(x, model = \"linear\"). able discriminate \\(x\\) \\(\\psi\\) relevant two functionalities bru offers. formula parameters bru() prediction method predict.bru interpreted mathematical sense. instance, predict may used analyze analytical combination covariate \\(x\\) intercept using predict(fit, data.frame(x=2)), ~ exp(psi + Intercept). corresponds mathematical expression e β + c. hand, predict may used look transformation latent variable \\(\\beta_\\psi\\) predict(fit, NULL, ~ exp(psi_latent)). corresponds mathematical expression e β.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Latent model component construction — component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren Finn.Lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent model component construction — component","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  cmp <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(cmp) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L, NULL #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) #> Label:\tIntercept #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = 1, group = 1L, replicate = 1L, NULL #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(Intercept, model = BRU_Intercept_main_model) # Equivalent shortcuts: cmp <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) cmp <- component_list(~ myLinearEffectOfX(x)) # Individual component cmp <- component(\"myLinearEffectOfX\", main = x, model = \"linear\") summary(cmp) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L, NULL #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) # \\donttest{ if (bru_safe_inla()) {   # As an example, let us create a linear component. Here, the component is   # called \"myEffectOfX\" while the covariate the component acts on is called \"x\":    cmp <- component(\"myEffectOfX\", main = x, model = \"linear\")   summary(cmp)    # A more complicated component:   cmp <- component(\"myEffectOfX\",     main = x,     model = INLA::inla.spde2.matern(fm_mesh_1d(1:10))   )    # Compound fixed effect component, where x and z are in the input data.   # The formula will be passed on to MatrixModels::model.Matrix:   cmp <- component(\"eff\", ~ -1 + x:z, model = \"fixed\")   summary(cmp) } #> Label:\teff #>   Type:\tmain = fixed, group = exchangeable, replicate = iid #>   Input:\tmain = ~-1 + x:z, group = 1L, replicate = 1L, NULL #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(eff, model = BRU_eff_main_model, hyper = #>       BRU_eff_main_fixed_hyper) # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component values in predictor expressions — component_eval","title":"Evaluate component values in predictor expressions — component_eval","text":"predictor expressions, name_eval(...) can used evaluate effect component called \"name\".","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"component_eval(   main,   group = NULL,   replicate = NULL,   weights = NULL,   .state = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component values in predictor expressions — component_eval","text":"main, group, replicate, weights Specification evaluate component. four inputs passed joint bru_mapper component,   .state internal component state. Normally supplied automatically internal methods evaluating inlabru predictor expressions.","code":"list(mapper = list(        main = main,        group = group,        replicate = replicate),      scale = weights)"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component values in predictor expressions — component_eval","text":"vector values component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate component values in predictor expressions — component_eval","text":"","code":"if (FALSE) { # \\dontrun{ if (bru_safe_inla()) {   mesh <- fmesher::fm_mesh_2d_inla(     cbind(0, 0),     offset = 2, max.edge = 0.25   )   spde <- INLA::inla.spde2.pcmatern(mesh,     prior.range = c(0.1, 0.01),     prior.sigma = c(2, 0.01)   )   data <- sp::SpatialPointsDataFrame(     matrix(runif(10), 5, 2),     data = data.frame(z = rnorm(5))   )   fit <- bru(z ~ -1 + field(coordinates, model = spde),     family = \"gaussian\", data = data   )   pred <- predict(     fit,     data = data.frame(x = 0.5, y = 0.5),     formula = ~ field_eval(cbind(x, y))   ) } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for inlabru component lists — component_list","title":"Methods for inlabru component lists — component_list","text":"Constructor methods inlabru component lists. Syntax details given component().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for inlabru component lists — component_list","text":"","code":"component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for class 'formula' component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for class 'list' component_list(object, lhoods = NULL, .envir = parent.frame(), ...)  # S3 method for class 'component_list' c(...)  # S3 method for class 'component' c(...)  # S3 method for class 'component_list' x[i]"},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for inlabru component lists — component_list","text":"object object operate lhoods bru_like_list object .envir evaluation environment non-formula input ... Parameters passed methods. Also see Details. x component_list object extract sub-list indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for inlabru component lists — component_list","text":"component_list.formula: Convert component formula component_list object component_list.list: Combine list components /component formulas component_list object c.component_list: ... arguments component_list objects. environment first argument applied resulting component_list. c.component: ... arguments component objects. environment first argument applied resulting “component_list`.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Methods for inlabru component lists — component_list","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/component_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for inlabru component lists — component_list","text":"","code":"# As an example, let us create a linear component. Here, the component is # called \"myLinearEffectOfX\" while the covariate the component acts on is # called \"x\". Note that a list of components is returned because the # formula may define multiple components  eff <- component_list(~ myLinearEffectOfX(main = x, model = \"linear\")) summary(eff[[1]]) #> Label:\tmyLinearEffectOfX #>   Type:\tmain = linear, group = exchangeable, replicate = iid #>   Input:\tmain = x, group = 1L, replicate = 1L, NULL #>   Map: Not yet initialised #>   INLA formula:\t #>     ~ . + f(myLinearEffectOfX, model = #>       BRU_myLinearEffectOfX_main_model) # Equivalent shortcuts: eff <- component_list(~ myLinearEffectOfX(x, model = \"linear\")) eff <- component_list(~ myLinearEffectOfX(x)) # Individual component eff <- component(\"myLinearEffectOfX\", main = x, model = \"linear\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise DIC and WAIC from lgcp objects. — deltaIC","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"Calculates DIC /WAIC differences produces ordered summary.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"deltaIC(..., criterion = \"DIC\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"... Comma-separated objects inheriting class inla obtained run INLA::inla(), bru() lgcp() criterion character vector. includes 'DIC', computes DIC differences; contains 'WAIC', computes WAIC differences. Default: 'DIC'","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"data frame row containing Model name, DIC Delta.DIC, /WAIC Delta.WAIC.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/deltaIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise DIC and WAIC from lgcp objects. — deltaIC","text":"","code":"# \\donttest{ if (bru_safe_inla()) {   # Generate some data   input.df <- data.frame(idx = 1:10, x = cos(1:10))   input.df <- within(     input.df,     y <- rpois(10, 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))   )    # Fit two models   fit1 <- bru(     y ~ x,     family = \"poisson\",     data = input.df,     options = list(control.compute = list(dic = TRUE))   )   fit2 <- bru(     y ~ x + rand(idx, model = \"iid\"),     family = \"poisson\",     data = input.df,     options = list(control.compute = list(dic = TRUE))   )    # Compare DIC    deltaIC(fit1, fit2) } #>   Model      DIC   Delta.DIC #> 1  fit1 40.99953 0.000000000 #> 2  fit2 41.00202 0.002494697 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance and correlations measures for prediction components — devel.cvmeasure","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Calculates local integrated variance correlation measures introduced Yuan et al. (2017).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"devel.cvmeasure(joint, prediction1, prediction2, samplers = NULL, mesh = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"joint joint prediction two latent model components. prediction1 prediction first component. prediction2 prediction second component. samplers SpatialPolygon object describing area compute cumulative variance measure. mesh inla.mesh prediction performed (required cumulative Vmeasure).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Variance correlations measures.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"Y. Yuan, F. E. Bachl, F. Lindgren, D. L. Brochers, J. B. Illian, S. T. Buckland, H. Rue, T. Gerrodette. 2017. Point process models spatio-temporal distance sampling data large-scale survey blue whales. https://arxiv.org/abs/1604.06013","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/devel.cvmeasure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance and correlations measures for prediction components — devel.cvmeasure","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(ggplot2, quietly = TRUE) &&     bru_safe_sp() &&     require(\"sp\")) {    # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use RColorBrewer    library(RColorBrewer)    # Fit a model with two components:   # 1) A spatial smooth SPDE   # 2) A spatial covariate effect (vegetation)    pcmatern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    cmp <- coordinates ~ vegetation(gorillas$gcov$vegetation, model = \"factor_contrast\") +     spde(coordinates, model = pcmatern) -     Intercept(1)    fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict SPDE and vegetation at the mesh vertex locations    vrt <- fm_vertices(gorillas$mesh, format = \"sp\")   pred <- predict(     fit,     vrt,     ~ list(       joint = spde + vegetation,       field = spde,       veg = vegetation     )   )    # Plot component mean    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$mean) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Plot component variance    multiplot(ggplot() +     gg(gorillas$mesh, color = pred$joint$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$field$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   ggplot() +     gg(gorillas$mesh, color = pred$veg$var) +     coord_equal() +     theme(legend.position = \"bottom\"),   cols = 3   )    # Calculate variance and correlation measure    vm <- devel.cvmeasure(pred$joint, pred$field, pred$veg)   lprange <- range(vm$var.joint, vm$var1, vm$var2)    # Variance contribution of the components    csc <- scale_fill_gradientn(colours = brewer.pal(9, \"YlOrRd\"), limits = lprange)   boundary <- gorillas$boundary    plot.1 <- ggplot() +     gg(gorillas$mesh, color = vm$var.joint, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"joint\") +     theme(legend.position = \"bottom\")   plot.2 <- ggplot() +     gg(gorillas$mesh, color = vm$var1, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"SPDE\") +     theme(legend.position = \"bottom\")   plot.3 <- ggplot() +     gg(gorillas$mesh, color = vm$var2, mask = boundary) +     csc +     coord_equal() +     ggtitle(\"vegetation\") +     theme(legend.position = \"bottom\")    multiplot(plot.1, plot.2, plot.3, cols = 3)    # Covariance of SPDE field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cov)    # Correlation between field and vegetation    ggplot() +     gg(gorillas$mesh, color = vm$cor)    # Variance and correlation integrated over space    vm.int <- devel.cvmeasure(pred$joint, pred$field, pred$veg,     samplers = fm_int(gorillas$mesh, gorillas$boundary),     mesh = gorillas$mesh   )   vm.int }    #>   var.joint      var1      var2        cor #> 1 0.5378219 0.7231497 0.2444615 -0.5111005 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate expressions in the data context — eval_in_data_context","title":"Evaluate expressions in the data context — eval_in_data_context","text":"Evaluate expressions data context","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate expressions in the data context — eval_in_data_context","text":"","code":"eval_in_data_context(   input,   data = NULL,   response_data = NULL,   default = NULL,   .envir = parent.frame() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate expressions in the data context — eval_in_data_context","text":"input expression evaluated data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. response_data Likelihood-specific data models need different size/format inputs response variables, data.frame SpatialPoints[DataFrame] object. default Value used expression evaluated NULL. Default NULL .envir evaluation environment","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_in_data_context.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate expressions in the data context — eval_in_data_context","text":"result expression evaluation","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate spatial covariates — eval_spatial","title":"Evaluate spatial covariates — eval_spatial","text":"Evaluate spatial covariates","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate spatial covariates — eval_spatial","text":"","code":"eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'SpatialPolygonsDataFrame' eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'SpatialPixelsDataFrame' eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'SpatialGridDataFrame' eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'sf' eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'SpatRaster' eval_spatial(data, where, layer = NULL, selector = NULL)  # S3 method for class 'stars' eval_spatial(data, where, layer = NULL, selector = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate spatial covariates — eval_spatial","text":"data Spatial data evaluate data layer data layer extract (integer character). May vector, specifying separate layer item. selector name variable specifying layer information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/eval_spatial.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Evaluate spatial covariates — eval_spatial","text":"eval_spatial(SpatialPolygonsDataFrame): Compatibility wrapper eval_spatial.sf eval_spatial(sf): Supports point--polygon information lookup. combinations untested.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all component linearisations — evaluate_comp_lin","title":"Compute all component linearisations — evaluate_comp_lin","text":"Computes individual bru_mapper_taylor objects included components model likelihood","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all component linearisations — evaluate_comp_lin","text":"","code":"evaluate_comp_lin(model, input, state, inla_f = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all component linearisations — evaluate_comp_lin","text":"model bru_model object input list named lists component inputs state named list component states inla_f Controls input data interpretations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_lin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all component linearisations — evaluate_comp_lin","text":"list (class 'comp_simple') named lists (class 'comp_simple_list') bru_mapper_taylor objects, one included component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute simplified component mappings — evaluate_comp_simple","title":"Compute simplified component mappings — evaluate_comp_simple","text":"Computes individual bru_mapper_taylor objects included linear components model likelihood, keeps non-linear mappers intact.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute simplified component mappings — evaluate_comp_simple","text":"","code":"evaluate_comp_simple(...)  # S3 method for class 'component_list' evaluate_comp_simple(components, input, inla_f = FALSE, ...)  # S3 method for class 'bru_model' evaluate_comp_simple(model, input, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute simplified component mappings — evaluate_comp_simple","text":"input list named lists component inputs inla_f Controls input data interpretations model bru_model object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute simplified component mappings — evaluate_comp_simple","text":"list (class 'comp_simple_list_list') named lists (class 'comp_simple_list') bru_mapper objects, one included component","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"Subsetting comp_simple_list objects, retaining class","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"","code":"# S3 method for class 'comp_simple_list' x[i]"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_comp_simple_list_subsetting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subsetting of comp_simple_list objects, retaining class — [.comp_simple_list","text":"x comp_simple_list object extract element(s) indices specifying elements extract","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a component effect — evaluate_effect_single_state","title":"Evaluate a component effect — evaluate_effect_single_state","text":"Calculate latent component effects given data state component's internal random variables.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a component effect — evaluate_effect_single_state","text":"","code":"evaluate_effect_single_state(...)  evaluate_effect_multi_state(...)  # S3 method for class 'bru_mapper' evaluate_effect_single_state(component, input, state, ..., label = NULL)  # S3 method for class 'comp_simple_list' evaluate_effect_single_state(components, input, state, ...)  # S3 method for class 'comp_simple_list' evaluate_effect_multi_state(components, input, state, ...)  # S3 method for class 'component_list' evaluate_effect_single_state(components, input, state, ...)  # S3 method for class 'component_list' evaluate_effect_multi_state(components, input, state, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a component effect — evaluate_effect_single_state","text":"... Optional additional parameters, e.g. inla_f. Normally unused. component bru_mapper, bru_component, comp_simple, comp_simple_list. input Pre-evaluated component input state Specification one (evaluate_effect_single_state) several (evaluate_effect_multi_State) latent variable states: evaluate_effect_single_state.bru_mapper: vector latent component state. evaluate_effect_single_state.*_list: list named state vectors. evaluate_effect_multi_state.*_list: list lists named state vectors. label Option label used warning messages, specifying affected component.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a component effect — evaluate_effect_single_state","text":"evaluate_effect_single_state.component_list: list evaluated component effect values evaluate_effect_multi.comp_simple_list: list lists evaluated component effects, one list state","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_effect.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate a component effect — evaluate_effect_single_state","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all index values — evaluate_index","title":"Compute all index values — evaluate_index","text":"Computes index values matrices included components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all index values — evaluate_index","text":"","code":"evaluate_index(model, lhoods)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all index values — evaluate_index","text":"model bru_model object lhoods bru_like_list object. Deprecated ignored","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute all index values — evaluate_index","text":"named list idx_full idx_inla, named list indices, inla_subset, inla_subset, named list logical subset specifications extracting INLA::f() compatible index subsets.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute all component inputs — evaluate_inputs","title":"Compute all component inputs — evaluate_inputs","text":"Computes component inputs included components model likelihood","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute all component inputs — evaluate_inputs","text":"","code":"evaluate_inputs(model, lhoods, inla_f)"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute all component inputs — evaluate_inputs","text":"model bru_model object lhoods bru_like_list object inla_f logical","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"Evaluate sample posterior result given model locations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"","code":"evaluate_model(   model,   state,   data = NULL,   input = NULL,   comp_simple = NULL,   predictor = NULL,   format = NULL,   used = NULL,   ... )  evaluate_state(   model,   result,   property = \"mode\",   n = 1,   seed = 0L,   num.threads = NULL,   internal_hyperpar = FALSE,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"model bru model state list state lists, generated evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate predictor. input Precomputed inputs list components comp_simple Precomputed comp_simple_list components predictor formula expression evaluated given posterior sample thereof. default (NULL) returns data.frame containing sampled effects. case formula right hand side used evaluation. format character; determines storage format predictor output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list element contains evaluated predictor expression state. used bru_used() object, NULL (default) ... Additional arguments passed inla.posterior.sample result bru object bru() lgcp() property Property model components obtain value . Default: \"mode\". options \"mean\", \"0.025quant\", \"0.975quant\", \"sd\" \"sample\". case \"sample\" obtain samples posterior (see n parameter). result NULL, -zero vectors returned component. n Number samples draw. seed seed != 0L, random seed num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" internal_hyperpar logical; TRUE, return hyperparameter properties internal scale. Currently ignored property=\"sample\". Default FALSE.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate or sample from a posterior result given a model and locations — evaluate_model","text":"evaluate_model wrapper evaluate model state, -matrices, effects, predictor, one call. evaluate_state evaluates model state properties samples","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate component effects or expressions — evaluate_predictor","title":"Evaluate component effects or expressions — evaluate_predictor","text":"Evaluate component effects expressions, based bru model one several states latent variables hyperparameters.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate component effects or expressions — evaluate_predictor","text":"","code":"evaluate_predictor(   model,   state,   data,   effects,   predictor,   used = NULL,   format = \"auto\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate component effects or expressions — evaluate_predictor","text":"state list element list named latent state information, produced evaluate_state() data list, data.frame, Spatial*DataFrame, coordinates covariates needed evaluate model. effects list element list named evaluated effects, computed evaluate_effect_multi_state.component_list() predictor Either formula expression used bru_used() object, NULL (default) format character; determines storage format output. Available options: \"auto\" first evaluated result vector single-column matrix, \"matrix\" format used, otherwise \"list\". \"matrix\" matrix column contains evaluated predictor expression state. \"list\" list column contains evaluated predictor expression state. Default: \"auto\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate component effects or expressions — evaluate_predictor","text":"list matrix returned, specified format","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/evaluate_predictor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate component effects or expressions — evaluate_predictor","text":"component, e.g. \"name\", state values available name_latent, arbitrary evaluation can done name_eval(...), see component_eval().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand labels — expand_labels","title":"Expand labels — expand_labels","text":"Expand labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand labels — expand_labels","text":"","code":"expand_labels(labels, expand, suffix)"},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand labels — expand_labels","text":"labels character vector; original labels expand character vector; subset labels expand suffix character; suffix add labels selected expand","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/expand_labels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand labels — expand_labels","text":"vector labels suffix appended selected labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a summary property from all results of an inla result — extract_property","title":"Extract a summary property from all results of an inla result — extract_property","text":"Extract summary property results inla result","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a summary property from all results of an inla result — extract_property","text":"","code":"extract_property(result, property, internal_hyperpar = FALSE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a summary property from all results of an inla result — extract_property","text":"result inla result object property character; \"mean\", \"sd\", \"mode\", column identifier inla result $summary.fixed, $summary.random$label, $summary.hyperpar, \"joint_mode\". \"joint_mode\", joint latent mode extracted, joint hyperparameter mode, internal scale. \"predictor_sd\" posterior standard deviations linear predictor returned. internal_hyperpar logical; TRUE, use internal scale hyperparamter properties. Default FALSE, except property \"joint_mode\" forces internal_hyperpar=TRUE.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/extract_property.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a summary property from all results of an inla result — extract_property","text":"named list estimated fixed effect coefficient, random effect vector, hyperparameter. hyperparameter names standardised bru_standardise_names()","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate samples from fitted bru models — generate","title":"Generate samples from fitted bru models — generate","text":"Generic function sampling fitted models. function invokes particular methods depend class first argument. Takes fitted bru object produced function bru() produces samples given new set values model covariates original values used model fit. samples can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate samples from fitted bru models — generate","text":"","code":"generate(object, ...)  # S3 method for class 'bru' generate(   object,   newdata = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   num.threads = NULL,   include = NULL,   exclude = NULL,   used = NULL,   ...,   data = deprecated() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate samples from fitted bru models — generate","text":"object bru object obtained calling bru(). ... additional, unused arguments. newdata data.frame SpatialPointsDataFrame covariates needed sampling. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default, 100, rather low provides quick approximate result. seed Random number generator seed passed INLA::inla.posterior.sample num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) newdata provided, otherwise character(0). exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) used Either NULL bru_used() object, overriding include exclude. data Deprecated. Use newdata instead. sampling.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate samples from fitted bru models — generate","text":"form value returned generate() depends data class prediction formula. Normally, data.frame returned, list data.frames (prediction formula generates list) List generated samples","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate samples from fitted bru models — generate","text":"addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/generate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate samples from fitted bru models — generate","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(\"sn\", quietly = TRUE)) {    # Generate data for a simple linear model    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit the model    fit <- bru(y ~ xeff(main = x, model = \"linear\"),     family = \"gaussian\", data = input.df   )   summary(fit)    # Generate samples for some predefined x    df <- data.frame(x = seq(-4, 4, by = 0.1))   smp <- generate(fit, df, ~ xeff + Intercept, n.samples = 10)    # Plot the resulting realizations    plot(df$x, smp[, 1], type = \"l\")   for (k in 2:ncol(smp)) points(df$x, smp[, k], type = \"l\")    # We can also draw samples form the joint posterior    df <- data.frame(x = 1)   smp <- generate(fit, df, ~ data.frame(xeff, Intercept), n.samples = 10)   smp[[1]]    # ... and plot them   if (require(ggplot2, quietly = TRUE)) {     plot(do.call(rbind, smp))   } } #>  #> Attaching package: ‘sn’ #> The following object is masked from ‘package:stats’: #>  #>     sd   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for RasterLayer objects — gg.RasterLayer","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function takes RasterLayer object, converts SpatialPixelsDataFrame uses geom_tile plot data.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"# S3 method for class 'RasterLayer' gg(   data,   mapping = ggplot2::aes(x = .data[[\"x\"]], y = .data[[\"y\"]], fill = .data[[\"layer\"]]),   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"data RasterLayer object. mapping aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"object returned geom_tile","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"function requires raster ggplot2 packages.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.RasterLayer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for RasterLayer objects — gg.RasterLayer","text":"","code":"if (FALSE) { # \\dontrun{ # Some features require the raster and spatstat.data packages. if (require(\"spatstat.data\", quietly = TRUE) &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   # Load Gorilla data   data(\"gorillas\", package = \"spatstat.data\")    # Convert elevation covariate to RasterLayer    elev <- as(gorillas.extra$elevation, \"RasterLayer\")    # Plot the elevation    ggplot() +     gg(elev) } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom wrapper for SpatRaster objects — gg.SpatRaster","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"Convenience wrapper function tidyterra::geom_spatraster(). Requires ggplot2 tidyterra packages.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"","code":"# S3 method for class 'SpatRaster' gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"data SpatRaster object. ... Arguments passed geom_spatraster.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatRaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom wrapper for SpatRaster objects — gg.SpatRaster","text":"output `geom_spatraster.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"Coerces input SpatialGridDataFrame SpatialPixelsDataFrame calls gg.SpatialPixelsDataFrame() plot . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# S3 method for class 'SpatialGridDataFrame' gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"data SpatialGridDataFrame object. ... Arguments passed gg.SpatialPixelsDataFrame().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"geom_tile value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialGridDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialGridDataFrame objects — gg.SpatialGridDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       bru_safe_sp() &&       require(\"sp\")) {     # Load Gorilla data      gorillas <- inlabru::gorillas      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialLines objects — gg.SpatialLines","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"Extracts start end points lines calls geom_segment plot lines . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# S3 method for class 'SpatialLines' gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"data SpatialLines SpatialLinesDataFrame object. mapping Aesthetic mappings created ggplot2::aes ggplot2::aes_ used update default mapping. default mapping ggplot2::aes(x = .data[[sp::coordnames(data)[1]]], y = .data[[sp::coordnames(data)[2]]], xend = .data[[paste0(\"end.\", sp::coordnames(data)[1])]], yend = .data[[paste0(\"end.\", sp::coordnames(data)[2])]]). crs CRS object defining coordinate system project data plotting. ... Arguments passed ggplot2::geom_segment.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"`geom_segment“ return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialLines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialLines objects — gg.SpatialLines","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       bru_safe_sp() &&       require(\"sp\")) {     # Load Gorilla data      gorillas <- inlabru::gorillas      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixels objects — gg.SpatialPixels","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"Uses geom_point plot pixel centers. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"# S3 method for class 'SpatialPixels' gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"data sp::SpatialPixels object. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"geom_tile return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixels objects — gg.SpatialPixels","text":"","code":"if (require(\"ggplot2\", quietly = TRUE) &&   bru_safe_sp()) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Turn elevation covariate into SpatialPixels   pxl <- sp::SpatialPixels(sp::SpatialPoints(gorillas$gcov$elevation))    # Plot the pixel centers   ggplot() +     gg(pxl, size = 0.1) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"Coerces input SpatialPixelsDataFrame data.frame uses geom_tile plot . Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# S3 method for class 'SpatialPixelsDataFrame' gg(data, mapping = NULL, crs = NULL, mask = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"data SpatialPixelsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[sp::coordnames(data)[1]]], y = .data[[sp::coordnames(data)[2]]], fill = .data[[names(data)[[1]]]]). crs sp::CRS object defining coordinate system project data plotting. mask sp::SpatialPolygons object defining region plotted. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"geom_tile return value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPixelsDataFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPixelsDataFrame objects — gg.SpatialPixelsDataFrame","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       bru_safe_sp() &&       require(\"sp\")) {     # Load Gorilla data      gorillas <- inlabru::gorillas      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPoints objects — gg.SpatialPoints","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"function coerces SpatialPoints data.frame uses geom_point plot points. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# S3 method for class 'SpatialPoints' gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"data SpatialPoints object. mapping Aesthetic mappings created aes used update default mapping. default mapping ggplot2::aes(x = .data[[sp::coordnames(data)[1]]], y = .data[[sp::coordnames(data)[2]]]). crs sp::CRS object defining coordinate system project data plotting. ... Arguments passed geom_point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"geom_point return value","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPoints objects — gg.SpatialPoints","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       bru_safe_sp() &&       require(\"sp\")) {     # Load Gorilla data      gorillas <- inlabru::gorillas      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for SpatialPolygons objects — gg.SpatialPolygons","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"Uses ggplot2::fortify() function turn SpatialPolygons objects data.frame. calls geom_polygon plot polygons. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# S3 method for class 'SpatialPolygons' gg(data, mapping = NULL, crs = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"data SpatialPolygons SpatialPolygonsDataFrame object. mapping Aesthetic mappings created aes used update default mapping. crs CRS object defining coordinate system project data plotting. ... Arguments passed geom_sf. Unless specified user, argument alpha = 0.2 (alpha level polygon filling) added.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"geom_sf object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"version 2.10.0, ggpolypath package used ensure proper plotting, since ggplot2::geom_polygon function always handle geometries holes properly. 2.10.0, object converted sf format passed gg.sf() instead, ggplot2 version 3.4.4 deprecated intenrally used ggplot2::fortify() method SpatialPolygons/DataFrame objects.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.SpatialPolygons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for SpatialPolygons objects — gg.SpatialPolygons","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE) &&       bru_safe_sp() &&       require(\"sp\")) {     # Load Gorilla data      gorillas <- inlabru::gorillas      # Plot Gorilla elevation covariate provided as SpatialPixelsDataFrame.     # The same syntax applies to SpatialGridDataFrame objects.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly) + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers) + # ship transects as SpatialLines       gg(mexdolphin$points) # dolphin sightings as SpatialPoints      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\") + # survey boundary as SpatialPolygon       gg(mexdolphin$samplers, color = \"red\") + # ship transects as SpatialLines       gg(mexdolphin$points, color = \"blue\") # dolphin sightings as SpatialPoints       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.bru_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for predictions — gg.bru_prediction","title":"Geom for predictions — gg.bru_prediction","text":"geom serves visualize prediction objects usually results call predict.bru(). Predictions objects provide summary statistics (mean, median, sd, ...) one random variables. single variables (requested setting bar = TRUE), boxplot-style geom constructed show statistics. multivariate predictions mean variable (y-axis) plotted row number variable prediction data frame (x-axis) using geom_line. addition, geom_ribbon used show confidence interval. Note: gg.bru_prediction also understands format INLA-style posterior summaries, e.g. fit$summary.fixed inla object fit Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.bru_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for predictions — gg.bru_prediction","text":"","code":"# S3 method for class 'bru_prediction' gg(data, mapping = NULL, ribbon = TRUE, alpha = NULL, bar = FALSE, ...)  # S3 method for class 'prediction' gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.bru_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for predictions — gg.bru_prediction","text":"data prediction object, usually result predict.bru() call. mapping set aesthetic mappings created aes. passed geom_line. ribbon TRUE, plot ribbon around line based smallest largest quantiles present data, found matching names starting q followed numerical value.  inla()-style numeric+\"quant\" names converted inlabru style matching. alpha ribbons numeric alpha (transparency) level [0,1]. bar TRUE plot boxplot-style summary variable. ... Arguments passed geom_line.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.bru_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for predictions — gg.bru_prediction","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.bru_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for predictions — gg.bru_prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for data.frame — gg.data.frame","title":"Geom for data.frame — gg.data.frame","text":"geom constructor simply call gg.bru_prediction() data provided.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for data.frame — gg.data.frame","text":"","code":"# S3 method for class 'data.frame' gg(...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for data.frame — gg.data.frame","text":"... Arguments passed gg.bru_prediction().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for data.frame — gg.data.frame","text":"Concatenation geom_line value optionally geom_ribbon value.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for data.frame — gg.data.frame","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.data.frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for data.frame — gg.data.frame","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"function generates geom_point object showing knots (vertices) 1D mesh. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"","code":"# S3 method for class 'fm_mesh_1d' gg(   data,   mapping = ggplot2::aes(.data[[\"x\"]], .data[[\"y\"]]),   y = 0,   shape = 4,   ... )  # S3 method for class 'inla.mesh.1d' gg(   data,   mapping = ggplot2::aes(.data[[\"x\"]], .data[[\"y\"]]),   y = 0,   shape = 4,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"data inla.mesh.1d object. mapping aesthetic mappings created aes. passed geom_point. y Single vector numeric defining y-coordinates mesh knots plot. shape Shape knot markers. ... parameters passed geom_point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"object generated geom_point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"gg(inla.mesh.1d): Alias gg.fm_mesh_1d, supporting inla.mesh.1d objects.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for fm_mesh_1d objects — gg.fm_mesh_1d","text":"","code":"# \\donttest{ if (require(\"fmesher\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   # Create a 1D mesh    mesh <- fm_mesh_1d(seq(0, 10, by = 0.5))    # Plot it    ggplot() +     gg(mesh)    # Plot it using a different shape and size for the mesh nodes    ggplot() +     gg(mesh, shape = \"|\", size = 5) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for inla.mesh objects — gg.fm_mesh_2d","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"function extracts graph inla.mesh object uses geom_line visualize graph's edges. Alternatively, color argument provided, interpolates colors across set SpatialPixels covering mesh area calls gg.SpatialPixelsDataFrame() plot interpolation. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"","code":"# S3 method for class 'fm_mesh_2d' gg(   data,   color = NULL,   alpha = NULL,   edge.color = \"grey\",   edge.linewidth = 0.25,   interior = TRUE,   int.color = \"blue\",   int.linewidth = 0.5,   exterior = TRUE,   ext.color = \"black\",   ext.linewidth = 1,   crs = NULL,   mask = NULL,   nx = 500,   ny = 500,   ... )  # S3 method for class 'inla.mesh' gg(   data,   color = NULL,   alpha = NULL,   edge.color = \"grey\",   edge.linewidth = 0.25,   interior = TRUE,   int.color = \"blue\",   int.linewidth = 0.5,   exterior = TRUE,   ext.color = \"black\",   ext.linewidth = 1,   crs = NULL,   mask = NULL,   nx = 500,   ny = 500,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"data fm_mesh_2d object. color vector scalar values fill mesh colors. length vector mus correspond number mesh vertices. alternative name colour also recognised. alpha vector scalar values setting alpha value colors provided. edge.color Color regular mesh edges. edge.linewidth Line width regular mesh edges. Default 0.25 interior TRUE, plot interior boundaries mesh. int.color Color used plot interior constraint edges. int.linewidth Line width interior constraint edges. Default 0.5 exterior TRUE, plot exterior boundaries mesh. ext.color Color used plot exterior boundary edges. ext.linewidth Line width exterior boundary edges. Default 1 crs CRS object supported fm_transform() defining coordinate system project mesh plotting. mask SpatialPolygon defining region plotted. nx Number pixels x direction (plotting using color parameter). ny Number pixels y direction (plotting using color parameter). ... ignored arguments (S3 generic compatibility).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"geom_line return values , color argument used, values gg.SpatialPixelsDataFrame().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"gg(inla.mesh): Alias gg.fm_mesh_2d, supporting inla.mesh objects.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.fm_mesh_2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for inla.mesh objects — gg.fm_mesh_2d","text":"","code":"# \\donttest{ if (require(fmesher, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {    # Load Gorilla data   gorillas <- inlabru::gorillas_sf    # Plot mesh using default edge colors    ggplot() +     gg(gorillas$mesh)    # Don't show interior and exterior boundaries    ggplot() +     gg(gorillas$mesh, interior = FALSE, exterior = FALSE)    # Change the edge colors    ggplot() +     gg(gorillas$mesh,       edge.color = \"green\",       int.color = \"black\",       ext.color = \"blue\"     )    # Use the x-coordinate of the vertices to colorize the triangles and   # mask the plotted area by the survey boundary, i.e. only plot the inside    xcoord <- gorillas$mesh$loc[, 1]   ggplot() +     gg(gorillas$mesh, color = (xcoord - 580), mask = gorillas$boundary) +     gg(gorillas$boundary, alpha = 0) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2 geomes for inlabru related objects — gg","title":"ggplot2 geomes for inlabru related objects — gg","text":"gg generic function generating geomes various kinds spatial objects, e.g. Spatial* data, meshes, Raster objects inla/inlabru predictions. function invokes particular methods depend class first argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"gg(data, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2 geomes for inlabru related objects — gg","text":"data object generate geom. ... Arguments passed geom method.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot2 geomes for inlabru related objects — gg","text":"form value returned gg depends class argument. See documentation particular methods details produced method.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot2 geomes for inlabru related objects — gg","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   # Load Gorilla data    data(gorillas, package = \"inlabru\")    # Invoke ggplot and add geomes for the Gorilla nests and the survey boundary    ggplot() +     gg(gorillas$boundary) +     gg(gorillas$nests) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom for matrix — gg.matrix","title":"Geom for matrix — gg.matrix","text":"Creates tile geom plotting matrix","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom for matrix — gg.matrix","text":"","code":"# S3 method for class 'matrix' gg(data, mapping = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom for matrix — gg.matrix","text":"data matrix object. mapping set aesthetic mappings created aes. passed geom_tile. ... Arguments passed geom_tile.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom for matrix — gg.matrix","text":"geom_tile reversed y scale.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Geom for matrix — gg.matrix","text":"Requires ggplot2 package.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom for matrix — gg.matrix","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   A <- matrix(runif(100), nrow = 10)   ggplot() +     gg(A) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Geom helper for sf objects — gg.sf","title":"Geom helper for sf objects — gg.sf","text":"function uses geom_sf(), unless overridden geom argument. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geom helper for sf objects — gg.sf","text":"","code":"# S3 method for class 'sf' gg(data, mapping = NULL, ..., geom = \"sf\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geom helper for sf objects — gg.sf","text":"data sf object. mapping Default mapping ggplot2::aes(geometry = ...), geometry name obtained attr(data, \"sf_column\"). merged user supplied mapping. ... Arguments passed geom_sf geom_tile. geom Either \"sf\" (default) \"tile\". \"tile\", uses geom_tile(..., stat = \"sf_coordinates\"), intended converting point data grid tiles fill aesthetic, default set first data column.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.sf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Geom helper for sf objects — gg.sf","text":"ggplot return value","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/gg.sf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Geom helper for sf objects — gg.sf","text":"","code":"# \\donttest{   if (require(ggplot2, quietly = TRUE)) {     # Load Gorilla data      gorillas <- inlabru::gorillas_sf     gorillas$gcov <- gorillas_sf_gcov()      # Plot Gorilla elevation covariate provided as terra::rast.      ggplot() +       gg(gorillas$gcov$elevation)      # Add Gorilla survey boundary and nest sightings      ggplot() +       gg(gorillas$gcov$elevation) +       gg(gorillas$boundary, alpha = 0) +       gg(gorillas$nests)      # Load pantropical dolphin data      mexdolphin <- inlabru::mexdolphin_sf      # Plot the pantropical survey boundary, ship transects and dolphin sightings      ggplot() +       gg(mexdolphin$ppoly, alpha = 0.5) + # survey boundary       gg(mexdolphin$samplers) + # ship transects       gg(mexdolphin$points) # dolphin sightings      # Change color      ggplot() +       gg(mexdolphin$ppoly, color = \"green\", alpha = 0.5) + # survey boundary       gg(mexdolphin$samplers, color = \"red\") + # ship transects       gg(mexdolphin$points, color = \"blue\") # dolphin sightings       # Visualize data annotations: line width by segment number      names(mexdolphin$samplers) # 'seg' holds the segment number     ggplot() +       gg(mexdolphin$samplers, aes(color = seg))      # Visualize data annotations: point size by dolphin group size      names(mexdolphin$points) # 'size' holds the group size     ggplot() +       gg(mexdolphin$points, aes(size = size))   }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a globe using RGL — globe","title":"Visualize a globe using RGL — globe","text":"Creates textured sphere lon/lat coordinate annotations. function requires rgl sphereplot packages.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a globe using RGL — globe","text":"","code":"globe(   R = 1,   R.grid = 1.05,   specular = \"black\",   axes = FALSE,   box = FALSE,   xlab = \"\",   ylab = \"\",   zlab = \"\" )"},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a globe using RGL — globe","text":"R Radius globe R.grid Radius annotation sphere. specular Light color specular effect. axes TRUE, plot x, y z axes. box TRUE, plot box around globe. xlab, ylab, zlab Axes labels","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a globe using RGL — globe","text":"value, used plotting side effect.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/globe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a globe using RGL — globe","text":"","code":"# \\donttest{ if (interactive() &&     require(\"rgl\", quietly = TRUE) &&     require(\"sphereplot\", quietly = TRUE) &&     bru_safe_sp() &&     require(\"sp\")) {   # Show the globe   globe()    # Load pantropoical dolphin data   data(\"mexdolphin\", package = \"inlabru\")    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh, alpha = 0.2)   glplot(mexdolphin$samplers, lwd = 5)   glplot(mexdolphin$points, size = 10) } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Render objects using RGL — glplot","title":"Render objects using RGL — glplot","text":"glplot() generic function renders various kinds spatial objects, .e. Spatial* data fm_mesh_2d objects. function invokes particular methods depend class first argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render objects using RGL — glplot","text":"","code":"glplot(object, ...)  # S3 method for class 'SpatialPoints' glplot(object, add = TRUE, color = \"red\", ...)  # S3 method for class 'SpatialLines' glplot(object, add = TRUE, ...)  # S3 method for class 'fm_mesh_2d' glplot(object, add = TRUE, col = NULL, ...)  # S3 method for class 'inla.mesh' glplot(object, add = TRUE, col = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render objects using RGL — glplot","text":"object object used select method. ... Parameters passed plot_rgl.fm_mesh_2d() add TRUE, add points existing plot. FALSE, create new plot. color vector R color characters. See material3d() details. col Color specification. single named color, vector scalar values, matrix RGB values.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Render objects using RGL — glplot","text":"glplot(SpatialPoints): function calculate cartesian coordinates points provided use points3d() order render . glplot(SpatialLines): function calculate cartesian representation lines provided use lines3d() order render . glplot(fm_mesh_2d): function transforms mesh 3D cartesian coordinates uses inla.plot.mesh() rgl=TRUE plot result.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/glplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Render objects using RGL — glplot","text":"","code":"# \\donttest{ if (interactive() &&     require(\"rgl\", quietly = TRUE) &&     require(\"sphereplot\", quietly = TRUE) &&     bru_safe_sp() &&     require(\"sp\")) {   # Show the globe   globe()    # Load pantropoical dolphin data   data(\"mexdolphin\", package = \"inlabru\")    # Add mesh, ship transects and dolphin sightings stored   # as inla.mesh, SpatialLines and SpatialPoints objects, respectively    glplot(mexdolphin$mesh, alpha = 0.2)   glplot(mexdolphin$samplers, lwd = 5)   glplot(mexdolphin$points, size = 10) } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla nesting sites — gorillas","title":"Gorilla nesting sites — gorillas","text":"gorillas dataset package spatstat.data, reformatted point process data use inlabru.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla nesting sites — gorillas","text":"","code":"gorillas # To avoid the name clash with spatstat.data::gorillas, use data(gorillas, package = \"inlabru\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gorilla nesting sites — gorillas","text":"data list contains elements: nests: SpatialPointsDataFrame object containing locations gorilla nests. boundary: SpatialPolygonsDataFrame object defining boundary region searched nests. mesh: inla.mesh object containing mesh can used function lgcp fit LGCP nest data. gcov: list SpatialGridDataFrame objects, one spatial covariates: aspect Compass direction terrain slope. Categorical, levels N, NE, E, SE, S, SW, W NW, coded integers 1 8. elevation Digital elevation terrain, metres. heat Heat Load Index point surface (Beer's aspect), discretised. Categorical values Warmest (Beer's aspect 0 0.999), Moderate (Beer's aspect 1 1.999), Coolest (Beer's aspect equals 2). coded integers 1, 2 3, order. slopangle Terrain slope, degrees. slopetype Type slope. Categorical, values Valley, Toe (toe slope), Flat, Midslope, Upper Ridge. coded integers 1 6. vegetation Vegetation type: categorical variable 6 levels coded integers 1 6 (order increasing expected habitat suitability) waterdist Euclidean distance nearest water body, metres. plotsample Plot sample gorilla nests, sampling 9x9 region, 60\\ counts SpatialPointsDataFrame frame elements x, y, count, exposure, x- y-coordinates centre plot, count plot area plot. plots SpatialPolygonsDataFrame defining individual plot boundaries. nests SpatialPointsDataFrame giving locations detected nest.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Gorilla nesting sites — gorillas","text":"Library spatstat.data.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gorilla nesting sites — gorillas","text":"Funwi-Gabga, N. (2008) pastoralist survey fire impact assessment Kagwene Gorilla Sanctuary, Cameroon. M.Sc. thesis, Geology Environmental Science, University Buea, Cameroon. Funwi-Gabga, N. Mateu, J. (2012) Understanding nesting spatial behaviour gorillas Kagwene Sanctuary, Cameroon. Stochastic Environmental Research Risk Assessment 26 (6), 793-811.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gorilla nesting sites — gorillas","text":"","code":"if (bru_safe_inla() &&   bru_safe_sp() &&   require(\"sp\") &&   require(ggplot2, quietly = TRUE)) {   data(gorillas, package = \"inlabru\") # get the data    # plot all the nests, mesh and boundary   ggplot() +     gg(gorillas$mesh) +     gg(gorillas$boundary) +     gg(gorillas$nests)    # Plot the elevation covariate   plot(gorillas$gcov$elevation)    # Plot the plot sample   ggplot() +     gg(gorillas$plotsample$plots) +     gg(gorillas$plotsample$nests) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Gorilla nesting sites in sf format — gorillas_sf","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"gorillas dataset package spatstat.data, reformatted point process data use inlabru.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"","code":"gorillas_sf data(gorillas_sf, package = \"inlabru\")  gorillas_sf_gcov()"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"data list contains elements: nests: sf object containing locations gorilla nests. boundary: sf object defining boundary region searched nests. mesh: fm_mesh_2d object containing mesh can used function lgcp fit LGCP nest data. gcov_file: -package filename terra::SpatRaster object, one layer spatial covariates: aspect Compass direction terrain slope. Categorical, levels N, NE, E, SE, S, SW, W NW, coded integers 1 8. elevation Digital elevation terrain, metres. heat Heat Load Index point surface (Beer's aspect), discretised. Categorical values Warmest (Beer's aspect 0 0.999), Moderate (Beer's aspect 1 1.999), Coolest (Beer's aspect equals 2). coded integers 1, 2 3, order. slopangle Terrain slope, degrees. slopetype Type slope. Categorical, values Valley, Toe (toe slope), Flat, Midslope, Upper Ridge. coded integers 1 6. vegetation Vegetation type: categorical variable 6 levels coded integers 1 6 (order increasing expected habitat suitability) waterdist Euclidean distance nearest water body, metres. Loading covariates can done gorillas_sf_gcov()   plotsample Plot sample gorilla nests, sampling 9x9 region, 60\\ counts SpatialPointsDataFrame frame elements x, y, count, exposure, x- y-coordinates centre plot, count plot area plot. plots SpatialPolygonsDataFrame defining individual plot boundaries. nests SpatialPointsDataFrame giving locations detected nest.","code":"gorillas_sf$gcov <- terra::rast(   system.file(gorillas_sf$gcov_file, package = \"inlabru\") )"},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"Library spatstat.data.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"gorillas_sf_gcov(): Access gorillas_sf covariates data terra::rast() object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"Funwi-Gabga, N. (2008) pastoralist survey fire impact assessment Kagwene Gorilla Sanctuary, Cameroon. M.Sc. thesis, Geology Environmental Science, University Buea, Cameroon. Funwi-Gabga, N. Mateu, J. (2012) Understanding nesting spatial behaviour gorillas Kagwene Sanctuary, Cameroon. Stochastic Environmental Research Risk Assessment 26 (6), 793-811.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/gorillas_sf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gorilla nesting sites in sf format — gorillas_sf","text":"","code":"if (interactive() &&   bru_safe_inla() &&   bru_safe_sp() &&   require(\"sp\") &&   require(ggplot2, quietly = TRUE) &&   requireNamespace(\"terra\")) {   # plot all the nests, mesh and boundary   ggplot() +     gg(gorillas_sf$mesh) +     geom_sf(       data = gorillas_sf$boundary,       alpha = 0.1, fill = \"blue\"     ) +     geom_sf(data = gorillas_sf$nests)    # Plot the elevation covariate   gorillas_sf$gcov <- terra::rast(     system.file(gorillas_sf$gcov_file, package = \"inlabru\")   )   plot(gorillas_sf$gcov$elevation)    # Plot the plot sample   ggplot() +     geom_sf(data = gorillas_sf$plotsample$plots) +     geom_sf(data = gorillas_sf$plotsample$nests) } if (FALSE) { # \\dontrun{ gorillas_sf$gcov <- gorillas_sf_gcov() } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":null,"dir":"Reference","previous_headings":"","what":"Iterated INLA — iinla","title":"Iterated INLA — iinla","text":"internal wrapper iterated runs INLA::inla. nonlinear models, linearisation done bru_compute_linearisation, line search method iteration. INLA::inla.stack information setup bru_make_stack().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iterated INLA — iinla","text":"","code":"iinla(model, lhoods, initial = NULL, options)"},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iterated INLA — iinla","text":"model bru_model object lhoods list likelihood objects like() initial previous bru result list named latent variable initial states (missing elements set zero), used starting point, NULL. non-null, overrides options$bru_initial options bru_options object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/iinla.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iterated INLA — iinla","text":"iinla object inherits INLA::inla, added field bru_iinla elements log diagnostic log messages produced run states list linearisation points, one inla run inla_stack inla.stack object final inla run track list convergence tracking vectors inla run aborted error, returned object also contains element error error object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain indices — index_eval","title":"Obtain indices — index_eval","text":"Indexes components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain indices — index_eval","text":"","code":"index_eval(...)  # S3 method for class 'component' index_eval(component, inla_f, ...)  # S3 method for class 'component_list' index_eval(components, inla_f, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain indices — index_eval","text":"... Unused. component component. inla_f logical; TRUE, must result values compatible INLA::f(...) specification corresponding INLA::inla.stack(...) constructions.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain indices — index_eval","text":"list indices latent variables compatible component mapper.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/index_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain indices — index_eval","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain inla index subset information — inla_subset_eval","title":"Obtain inla index subset information — inla_subset_eval","text":"Subsets INLA::f() compatible indexing","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain inla index subset information — inla_subset_eval","text":"","code":"inla_subset_eval(...)  # S3 method for class 'component_list' inla_subset_eval(components, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain inla index subset information — inla_subset_eval","text":"... Unused. components component list.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inla_subset_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain inla index subset information — inla_subset_eval","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in inlabru — ipoints","title":"Deprecated functions in inlabru — ipoints","text":"functions still attempt job, removed future version.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in inlabru — ipoints","text":"","code":"ipoints(   samplers = NULL,   domain = NULL,   name = NULL,   group = NULL,   int.args = NULL,   project = deprecated() )  cprod(..., na.rm = NULL, .blockwise = FALSE)  gmap(...)  gm(...)  integration_weight_aggregation(mesh, integ)  mesh_triangle_integration(mesh, tri_subset = NULL, nsub = NULL)  bru_int_polygon(...)  # Default S3 method bru_mapper(...)  bru_mapper_offset(...)  is.inside(mesh, loc, mesh.coords = NULL)  vertices.inla.mesh(...)  pixels(mesh, nx = 150, ny = 150, mask = TRUE)"},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions in inlabru — ipoints","text":"samplers Description integration region boundary. 1D, length 2 vector two-column matrix row describes interval, NULL 2D either SpatialPolygon SpatialLinesDataFrame weight column defining width transect line, optionally columns used group argument, NULL.  domain NULL, samplers may also inla.mesh.1d inla.mesh object, treated domain argument instead. domain Either samplers 1D interval(s) definition , domain can single integer number integration points place 1D interval, overriding int.args[[\"nsub1\"]], otherwise samplers NULL, domain can numeric vector points, given integration weight 1 (additional points added ), inla.mesh.1d object continuous 1D integration, inla.mesh.2d object continuous 2D integration. name Character array stating name domains dimension(s). NULL, names taken coordinate names samplers Spatial* objects, otherwise \"x\", \"y\", \"z\" 2D regions \"x\" 1D regions group Column names samplers object (applicable) integration points calculated independently merged aggregating mesh nodes. int.args List arguments passed bru_int_polygon. method: \"stable\" (aggregate integration weights onto mesh nodes) \"direct\" (construct within triangle/segment integration scheme without aggregating onto mesh nodes) nsub1, nsub2: integers controlling number internal integration points aggregation. Points per triangle: (nsub2+1)^2. Points per knot segment: nsub1 poly_method: set \"legacy\", selects old polygon integration method handle holes. longer supported, generate error. project Deprecated favour int.args(method=...). TRUE, aggregate integration points mesh vertices. Default: project = (identical(int.args$method, \"stable\")) ... Usually passed methods na.rm logical; TRUE, rows weight NA non-overlapping full_join removed; FALSE, set undefined weights NA. NULL (default), act TRUE, warn elements needed removing. .blockwise logical; FALSE, computes full tensor product integration. TRUE, computes within-block tensor product integration (used internally fm_int()). Default FALSE mesh inla.mesh object integ list loc, integration points, weight, integration weights, SpatialPointsDataFrame. coordinates weight column handled. tri_subset Optional triangle index vector integration subset mesh triangles (Default NULL) nsub number subdivision points along triangle edge, giving (nsub + 1)^2 proto-integration points used compute vertex weights (default NULL=9, giving 100 integration points triangle) loc Points space stored either data.frame, two-column matrix x y coordinates SpatialPoints object. mesh.coords Coordinate names mesh. Use loc data.frame respective column names. nx Number pixels x direction ny Number pixels y direction mask logical TRUE, remove pixels outside mesh. mask Spatial object, return pixels covered object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deprecated functions in inlabru — ipoints","text":"ipoints(): data.frame, tibble, sf, SpatialPointsDataFrame 1D 2D integration points, including weight column .block column. data.frame, sf, SpatialPointsDataFrame multidimensional integration points weights mesh_triangle_integration returns list elements loc weight integration points mesh .inside(): Single column matrix Boolean values indicating point inside mesh. SpatialPixelsDataFrame covering mesh","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Deprecated functions in inlabru — ipoints","text":"ipoints():  favour fmesher::fm_int() cprod(): (Blockwise) cross product integration points. Calculates groupwise cross product integration points different dimensions multiplies weights accordingly. object defining points particular dimension weights attached weights assumed 1. Legacy wrapper fm_cprod() gmap(): Plot map using extent spatial object function deprecated ggmap supported. Used ggmap::get_map() query map services like Google Maps region centered around spatial object provided. calls ggmap() plot map. function required ggmap package. gm():  function deprecated ggmap supported. ggplot geom spatial data gm wrapper gg method. take first argument transform coordinate system latitude longitude. Thereafter, gg called using transformed data arguments provided via .... gm intended replace gg whenever data supposed plotted spatial map generated gmap, works coordinate system latitude/longitude. integration_weight_aggregation(): Aggregate integration weights onto mesh nodes Use fmesher::fm_vertex_projection() instead. mesh_triangle_integration(): Integration scheme mesh triangle interiors Use fmesher::fm_int_mesh_2d_core() instead. bru_int_polygon(): Integration points polygons inside inla.mesh Use fmesher::fm_int() instead. bru_mapper(default): Calls bru_mapper_define, passing arguments along. Mapper implementations call bru_mapper_define() instead, supply least new_class class name. Use bru_mapper.default method deprecated version 2.7.0, removed version 2.11.0 bru_mapper_offset(): Creates bru_mapper_const() mapper. .inside(): Find points inside mesh.  favour fm_is_within(). Replace .inside(mesh, loc) fm_is_within(loc, mesh). vertices.inla.mesh(): Extract vertex locations inla.mesh. Converts vertices inla.mesh object SpatialPointsDataFrame. Deprecated favour fm_vertices() pixels(): Generate SpatialPixels covering inla.mesh.  favour fmesher::fm_pixels()","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deprecated functions in inlabru — ipoints","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deprecated functions in inlabru — ipoints","text":"","code":"if (FALSE) { # \\dontrun{ # if (requireNamespace(\"ggmap\", quietly = TRUE) && #   require(\"ggplot2\", quietly = TRUE)) { #  # Load the Gorilla data #  data(gorillas, package = \"inlabru\") # #   # Create a base map centred around the nests and plot the boundary as well #   # as the nests #   gmap(gorillas$nests, maptype = \"satellite\") + #     gm(gorillas$boundary) + #     gm(gorillas$nests, color = \"white\", size = 0.5) # } } # } if (FALSE) { # \\dontrun{ # if (require(\"ggplot2\", quietly = TRUE)) { #   # Load the Gorilla data #   data(gorillas, package = \"inlabru\") # #   # Create a base map centered around the nests and plot the boundary as well as the nests #   gmap(gorillas$nests, maptype = \"satellite\") + #     gm(gorillas$boundary) + #     gm(gorillas$nests, color = \"white\", size = 0.5) # } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":null,"dir":"Reference","previous_headings":"","what":"inlabru — inlabru-package","title":"inlabru — inlabru-package","text":"Convenient model fitting using (iterated) INLA.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"inlabru — inlabru-package","text":"inlabru facilitates Bayesian spatial modelling using integrated nested Laplace approximations. heavily based R-inla (https://www.r-inla.org) adds additional modelling abilities simplified syntax (particular) spatial models. Tutorials information can found https://inlabru-org.github.io/inlabru/ http://www.inlabru.org/. iterative method used non-linear predictors documented method vignette. main function inference using inlabru bru(). general model specification details documented component() like(). Posterior quantities beyond basic summaries can calculated predict() method, documented predict.bru(). point process inference lgcp() can used shortcut bru(..., like(model=\"cp\", ...)). package comes multiple real world data sets, namely gorillas, mexdolphin, gorillas_sf, mexdolphin_sf, seals_sp. Plotting data sets straight forward using inlabru's extensions ggplot2, e.g. gg() function. educational purposes simulated data sets available well, e.g. Poisson1_1D, Poisson2_1D, Poisson2_1D toygroups.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/inlabru-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"inlabru — inlabru-package","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain component inputs — input_eval","title":"Obtain component inputs — input_eval","text":"Obtain component inputs","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain component inputs — input_eval","text":"","code":"input_eval(...)  # S3 method for class 'component' input_eval(component, data, ...)  # S3 method for class 'component_list' input_eval(components, data, ...)  # S3 method for class 'bru_input' input_eval(input, data, env = NULL, null.on.fail = FALSE, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain component inputs — input_eval","text":"... Unused. component component. data data.frame, tibble, sf, list, Spatial* object covariates /point locations. NULL, return component's map.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain component inputs — input_eval","text":"list mapper input values, formatted full component mapper (type bru_mapper_pipe)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Obtain component inputs — input_eval","text":"input_eval(bru_input): Attempts evaluate component input (e.g. main, group, replicate, weight), process results: eval() failed, return NULL map everything 1 (see null..fail argument). normally happen, unless component use logic incorrect, (e.g. via include/exclude) leading missing columns certain likelihood multi-like() model. obtain function, apply function data object obtain object supported eval_spatial(), extract values data frame point locations Else obtain vector return -. happens input references column data points, complete expression","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"simple-covariates-and-the-map-parameter","dir":"Reference","previous_headings":"","what":"Simple covariates and the map parameter","title":"Obtain component inputs — input_eval","text":"unusual random effect act transformation covariate. frameworks mean transformed covariate calculated advance added data frame usually provided via data parameter. inlabru provides option transformation automatically. instance, one might interested effect covariate \\(x^2\\). inla frameworks require add column xsquared input data frame use formula formula = y ~ f(xsquared, model = \"linear\"), inlabru can achieved several ways using main parameter (map version 2.1.13 earlier), need named. components = y ~ psi(main = x^2, model = \"linear\") components = y ~ psi(x^2, model = \"linear\") components = y ~ psi(mySquareFun(x), model = \"linear\"), components = y ~ psi(myOtherSquareFun, model = \"linear\"), first example inlabru interpret map parameter expression evaluated within data provided. Since \\(x\\) known covariate know calculate . second example expression well uses function called mySquareFun. function defined user accessible within work space setting components. third example provides function myOtherSquareFun. case, inlabru call function myOtherSquareFun(.data.), .data. data provided via like() data parameter. function needs know parts data use construct needed output. example,","code":"myOtherSquareFun <- function(data) {   data[ ,\"x\"]^2 }"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"spatial-covariates","dir":"Reference","previous_headings":"","what":"Spatial Covariates","title":"Obtain component inputs — input_eval","text":"fitting spatial models common work covariates depend space, e.g. sea surface temperature elevation. Although straightforward add data input data frame write covariate function like previous section even convenient way inlabru. Spatial covariates often stored SpatialPixelsDataFrame, SpatialPixelsDataFrame RasterLayer objects. can provided directly via input expressions supported eval_spatial(), like() data sf SpatialPointsDataFrame object. inlabru automatically evaluate /interpolate covariate data locations using code like   precise control, use layer selector arguments (see component()), call eval_spatial() directly, e.g.:","code":"components = y ~ psi(mySpatialPixels, model = \"linear\") components = y ~ psi(eval_spatial(mySpatialPixels, where = .data.), model = \"linear\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"coordinates","dir":"Reference","previous_headings":"","what":"Coordinates","title":"Obtain component inputs — input_eval","text":"common spatial modelling component using inla SPDE models. important feature inlabru automatically calculate called -matrix (component model matrix) maps SPDE values mesh vertices values data locations. purpose, input can set coordinates, sp package function extracts point coordinates SpatialPointsDataFrame provided input like(). code look follows:   Since coordinates function sp package, results evaluation sp::coordinates(.data.), loses CRS information data object. sf data geometry column (default named geometry), use   Since CRS information part geometry column sf object, retains CRS information, robust, allows model built different CRS observation data.","code":"components = y ~ field(coordinates, model = inla.spde2.matern(...)) components = y ~ field(geometry, model = inla.spde2.matern(...))"},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/input_eval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain component inputs — input_eval","text":"Fabian E. Bachl bachlfab@gmail.com, Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"function performs inference LGCP observed via points residing possibly multiple dimensions. dimensions defined via left hand side formula provided via model parameter. left hand side determines intensity function assumed drive LGCP. may include effects lead thinning (filtering) point process. default, log intensity assumed linear combination effects defined formula's RHS. sophisticated models, e.g. non-linear thinning, can achieved using predictor argument. latter requires multiple runs INLA improving required approximation predictor. many applications LGCP observed subsets dimensions process living . example, spatial point realizations may known sub-areas modelled space. observed subsets LGCP domain called samplers can provided via respective parameter. samplers NULL assumed LGCP's dimensions observed completely.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"lgcp(   components,   data,   domain = NULL,   samplers = NULL,   ips = NULL,   formula = . ~ .,   ...,   options = list(),   .envir = parent.frame() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"components formula-like specification latent components. Also used define default linear additive predictor.  See component() details. data Likelihood-specific data, data.frame SpatialPoints[DataFrame] object. domain, samplers, ips Arguments used family=\"cp\". domain Named list domain definitions. samplers Integration subdomain 'cp' family. ips Integration points 'cp' family. Defaults fmesher::fm_int(domain, samplers). explicitly given, overrides domain samplers. formula formula right hand side general R expression defines predictor used model. ... arguments passed like(). particular, optional E, single numeric used rescale integration weights fixed factor. options bru_options options object list options passed bru_options() .envir evaluation environment use special arguments (E, Ntrials, weights, scale) found response_data data. Defaults calling environment.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"bru() object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log Gaussian Cox process (LGCP) inference using INLA — lgcp","text":"","code":"# \\donttest{ if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   require(fmesher, quietly = TRUE)) {   # Load the Gorilla data   data <- gorillas_sf    # Plot the Gorilla nests, the mesh and the survey boundary   ggplot() +     geom_fm(data = data$mesh) +     gg(data$boundary, fill = \"blue\", alpha = 0.2) +     gg(data$nests, col = \"red\", alpha = 0.2)    # Define SPDE prior   matern <- INLA::inla.spde2.pcmatern(     data$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.1, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE   # effect and Intercept)   cmp <- geometry ~ field(geometry, model = matern) + Intercept(1)    # Fit the model (with int.strategy=\"eb\" to make the example take less time)   fit <- lgcp(cmp, data$nests,     samplers = data$boundary,     domain = list(geometry = data$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Predict the spatial intensity surface   lambda <- predict(     fit,     fm_pixels(data$mesh, mask = data$boundary),     ~ exp(field + Intercept)   )    # Plot the intensity   ggplot() +     gg(lambda, geom = \"tile\") +     geom_fm(data = data$mesh, alpha = 0, linewidth = 0.05) +     gg(data$nests, col = \"red\", alpha = 0.2) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":null,"dir":"Reference","previous_headings":"","what":"Unit test helpers — local_testthat","title":"Unit test helpers — local_testthat","text":"Local helper functions package unit tests","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unit test helpers — local_testthat","text":"","code":"local_bru_testthat_assign(x, values, envir = parent.frame())  local_bru_testthat_tolerances(   tolerances = c(1e-04, 0.01, 0.1),   envir = parent.frame() )  local_bru_options_set(..., .reset = FALSE, envir = parent.frame())  local_basic_intercept_testdata()  local_basic_fixed_effect_testdata()  local_mrsea_convert(x, use_km = FALSE)  local_bru_safe_inla(multicore = FALSE, quietly = TRUE, envir = parent.frame())  local_bru_testthat_setup(envir = parent.frame())"},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unit test helpers — local_testthat","text":"x character; Name variable assign values object assign x envir environment exit handlers tolerances numeric vector length 3; [lowtol, midtol, hitol] .reset local_bru_options_set, logical indicating global override options list emptied setting new option(s). multicore logical; TRUE, multiple cores allowed, INLA num.threads option checked altered. Default: FALSE, multicore allowed (used examples unit tests). quietly logical; TRUE, prints diagnostic messages. message always printed INLA num.threads option altered, regardless quietly argument. Default: TRUE.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() returns copy global override options (including defaults), invisibly.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unit test helpers — local_testthat","text":"local_bru_options_set() used set global package options.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Unit test helpers — local_testthat","text":"local_bru_testthat_assign(): Assign local variable. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_bru_testthat_tolerances(): Assign test tolerances Assign local tolerance variables. Useful easy cleanup global workspace withr::deferred_run() running tests interactively. local_bru_options_set(): Calls bru_options_set() reversible way local_bru_safe_inla(): Tests set num.threads = \"1:1\" ensure within-system repeatability calling local_bru_safe_inla(); see also bru_safe_inla() local_bru_testthat_setup(): Initialise environment tests. Assigns tolerance variables. called either top testfile, inside tests. call local_bru_safe_inla(), since may invoke skip called inside test relies INLA.","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/local_testthat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unit test helpers — local_testthat","text":"","code":"my_fun <- function(val) {   local_bru_options_set(bru_verbose = val)   bru_options_get(\"bru_verbose\") } # Inside the function, the bru_verbose option is changed. # Outside the function, the bru_verbose option is unchanged. print(my_fun(TRUE)) #> [1] TRUE print(bru_options_get(\"bru_verbose\")) #> [1] 0 print(my_fun(FALSE)) #> [1] FALSE print(bru_options_get(\"bru_verbose\")) #> [1] 0"},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":null,"dir":"Reference","previous_headings":"","what":"Matern correlation or covariance function approximate credible bands. — materncov.bands","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Evaluate covariance function inla.spde objectPlots posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"","code":"materncov.bands(   manifold,   dist,   log.range,   log.variance = NULL,   alpha = 2,   quantile = 0.95,   n = 64,   S1.L = NULL )"},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"manifold Either \"R1\", \"S1\", \"R2\", \"S2\", mesh$manifold, full inla.mesh inla.mesh.1d object. dist vector distances calculate covariances/correlations log.range scalar list (mean, sd), produced inla.spde.result(...)$summary.log.range.nominal[[1]][c(\"mean\",\"sd\")] log.variance Either NULL, scalar, vector type log.range. NULL, correlations calculated instead covariances. alpha SPDE operator order. Default 2. quantile target credible probability. Default 0.95. n number parameter combinations use approximation. Default 64. S1.L manifold \"S1\", give length cyclic interval","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"list estimated covariance correlation (log.variance NULL) functions: lower approximate lower bound quantile credible region median function approximate median parameters quantile upper approximate upper bound quantile credible region","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Uses Gaussian assumption internal model parameters, finds region parameter space approximately quantile probability.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/materncov.bands.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Matern correlation or covariance function approximate credible bands. — materncov.bands","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"version mexdolphins dataset package dsm, reformatted point process data use inlabru. data combination several NOAA shipboard surveys conducted pan-tropical spotted dolphins Gulf Mexico. 47 observations groups dolphins detected. group size recorded, well Beaufort sea state time observation. Transect width 16 km, .e. maximal detection distance 8 km (transect half-width 8 km).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"mexdolphin"},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"list objects: points: SpatialPointsDataFrame object containing locations detected dolphin groups, size attribute. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: inla.mesh object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. ppoly: SpatialPolygonsDataFrame object defining boundary survey region. simulated: SpatialPointsDataFrame object containing locations simulated population dolphin groups. population simulated inlabru model fitted actual survey data. Note simulated data associated size information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Library dsm.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"Halpin, P.N., .J. Read, E. Fujioka, B.D. Best, B. Donnelly, L.J. Hazen, C. Kot, K. Urian, E. LaBrecque, . Dimatteo, J. Cleary, C. Good, L.B. Crowder, K.D. Hyrenbach. 2009. OBIS-SEAMAP: world data center marine mammal, sea bird, sea turtle distributions. Oceanography 22(2):104-115 NOAA Southeast Fisheries Science Center. 1996. Report Cetacean Survey Oceanic Selected Continental Shelf Waters Northern Gulf Mexico aboard NOAA Ship Oregon II (Cruise 220)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(mexdolphin, package = \"inlabru\")   ggplot() +     gg(mexdolphin$mesh) +     gg(mexdolphin$ppoly, color = \"blue\") +     gg(mexdolphin$samplers) +     gg(mexdolphin$points, aes(size = size), color = \"red\") +     coord_equal()    ggplot() +     gg(mexdolphin$mesh, col = mexdolphin$lambda, mask = mexdolphin$ppoly) +     coord_equal() }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"version mexdolphins dataset package dsm, reformatted point process data use inlabru, parts stored sf format. data combination several NOAA shipboard surveys conducted pan-tropical spotted dolphins Gulf Mexico. 47 observations groups dolphins detected. group size recorded, well Beaufort sea state time observation. Transect width 16 km, .e. maximal detection distance 8 km (transect half-width 8 km).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"","code":"mexdolphin_sf"},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"list objects: points: sf object containing locations detected dolphin groups, size attribute. samplers: sf object containing transect lines surveyed. mesh: fm_mesh_2d object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. ppoly: sf object defining boundary survey region. simulated: sf object containing locations simulated population dolphin groups. population simulated inlabru model fitted actual survey data. Note simulated data associated size information.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"Library dsm.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"Halpin, P.N., .J. Read, E. Fujioka, B.D. Best, B. Donnelly, L.J. Hazen, C. Kot, K. Urian, E. LaBrecque, . Dimatteo, J. Cleary, C. Good, L.B. Crowder, K.D. Hyrenbach. 2009. OBIS-SEAMAP: world data center marine mammal, sea bird, sea turtle distributions. Oceanography 22(2):104-115 NOAA Southeast Fisheries Science Center. 1996. Report Cetacean Survey Oceanic Selected Continental Shelf Waters Northern Gulf Mexico aboard NOAA Ship Oregon II (Cruise 220)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mexdolphin_sf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pan-tropical spotted dolphins in the Gulf of Mexico — mexdolphin_sf","text":"","code":"# \\donttest{ if (require(\"ggplot2\", quietly = TRUE)) {   data(mexdolphin_sf, package = \"inlabru\")   ggplot() +     gg(mexdolphin_sf$mesh) +     gg(mexdolphin_sf$ppoly, color = \"blue\", alpha = 0, linewidth = 1) +     gg(mexdolphin_sf$samplers) +     gg(mexdolphin_sf$points, aes(size = size), color = \"red\") +     scale_size_area()    ggplot() +     gg(mexdolphin_sf$mesh, color = mexdolphin_sf$lambda, mask = mexdolphin_sf$ppoly) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":null,"dir":"Reference","previous_headings":"","what":"Marine renewables strategic environmental assessment — mrsea","title":"Marine renewables strategic environmental assessment — mrsea","text":"Data imported package MRSea, see https://www.creem.st-andrews.ac.uk/software/","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"mrsea"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Marine renewables strategic environmental assessment — mrsea","text":"list objects: points: SpatialPointsDataFrame object containing locations XXXXX. samplers: SpatialLinesDataFrame object containing transect lines surveyed. mesh: fm_mesh_2d object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. boundary: SpatialPolygonsDataFrame object defining boundary survey region. covar: SpatialPointsDataFrame containing sea depth estimates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Marine renewables strategic environmental assessment — mrsea","text":"Library MRSea.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marine renewables strategic environmental assessment — mrsea","text":"NONE YET","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marine renewables strategic environmental assessment — mrsea","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   ggplot() +     geom_fm(data = mrsea$mesh) +     gg(mrsea$samplers) +     gg(mrsea$points) +     gg(mrsea$boundary) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Marine renewables strategic environmental assessment — mrsea_sf","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"Data imported package MRSea, see https://www.creem.st-andrews.ac.uk/software/","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"","code":"mrsea_sf"},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"list objects: points: sf object containing locations XXXXX. samplers: sf object containing transect lines surveyed. mesh: fm_mesh_2d object containing Delaunay triangulation mesh (type discretization continuous space) covering survey region. boundary: sf object defining boundary polygon survey region. covar: sf containing sea depth estimates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"Library MRSea.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"NONE YET","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/reference/mrsea_sf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marine renewables strategic environmental assessment — mrsea_sf","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   ggplot() +     geom_fm(data = mrsea$mesh) +     gg(mrsea$samplers) +     gg(mrsea$points) +     gg(mrsea$boundary) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple ggplots on a page. — multiplot","title":"Multiple ggplots on a page. — multiplot","text":"Renders multiple ggplots single page.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple ggplots on a page. — multiplot","text":"","code":"multiplot(..., plotlist = NULL, cols = 1, layout = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Multiple ggplots on a page. — multiplot","text":"http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple ggplots on a page. — multiplot","text":"... Comma-separated ggplot objects. plotlist list ggplot objects - alternative comma-separated argument . cols Number columns plots page. layout matrix specifying layout. present, 'cols' ignored. layout something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE), plot 1 go upper left, 2 go upper right, 3 go way across bottom.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiple ggplots on a page. — multiplot","text":"David L. Borchers dlb@st-andrews.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/multiplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple ggplots on a page. — multiplot","text":"","code":"if (require(\"ggplot2\", quietly = TRUE)) {   df <- data.frame(x = 1:10, y = 1:10, z = 11:20)   pl1 <- ggplot(data = df) +     geom_line(mapping = aes(x, y), color = \"red\")   pl2 <- ggplot(data = df) +     geom_line(mapping = aes(x, z), color = \"blue\")   multiplot(pl1, pl2, cols = 2) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse inclusion of component labels in a predictor expression — parse_inclusion","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"Parse inclusion component labels predictor expression","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"","code":"parse_inclusion(thenames, include = NULL, exclude = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/parse_inclusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse inclusion of component labels in a predictor expression — parse_inclusion","text":"thenames Set labels restrict include Character vector component labels needed predictor expression; Default: NULL (include components explicitly excluded) exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":null,"dir":"Reference","previous_headings":"","what":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"Make hierarchical mesh basis functions","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"","code":"make_hierarchical_mesh_basis(mesh, forward = TRUE)  inla.spde2.pcmatern_B(mesh, ..., B)"},{"path":"https://inlabru-org.github.io/inlabru/reference/pcmatern_B.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Make hierarchical mesh basis functions — make_hierarchical_mesh_basis","text":"inla.spde2.pcmatern_B(): Construct pcmatern model basis change","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for posterior marginals estimated by bru — plot.bru","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"version 2.11.0, plot.bru(x, ...) calls plot.inla(x, ...) INLA package, unless first argument x character, case pre-2.11.0 behaviour used, calling plotmarginal.inla(x, ...) instead. Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"# S3 method for class 'bru' plot(x, ...)  plotmarginal.inla(   result,   varname = NULL,   index = NULL,   link = function(x) {      x  },   add = FALSE,   ggp = TRUE,   lwd = 3,   ... )"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"x fitted bru() model. ... Options passed methods. result inla bru result object varname character; name variable plot index integer; index random effect plot link function; link function apply variable add logical; TRUE, add existing plot ggp logical; unused lwd numeric; line width","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for posterior marginals estimated by bru — plot.bru","text":"","code":"if (FALSE) { # \\dontrun{ if (require(\"ggplot2\", quietly = TRUE)) {   # Generate some data and fit a simple model   input.df <- data.frame(x = cos(1:10))   input.df <- within(     input.df,     y <- 5 + 2 * x + rnorm(length(x), mean = 0, sd = 0.1)   )   fit <- bru(y ~ x, family = \"gaussian\", data = input.df)   summary(fit)    # Plot the posterior density of the model's x-effect   plot(fit, \"x\") } } # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prediction using ggplot2 — plot.bru_prediction","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"Generates base ggplot2 using ggplot() adds geom input x using gg.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"","code":"# S3 method for class 'bru_prediction' plot(x, y = NULL, ...)  # S3 method for class 'prediction' plot(x, y = NULL, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"x prediction object. y Ignored argument required S3 compatibility. ... Arguments passed gg.prediction().","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"object class gg","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"Requires ggplot2 package.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plot.bru_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prediction using ggplot2 — plot.bru_prediction","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     require(sn, quietly = TRUE) &&     require(ggplot2, quietly = TRUE)) {   # Generate some data    input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, y <- 5 + 2 * cos(1:10) + rnorm(10, mean = 0, sd = 0.1))    # Fit a model with fixed effect 'x' and intercept 'Intercept'    fit <- bru(y ~ x, family = \"gaussian\", data = input.df)    # Predict posterior statistics of 'x'    xpost <- predict(fit, NULL, formula = ~x_latent)    # The statistics include mean, standard deviation, the 2.5% quantile, the median,   # the 97.5% quantile, minimum and maximum sample drawn from the posterior as well as   # the coefficient of variation and the variance.    xpost    # For a single variable like 'x' the default plotting method invoked by gg() will   # show these statisics in a fashion similar to a box plot:   ggplot() +     gg(xpost)     # The predict function can also be used to simultaneously estimate posteriors   # of multiple variables:    xipost <- predict(fit,     newdata = NULL,     formula = ~ c(       Intercept = Intercept_latent,       x = x_latent     )   )   xipost    # If we still want a plot in the previous style we have to set the bar parameter to TRUE    p1 <- ggplot() +     gg(xipost, bar = TRUE)   p1    # Note that gg also understands the posterior estimates generated while running INLA    p2 <- ggplot() +     gg(fit$summary.fixed, bar = TRUE)   multiplot(p1, p2)    # By default, if the prediction has more than one row, gg will plot the column 'mean' against   # the row index. This is for instance usefuul for predicting and plotting function   # but not very meaningful given the above example:    ggplot() +     gg(xipost)    # For ease of use we can also type    plot(xipost)    # This type of plot will show a ribbon around the mean, which viszualizes the upper and lower   # quantiles mentioned above (2.5 and 97.5%). Plotting the ribbon can be turned of using the   # \\code{ribbon} parameter    ggplot() +     gg(xipost, ribbon = FALSE)    # Much like the other geomes produced by gg we can adjust the plot using ggplot2 style   # commands, for instance    ggplot() +     gg(xipost) +     gg(xipost, mapping = aes(y = median), ribbon = FALSE, color = \"red\") }   # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a plot sample. — plotsample","title":"Create a plot sample. — plotsample","text":"Creates plot sample regular grid random start location.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a plot sample. — plotsample","text":"","code":"plotsample(spdf, boundary, x.ppn = 0.25, y.ppn = 0.25, nx = 5, ny = 5)"},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a plot sample. — plotsample","text":"spdf SpatialPointsDataFrame defining points sampled plot sample. boundary SpatialPolygonsDataFrame defining survey boundary within  points occur. x.ppn proportion x=axis included plots. y.ppn proportion y=axis included plots. nx number plots x-dimension. ny number plots y-dimension.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a plot sample. — plotsample","text":"list three components: plots: SpatialPolygonsDataFrame object containing plots sampled. dets: SpatialPointsDataFrame object containing locations points within plots. counts: dataframe containing following columns x: x-coordinates centres plots within boundary. y: y-coordinates centres plots within boundary. n: numbers points plot. area: areas plots within boundary .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/plotsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a plot sample. — plotsample","text":"","code":"# \\donttest{ # Some features require the raster package if (bru_safe_sp() &&   require(\"sp\") &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets, pch = \"+\", cex = 2) +     gg(gorillas$boundary) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a plot sample of points into one of counts. — point2count","title":"Convert a plot sample of points into one of counts. — point2count","text":"Converts plot sample locations point within plot, plot sample count within plot.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"point2count(plots, dets)"},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a plot sample of points into one of counts. — point2count","text":"plots SpatialPolygonsDataFrame object containing plots sampled. dets SpatialPointsDataFrame object containing locations points within plots.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a plot sample of points into one of counts. — point2count","text":"SpatialPolygonsDataFrame counts plot contained slot @data$n.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/point2count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a plot sample of points into one of counts. — point2count","text":"","code":"# \\donttest{ # Some features require the raster package if (bru_safe_sp() &&   require(\"sp\") &&   require(\"raster\", quietly = TRUE) &&   require(\"ggplot2\", quietly = TRUE)) {   data(gorillas, package = \"inlabru\")   plotpts <- plotsample(gorillas$nests, gorillas$boundary,     x.ppn = 0.4, y.ppn = 0.4, nx = 5, ny = 5   )   p1 <- ggplot() +     gg(plotpts$plots) +     gg(plotpts$dets) +     gg(gorillas$boundary)   countdata <- point2count(plotpts$plots, plotpts$dets)   x <- sp::coordinates(countdata)[, 1]   y <- sp::coordinates(countdata)[, 2]   count <- countdata@data$n   p2 <- ggplot() +     gg(gorillas$boundary) +     gg(plotpts$plots) +     geom_text(aes(label = count, x = x, y = y))   multiplot(p1, p2, cols = 2) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction from fitted bru model — predict.bru","title":"Prediction from fitted bru model — predict.bru","text":"Takes fitted bru object produced function bru() produces predictions given new set values model covariates original values used model fit. predictions can based R expression valid given values/covariates joint posterior estimated random effects.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# S3 method for class 'bru' predict(   object,   newdata = NULL,   formula = NULL,   n.samples = 100,   seed = 0L,   probs = c(0.025, 0.5, 0.975),   num.threads = NULL,   include = NULL,   exclude = NULL,   used = NULL,   drop = FALSE,   ...,   data = deprecated() )"},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction from fitted bru model — predict.bru","text":"object object obtained calling bru() lgcp(). newdata data.frame SpatialPointsDataFrame covariates needed prediction. formula formula right hand side defines R expression evaluate generated sample. NULL, latent hyperparameter states returned named list elements. See Details information. n.samples Integer setting number samples draw order calculate posterior statistics. default rather low provides quick approximate result. seed Random number generator seed passed inla.posterior.sample probs numeric vector probabilities values [0, 1], passed stats::quantile num.threads Specification desired number threads parallel computations. Default NULL, leaves INLA. seed != 0, overridden \"1:1\" include Character vector component labels needed predictor expression; Default: result [.vars()] predictor expression, unless expression \".\", case include=NULL, include components explicitly excluded. bru_used() methods used extract variable names, followed removal non-component names components available. exclude Character vector component labels used predictor expression. exclusion list applied list determined include parameter; Default: NULL (remove components inclusion list) used Either NULL bru_used() object, overriding include exclude. Default NULL drop logical; keep=FALSE, newdata Spatial*DataFrame, prediciton summary number rows newdata, output Spatial*DataFrame object. Default FALSE. ... Additional arguments passed inla.posterior.sample() data Use newdata instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction from fitted bru model — predict.bru","text":"data.frame, sf, Spatial* object predicted mean values summary statistics attached. Non-S4 object outputs class \"bru_prediction\" added front class list.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction from fitted bru model — predict.bru","text":"Mean value predictions accompanied standard errors, upper lower 2.5% quantiles, median, variance, coefficient variation well variance minimum maximum sample value drawn course estimating statistics. Internally, method calls generate.bru() order draw samples model. addition component names (give effect component evaluated input data), suffix _latent variable name can used directly access latent state component, suffix function _eval can used evaluate component input values expressions defined component definition , e.g. field_eval(cbind(x, y)) component defined field(coordinates, ...) (see also component_eval()). \"iid\" models mapper = bru_mapper_index(n), rnorm() used generate new realisations indices greater n.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/predict.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction from fitted bru model — predict.bru","text":"","code":"# \\donttest{ if (bru_safe_inla() &&     bru_safe_sp() &&     require(\"sp\") &&     require(\"sn\", quietly = TRUE) &&     require(\"ggplot2\", quietly = TRUE)) {    # Load the Gorilla data    data(gorillas, package = \"inlabru\")    # Plot the Gorilla nests, the mesh and the survey boundary    ggplot() +     gg(gorillas$mesh) +     gg(gorillas$nests) +     gg(gorillas$boundary)    # Define SPDE prior    matern <- INLA::inla.spde2.pcmatern(gorillas$mesh,     prior.sigma = c(0.1, 0.01),     prior.range = c(0.01, 0.01)   )    # Define domain of the LGCP as well as the model components (spatial SPDE effect and Intercept)    cmp <- coordinates ~ mySmooth(main = coordinates, model = matern) + Intercept(1)    # Fit the model, with \"eb\" instead of full Bayes   fit <- lgcp(cmp, gorillas$nests,     samplers = gorillas$boundary,     domain = list(coordinates = gorillas$mesh),     options = list(control.inla = list(int.strategy = \"eb\"))   )    # Once we obtain a fitted model the predict function can serve various purposes.   # The most basic one is to determine posterior statistics of a univariate   # random variable in the model, e.g. the intercept    icpt <- predict(fit, NULL, ~ c(Intercept = Intercept_latent))   plot(icpt)    # The formula argument can take any expression that is valid within the model, for   # instance a non-linear transformation of a random variable    exp.icpt <- predict(fit, NULL, ~ c(     \"Intercept\" = Intercept_latent,     \"exp(Intercept)\" = exp(Intercept_latent)   ))   plot(exp.icpt, bar = TRUE)    # The intercept is special in the sense that it does not depend on other variables   # or covariates. However, this is not true for the smooth spatial effects 'mySmooth'.   # In order to predict 'mySmooth' we have to define where (in space) to predict. For   # this purpose, the second argument of the predict function can take \\code{data.frame}   # objects as well as Spatial objects. For instance, we might want to predict   # 'mySmooth' at the locations of the mesh vertices. Using    vrt <- fm_vertices(gorillas$mesh, format = \"sp\")    # we obtain these vertices as a SpatialPointsDataFrame    ggplot() +     gg(gorillas$mesh) +     gg(vrt, color = \"red\")    # Predicting 'mySmooth' at these locations works as follows    mySmooth <- predict(fit, vrt, ~mySmooth)    # Note that just like the input also the output will be a SpatialPointsDataFrame   # and that the predicted statistics are simply added as columns    class(mySmooth)   head(vrt)   head(mySmooth)    # Plotting the mean, for instance, at the mesh node is straight forward    ggplot() +     gg(gorillas$mesh) +     gg(mySmooth, aes(color = mean), size = 3)    # However, we are often interested in a spatial field and thus a linear interpolation,   # which can be achieved by using the gg mechanism for meshes    ggplot() +     gg(gorillas$mesh, color = mySmooth$mean)    # Alternatively, we can predict the spatial field at a grid of locations, e.g. a   # SpatialPixels object covering the mesh    pxl <- fm_pixels(gorillas$mesh, format = \"sp\")   mySmooth2 <- predict(fit, pxl, ~mySmooth)    # This will give us a SpatialPixelDataFrame with the columns we are looking for    head(mySmooth2)   ggplot() +     gg(mySmooth2) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. fmesher fm_as_fm, fm_as_inla_mesh, fm_as_inla_mesh_segment, fm_as_lattice_2d, fm_as_mesh_1d, fm_as_mesh_2d, fm_as_segm, fm_as_sfc, fm_as_sp_crs, fm_centroids, fm_contains, fm_cprod, fm_crs, fm_CRS, fm_CRS_as_list, fm_crs_get_ellipsoid_radius, fm_crs_get_lengthunit, fm_crs_get_wkt, fm_crs_is_geocent, fm_crs_is_identical, fm_crs_oblique, fm_crs_oblique<-, fm_crs_set_ellipsoid_radius, fm_crs_set_lengthunit, fm_CRSargs, fm_CRSargs_as_list, fm_ellipsoid_radius, fm_ellipsoid_radius<-, fm_evaluate, fm_evaluator, fm_evaluator_lattice, fm_has_PROJ6, fm_identical_CRS, fm_int, fm_int_multi_sampler, fm_is_within, fm_lattice_2d, fm_length_unit, fm_length_unit<-, fm_list_as_CRS, fm_mesh_1d, fm_mesh_2d, fm_pixels, fm_proj4string, fm_segm, fm_sp_get_crs, fm_sp2segment, fm_spTransform, fm_store_points, fm_transform, fm_vertices, fm_wkt, fm_wkt_as_wkt_tree, fm_wkt_get_ellipsoid_radius, fm_wkt_get_lengthunit, fm_wkt_is_geocent, fm_wkt_predef, fm_wkt_set_ellipsoid_radius, fm_wkt_set_lengthunit, fm_wkt_tree_as_wkt, fm_wkt_tree_get_item, fm_wkt_tree_set_item, fm_wkt_unit_params","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"robins_subset — robins_subset","title":"robins_subset — robins_subset","text":"robins_subset dataset, subset full robins data set used demonstrate spatially varying trend coefficient model Meehan et al. 2019. dataset includes American Robin counts, along time, location, effort information, Audubon Christimas Bird Counts (CBC) conducted six US states 1987 2016.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"robins_subset — robins_subset","text":"","code":"robins_subset"},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"robins_subset — robins_subset","text":"data data.frame variables circle: Four-letter code CBC circle. bcr: Numeric code bird conservation region encompassing count circle. state: US state encompassing count circle. year: calendar year count conducted. std_yr: transformed year, 2016 = 0. count: number robins recorded. log_hrs: natural log party hours. lon: longitude count circle centroid. lat: latitude count circle centroid. obs: unique record identifier.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"robins_subset — robins_subset","text":"https://github.com/tmeeha/inlaSVCBC","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"robins_subset — robins_subset","text":"Meehan, T.D., Michel, N.L., Rue, H. 2019. Spatial modeling Audubon Christmas Bird Counts reveals fine-scale patterns drivers relative abundance trends. Ecosphere, 10(4), p.e02707.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/robins_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"robins_subset — robins_subset","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   data(robins_subset, package = \"inlabru\") # get the data    # plot the counts for one year of data   ggplot(robins_subset[robins_subset$std_yr == 0, ]) +     geom_point(aes(lon, lat, colour = count + 1)) +     scale_colour_gradient(low = \"blue\", high = \"red\", trans = \"log\") }"},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-wise Kronecker products — row_kron","title":"Row-wise Kronecker products — row_kron","text":"favour fmesher::fm_row_kron(). Takes two Matrices computes row-wise Kronecker product.  Optionally applies row-wise weights /applies additional 0/1 row-wise Kronecker matrix product.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-wise Kronecker products — row_kron","text":"","code":"row_kron(M1, M2, repl = NULL, n.repl = NULL, weights = NULL)"},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-wise Kronecker products — row_kron","text":"M1 matrix can transformed sparse Matrix. M2 matrix can transformed sparse Matrix. repl optional index vector.  entry, specifies replicate row belongs , sense used INLA::inla.spde.make.n.repl maximum replicate index, sense used INLA::inla.spde.make.(). weights Optional scaling weights applied row-wise resulting matrix.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-wise Kronecker products — row_kron","text":"Matrix::sparseMatrix object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/row_kron.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Row-wise Kronecker products — row_kron","text":"Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from an inhomogeneous Poisson process — sample.lgcp","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"function provides point samples one- two-dimensional inhomogeneous Poisson processes. log intensity provided via values nodes inla.mesh.1d inla.mesh object. mesh nodes log intensity assumed linear.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"sample.lgcp(   mesh,   loglambda,   strategy = NULL,   R = NULL,   samplers = NULL,   ignore.CRS = FALSE )"},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"mesh INLA::inla.mesh object loglambda vector matrix; vector log intensities mesh vertices (higher order basis functions, e.g. inla.mesh.1d meshes, loglambda given mesh$m basis function weights rather values mesh$n vertices) single scalar expanded vector appropriate length. matrix supplied, one process sample column produced. strategy relevant 2D meshes. One 'triangulated', 'rectangle', 'sliced-spherical', 'spherical'. 'rectangle' method valid CRS-less flat 2D meshes. NULL 'auto', likely fastest method chosen; 'rectangle' flat 2D meshes CRS, 'sliced-spherical' CRS 'longlat' meshes, 'triangulated' meshes. R Numerical value applicable spherical geographical meshes. interpreted R equivalent Earth radius, km, used scale lambda intensity. CRS enabled meshes, default 6371. CRS-less spherical meshes, default 1. samplers SpatialPolygonsDataFrame inla.mesh object. Simulated points fall outside polygons discarded. ignore.CRS logical; TRUE, ignore CRS information mesh. Default FALSE. affects R permitted values strategy.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"data.frame (1D case), SpatialPoints (2D flat 3D spherical surface cases) SpatialPointsDataFrame (2D/3D surface cases multiple samples). multiple samples, data.frame output column 'sample' giving index sample. object point locations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"2D processes sphere R parameter can used adjust sphere's radius implied mesh. intensity high standard strategy \"spherical\" can cause memory issues. Using \"sliced-spherical\" strategy can help case. crs-less meshes R2: Lambda interpreted raw coordinate system. Output NA CRS. crs-less meshes S2: Lambda raw units, scaling mesh radius R, specified. Output given domain mesh, NA CRS. crs meshes R2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh. crs meshes S2: Lambda interpreted per km^2, scaling globe Earth radius 6371 km, R, specified. Output given CRS mesh.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"Daniel Simpson dp.simpson@gmail.com (base rectangle spherical algorithms), Fabian E. Bachl bachlfab@gmail.com (inclusion inlabru, sliced spherical sampling), Finn Lindgren finn.lindgren@gmail.com (extended CRS support, triangulated sampling)","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sample.lgcp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from an inhomogeneous Poisson process — sample.lgcp","text":"","code":"# \\donttest{ # The INLA package is required if (bru_safe_inla() &&   bru_safe_sp() &&   require(\"sp\")) {   vertices <- seq(0, 3, by = 0.1)   mesh <- fm_mesh_1d(vertices)   loglambda <- 5 - 0.5 * vertices   pts <- sample.lgcp(mesh, loglambda)   pts$y <- 0   plot(vertices, exp(loglambda), type = \"l\", ylim = c(0, 150))   points(pts, pch = \"|\") }  # }  # \\donttest{ # The INLA package is required if (bru_safe_inla() &&   require(ggplot2, quietly = TRUE) &&   bru_safe_sp() &&   require(\"sp\")) {   data(\"gorillas\", package = \"inlabru\")   pts <- sample.lgcp(gorillas$mesh,     loglambda = 1.5,     samplers = gorillas$boundary   )   ggplot() +     gg(gorillas$mesh) +     gg(pts) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":null,"dir":"Reference","previous_headings":"","what":"Seal pups — seals","title":"Seal pups — seals","text":"single transect aereal photo seal pup survey Greenland Sea","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Seal pups — seals","text":"","code":"data(seals_sp)"},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Seal pups — seals","text":"data contain objects: points: SpatialPointsDataFrame Center locations photos mesh: fm_mesh_2d enclosing plane's transect ice.data: SpatialPointsDataFrame MODIS ice concentration estimates ice.cv: covdata object interpolated ice coverage data","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Seal pups — seals","text":"Martin Jullum Martin.Jullum@nr.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Seal pups — seals","text":"Oigard, T. . (2013) pup production quotas: current status harp seals Greenland Sea. ICES Journal Marine Science, doi.10.1093/icesjms/fst155. Oigard, T. . (2014) Current status hooded seals Greenland Sea. Victims climate change predation?, Biological Conservation , 2014, 172, 29 - 36.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/seals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Seal pups — seals","text":"","code":"if (require(ggplot2, quietly = TRUE)) {   ggplot() +     geom_fm(data = seals_sp$mesh) +     gg(seals_sp$points) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":null,"dir":"Reference","previous_headings":"","what":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Blue red shrimp Western Mediterranean Sea.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"data(shrimp)"},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"list objects: hauls: sf object containing haul locations mesh: fm_mesh_2d object containing Delaunay triangulation mesh (type discretization continuous space) covering haul locations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, Maria Grazia. Personal communication.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"Pennino, M. G., Paradinas, ., Munoz, F., Illian, J.,Quilez-Lopez, ., Bellido, J.M., Conesa, D. Accounting preferential sampling species distribution models. Ecology Evolution,  Press.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/shrimp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Blue and red shrimp in the Western Mediterranean Sea — shrimp","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   data(shrimp_sf, package = \"inlabru\")   ggplot() +     geom_fm(data = shrimp_sf$mesh) +     gg(shrimp_sf$hauls, aes(col = catch)) +     coord_sf(datum = fm_crs(shrimp_sf$hauls)) } #> Warning: data set ‘shrimp_sf’ not found #> Error: object 'shrimp_sf' not found # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame to SpatialLinesDataFrame — sline","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"line 2D space defined start end point, associated 2D coordinates. function takes data.frame input assumes row defines line space. order , data frame must least four columns start.cols end.cols parameters must used point names columns define start end coordinates line. data converted SpatialLinesDataFrame DF. coordinate reference system crs provided attached DF. also .crs provided, coordinate system DF transfromed accordingly. Additional columns input data, e.g. covariates, retained attached DF.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"sline(   data,   start.cols,   end.cols,   crs = fm_crs(),   to.crs = NULL,   format = c(\"sp\", \"sf\") )"},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"data data.frame start.cols Character array poitning columns data hold start points lines end.cols Character array poitning columns data hold end points lines crs Coordinate reference system original data .crs Coordinate reference system SpatialLines ouput. format Format output object. Either \"sp\" (default) \"sf\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"sp::SpatialLinesDataFrame sf::sf","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/sline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame to SpatialLinesDataFrame — sline","text":"","code":"# \\donttest{ # Create a data frame defining three lines lns <- data.frame(   xs = c(1, 2, 3), ys = c(1, 1, 1), # start points   xe = c(2, 3, 4), ye = c(2, 2, 2) ) # end points   # Conversion to sf without CRS spl <- sline(lns,   start.cols = c(\"xs\", \"ys\"),   end.cols = c(\"xe\", \"ye\"),   format = \"sf\" )  if (require(ggplot2, quietly = TRUE)) {   # Plot the lines   ggplot() +     gg(spl) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"Spatstat point pattern objects consist points observation windows. function uses SpatialPoints object SpatialPolygon object generate points window. Lastly, ppp() function called create ppp object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"spatial.to.ppp(points, samplers)"},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"points SpatialPoints[DataFrame] object describing point pattern. samplers SpatialPolygons[DataFrame] object describing observation window.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"spatstat spatstat ppp object","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spatial.to.ppp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert SpatialPoints and boundary polygon to spatstat ppp object — spatial.to.ppp","text":"","code":"# \\donttest{ if (require(\"spatstat.geom\") &&   bru_safe_sp() &&   require(\"sp\")) {   # Load Gorilla data    data(\"gorillas\", package = \"inlabru\")    # Use nest locations and survey boundary to create a spatstat ppp object    gp <- spatial.to.ppp(gorillas$nests, gorillas$boundary)   class(gp)    # Plot it    plot(gp) } #> Loading required package: spatstat.geom #> Loading required package: spatstat.data #>  #> Attaching package: ‘spatstat.data’ #> The following object is masked _by_ ‘.GlobalEnv’: #>  #>     gorillas #> The following object is masked from ‘package:inlabru’: #>  #>     gorillas #> Loading required package: spatstat.univar #> spatstat.univar 3.0-1 #> spatstat.geom 3.3-2 #>  #> Attaching package: ‘spatstat.geom’ #> The following objects are masked from ‘package:raster’: #>  #>     area, rotate, shift #> Warning: data contain duplicated points  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Calculate posterior distribution range, log(range), variance, log(variance) parameter model's SPDE component. Can also plot Matern correlation covariance function. inla.spde.result.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"spde.posterior(result, name, what = \"range\")"},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"result object inheriting inla. name Character stating name SPDE effect, see names(result$summary.random). One \"range\", \"log.range\", \"variance\", \"log.variance\", \"matern.correlation\" \"matern.covariance\".","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"prediction object.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"Finn Lindgren Finn.Lindgren@ed.ac.uk","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spde.posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posteriors of SPDE hyper parameters and Matern correlation or covariance function. — spde.posterior","text":"","code":"# \\donttest{ if (bru_safe_inla() && require(ggplot2, quietly = TRUE)) {    # Load 1D Poisson process data    data(Poisson2_1D, package = \"inlabru\")     # Take a look at the point (and frequency) data    ggplot(pts2) +     geom_histogram(aes(x = x), binwidth = 55 / 20, boundary = 0, fill = NA, color = \"black\") +     geom_point(aes(x), y = 0, pch = \"|\", cex = 4) +     coord_fixed(ratio = 1)    # Fit an LGCP model with  and SPDE component    x <- seq(0, 55, length.out = 20)   mesh1D <- fm_mesh_1d(x, boundary = \"free\")   mdl <- x ~ spde1D(x, model = INLA::inla.spde2.matern(mesh1D)) + Intercept(1)   fit <- lgcp(mdl, data = pts2, domain = list(x = mesh1D))    # Calculate and plot the posterior range    range <- spde.posterior(fit, \"spde1D\", \"range\")   plot(range)    # Calculate and plot the posterior log range    lrange <- spde.posterior(fit, \"spde1D\", \"log.range\")   plot(lrange)    # Calculate and plot the posterior variance    variance <- spde.posterior(fit, \"spde1D\", \"variance\")   plot(variance)    # Calculate and plot the posterior log variance    lvariance <- spde.posterior(fit, \"spde1D\", \"log.variance\")   plot(lvariance)    # Calculate and plot the posterior Matern correlation    matcor <- spde.posterior(fit, \"spde1D\", \"matern.correlation\")   plot(matcor)    # Calculate and plot the posterior Matern covariance    matcov <- spde.posterior(fit, \"spde1D\", \"matern.covariance\")   plot(matcov) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"polygon can described sequence points defining polygon's boundary. given sequence (anti clockwise!) function creates SpatialPolygonsDataFrame sf holding polygon decribed. default, first two columns data assumed define x y coordinates points. behaviour can changed using cols parameter, points names columns holding coordinates. coordinate reference system resulting spatial polygon can set via crs parameter. Posterior conversion different CRS supported using .crs parameter.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"spoly(   data,   cols = colnames(data)[1:2],   crs = fm_crs(),   to.crs = NULL,   format = c(\"sp\", \"sf\") )"},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"data data.frame points describing boundary polygon (unique points, holes) cols Column names x y coordinates within data crs Coordinate reference system points .crs Coordinate reference system SpatialLines/sf ouput. format Format output object. Either \"sp\" (default) \"sf\"","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"sp::SpatialPolygonsDataFrame sf::sf","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/spoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a data.frame of boundary points into a SpatialPolgonsDataFrame — spoly","text":"","code":"# \\donttest{ # Create data frame of boundary points (anti clockwise!) pts <- data.frame(   x = c(1, 2, 1.7, 1.3),   y = c(1, 1, 2, 2) )  # Convert to sf pol <- spoly(pts, format = \"sf\")  if (require(ggplot2, quietly = TRUE)) {   # Plot it!   ggplot() +     gg(pol) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for an inlabru fit — summary.bru","title":"Summary for an inlabru fit — summary.bru","text":"Takes fitted bru object produced bru() lgcp() creates various summaries .","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# S3 method for class 'bru' summary(object, verbose = FALSE, ...)  # S3 method for class 'summary_bru' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for an inlabru fit — summary.bru","text":"object object obtained bru() lgcp() call verbose logical; TRUE, include details component definitions. FALSE, show basic component definition information. Default: FALSE ... arguments passed component summary functions, see summary.component(). x object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary for an inlabru fit — summary.bru","text":"","code":"# \\donttest{ if (bru_safe_inla()) {   # Simulate some covariates x and observations y   input.df <- data.frame(x = cos(1:10))   input.df <- within(input.df, {     y <- 5 + 2 * x + rnorm(10, mean = 0, sd = 0.1)   })    # Fit a Gaussian likelihood model   fit <- bru(y ~ x + Intercept(1), family = \"gaussian\", data = input.df)    # Obtain summary   fit$summary.fixed } #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.036746 0.03526492   1.966278 2.036747   2.107212 2.036746 #> Intercept 4.984820 0.02493250   4.934999 4.984821   5.034640 4.984821 #>                    kld #> x         5.770652e-06 #> Intercept 5.770744e-06   if (bru_safe_inla()) {   # Alternatively, we can use the like() function to construct the likelihood:    lik <- like(family = \"gaussian\",               formula = y ~ x + Intercept,               data = input.df)   fit <- bru(~ x + Intercept(1), lik)   fit$summary.fixed } #>               mean         sd 0.025quant 0.5quant 0.975quant     mode #> x         2.036746 0.03526302   1.966282 2.036747   2.107208 2.036746 #> Intercept 4.984820 0.02493116   4.935002 4.984821   5.034637 4.984821 #>                    kld #> x         5.776789e-06 #> Intercept 5.776880e-06  # An important addition to the INLA methodology is bru's ability to use # non-linear predictors. Such a predictor can be formulated via like()'s # \\code{formula} parameter. The z(1) notation is needed to ensure that # the z component should be interpreted as single latent variable and not # a covariate:  if (bru_safe_inla()) {   z <- 2   input.df <- within(input.df, {     y <- 5 + exp(z) * x + rnorm(10, mean = 0, sd = 0.1)   })   lik <- like(     family = \"gaussian\", data = input.df,     formula = y ~ exp(z) * x + Intercept   )   fit <- bru(~ z(1) + Intercept(1), lik)    # Check the result (z posterior should be around 2)   fit$summary.fixed } #>               mean          sd 0.025quant 0.5quant 0.975quant     mode #> z         1.997146 0.006202177   1.984753 1.997146   2.009539 1.997146 #> Intercept 4.990304 0.032308627   4.925743 4.990305   5.054862 4.990304 #>                    kld #> z         5.775025e-06 #> Intercept 5.774885e-06 # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Print inlabru options — summary.bru_options","title":"Print inlabru options — summary.bru_options","text":"Print inlabru options","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print inlabru options — summary.bru_options","text":"","code":"# S3 method for class 'bru_options' summary(   object,   legend = TRUE,   include_global = TRUE,   include_default = TRUE,   ... )  # S3 method for class 'summary_bru_options' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print inlabru options — summary.bru_options","text":"object bru_options object summarised legend logical; TRUE, include explanatory text, Default: TRUE include_global logical; TRUE, include global override options include_default logical; TRUE, include default options ... parameters, currently ignored x summary_bru_options object printed","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.bru_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print inlabru options — summary.bru_options","text":"","code":"if (interactive()) {   options <- bru_options(verbose = TRUE)    # Don't print options only set in default:   print(options, include_default = FALSE)    # Only include options set in the object:   print(options, include_default = FALSE, include_global = FALSE) }"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise components — summary.component","title":"Summarise components — summary.component","text":"Summarise components","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise components — summary.component","text":"","code":"# S3 method for class 'component' summary(object, ..., depth = Inf, verbose = TRUE)  # S3 method for class 'component_list' summary(object, verbose = TRUE, ...)  # S3 method for class 'component' print(x, ...)  # S3 method for class 'component_list' print(x, ...)  # S3 method for class 'bru_subcomponent' format(x, verbose = TRUE, ..., label.override = NULL)  # S3 method for class 'bru_subcomponent' summary(object, verbose = TRUE, ..., label.override = NULL)  # S3 method for class 'bru_subcomponent' print(x, verbose = TRUE, ..., label.override = NULL)  # S3 method for class 'bru_input' format(x, verbose = TRUE, ..., label.override = NULL, type = NULL)  # S3 method for class 'bru_input' summary(object, verbose = TRUE, ..., label.override = NULL)  # S3 method for class 'bru_input' print(x, verbose = TRUE, ..., label.override = NULL)  # S3 method for class 'summary_component' print(x, ...)  # S3 method for class 'summary_component_list' print(x, ...)  # S3 method for class 'summary_bru_subcomponent' print(x, ...)  # S3 method for class 'summary_bru_input' print(x, ...)"},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise components — summary.component","text":"object Object summarised. ... Passed summary methods. depth depth expand component mapper. Default Inf, traverse entire mapper tree. verbose logical; TRUE, includes details component definitions. FALSE, show basic component definition information.  Default TRUE. x summary object printed. label.override character; NULL, use label instead object's label. type character; non-NULL, added output'; label = type(input).","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/summary.component.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarise components — summary.component","text":"Fabian E. Bachl bachlfab@gmail.com Finn Lindgren finn.lindgren@gmail.com","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated 1D animal group locations and group sizes — toygroups","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data set serves teach concept modelling species gather groups grouping behaviour depends space.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"data(toygroups)"},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"data list contains elements: groups: data.frame group locations x size size df.size: IGNORE df.intensity: data.frame Poisson process intensity d.lambda locations x df.rate: data.frame locations x associated rate parameterized exponential distribution group sizes drawn.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toygroups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated 1D animal group locations and group sizes — toygroups","text":"","code":"# \\donttest{ if (require(ggplot2, quietly = TRUE)) {   # Load the data    data(\"toygroups\", package = \"inlabru\")    # The data set is a simulation of animal groups residing in a 1D space. Their   # locations in x-space are sampled from a Cox process with intensity    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda))    # Adding the simulated group locations to this plot we obtain    ggplot(toygroups$df.intensity) +     geom_line(aes(x = x, y = g.lambda)) +     geom_point(data = toygroups$groups, aes(x, y = 0), pch = \"|\")    # Each group has a size mark attached to it.   # These group sizes are sampled from an exponential distribution   # for which the rate parameter depends on the x-coordinate    ggplot(toygroups$groups) +     geom_point(aes(x = x, y = size))    ggplot(toygroups$df.rate) +     geom_line(aes(x, rate)) }  # }"},{"path":"https://inlabru-org.github.io/inlabru/reference/toypoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated 2D point process data — toypoints","title":"Simulated 2D point process data — toypoints","text":"data set serves example basic inlabru.","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toypoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated 2D point process data — toypoints","text":"","code":"data(toypoints)"},{"path":"https://inlabru-org.github.io/inlabru/reference/toypoints.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated 2D point process data — toypoints","text":"data list contains elements: points sf object point locations z measurements mesh fm_mesh_2d object boundary sf polygon denting region interest pred_locs sf object prediction point locations","code":""},{"path":"https://inlabru-org.github.io/inlabru/reference/toypoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated 2D point process data — toypoints","text":"","code":"if (require(\"ggplot2\")) {   ggplot() +     fmesher::geom_fm(data = toypoints$mesh, alpha = 0) +     geom_sf(data = toypoints$boundary, fill = \"blue\", alpha = 0.1) +     geom_sf(data = toypoints$points, aes(color = z)) +     scale_color_viridis_c() }"},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-development-version","dir":"Changelog","previous_headings":"","what":"inlabru (development version)","title":"inlabru (development version)","text":"Remove unneeded \"list\" class inheritance solitary classes (version 2.11.1.9001) Expand summary print method class coverage (version 2.11.1.9002) Remove ggmap support (version 2.11.1.9002) Move sp Imports Suggests. Component definitions using coordinates input require either sp::coordinates sp already loaded e.g. library(sp) (version 2.11.1.9003) Use bru_safe_inla(multicore=TRUE) bru() allow multicore non-interactive mode. Fixes regression bug disabled multicore non-interactive sessions. (version 2.11.1.9004) Reduced amount diagnostic messages bru_safe_inla() (version 2.11.1.9005) Add sf version mrsea_sf data set (version 2.11.1.9006) Add sf output format support sline spoly (version 2.11.1.9006) Convert shrimp data set sf format (version 2.11.1.9007)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2111","dir":"Changelog","previous_headings":"","what":"inlabru 2.11.1","title":"inlabru 2.11.1","text":"CRAN release: 2024-07-01","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-11-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.11.1","text":"Fix documentation link issues spotted local github package checks Work around invalid geometry map data used Spatially Varying Coefficients vignette","code":""},{"path":[]},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"new-features-2-11-0","dir":"Changelog","previous_headings":"","what":"New features","title":"inlabru 2.11.0","text":"Add support scale parameter like(). Add support special response objects like inla.mdata() inla.surv(), INLA version > 24.06.02 (mdata) > 24.06.26 (surv) available (version 2.10.1.9011) New toypoints example data set, basic modelling examples (version 2.10.1.9003)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-2-11-0","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru 2.11.0","text":"Updated convergence plots, reducing random effect aspects summary statistics, improving speed visual coherence (version 2.10.1.9004) Add options bru_convergence_plot() control number iterations shown, optionally show initial values stored version (version 2.10.1.9005) Switch timing mechanism Sys.time() proc.time() capture CPU time instead elapsed clock time. Added bru_timings() method extract timings safely fitted bru object (version 2.10.1.9007 2.10.1.9010) Add verbosity level information bru log data structure, allowing filtered log extraction flexible log display (version 2.10.1.9012)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-11-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.11.0","text":"Fix regression bug \"bym\" model support, latent state size wasn’t correctly handled mapper system (version 2.10.1.9002) Add filter limit mapper construction components used predictor expression, avoid unused components breaking initialisation. allows easier testing multi-likelihood models (version 2.10.1.9006) Improved backwards compatibility support sp data input family = \"cp\" (version 2.10.1.9008)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"deprecated-methods-2-11-0","dir":"Changelog","previous_headings":"","what":"Deprecated methods","title":"inlabru 2.11.0","text":"Deprecated (since 2.9.0) method ipoints(samplers, domain) longer available. Use fmesher::fm_int(domain, samplers) instead. allow_latent, include_latent arguments like() deprecated favour general bru_used() framework, auto-detects component effects latent effects used predictor expression. deprecated (since 2.8.0) cprod() method now gives warning removed future version. Use fmesher::fm_cprod() instead. integration_weight_aggregation method removed (deprecated since 2.8.0). Use fmesher::fm_vertex_projection() instead. mesh_triangle_integration method removed (deprecated since 2.8.0). Use fmesher::fm_int() instead. Old use bru_mapper.default() define new mapper classes disabled (deprecated since 2.7.0). Use bru_mapper_define() instead. Deprecated (since 2.8.0) methods .inside(), vertices.inla.mesh(), pixels() disabled. Use fmesher::fm_is_within(), fmesher::fm_vertices(), fmesher::fm_pixels() instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2101","dir":"Changelog","previous_headings":"","what":"inlabru 2.10.1","title":"inlabru 2.10.1","text":"CRAN release: 2023-12-21","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-2-10-1","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru 2.10.1","text":"Add new web article ZIP/ZAP models (zero inflated Poisson models) non-zero probability modelled separate predictor predictor Poisson model parameter: https://inlabru-org.github.io/inlabru/articles/zip_zap_models.html. (Thanks Dmytro Perepolkin)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-and-dependency-simplification-2-10-1","dir":"Changelog","previous_headings":"","what":"Bug fixes and dependency simplification","title":"inlabru 2.10.1","text":"Remove dependence ggpolypath package, ggplot2::fortify.SpatialPolygons/DataFrame() methods deprecated ggplot2 version 3.4.4. Code using gg.SpatialPolygons() together coord_fixed()/coord_equal() coordinate axis control needs use coord_sf() instead. Detect need vectorised parameters bru_forward_transformation allow bru_mapper_marginal applied e.g. spatially varying parameters. (version 2.10.0.9001) Detect terra version >= 1.7-66 removes need detecting special cases (nrow() == 1 terra::nlyr(data) == 1). Workaround code used versions < 1.7-66. (version 2.10.0.9002) (Thanks Robert J. Hijmans)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2100","dir":"Changelog","previous_headings":"","what":"inlabru 2.10.0","title":"inlabru 2.10.0","text":"CRAN release: 2023-10-29","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-2-10-0","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru 2.10.0","text":"Add new ibm_simplify() generic handle mapper simplification generally; needed properly support non-linear component mappers. (version 2.9.0.9004) Add new bru_mapper_marginal() mapper class can used part component mapper pipelines. (version 2.9.0.9004) Add new ibm_eval2() generic computes evaluation Jacobian, avoiding double-computing Jacobian, practical. (version 2.9.0.9005) Add new bru_timings_plot() function plots time used nonlinear iteration (version 2.9.0.9007) Speed bru_fill_missing() (orders magnitude) changing method finding nearest available data point. (version 2.9.0.9011) Add new bru_mapper_shift() mapper class works like bru_mapper_scale() additive shifts instead multiplicative scaling. (version 2.9.0.9012) Added checks invalid component predictor evaluations, help catch user errors sooner, informative messages. (version 2.9.0.9013) Expand bru_mapper_matrix, previously used component model = \"fixed\", allow integer indexing addition previous factor/character-indexing. (version 2.9.0.9014)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-10-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.10.0","text":"is_linear flag wasn’t correctly set bru_mapper_logsumexp mappers. Since previous versions accept non-linear component mappers, unlikely affected user code. (Fixed version 2.9.0.9001) Improved error messages missing incomplete LGCP domain specification. (version 2.9.0.9002 2.9.0.9006) Allow NULL automatic component usage detection. (version 2.9.0.9003) Corrected crs information gorillas$plotsample$counts gorillas_sf$plotsample$counts +units=m +units=km. (version 2.9.0.9010) geometry information counts unlikely used examples analysis code, problem immediately obvious; plotting geometric operations use crs information heve completely wrong, detected now code uses crs information . Thanks Dmytro Perepolkin reporting issue #205 Fix problem bru_fill_missing() cases input data object also missing values. (version 2.9.0.9011) Make eval_spatial() transform coordinates crs input data, SpatRaster sf inputs, allow different crs specifications. (version 2.9.0.9012)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-290","dir":"Changelog","previous_headings":"","what":"inlabru 2.9.0","title":"inlabru 2.9.0","text":"CRAN release: 2023-08-28","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-2-9-0","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru 2.9.0","text":"Conversion code use fmesher mesh geometry handling; interface supports existing objects methods. See https://inlabru-org.github.io/fmesher/articles/inla_conversion.html information. General speed improvements, see details. Added gg.sf() method. Add experimental support stars via eval_spatial(). (version 2.8.0.9007) Move sp package ‘Depends’ ‘Imports’. means user code either use sp:: library(\"sp\") access sp methods. bru_safe_sp() helper function can used check safe sp package configuration transition rgdal sf, needed may run systems sp installations older “2.0-0” sp::get_evolution_status() < 2. (version 2.8.2011) Now preserves previous log output using bru_rerun(), bru_log() now set S3 methods, supporting extracting full inlabru log well bru-object specific logs (version 2.8.0.9008). Note: version 2.9.0, use bru_log() access global log, bru_log(fit) access stored estimation log. version 2.8.0, bru_log() deprecated alias bru_log_message(). running 2.8.0 earlier, use bru_log_get() access global log, cat(fit$bru_iinla$log, sep = \"\\n\") print stored estimation object log.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-and-speed-improvements-2-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes and speed improvements","title":"inlabru 2.9.0","text":"Covariate object component inputs type SpatialPolygonsDataFrame automatically passed eval_spatial(). logic now changed object eval_spatial() method trigger call eval_spatial(). See ?input_eval information. (version 2.8.0.9001) fm_crs_is_null(), fm_transform() now supports oblique fm_crs CRS objects, .na() methods fm_crs inla.CRS classes added. (version 2.8.0.9003) Significant speed predict() using quantile(..., names = FALSE). (version 2.8.0.9004) Improved row_kron() code, causing speedups factor 2-30 randomised test cases. (version 2.8.0.9005) Removed incorrect code sf method eval_spatial(), causing failure extracting multiple layers single call. (version 2.8.0.9007) Improved handling posterior sample variable extraction generate() predict(). Now much faster large models. (version 2.8.0.9009) Fixed linearisation issue using *_latent form component. (version 2.8.0.9015) Workaround equivalent textually different CRS/WKT information bru_fill_missing(). (version 2.8.0.9016, fixes #200)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"deprecation-of-old-functions-2-9-0","dir":"Changelog","previous_headings":"","what":"Deprecation of old functions","title":"inlabru 2.9.0","text":"eval_SpatialDF removed, deprecated since 2.8.0. See eval_spatial instead. stransform, ibm_amatrix, ibm_valid_input removed, deprecated since 2.7.0. See fm_transform ibm_jacobian instead. bru_mapper_offset, deprecated since 2.6.0 now returns pure bru_mapper_const object, bru_mapper_offset ibm_* methods removed. init.tutorial removed, deprecated since 2.5.0 generate.inla predict.inla removed, deprecated since 2.1.0","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-280","dir":"Changelog","previous_headings":"","what":"inlabru 2.8.0","title":"inlabru 2.8.0","text":"CRAN release: 2023-06-20","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-updates-2-8-0","dir":"Changelog","previous_headings":"","what":"Feature updates","title":"inlabru 2.8.0","text":"iterative inla method given sharper internal inla() optimisation criteria iterations (thanks Haavard Rue), relaxed nonlinear iteration stopping criterion; default bru_method$rel_tol values changed 1 10 percent change. iterations terminated latent hyper-parameter mode changes fullfil |change|/SD < rel_tol, non-linear line search inactive. seems strike useful balance different optimisation criteria, allowing iterations converge faster also detect convergence sooner. logic components needed predictor expression (like() generate()/predict()) updated possible extract list components expression . user can override default necessary, using include/exclude arguments. bru_used() methods used guess needed component names, applied right-hand side formula arguments. allow_latent argument like() deprecated favour include_latent (default auto-detected use _latent _eval). internal information storage handled new bru_used() methods, can also used directly user supplied via used argument like()/generate()/predict(). Add fm_int() integration methods, replacing old ipmaker() ipoints() methods. Supports sf sp sampler objects. Add fm_pixels() methods gridded points. old pixels() method now calls fm_pixels(..., format = \"sp\") eval_spatial support sf objects (point--polygon data lookups) Allow precomputed spatial covariates data point process observations Add edge|int|ext.linewidth arguments gg.inla.mesh #188 Rename predict() generate() data arguments newdata, better compatibility predict() methods. old argument name still accepted, give warning. Code name data argument affected. Note: Coordinate names Spatial* objects inconsistently available predictor expression evaluation. However, due internal conversions might inadvertently change names, can relied , longer made available predictor expression. side effect, change also speeds bru() runs around factor 2, since avoids converting Spatial* regular data.frame time-sensitive core evaluation code. need access raw coordinate values, use explicit calls sp::coordinates(.data.) (e.g. custom spatial covariate evaluation.). possible, use built-covariate evaluation method, eval_spatial(), either implicitly comp(covariate, ...) explicitly, comp(eval_spatial(covariate, = .data.), ...), handles crs information correctly. Also consider transitioning sp sf data storage, using geometry instead raw coordinates.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-and-dependency-updates-2-8-0","dir":"Changelog","previous_headings":"","what":"Bug and dependency updates","title":"inlabru 2.8.0","text":"Remove rgdal maptools dependencies #178 Add bru_safe_sp() check sp can used safely (checks rgdal availability sp evolution status, optionally forcing use sf) #178 Remove PROJ4 support #178 Change rgl.* functions *3d. Thanks Duncan Murdoch #181 Speed ibm_jacobian.bru_mapper_harmonics large models Add workarounds inconsistent polygon orientation resulting sf::st_* calls don’t account geos canonical representation CW, whereas canonical Simple Features representation CCW. See https://github.com/r-spatial/sf/issues/2096","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-270","dir":"Changelog","previous_headings":"","what":"inlabru 2.7.0","title":"inlabru 2.7.0","text":"CRAN release: 2022-12-02","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-overview-2-7-0","dir":"Changelog","previous_headings":"","what":"Feature overview","title":"inlabru 2.7.0","text":"Added support sf terra inputs methods Expanded geometry mesh handling methods Expanded bru_mapper() system Added convergence diagnostics plot bru_convergence_plot()","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"feature-details-2-7-0","dir":"Changelog","previous_headings":"","what":"Feature details","title":"inlabru 2.7.0","text":"Allow NA input default 1D mappers generate effect zero, like inla(). New expanded methods fm_crs(), fm_CRS(), fm_transform(), fm_ellipsoid_radius(), fm_length_unit() support sf objects. fm_crs() extraction method also supports terra objects. bru_fill_missing() now supports terra SpatRaster data sf locations. New experimental methods fm_evaluator() fm_evaluate(), replacing INLA inla.mesh.projector inla.mesh.project methods. Experimental integration support sphere globe meshes. Allow sf input family=\"cp\" models. bru_mapper() method updates; Deprecated ibm_amatrix() names() methods, replaced ibm_jacobian() ibm_names(). Introduced bru_mapper_pipe(), used link mappers sequence. Introduced bru_mapper_aggregate() bru_mapper_logsumexp(), used blockwise weighted sums log-sum-exp mappings, output[k] = sum(weights[block==k]*state[block==k]))) output[k] = log(sum(weights[block==k]*exp(state[block==k]))), optional weight normalisation within block. Allows providing weights log-weights, uses block-wise shifts avoid potential overflow. summary methods bru_mapper objects (summary.bru_mapper()) Removed methods argument bru_mapper_define(). Implementations register S3 methods instead.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-7-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.7.0","text":"Remove unused spatstat.core dependency. Fixes #165 Fixed issue plain mapper evaluation ibm_eval.default() ibm_eval.bru_mapper_collect() methods, return zeros instead intended values. main component evaluation estimation code directly affected based bru_mapper_multi() class methods rely Jacobians instead. bug therefore mainly impacted future, yet supported nonlinear mapper extensions. Fix eval_spatial.SpatRaster; Work around inconsistent logic terra::extract(..., layer) length(layer)==1 nrow()==1. Fixes #169 Add indexed logical option bru_mapper_factor(), allow factor inputs mapped index values, needed group replicate. Fixes #174","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-260","dir":"Changelog","previous_headings":"","what":"inlabru 2.6.0","title":"inlabru 2.6.0","text":"CRAN release: 2022-10-24","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-6-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.6.0","text":"Add bru_get_mapper generic, associated methods inla.spde inla.rgeneric objects. allows inlabru automatically extract appropriate bru_mapper object model component, can used hook external packages implementing new INLA object classes. Add weights argument like(), likelihood-specific log-likelihood weights, passed INLA::inla() weights argument. Evaluated data context. <component>_eval() methods available predictor expressions now handle optional scaling weights, like ordinary component effect evaluation. Add terra support covariate inputs component *_layer arguments now evaluated data context, allow dynamic layer selection spatial raster covariates. new generic eval_spatial() provides support grid/pixel based Spatial*DataFrame evaluation, SpatRaster. Expanded support progress. New vignettes bru_mapper system, component definitions, prediction_scores General overhaul bru_mapper linearised predictor system, prepare new features. Add ibm_eval generic evaluating mappers given states. Add bru_mapper_taylor, used internal mapper linearised mappers. ibm_eval aimed future support nonlinear mappers. Associated new generic methods: ibm_{is_linear,jacobian,linear}. New mapper implementations use ibm_jacobian instead ibm_amatrix. allows defining linearised mapper via ibm_eval(input, state0) + ibm_jacobian(input, state0) %*% (state - state0). New mapper class bru_mapper_const, replaces bru_mapper_offset. bru_mapper_offset now deprecated produce warnings.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.6.0","text":"Enable datum/ensemble container ellipsoid information, support epsg:4326. Fixes #154 Make duplicated component names error instead warning. Relates #155 Fix Tsparse assumptions row_kron prepare Matrix 1.5-2. Fixes #162","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-253","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.3","title":"inlabru 2.5.3","text":"CRAN release: 2022-09-05","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-5-3","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.3","text":"Add bru_mapper_harmonics mapper cos sin basis sets. Allow predict() input data list. Allow arbitrary quantile summaries predict() Remove cv, var, smin, smax summaries predict() Add mean.mc_std_err sd.mc_std_err output predict() Add robins_subset data set associated variable coefficient web vignette","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-5-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.3","text":"Propagate multi-likelihood -matrix information instead recomputing. Fixes iteration issue bym2 bru_mapper_collect models. Turn predictor summaries iterations allow inla.mode=\"classic\" use proper line search. Avoid deprecated Matrix (>=1.4-2) class coercion methods Work around lack full Matrix ModelMatrix support unique method. Fixes #145","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-252","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.2","title":"inlabru 2.5.2","text":"CRAN release: 2022-03-30 robust package checks robust namespace INLA availability checks Add package vignette links website examples","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-251","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.1","title":"inlabru 2.5.1","text":"Revert R language features compatible R 4.0.5 Use strategy=\"gaussian\" iterations.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-250","dir":"Changelog","previous_headings":"","what":"inlabru 2.5.0","title":"inlabru 2.5.0","text":"CRAN release: 2022-03-21","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-5-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.5.0","text":"Add bru() timing information $bru_timings $bru_iinla$timings Add SpatialPolygonsDataFrame support gg() methods Allow accessing E Ntrials response_data data (special arguments remain added) deltaIC improvements New transformation helper tools bru_{forward/inverse}_transformation() Experimental support matrix formula component inputs. E.g. ~ name(~ -1 + + b + :b, model = \"fixed\"), covariate fixed effect interaction specifications can made. formula input, MatrixModels::model.Matrix() called construct matrix input used -matrix fixed effects, one per column, added form combined effect. Documentation examples improvements","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bug-fixes-2-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"inlabru 2.5.0","text":"Fix -matrix construction evaluate_model() cases inla_f argument matters efficient robust mesh integration code Cleanup environment handling component lists","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-240","dir":"Changelog","previous_headings":"","what":"inlabru 2.4.0","title":"inlabru 2.4.0","text":"CRAN release: 2021-12-19","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"features-2-4-0","dir":"Changelog","previous_headings":"","what":"Features","title":"inlabru 2.4.0","text":"Allow predictors different size input data. data argument now allowed list(), new argument response_data allows separate specification component inputs response variables. Add bru_mapper_collect class handling sequential collections mappers, including collections first mapper hidden INLA::f() arguments n values, needed support e.g. “bym2” models. Add control.family direct argument like(). Gives warning control.family argument supplied options argument bru(), least one likelihood control.family information. (Issue #109)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"bugfixes-2-4-0","dir":"Changelog","previous_headings":"","what":"Bugfixes","title":"inlabru 2.4.0","text":"Fix support SpatialPointsDataFrame SpatialGridDataFrame input bru_fill_missing() Force explicit model = \"offset\" components instead special options, avoid interfering linearisation system (Issue #123) Make iterations robust resetting internal INLA predictor states initial value zero step","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"miscellaneous-2-4-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"inlabru 2.4.0","text":"Rename option bru_method$stop_at_max_rel_deviation bru_method$rel_tol. Automatic conversion new name, warning given. Add option bru_method$max_step control largest allowed line search scaling factor. See ?bru_options New default option bru_compress_cp set TRUE compress predictor expression family=\"cp\" use single element linear predictor sum.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-231","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.1","title":"inlabru 2.3.1","text":"CRAN release: 2021-03-22 Documentation dependency updates CRAN compatibility See NEWS version 2.3.0 major updates since version 2.1.13","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-230","dir":"Changelog","previous_headings":"","what":"inlabru 2.3.0","title":"inlabru 2.3.0","text":"CRAN release: 2021-03-16","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"breaking-changes-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes since version 2.1.13","title":"inlabru 2.3.0","text":"model component argument map deprecated. Use main specify main component input, ~ elev(main = elevation, model = \"rw2\"). Unlike old map argument, main first one, shorter version ~ elev(elevation, model = \"rw2\") also works. Intercept-like components now explicit inputs, e.g. ~ Intercept(1) avoid accidental confusion variables. argument list bru() simplified, arguments except components options must either outputs calls like(), arguments can sent single like() call. option setting system replaced coherent system; see ?bru_options() details. samplers domain system lgcp models now stricter, requires explicit domain definitions point process dimensions. Alternatively, user-defined integration schemes can supplied via ips argument.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"new-features-since-version-2-3-0","dir":"Changelog","previous_headings":"","what":"New features since version 2.1.13","title":"inlabru 2.3.0","text":"model component input arguments main, group, replicate, weights can now take general R expressions using data inputs. Special cases detected: SpatialPixels/GridDataFrame objects evaluated spatial locations input data SpatialPointsDataFrame object. Functions evaluated data object, e.g. field(coordinates, model = spde) component arguments mapper, group_mapper, replicate_mapper can used precise control mapping inputs latent variables. See ?bru_mapper details. Mapper information automatically extracted INLA::inla.spde2.pcmatern() model objects. R-INLA weights copy features now supported. predictor expressions can access data object directly via .data. data several rows can affect output row, allow_combine = TRUE argument must supplied like() include exclude arguments like(), generate(), predict() can used specify components used given likelihood model predictor expression. can used prevent evaluation components invalid likelihood predictor. Predictor expressions can access latent state model component directly, adding suffix _latent component name, e.g. name_latent. like(), requires allow_latent = TRUE activate needed linearisation code . Predictor expressions can evaluate component effects arbitrary inputs adding suffix _eval access special evaluator functions, e.g. name_eval(1:10). useful evaluating 1D effect spatial covariates. See NEWS item version 2.2.8 details. internal system predictor linearisation iterated INLA inference rewritten faster robust See NEWS entries versions 2.1.14 2.2.8 details new features bug fixes","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-228","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.8","title":"inlabru 2.2.8","text":"Add _eval suffix feature generate.bru predict.bru, provides general evaluator function component, allowing evaluation e.g. nonlinear effects spatial covariates function covariate value instead spatial evaluator used component definition. example, components = ~ covar(spatial_grid_df, model = \"rw1\"), prediction expression can ~ covar_eval(covariate), covariate data column prediction data object. components group replicate features, also need provided _eval function, ..._eval(..., group = ..., replicate = ...) feature built top _latent suffix feature, gives direct access latent state variables component, order use _eval model predictor , must use like(..., allow_latent = TRUE) model definition.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-227","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.7","title":"inlabru 2.2.7","text":"Add support ngroup nrep component definitions Updated mexdolphin mrsea data sets, consistent km units improved mesh designs","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-226","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.6","title":"inlabru 2.2.6","text":"Add predict(..., include) discussion distance sampling vignette, handling non-spatial prediction spatial models. Fix bugs gg.SpatialLines","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-225","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.5","title":"inlabru 2.2.5","text":"Vignette corrections Documentation improvements Fix minor bug Spatial* object handling plotting","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-224","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.4","title":"inlabru 2.2.4","text":"Properly extract joint latent conditional mode instead marginal latent conditional mode","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-222","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.2","title":"inlabru 2.2.2","text":"Fixed issue predict() logic converting output Spatial*DataFrame Use control.mode=list(restart=FALSE) final inla run nonlinear models, avoid unnecessary optimisation. Fix issues pixels() bru_fill_missing() Spatial*DataFrame objects ncol=0 data frame parts.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-221","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.1","title":"inlabru 2.2.1","text":"Fixed code regression bug function input covariates","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-220","dir":"Changelog","previous_headings":"","what":"inlabru 2.2.0","title":"inlabru 2.2.0","text":"Support INLA “copy” feature, comp2(input, copy = \"comp1\") Allow component weights unnamed parameter, comp(input, weights, ...) Direct access data objects component inputs predictor expressions, .data., allowing e.g. covar(fun(.data.), ...) complex covariate extractor method fun() Partial support spherical manifold meshes Uses INLA integration strategy “eb” initial nonlinear iterations, specified integration strategy final iteration, computations faster, uses conditional latent mode linearisation point.","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2115","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.15","title":"inlabru 2.1.15","text":"New options system New faster linearisation method New line search method make nonlinear inla iterations robust Method updating old stored estimation objects System supplying mappings latent models evaluated effects via bru_mapper objects Improved factor support; Either “contrast 1st level”, via special \"factor_contrast\" model, levels model \"factor_full\". options planned (e.g. simpler options fix precision parameter). estimated coefficients appear random effects inla() output. Interface restructuring support new features keeping backwards compatibility. Change map= main= unnamed first argument; Since main first parameter, doesn’t need named argument. Keep components zero derivative linearisation PROJ6 support Add random seed option posterior sampling Add package unit testing New backend code make extended feature support easier New int.args option control spatial integration resolution, thanks Martin Jullum (martinju)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2113","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.13","title":"inlabru 2.1.13","text":"CRAN release: 2020-02-16 Fix CRAN complaint regarding documentation","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2112","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.12","title":"inlabru 2.1.12","text":"CRAN release: 2019-06-24 Workaround integration points error old (ca pre-2018) INLA versions","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2111-1","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.11","title":"inlabru 2.1.11","text":"Add CITATION file","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-2110-1","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.10","title":"inlabru 2.1.10","text":"Fix internal sampling bug due INLA changes","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-219","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.9","title":"inlabru 2.1.9","text":"CRAN release: 2018-07-24 Remove unused VignetteBuilder entry DESCRIPTION","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-218","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.8","title":"inlabru 2.1.8","text":"Update default options Prevent int.polygon integrating outside mesh domain, generally robust integration scheme construction. Fix bru() like() parameter logic. (Thanks Peter Vesk bug example)","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-217","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.7","title":"inlabru 2.1.7","text":"Added NEWS.md file track changes package. Added inla methods predict() generate() convert inla output bru objects calling bru prediction posterior sample generator. Added protection examples requiring optional packages Fix sample.lgcp output formatting, extended CRS support, efficient sampling algorithm Avoid dense matrices effect mapping","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-214","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.4","title":"inlabru 2.1.4","text":"iinla() tracks convergence fixed random effects","code":""},{"path":"https://inlabru-org.github.io/inlabru/news/index.html","id":"inlabru-213","dir":"Changelog","previous_headings":"","what":"inlabru 2.1.3","title":"inlabru 2.1.3","text":"CRAN release: 2018-02-11 Added matrix geom gg.matrix() Fixed CRAN test issues","code":""}]
